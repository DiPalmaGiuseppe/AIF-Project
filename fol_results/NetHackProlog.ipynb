{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDLPwb2graDr"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyswip import Prolog\n",
    "from utils import create_level, define_reward, process_state, perform_action, show_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt08TdO1raDr"
   },
   "outputs": [],
   "source": [
    "H = 15\n",
    "W = 15\n",
    "NUM_EPISODES = 100\n",
    "MAX_STEPS = 200\n",
    "MONSTER = ['kobold', 'giant bat']\n",
    "WEAPON = []\n",
    "PATH = 'kb.pl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjuSvDAPraDr"
   },
   "outputs": [],
   "source": [
    "des_file = create_level(width = W, height = H, monsters = MONSTER, weapons = WEAPON, potion = True, armor = False)\n",
    "print(des_file)\n",
    "reward_manager = define_reward(monsters = MONSTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwbgwbwlraDs"
   },
   "outputs": [],
   "source": [
    "env = gym.make('MiniHack-Skill-Custom-v0',\n",
    "               character=\"sam-hum-neu-mal\",\n",
    "               #character=\"bar-hum-neu-mal\",\n",
    "               observation_keys=('screen_descriptions','inv_strs','blstats','message','pixel'),\n",
    "               des_file=des_file,\n",
    "               reward_manager=reward_manager\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GHRtYXrLraDs",
    "outputId": "f440128e-df4c-4e51-a600-4528edb76e0c"
   },
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "X9fiaLFEraDs",
    "outputId": "161d7f5f-96f5-4620-ad67-1c2a19e3360e"
   },
   "outputs": [],
   "source": [
    "plt.imshow(obs['pixel'][20:300, 480:775])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVkpe-GJraDt"
   },
   "source": [
    "Initialize the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6H66hiUPraDt",
    "outputId": "93ab5ba5-6098-48ec-a9de-488a867eec09"
   },
   "outputs": [],
   "source": [
    "KB = Prolog()\n",
    "KB.consult(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-JMaHW2raDt"
   },
   "source": [
    "#### Main code\n",
    "- Perform `NUM_EPISODES` experiences in the environment.\n",
    "- Use `Prolog` to define the axioms and choose the action to perform.\n",
    "- The main goal is to _reach and eat_ the `apple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(0):\n",
    "#     print(f'Action performed: {i} {repr(env.actions[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Fr3ggl4craDu",
    "outputId": "ec445959-25fa-4e08-edf8-ef716c4b9ced"
   },
   "outputs": [],
   "source": [
    "rewards = [] \n",
    "step = []\n",
    "step_win = []\n",
    "wins = 0\n",
    "for episode in range(NUM_EPISODES):\n",
    "    # count the number of steps of the current episode\n",
    "    steps = 0\n",
    "    # store the cumulative reward\n",
    "    reward = 0.0\n",
    "    # collect obs['pixel'] to visualize\n",
    "    ep_states = []\n",
    "\n",
    "    obs = env.reset()\n",
    "    ep_states.append(obs['pixel'])\n",
    "    done = False\n",
    "\n",
    "    # Main loop\n",
    "    while not done and steps < MAX_STEPS:\n",
    "        # Get the observation from the env and assert the facts in the kb\n",
    "        process_state(obs, KB, MONSTER)\n",
    "        # Query Prolog\n",
    "        # Run the inference and get the action to perform\n",
    "        # Get the first answer from Prolog -> the top-priority action\n",
    "        try:\n",
    "            action = list(KB.query('action(X)'))[0]\n",
    "            action = action['X']\n",
    "            # print(\"ACTION: \", action)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            action = None\n",
    "\n",
    "        # Perform the action in the environment\n",
    "        if action:\n",
    "            # print(f\"Action from kb: {action}\")\n",
    "            obs, rwd, done, info = perform_action(action, env, KB)\n",
    "            message = bytes(obs['message']).decode('utf-8').rstrip('\\x00')\n",
    "            # print(message)\n",
    "            reward += rwd\n",
    "            ep_states.append(obs['pixel'])\n",
    "            # env.render()\n",
    "        else:\n",
    "            print(\"ERROR: No action can be performed\")\n",
    "            break\n",
    "\n",
    "        steps += 1\n",
    "        step.append(steps)\n",
    "    \n",
    "    if info[\"end_status\"].name == \"TASK_SUCCESSFUL\":\n",
    "        wins += 1\n",
    "        step_win.append(steps)\n",
    "\n",
    "    # Display game with interface\n",
    "    show_match(ep_states)\n",
    "    # Print information about the ended episode\n",
    "    print(f'Episode {episode + 1} - {steps} steps')\n",
    "    print(f'End status: {info[\"end_status\"].name}')\n",
    "    print(f'Final reward: {reward}')\n",
    "\n",
    "    rewards.append(reward)\n",
    "\n",
    "    # reset the environment and retract axioms that may cause errors\n",
    "    obs = env.reset()\n",
    "    KB = Prolog()\n",
    "    KB.consult(PATH)\n",
    "\n",
    "    # time.sleep(1)\n",
    "\n",
    "\n",
    "print(f'After {NUM_EPISODES} episodes, mean return is {sum(rewards)/NUM_EPISODES}')\n",
    "print(f'and the total number of winning episodes is {wins}')\n",
    "print(f'the mean number of step per episode is {sum(step)/len(step)}')\n",
    "print(f'the mean number of step per winning epidose is {sum(step_win)/len(step_win)}')\n",
    "print(\"The rewards of the episodes are:\", rewards)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
