[[36m2025-01-17 21:02:08,943[0m][[34mroot[0m][[32mINFO[0m] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
[0m
[[36m2025-01-17 21:02:08,995[0m][[34mroot[0m][[32mINFO[0m] - Symlinked log directory: /opt/minihack/latest[0m
[[36m2025-01-17 21:02:08,996[0m][[34mroot[0m][[32mINFO[0m] - Found archive directory: /opt/minihack/archives[0m
[[36m2025-01-17 21:02:09,000[0m][[34mroot[0m][[32mINFO[0m] - Logging results to /opt/minihack[0m
[[36m2025-01-17 21:02:09,055[0m][[34mpalaas/out[0m][[32mINFO[0m] - Found log directory: /opt/minihack[0m
[[36m2025-01-17 21:02:09,055[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving arguments to /opt/minihack/meta.json[0m
[[36m2025-01-17 21:02:09,056[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving messages to /opt/minihack/out.log[0m
[[36m2025-01-17 21:02:09,056[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs data to /opt/minihack/logs.csv[0m
[[36m2025-01-17 21:02:09,056[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs' fields to /opt/minihack/fields.csv[0m
[[36m2025-01-17 21:02:09,057[0m][[34mroot[0m][[32mINFO[0m] - Not using CUDA.[0m
[[36m2025-01-17 21:02:09,070[0m][[34mroot[0m][[32mINFO[0m] - Using model baseline[0m
{'staircase': <class 'nle.env.tasks.NetHackStaircase'>, 'score': <class 'nle.env.tasks.NetHackScore'>, 'pet': <class 'nle.env.tasks.NetHackStaircasePet'>, 'oracle': <class 'nle.env.tasks.NetHackOracle'>, 'gold': <class 'nle.env.tasks.NetHackGold'>, 'eat': <class 'nle.env.tasks.NetHackEat'>, 'scout': <class 'nle.env.tasks.NetHackScout'>, 'small_room': <class 'minihack.envs.room.MiniHackRoom5x5'>, 'small_room_random': <class 'minihack.envs.room.MiniHackRoom5x5Random'>, 'small_room_dark': <class 'minihack.envs.room.MiniHackRoom5x5Dark'>, 'small_room_monster': <class 'minihack.envs.room.MiniHackRoom5x5Monster'>, 'small_room_trap': <class 'minihack.envs.room.MiniHackRoom5x5Trap'>, 'small_room_ultimate': <class 'minihack.envs.room.MiniHackRoom5x5Ultimate'>, 'big_room': <class 'minihack.envs.room.MiniHackRoom15x15'>, 'big_room_random': <class 'minihack.envs.room.MiniHackRoom15x15Random'>, 'big_room_dark': <class 'minihack.envs.room.MiniHackRoom15x15Dark'>, 'big_room_monster': <class 'minihack.envs.room.MiniHackRoom15x15Monster'>, 'big_room_trap': <class 'minihack.envs.room.MiniHackRoom15x15Trap'>, 'big_room_ultimate': <class 'minihack.envs.room.MiniHackRoom15x15Ultimate'>, 'corridor2': <class 'minihack.envs.corridor.MiniHackCorridor2'>, 'corridor3': <class 'minihack.envs.corridor.MiniHackCorridor3'>, 'corridor5': <class 'minihack.envs.corridor.MiniHackCorridor5'>, 'keyroom_small_fixed': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Fixed'>, 'keyroom_small': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5'>, 'keyroom_small_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Dark'>, 'keyroom_big': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15'>, 'keyroom_big_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15Dark'>, 'mazewalk_small': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9'>, 'mazewalk_small_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9Premapped'>, 'mazewalk_big': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15'>, 'mazewalk_big_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15Premapped'>, 'mazewalk_huge': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19'>, 'mazewalk_huge_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19Premapped'>, 'fight_corridor': <class 'minihack.envs.fightcorridor.MiniHackFightCorridor'>, 'fight_corridor_dark': <class 'minihack.envs.fightcorridor.MiniHackFightCorridorDark'>, 'river': <class 'minihack.envs.river.MiniHackRiver'>, 'river_lava': <class 'minihack.envs.river.MiniHackRiverLava'>, 'river_monster': <class 'minihack.envs.river.MiniHackRiverMonster'>, 'river_monsterlava': <class 'minihack.envs.river.MiniHackRiverMonsterLava'>, 'river_narrow': <class 'minihack.envs.river.MiniHackRiverNarrow'>, 'memento_short': <class 'minihack.envs.memento.MiniHackMementoShortF2'>, 'memento': <class 'minihack.envs.memento.MiniHackMementoF2'>, 'memento_hard': <class 'minihack.envs.memento.MiniHackMementoF4'>, 'hidenseek': <class 'minihack.envs.hidenseek.MiniHackHideAndSeek'>, 'hidenseek_mapped': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekMapped'>, 'hidenseek_lava': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekLava'>, 'hidenseek_big': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekBig'>, 'explore_easy': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasy'>, 'explore_easy_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasyMapped'>, 'explore_hard': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHard'>, 'explore_hard_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHardMapped'>, 'multiroom_2': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2'>, 'multiroom_4': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4'>, 'multiroom_6': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6'>, 'multiroom_2_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Locked'>, 'multiroom_4_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Locked'>, 'multiroom_6_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Locked'>, 'multiroom_2_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Lava'>, 'multiroom_4_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Lava'>, 'multiroom_6_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Lava'>, 'multiroom_2_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Monster'>, 'multiroom_4_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Monster'>, 'multiroom_6_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Monster'>, 'multiroom_2_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Extreme'>, 'multiroom_4_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Extreme'>, 'multiroom_6_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Extreme'>, 'boxoban_unfiltered': <class 'minihack.envs.boxohack.MiniHackBoxobanUnfiltered'>, 'boxoban_hard': <class 'minihack.envs.boxohack.MiniHackBoxobanHard'>, 'boxoban_medium': <class 'minihack.envs.boxohack.MiniHackBoxobanMedium'>, 'mini_eat': <class 'minihack.envs.skills_simple.MiniHackEat'>, 'mini_pray': <class 'minihack.envs.skills_simple.MiniHackPray'>, 'mini_sink': <class 'minihack.envs.skills_simple.MiniHackSink'>, 'mini_read': <class 'minihack.envs.skills_simple.MiniHackRead'>, 'mini_zap': <class 'minihack.envs.skills_simple.MiniHackZap'>, 'mini_puton': <class 'minihack.envs.skills_simple.MiniHackPutOn'>, 'mini_wear': <class 'minihack.envs.skills_simple.MiniHackWear'>, 'mini_wield': <class 'minihack.envs.skills_simple.MiniHackWield'>, 'mini_locked': <class 'minihack.envs.skills_simple.MiniHackLockedDoor'>, 'mini_eat_fixed': <class 'minihack.envs.skills_simple.MiniHackEatFixed'>, 'mini_pray_fixed': <class 'minihack.envs.skills_simple.MiniHackPrayFixed'>, 'mini_sink_fixed': <class 'minihack.envs.skills_simple.MiniHackSinkFixed'>, 'mini_read_fixed': <class 'minihack.envs.skills_simple.MiniHackReadFixed'>, 'mini_zap_fixed': <class 'minihack.envs.skills_simple.MiniHackZapFixed'>, 'mini_puton_fixed': <class 'minihack.envs.skills_simple.MiniHackPutOnFixed'>, 'mini_wear_fixed': <class 'minihack.envs.skills_simple.MiniHackWearFixed'>, 'mini_wield_fixed': <class 'minihack.envs.skills_simple.MiniHackWieldFixed'>, 'mini_locked_fixed': <class 'minihack.envs.skills_simple.MiniHackLockedDoorFixed'>, 'mini_eat_distr': <class 'minihack.envs.skills_simple.MiniHackEatDistr'>, 'mini_pray_distr': <class 'minihack.envs.skills_simple.MiniHackPrayDistr'>, 'mini_sink_distr': <class 'minihack.envs.skills_simple.MiniHackSinkDistr'>, 'mini_read_distr': <class 'minihack.envs.skills_simple.MiniHackReadDistr'>, 'mini_zap_distr': <class 'minihack.envs.skills_simple.MiniHackZapDistr'>, 'mini_puton_distr': <class 'minihack.envs.skills_simple.MiniHackPutOnDistr'>, 'mini_wear_distr': <class 'minihack.envs.skills_simple.MiniHackWearDistr'>, 'mini_wield_distr': <class 'minihack.envs.skills_simple.MiniHackWieldDistr'>, 'wod_easy': <class 'minihack.envs.skills_wod.MiniHackWoDEasy'>, 'wod_medium': <class 'minihack.envs.skills_wod.MiniHackWoDMedium'>, 'wod_hard': <class 'minihack.envs.skills_wod.MiniHackWoDHard'>, 'wod_pro': <class 'minihack.envs.skills_wod.MiniHackWoDPro'>, 'lava': <class 'minihack.envs.skills_lava.MiniHackLC'>, 'lava_lev': <class 'minihack.envs.skills_lava.MiniHackLCLevitate'>, 'lava_lev_potion_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionInv'>, 'lava_lev_potion_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionPickup'>, 'lava_lev_ring_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingInv'>, 'lava_lev_ring_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingPickup'>, 'quest_easy': <class 'minihack.envs.skills_quest.MiniHackQuestEasy'>, 'quest_medium': <class 'minihack.envs.skills_quest.MiniHackQuestMedium'>, 'quest_hard': <class 'minihack.envs.skills_quest.MiniHackQuestHard'>, 'custom_skills': <class 'minihack.envs.custom_skills_combat.MiniHackCombatSkill'>}
custom_skills
[[36m2025-01-17 21:02:09,071[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
(<CompassDirection.N: 107>, <CompassDirection.E: 108>, <CompassDirection.S: 106>, <CompassDirection.W: 104>, <CompassDirection.NE: 117>, <CompassDirection.SE: 110>, <CompassDirection.SW: 98>, <CompassDirection.NW: 121>, <CompassDirectionLonger.N: 75>, <CompassDirectionLonger.E: 76>, <CompassDirectionLonger.S: 74>, <CompassDirectionLonger.W: 72>, <CompassDirectionLonger.NE: 85>, <CompassDirectionLonger.SE: 78>, <CompassDirectionLonger.SW: 66>, <CompassDirectionLonger.NW: 89>, <MiscDirection.DOWN: 62>, <MiscDirection.WAIT: 46>, <MiscAction.MORE: 13>, <Command.ADJUST: 225>, <Command.APPLY: 97>, <Command.ATTRIBUTES: 24>, <Command.CALL: 67>, <Command.CAST: 90>, <Command.CHAT: 227>, <Command.CLOSE: 99>, <Command.DIP: 228>, <Command.DROP: 100>, <Command.DROPTYPE: 68>, <Command.EAT: 101>, <Command.ENGRAVE: 69>, <Command.ENHANCE: 229>, <Command.ESC: 27>, <Command.FIGHT: 70>, <Command.FIRE: 102>, <Command.FORCE: 230>, <Command.INVENTORY: 105>, <Command.INVENTTYPE: 73>, <Command.INVOKE: 233>, <Command.JUMP: 234>, <Command.KICK: 4>, <Command.LOOK: 58>, <Command.LOOT: 236>, <Command.MONSTER: 237>, <Command.MOVE: 109>, <Command.MOVEFAR: 77>, <Command.OFFER: 239>, <Command.OPEN: 111>, <Command.PAY: 112>, <Command.PICKUP: 44>, <Command.PRAY: 240>, <Command.PUTON: 80>, <Command.QUAFF: 113>, <Command.QUIVER: 81>, <Command.READ: 114>, <Command.REMOVE: 82>, <Command.RIDE: 210>, <Command.RUB: 242>, <Command.RUSH: 103>, <Command.RUSH2: 71>, <Command.SEARCH: 115>, <Command.SEEARMOR: 91>, <Command.SEERINGS: 61>, <Command.SEETOOLS: 40>, <Command.SEETRAP: 94>, <Command.SEEWEAPON: 41>, <Command.SHELL: 33>, <Command.SIT: 243>, <Command.SWAP: 120>, <Command.TAKEOFF: 84>, <Command.TAKEOFFALL: 65>, <Command.THROW: 116>, <Command.TIP: 212>, <Command.TURN: 244>, <Command.TWOWEAPON: 88>, <Command.UNTRAP: 245>, <Command.VERSIONSHORT: 118>, <Command.WEAR: 87>, <Command.WIELD: 119>, <Command.WIPE: 247>, <Command.ZAP: 122>, <TextCharacters.PLUS: 43>, <TextCharacters.QUOTE: 34>, <TextCharacters.DOLLAR: 36>, <TextCharacters.SPACE: 32>)
[[36m2025-01-17 21:02:09,099[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,162[0m][[34mroot[0m][[32mINFO[0m] - Number of model parameters: 4264078[0m
{'staircase': <class 'nle.env.tasks.NetHackStaircase'>, 'score': <class 'nle.env.tasks.NetHackScore'>, 'pet': <class 'nle.env.tasks.NetHackStaircasePet'>, 'oracle': <class 'nle.env.tasks.NetHackOracle'>, 'gold': <class 'nle.env.tasks.NetHackGold'>, 'eat': <class 'nle.env.tasks.NetHackEat'>, 'scout': <class 'nle.env.tasks.NetHackScout'>, 'small_room': <class 'minihack.envs.room.MiniHackRoom5x5'>, 'small_room_random': <class 'minihack.envs.room.MiniHackRoom5x5Random'>, 'small_room_dark': <class 'minihack.envs.room.MiniHackRoom5x5Dark'>, 'small_room_monster': <class 'minihack.envs.room.MiniHackRoom5x5Monster'>, 'small_room_trap': <class 'minihack.envs.room.MiniHackRoom5x5Trap'>, 'small_room_ultimate': <class 'minihack.envs.room.MiniHackRoom5x5Ultimate'>, 'big_room': <class 'minihack.envs.room.MiniHackRoom15x15'>, 'big_room_random': <class 'minihack.envs.room.MiniHackRoom15x15Random'>, 'big_room_dark': <class 'minihack.envs.room.MiniHackRoom15x15Dark'>, 'big_room_monster': <class 'minihack.envs.room.MiniHackRoom15x15Monster'>, 'big_room_trap': <class 'minihack.envs.room.MiniHackRoom15x15Trap'>, 'big_room_ultimate': <class 'minihack.envs.room.MiniHackRoom15x15Ultimate'>, 'corridor2': <class 'minihack.envs.corridor.MiniHackCorridor2'>, 'corridor3': <class 'minihack.envs.corridor.MiniHackCorridor3'>, 'corridor5': <class 'minihack.envs.corridor.MiniHackCorridor5'>, 'keyroom_small_fixed': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Fixed'>, 'keyroom_small': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5'>, 'keyroom_small_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Dark'>, 'keyroom_big': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15'>, 'keyroom_big_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15Dark'>, 'mazewalk_small': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9'>, 'mazewalk_small_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9Premapped'>, 'mazewalk_big': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15'>, 'mazewalk_big_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15Premapped'>, 'mazewalk_huge': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19'>, 'mazewalk_huge_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19Premapped'>, 'fight_corridor': <class 'minihack.envs.fightcorridor.MiniHackFightCorridor'>, 'fight_corridor_dark': <class 'minihack.envs.fightcorridor.MiniHackFightCorridorDark'>, 'river': <class 'minihack.envs.river.MiniHackRiver'>, 'river_lava': <class 'minihack.envs.river.MiniHackRiverLava'>, 'river_monster': <class 'minihack.envs.river.MiniHackRiverMonster'>, 'river_monsterlava': <class 'minihack.envs.river.MiniHackRiverMonsterLava'>, 'river_narrow': <class 'minihack.envs.river.MiniHackRiverNarrow'>, 'memento_short': <class 'minihack.envs.memento.MiniHackMementoShortF2'>, 'memento': <class 'minihack.envs.memento.MiniHackMementoF2'>, 'memento_hard': <class 'minihack.envs.memento.MiniHackMementoF4'>, 'hidenseek': <class 'minihack.envs.hidenseek.MiniHackHideAndSeek'>, 'hidenseek_mapped': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekMapped'>, 'hidenseek_lava': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekLava'>, 'hidenseek_big': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekBig'>, 'explore_easy': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasy'>, 'explore_easy_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasyMapped'>, 'explore_hard': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHard'>, 'explore_hard_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHardMapped'>, 'multiroom_2': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2'>, 'multiroom_4': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4'>, 'multiroom_6': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6'>, 'multiroom_2_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Locked'>, 'multiroom_4_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Locked'>, 'multiroom_6_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Locked'>, 'multiroom_2_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Lava'>, 'multiroom_4_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Lava'>, 'multiroom_6_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Lava'>, 'multiroom_2_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Monster'>, 'multiroom_4_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Monster'>, 'multiroom_6_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Monster'>, 'multiroom_2_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Extreme'>, 'multiroom_4_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Extreme'>, 'multiroom_6_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Extreme'>, 'boxoban_unfiltered': <class 'minihack.envs.boxohack.MiniHackBoxobanUnfiltered'>, 'boxoban_hard': <class 'minihack.envs.boxohack.MiniHackBoxobanHard'>, 'boxoban_medium': <class 'minihack.envs.boxohack.MiniHackBoxobanMedium'>, 'mini_eat': <class 'minihack.envs.skills_simple.MiniHackEat'>, 'mini_pray': <class 'minihack.envs.skills_simple.MiniHackPray'>, 'mini_sink': <class 'minihack.envs.skills_simple.MiniHackSink'>, 'mini_read': <class 'minihack.envs.skills_simple.MiniHackRead'>, 'mini_zap': <class 'minihack.envs.skills_simple.MiniHackZap'>, 'mini_puton': <class 'minihack.envs.skills_simple.MiniHackPutOn'>, 'mini_wear': <class 'minihack.envs.skills_simple.MiniHackWear'>, 'mini_wield': <class 'minihack.envs.skills_simple.MiniHackWield'>, 'mini_locked': <class 'minihack.envs.skills_simple.MiniHackLockedDoor'>, 'mini_eat_fixed': <class 'minihack.envs.skills_simple.MiniHackEatFixed'>, 'mini_pray_fixed': <class 'minihack.envs.skills_simple.MiniHackPrayFixed'>, 'mini_sink_fixed': <class 'minihack.envs.skills_simple.MiniHackSinkFixed'>, 'mini_read_fixed': <class 'minihack.envs.skills_simple.MiniHackReadFixed'>, 'mini_zap_fixed': <class 'minihack.envs.skills_simple.MiniHackZapFixed'>, 'mini_puton_fixed': <class 'minihack.envs.skills_simple.MiniHackPutOnFixed'>, 'mini_wear_fixed': <class 'minihack.envs.skills_simple.MiniHackWearFixed'>, 'mini_wield_fixed': <class 'minihack.envs.skills_simple.MiniHackWieldFixed'>, 'mini_locked_fixed': <class 'minihack.envs.skills_simple.MiniHackLockedDoorFixed'>, 'mini_eat_distr': <class 'minihack.envs.skills_simple.MiniHackEatDistr'>, 'mini_pray_distr': <class 'minihack.envs.skills_simple.MiniHackPrayDistr'>, 'mini_sink_distr': <class 'minihack.envs.skills_simple.MiniHackSinkDistr'>, 'mini_read_distr': <class 'minihack.envs.skills_simple.MiniHackReadDistr'>, 'mini_zap_distr': <class 'minihack.envs.skills_simple.MiniHackZapDistr'>, 'mini_puton_distr': <class 'minihack.envs.skills_simple.MiniHackPutOnDistr'>, 'mini_wear_distr': <class 'minihack.envs.skills_simple.MiniHackWearDistr'>, 'mini_wield_distr': <class 'minihack.envs.skills_simple.MiniHackWieldDistr'>, 'wod_easy': <class 'minihack.envs.skills_wod.MiniHackWoDEasy'>, 'wod_medium': <class 'minihack.envs.skills_wod.MiniHackWoDMedium'>, 'wod_hard': <class 'minihack.envs.skills_wod.MiniHackWoDHard'>, 'wod_pro': <class 'minihack.envs.skills_wod.MiniHackWoDPro'>, 'lava': <class 'minihack.envs.skills_lava.MiniHackLC'>, 'lava_lev': <class 'minihack.envs.skills_lava.MiniHackLCLevitate'>, 'lava_lev_potion_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionInv'>, 'lava_lev_potion_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionPickup'>, 'lava_lev_ring_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingInv'>, 'lava_lev_ring_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingPickup'>, 'quest_easy': <class 'minihack.envs.skills_quest.MiniHackQuestEasy'>, 'quest_medium': <class 'minihack.envs.skills_quest.MiniHackQuestMedium'>, 'quest_hard': <class 'minihack.envs.skills_quest.MiniHackQuestHard'>, 'custom_skills': <class 'minihack.envs.custom_skills_combat.MiniHackCombatSkill'>}
custom_skills
[[36m2025-01-17 21:02:09,163[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
(<CompassDirection.N: 107>, <CompassDirection.E: 108>, <CompassDirection.S: 106>, <CompassDirection.W: 104>, <CompassDirection.NE: 117>, <CompassDirection.SE: 110>, <CompassDirection.SW: 98>, <CompassDirection.NW: 121>, <CompassDirectionLonger.N: 75>, <CompassDirectionLonger.E: 76>, <CompassDirectionLonger.S: 74>, <CompassDirectionLonger.W: 72>, <CompassDirectionLonger.NE: 85>, <CompassDirectionLonger.SE: 78>, <CompassDirectionLonger.SW: 66>, <CompassDirectionLonger.NW: 89>, <MiscDirection.DOWN: 62>, <MiscDirection.WAIT: 46>, <MiscAction.MORE: 13>, <Command.ADJUST: 225>, <Command.APPLY: 97>, <Command.ATTRIBUTES: 24>, <Command.CALL: 67>, <Command.CAST: 90>, <Command.CHAT: 227>, <Command.CLOSE: 99>, <Command.DIP: 228>, <Command.DROP: 100>, <Command.DROPTYPE: 68>, <Command.EAT: 101>, <Command.ENGRAVE: 69>, <Command.ENHANCE: 229>, <Command.ESC: 27>, <Command.FIGHT: 70>, <Command.FIRE: 102>, <Command.FORCE: 230>, <Command.INVENTORY: 105>, <Command.INVENTTYPE: 73>, <Command.INVOKE: 233>, <Command.JUMP: 234>, <Command.KICK: 4>, <Command.LOOK: 58>, <Command.LOOT: 236>, <Command.MONSTER: 237>, <Command.MOVE: 109>, <Command.MOVEFAR: 77>, <Command.OFFER: 239>, <Command.OPEN: 111>, <Command.PAY: 112>, <Command.PICKUP: 44>, <Command.PRAY: 240>, <Command.PUTON: 80>, <Command.QUAFF: 113>, <Command.QUIVER: 81>, <Command.READ: 114>, <Command.REMOVE: 82>, <Command.RIDE: 210>, <Command.RUB: 242>, <Command.RUSH: 103>, <Command.RUSH2: 71>, <Command.SEARCH: 115>, <Command.SEEARMOR: 91>, <Command.SEERINGS: 61>, <Command.SEETOOLS: 40>, <Command.SEETRAP: 94>, <Command.SEEWEAPON: 41>, <Command.SHELL: 33>, <Command.SIT: 243>, <Command.SWAP: 120>, <Command.TAKEOFF: 84>, <Command.TAKEOFFALL: 65>, <Command.THROW: 116>, <Command.TIP: 212>, <Command.TURN: 244>, <Command.TWOWEAPON: 88>, <Command.UNTRAP: 245>, <Command.VERSIONSHORT: 118>, <Command.WEAR: 87>, <Command.WIELD: 119>, <Command.WIPE: 247>, <Command.ZAP: 122>, <TextCharacters.PLUS: 43>, <TextCharacters.QUOTE: 34>, <TextCharacters.DOLLAR: 36>, <TextCharacters.SPACE: 32>)
[[36m2025-01-17 21:02:09,184[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,241[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,243[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,243[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,243[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,245[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,248[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,248[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,248[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,249[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,249[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,250[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,247[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,244[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,252[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,252[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,254[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,255[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,255[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,261[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,261[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,261[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,261[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,262[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,263[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,253[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,265[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,265[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,265[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,265[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,265[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,261[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,269[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,271[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,268[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,272[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,266[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,268[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,276[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,274[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
First Environment waiting for connection to unix:/tmp/poly..opt.minihack.0 ... connection established.
[[36m2025-01-17 21:02:09,281[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,281[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,282[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,285[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,287[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,286[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,285[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,273[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,288[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,286[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,287[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,290[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,292[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,293[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,294[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,289[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,296[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,291[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,293[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,294[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,295[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,302[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,298[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,309[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:09,307[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:02:14,240[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 43. Learner queue size: 0. Other stats: (train_seconds = 5.0)[0m
[[36m2025-01-17 21:02:22,781[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (train_seconds = 13.5)[0m
[[36m2025-01-17 21:02:27,784[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 60. Learner queue size: 32. Other stats: (train_seconds = 18.5)[0m
[[36m2025-01-17 21:02:32,819[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (train_seconds = 23.6)[0m
[[36m2025-01-17 21:02:37,824[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (train_seconds = 28.6)[0m
[[36m2025-01-17 21:02:42,830[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (train_seconds = 33.6)[0m
[[36m2025-01-17 21:02:44,483[0m][[34mpalaas/out[0m][[32mINFO[0m] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size'][0m
[[36m2025-01-17 21:02:47,836[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.tar[0m
[[36m2025-01-17 21:02:47,893[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 511.4 SPS. Inference batcher size: 61. Learner queue size: 32. Other stats: (train_seconds = 38.6, step = 2560, mean_episode_return = -0.026687, mean_episode_step = 31.829, total_loss = -1578.0, entropy_loss = -11.371, pg_loss = -1803.2, baseline_loss = 236.53, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:02:52,899[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (train_seconds = 43.7, step = 2560, mean_episode_return = -0.026687, mean_episode_step = 31.829, total_loss = -1578.0, entropy_loss = -11.371, pg_loss = -1803.2, baseline_loss = 236.53, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:02:57,904[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 68. Learner queue size: 32. Other stats: (train_seconds = 48.7, step = 2560, mean_episode_return = -0.026687, mean_episode_step = 31.829, total_loss = -1578.0, entropy_loss = -11.371, pg_loss = -1803.2, baseline_loss = 236.53, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:02,915[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 510.9 SPS. Inference batcher size: 111. Learner queue size: 32. Other stats: (train_seconds = 53.7, step = 5120, mean_episode_return = -0.037706, mean_episode_step = 36.22, total_loss = 530.27, entropy_loss = -11.366, pg_loss = 313.0, baseline_loss = 228.64, learner_queue_size = 32, _tick = 1, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:07,920[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 44. Learner queue size: 32. Other stats: (train_seconds = 58.7, step = 5120, mean_episode_return = -0.037706, mean_episode_step = 36.22, total_loss = 530.27, entropy_loss = -11.366, pg_loss = 313.0, baseline_loss = 228.64, learner_queue_size = 32, _tick = 1, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:12,951[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 508.9 SPS. Inference batcher size: 48. Learner queue size: 32. Other stats: (train_seconds = 63.7, step = 7680, mean_episode_return = -0.053148, mean_episode_step = 56.984, total_loss = 868.68, entropy_loss = -11.368, pg_loss = 615.03, baseline_loss = 265.01, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:17,956[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 0.0 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 68.7, step = 7680, mean_episode_return = -0.053148, mean_episode_step = 56.984, total_loss = 868.68, entropy_loss = -11.368, pg_loss = 615.03, baseline_loss = 265.01, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:22,961[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 0.0 SPS. Inference batcher size: 59. Learner queue size: 32. Other stats: (train_seconds = 73.7, step = 7680, mean_episode_return = -0.053148, mean_episode_step = 56.984, total_loss = 868.68, entropy_loss = -11.368, pg_loss = 615.03, baseline_loss = 265.01, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:27,966[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 78.7, step = 10240, mean_episode_return = -0.036394, mean_episode_step = 57.641, total_loss = -1077.9, entropy_loss = -11.32, pg_loss = -1158.5, baseline_loss = 91.943, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:32,971[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 83.7, step = 10240, mean_episode_return = -0.036394, mean_episode_step = 57.641, total_loss = -1077.9, entropy_loss = -11.32, pg_loss = -1158.5, baseline_loss = 91.943, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:37,976[0m][[34mroot[0m][[32mINFO[0m] - Step 12800 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 88.7, step = 12800, mean_episode_return = -0.056174, mean_episode_step = 49.706, total_loss = -325.34, entropy_loss = -11.33, pg_loss = -316.38, baseline_loss = 2.3657, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:42,982[0m][[34mroot[0m][[32mINFO[0m] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 93.7, step = 12800, mean_episode_return = -0.056174, mean_episode_step = 49.706, total_loss = -325.34, entropy_loss = -11.33, pg_loss = -316.38, baseline_loss = 2.3657, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:47,989[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 511.3 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 98.8, step = 15360, mean_episode_return = 0.053083, mean_episode_step = 36.218, total_loss = 289.34, entropy_loss = -11.26, pg_loss = 238.29, baseline_loss = 62.319, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:52,995[0m][[34mroot[0m][[32mINFO[0m] - Step 17920 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 103.8, step = 17920, mean_episode_return = -0.01384, mean_episode_step = 45.311, total_loss = 645.63, entropy_loss = -11.294, pg_loss = 578.29, baseline_loss = 78.634, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:03:58,000[0m][[34mroot[0m][[32mINFO[0m] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 108.8, step = 17920, mean_episode_return = -0.01384, mean_episode_step = 45.311, total_loss = 645.63, entropy_loss = -11.294, pg_loss = 578.29, baseline_loss = 78.634, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:03,005[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 113.8, step = 20480, mean_episode_return = -0.08775, mean_episode_step = 58.722, total_loss = -41.304, entropy_loss = -11.291, pg_loss = -113.06, baseline_loss = 83.052, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:08,015[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 118.8, step = 20480, mean_episode_return = -0.08775, mean_episode_step = 58.722, total_loss = -41.304, entropy_loss = -11.291, pg_loss = -113.06, baseline_loss = 83.052, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:13,020[0m][[34mroot[0m][[32mINFO[0m] - Step 23040 @ 511.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 123.8, step = 23040, mean_episode_return = 0.0415, mean_episode_step = 69.068, total_loss = 114.12, entropy_loss = -11.273, pg_loss = 70.09, baseline_loss = 55.303, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:18,025[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 128.8, step = 25600, mean_episode_return = -0.029571, mean_episode_step = 62.304, total_loss = -328.26, entropy_loss = -11.218, pg_loss = -317.9, baseline_loss = 0.85438, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:23,031[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 133.8, step = 25600, mean_episode_return = -0.029571, mean_episode_step = 62.304, total_loss = -328.26, entropy_loss = -11.218, pg_loss = -317.9, baseline_loss = 0.85438, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:28,037[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 138.8, step = 28160, mean_episode_return = -0.083067, mean_episode_step = 58.375, total_loss = 242.93, entropy_loss = -11.209, pg_loss = 230.95, baseline_loss = 23.192, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:33,043[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 143.8, step = 28160, mean_episode_return = -0.083067, mean_episode_step = 58.375, total_loss = 242.93, entropy_loss = -11.209, pg_loss = 230.95, baseline_loss = 23.192, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:38,048[0m][[34mroot[0m][[32mINFO[0m] - Step 30720 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 148.8, step = 30720, mean_episode_return = -0.033423, mean_episode_step = 56.188, total_loss = -282.45, entropy_loss = -11.213, pg_loss = -272.91, baseline_loss = 1.6651, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:43,054[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 153.8, step = 33280, mean_episode_return = -0.021935, mean_episode_step = 46.419, total_loss = 427.33, entropy_loss = -11.195, pg_loss = 398.4, baseline_loss = 40.119, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:48,055[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 158.8, step = 33280, mean_episode_return = -0.021935, mean_episode_step = 46.419, total_loss = 427.33, entropy_loss = -11.195, pg_loss = 398.4, baseline_loss = 40.119, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:53,060[0m][[34mroot[0m][[32mINFO[0m] - Step 35840 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 163.8, step = 35840, mean_episode_return = -0.0088788, mean_episode_step = 58.561, total_loss = 222.42, entropy_loss = -11.205, pg_loss = 157.31, baseline_loss = 76.315, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:04:58,066[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 168.8, step = 38400, mean_episode_return = 0.063483, mean_episode_step = 61.868, total_loss = 384.98, entropy_loss = -11.16, pg_loss = 245.32, baseline_loss = 150.82, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:03,072[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 173.8, step = 38400, mean_episode_return = 0.063483, mean_episode_step = 61.868, total_loss = 384.98, entropy_loss = -11.16, pg_loss = 245.32, baseline_loss = 150.82, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:08,078[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 178.8, step = 40960, mean_episode_return = -0.074706, mean_episode_step = 58.393, total_loss = -635.0, entropy_loss = -11.157, pg_loss = -627.11, baseline_loss = 3.2677, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:13,083[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 183.8, step = 40960, mean_episode_return = -0.074706, mean_episode_step = 58.393, total_loss = -635.0, entropy_loss = -11.157, pg_loss = -627.11, baseline_loss = 3.2677, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:18,088[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 188.9, step = 43520, mean_episode_return = -0.031043, mean_episode_step = 54.763, total_loss = 517.7, entropy_loss = -11.158, pg_loss = 382.4, baseline_loss = 146.46, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:23,093[0m][[34mroot[0m][[32mINFO[0m] - Step 46080 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 193.9, step = 46080, mean_episode_return = -0.010189, mean_episode_step = 59.207, total_loss = 275.84, entropy_loss = -11.131, pg_loss = 112.46, baseline_loss = 174.51, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:28,098[0m][[34mroot[0m][[32mINFO[0m] - Step 46080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 198.9, step = 46080, mean_episode_return = -0.010189, mean_episode_step = 59.207, total_loss = 275.84, entropy_loss = -11.131, pg_loss = 112.46, baseline_loss = 174.51, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:33,103[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 203.9, step = 48640, mean_episode_return = -0.084647, mean_episode_step = 59.542, total_loss = 123.25, entropy_loss = -11.056, pg_loss = -29.859, baseline_loss = 164.17, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:38,109[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 208.9, step = 51200, mean_episode_return = 0.00021214, mean_episode_step = 62.049, total_loss = -316.32, entropy_loss = -10.928, pg_loss = -332.02, baseline_loss = 26.63, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:43,114[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 213.9, step = 51200, mean_episode_return = 0.00021214, mean_episode_step = 62.049, total_loss = -316.32, entropy_loss = -10.928, pg_loss = -332.02, baseline_loss = 26.63, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:48,119[0m][[34mroot[0m][[32mINFO[0m] - Step 53760 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 218.9, step = 53760, mean_episode_return = -0.070333, mean_episode_step = 64.125, total_loss = 212.71, entropy_loss = -10.925, pg_loss = 155.74, baseline_loss = 67.899, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:53,124[0m][[34mroot[0m][[32mINFO[0m] - Step 53760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 223.9, step = 53760, mean_episode_return = -0.070333, mean_episode_step = 64.125, total_loss = 212.71, entropy_loss = -10.925, pg_loss = 155.74, baseline_loss = 67.899, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:05:58,129[0m][[34mroot[0m][[32mINFO[0m] - Step 56320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 228.9, step = 56320, mean_episode_return = 0.012216, mean_episode_step = 55.607, total_loss = -116.29, entropy_loss = -10.887, pg_loss = -172.0, baseline_loss = 66.597, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:03,135[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 233.9, step = 58880, mean_episode_return = -0.0020512, mean_episode_step = 54.67, total_loss = 291.97, entropy_loss = -10.876, pg_loss = 185.73, baseline_loss = 117.12, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:08,140[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 238.9, step = 58880, mean_episode_return = -0.0020512, mean_episode_step = 54.67, total_loss = 291.97, entropy_loss = -10.876, pg_loss = 185.73, baseline_loss = 117.12, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:13,145[0m][[34mroot[0m][[32mINFO[0m] - Step 61440 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 243.9, step = 61440, mean_episode_return = -0.030973, mean_episode_step = 48.039, total_loss = -220.29, entropy_loss = -10.787, pg_loss = -252.93, baseline_loss = 43.425, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:18,150[0m][[34mroot[0m][[32mINFO[0m] - Step 61440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 248.9, step = 61440, mean_episode_return = -0.030973, mean_episode_step = 48.039, total_loss = -220.29, entropy_loss = -10.787, pg_loss = -252.93, baseline_loss = 43.425, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:23,155[0m][[34mroot[0m][[32mINFO[0m] - Step 64000 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 253.9, step = 64000, mean_episode_return = -0.012152, mean_episode_step = 55.064, total_loss = 515.28, entropy_loss = -10.781, pg_loss = 370.04, baseline_loss = 156.02, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:28,161[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 511.5 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 258.9, step = 66560, mean_episode_return = -0.0031025, mean_episode_step = 45.967, total_loss = 429.34, entropy_loss = -10.702, pg_loss = 236.29, baseline_loss = 203.75, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:33,166[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 263.9, step = 66560, mean_episode_return = -0.0031025, mean_episode_step = 45.967, total_loss = 429.34, entropy_loss = -10.702, pg_loss = 236.29, baseline_loss = 203.75, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:38,172[0m][[34mroot[0m][[32mINFO[0m] - Step 69120 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 268.9, step = 69120, mean_episode_return = -0.058537, mean_episode_step = 55.151, total_loss = -126.28, entropy_loss = -10.575, pg_loss = -205.33, baseline_loss = 89.622, learner_queue_size = 32, _tick = 26, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:43,178[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 273.9, step = 71680, mean_episode_return = -0.019543, mean_episode_step = 51.56, total_loss = 89.611, entropy_loss = -10.5, pg_loss = -6.7693, baseline_loss = 106.88, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:48,184[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 278.9, step = 71680, mean_episode_return = -0.019543, mean_episode_step = 51.56, total_loss = 89.611, entropy_loss = -10.5, pg_loss = -6.7693, baseline_loss = 106.88, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:53,189[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 284.0, step = 74240, mean_episode_return = 0.046282, mean_episode_step = 47.479, total_loss = 389.31, entropy_loss = -10.506, pg_loss = 252.3, baseline_loss = 147.51, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:06:58,194[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 289.0, step = 74240, mean_episode_return = 0.046282, mean_episode_step = 47.479, total_loss = 389.31, entropy_loss = -10.506, pg_loss = 252.3, baseline_loss = 147.51, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:03,202[0m][[34mroot[0m][[32mINFO[0m] - Step 76800 @ 511.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 294.0, step = 76800, mean_episode_return = 0.020488, mean_episode_step = 48.146, total_loss = -79.74, entropy_loss = -10.533, pg_loss = -186.6, baseline_loss = 117.4, learner_queue_size = 32, _tick = 29, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:08,207[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 299.0, step = 79360, mean_episode_return = 0.0054091, mean_episode_step = 41.571, total_loss = -64.584, entropy_loss = -10.381, pg_loss = -128.72, baseline_loss = 74.519, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:13,212[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 304.0, step = 79360, mean_episode_return = 0.0054091, mean_episode_step = 41.571, total_loss = -64.584, entropy_loss = -10.381, pg_loss = -128.72, baseline_loss = 74.519, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:18,217[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 309.0, step = 81920, mean_episode_return = -0.0064999, mean_episode_step = 56.6, total_loss = 618.92, entropy_loss = -10.184, pg_loss = 474.79, baseline_loss = 154.3, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:23,222[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 314.0, step = 81920, mean_episode_return = -0.0064999, mean_episode_step = 56.6, total_loss = 618.92, entropy_loss = -10.184, pg_loss = 474.79, baseline_loss = 154.3, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:28,227[0m][[34mroot[0m][[32mINFO[0m] - Step 84480 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 319.0, step = 84480, mean_episode_return = 0.017705, mean_episode_step = 47.182, total_loss = -227.58, entropy_loss = -10.173, pg_loss = -288.51, baseline_loss = 71.105, learner_queue_size = 32, _tick = 32, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:33,232[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 324.0, step = 87040, mean_episode_return = 0.067256, mean_episode_step = 57.168, total_loss = 360.7, entropy_loss = -10.111, pg_loss = 251.5, baseline_loss = 119.31, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:38,238[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 329.0, step = 87040, mean_episode_return = 0.067256, mean_episode_step = 57.168, total_loss = 360.7, entropy_loss = -10.111, pg_loss = 251.5, baseline_loss = 119.31, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:43,245[0m][[34mroot[0m][[32mINFO[0m] - Step 89600 @ 511.3 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 334.0, step = 89600, mean_episode_return = -0.0048809, mean_episode_step = 47.883, total_loss = -46.385, entropy_loss = -10.082, pg_loss = -136.03, baseline_loss = 99.727, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:48,251[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 511.3 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 339.0, step = 92160, mean_episode_return = -0.031327, mean_episode_step = 54.55, total_loss = -88.374, entropy_loss = -9.9982, pg_loss = -148.11, baseline_loss = 69.737, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:53,257[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 344.0, step = 92160, mean_episode_return = -0.031327, mean_episode_step = 54.55, total_loss = -88.374, entropy_loss = -9.9982, pg_loss = -148.11, baseline_loss = 69.737, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:07:58,262[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 349.0, step = 94720, mean_episode_return = 0.017935, mean_episode_step = 62.753, total_loss = 1580.8, entropy_loss = -10.03, pg_loss = 1277.9, baseline_loss = 312.97, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:03,267[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 354.0, step = 94720, mean_episode_return = 0.017935, mean_episode_step = 62.753, total_loss = 1580.8, entropy_loss = -10.03, pg_loss = 1277.9, baseline_loss = 312.97, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:08,272[0m][[34mroot[0m][[32mINFO[0m] - Step 97280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 359.0, step = 97280, mean_episode_return = 0.045806, mean_episode_step = 51.76, total_loss = 832.14, entropy_loss = -10.035, pg_loss = 587.39, baseline_loss = 254.79, learner_queue_size = 32, _tick = 37, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:13,285[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 510.7 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 364.1, step = 99840, mean_episode_return = 0.081333, mean_episode_step = 63.611, total_loss = 69.586, entropy_loss = -10.015, pg_loss = -111.6, baseline_loss = 191.2, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:18,290[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 369.1, step = 99840, mean_episode_return = 0.081333, mean_episode_step = 63.611, total_loss = 69.586, entropy_loss = -10.015, pg_loss = -111.6, baseline_loss = 191.2, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:23,295[0m][[34mroot[0m][[32mINFO[0m] - Step 102400 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 374.1, step = 102400, mean_episode_return = 0.055167, mean_episode_step = 43.926, total_loss = 846.79, entropy_loss = -9.9088, pg_loss = 598.93, baseline_loss = 257.77, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:28,301[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 379.1, step = 104960, mean_episode_return = 0.097387, mean_episode_step = 54.856, total_loss = 386.05, entropy_loss = -9.8826, pg_loss = 200.58, baseline_loss = 195.35, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:33,306[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 384.1, step = 104960, mean_episode_return = 0.097387, mean_episode_step = 54.856, total_loss = 386.05, entropy_loss = -9.8826, pg_loss = 200.58, baseline_loss = 195.35, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:38,312[0m][[34mroot[0m][[32mINFO[0m] - Step 107520 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 389.1, step = 107520, mean_episode_return = 0.03882, mean_episode_step = 58.474, total_loss = -463.74, entropy_loss = -9.926, pg_loss = -593.92, baseline_loss = 140.1, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:43,318[0m][[34mroot[0m][[32mINFO[0m] - Step 107520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 394.1, step = 107520, mean_episode_return = 0.03882, mean_episode_step = 58.474, total_loss = -463.74, entropy_loss = -9.926, pg_loss = -593.92, baseline_loss = 140.1, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:48,323[0m][[34mroot[0m][[32mINFO[0m] - Step 110080 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 399.1, step = 110080, mean_episode_return = 0.032863, mean_episode_step = 50.463, total_loss = 242.77, entropy_loss = -9.9304, pg_loss = 87.74, baseline_loss = 164.96, learner_queue_size = 32, _tick = 42, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:53,328[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 404.1, step = 112640, mean_episode_return = 0.075143, mean_episode_step = 64.407, total_loss = 58.788, entropy_loss = -9.7594, pg_loss = -72.609, baseline_loss = 141.16, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:08:58,333[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 409.1, step = 112640, mean_episode_return = 0.075143, mean_episode_step = 64.407, total_loss = 58.788, entropy_loss = -9.7594, pg_loss = -72.609, baseline_loss = 141.16, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:03,338[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 414.1, step = 115200, mean_episode_return = 0.050929, mean_episode_step = 50.042, total_loss = 896.34, entropy_loss = -9.754, pg_loss = 592.73, baseline_loss = 313.37, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:08,343[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 419.1, step = 115200, mean_episode_return = 0.050929, mean_episode_step = 50.042, total_loss = 896.34, entropy_loss = -9.754, pg_loss = 592.73, baseline_loss = 313.37, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:13,348[0m][[34mroot[0m][[32mINFO[0m] - Step 117760 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 424.1, step = 117760, mean_episode_return = 0.04675, mean_episode_step = 56.561, total_loss = -706.34, entropy_loss = -9.6962, pg_loss = -775.9, baseline_loss = 79.248, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:18,353[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 429.1, step = 120320, mean_episode_return = 0.074915, mean_episode_step = 48.613, total_loss = 404.16, entropy_loss = -9.6881, pg_loss = 194.7, baseline_loss = 219.15, learner_queue_size = 32, _tick = 46, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:23,358[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 434.1, step = 120320, mean_episode_return = 0.074915, mean_episode_step = 48.613, total_loss = 404.16, entropy_loss = -9.6881, pg_loss = 194.7, baseline_loss = 219.15, learner_queue_size = 32, _tick = 46, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:28,363[0m][[34mroot[0m][[32mINFO[0m] - Step 122880 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 439.1, step = 122880, mean_episode_return = 0.073936, mean_episode_step = 57.016, total_loss = -85.085, entropy_loss = -9.668, pg_loss = -282.92, baseline_loss = 207.5, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:33,368[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar[0m
[[36m2025-01-17 21:09:33,422[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 444.1, step = 125440, mean_episode_return = 0.059762, mean_episode_step = 54.111, total_loss = 783.72, entropy_loss = -9.6851, pg_loss = 542.26, baseline_loss = 251.14, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:38,428[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 449.2, step = 125440, mean_episode_return = 0.059762, mean_episode_step = 54.111, total_loss = 783.72, entropy_loss = -9.6851, pg_loss = 542.26, baseline_loss = 251.14, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:43,434[0m][[34mroot[0m][[32mINFO[0m] - Step 128000 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 454.2, step = 128000, mean_episode_return = 0.086978, mean_episode_step = 57.766, total_loss = 19.621, entropy_loss = -9.6052, pg_loss = -121.55, baseline_loss = 150.77, learner_queue_size = 32, _tick = 49, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:48,439[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 459.2, step = 130560, mean_episode_return = 0.058739, mean_episode_step = 55.318, total_loss = 191.77, entropy_loss = -9.4995, pg_loss = 12.443, baseline_loss = 188.82, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:53,444[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 464.2, step = 130560, mean_episode_return = 0.058739, mean_episode_step = 55.318, total_loss = 191.77, entropy_loss = -9.4995, pg_loss = 12.443, baseline_loss = 188.82, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:09:58,450[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 469.2, step = 133120, mean_episode_return = 0.047375, mean_episode_step = 63.502, total_loss = 268.2, entropy_loss = -9.44, pg_loss = 117.84, baseline_loss = 159.8, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:03,455[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 474.2, step = 133120, mean_episode_return = 0.047375, mean_episode_step = 63.502, total_loss = 268.2, entropy_loss = -9.44, pg_loss = 117.84, baseline_loss = 159.8, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:08,461[0m][[34mroot[0m][[32mINFO[0m] - Step 135680 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 479.2, step = 135680, mean_episode_return = 0.0992, mean_episode_step = 63.229, total_loss = -0.64085, entropy_loss = -9.3433, pg_loss = -119.2, baseline_loss = 127.91, learner_queue_size = 32, _tick = 52, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:13,466[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 511.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 484.2, step = 138240, mean_episode_return = 0.16529, mean_episode_step = 51.921, total_loss = 86.88, entropy_loss = -9.2505, pg_loss = -11.704, baseline_loss = 107.83, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:18,471[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 489.2, step = 138240, mean_episode_return = 0.16529, mean_episode_step = 51.921, total_loss = 86.88, entropy_loss = -9.2505, pg_loss = -11.704, baseline_loss = 107.83, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:23,476[0m][[34mroot[0m][[32mINFO[0m] - Step 140800 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 494.2, step = 140800, mean_episode_return = 0.057621, mean_episode_step = 59.608, total_loss = 40.908, entropy_loss = -9.313, pg_loss = -49.693, baseline_loss = 99.914, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:28,482[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 499.2, step = 143360, mean_episode_return = 0.07371, mean_episode_step = 66.925, total_loss = -50.46, entropy_loss = -9.1488, pg_loss = -128.08, baseline_loss = 86.769, learner_queue_size = 32, _tick = 55, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:33,488[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 504.3, step = 143360, mean_episode_return = 0.07371, mean_episode_step = 66.925, total_loss = -50.46, entropy_loss = -9.1488, pg_loss = -128.08, baseline_loss = 86.769, learner_queue_size = 32, _tick = 55, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:38,493[0m][[34mroot[0m][[32mINFO[0m] - Step 145920 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 509.3, step = 145920, mean_episode_return = 0.020475, mean_episode_step = 54.26, total_loss = 370.68, entropy_loss = -8.9583, pg_loss = 281.2, baseline_loss = 98.441, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:43,498[0m][[34mroot[0m][[32mINFO[0m] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 514.3, step = 145920, mean_episode_return = 0.020475, mean_episode_step = 54.26, total_loss = 370.68, entropy_loss = -8.9583, pg_loss = 281.2, baseline_loss = 98.441, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:48,503[0m][[34mroot[0m][[32mINFO[0m] - Step 148480 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 519.3, step = 148480, mean_episode_return = 0.063625, mean_episode_step = 77.491, total_loss = 292.14, entropy_loss = -8.8971, pg_loss = 174.51, baseline_loss = 126.52, learner_queue_size = 32, _tick = 57, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:53,508[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 524.3, step = 151040, mean_episode_return = 0.12326, mean_episode_step = 67.28, total_loss = 333.77, entropy_loss = -8.826, pg_loss = 205.04, baseline_loss = 137.55, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:10:58,513[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 529.3, step = 151040, mean_episode_return = 0.12326, mean_episode_step = 67.28, total_loss = 333.77, entropy_loss = -8.826, pg_loss = 205.04, baseline_loss = 137.55, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:03,518[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 534.3, step = 153600, mean_episode_return = 0.11956, mean_episode_step = 61.837, total_loss = -57.188, entropy_loss = -8.7836, pg_loss = -176.79, baseline_loss = 128.38, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:08,523[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 539.3, step = 153600, mean_episode_return = 0.11956, mean_episode_step = 61.837, total_loss = -57.188, entropy_loss = -8.7836, pg_loss = -176.79, baseline_loss = 128.38, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:13,528[0m][[34mroot[0m][[32mINFO[0m] - Step 156160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 544.3, step = 156160, mean_episode_return = 0.14754, mean_episode_step = 72.754, total_loss = -32.911, entropy_loss = -8.7747, pg_loss = -155.65, baseline_loss = 131.52, learner_queue_size = 32, _tick = 60, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:18,533[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 549.3, step = 158720, mean_episode_return = 0.070216, mean_episode_step = 51.428, total_loss = 778.97, entropy_loss = -8.7267, pg_loss = 578.74, baseline_loss = 208.96, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:23,538[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 554.3, step = 158720, mean_episode_return = 0.070216, mean_episode_step = 51.428, total_loss = 778.97, entropy_loss = -8.7267, pg_loss = 578.74, baseline_loss = 208.96, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:28,544[0m][[34mroot[0m][[32mINFO[0m] - Step 161280 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 559.3, step = 161280, mean_episode_return = 0.1348, mean_episode_step = 62.543, total_loss = -799.59, entropy_loss = -8.7698, pg_loss = -850.06, baseline_loss = 59.232, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:33,549[0m][[34mroot[0m][[32mINFO[0m] - Step 163840 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 564.3, step = 163840, mean_episode_return = 0.077763, mean_episode_step = 55.105, total_loss = -431.27, entropy_loss = -8.7689, pg_loss = -565.39, baseline_loss = 142.89, learner_queue_size = 32, _tick = 63, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:38,555[0m][[34mroot[0m][[32mINFO[0m] - Step 163840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 569.3, step = 163840, mean_episode_return = 0.077763, mean_episode_step = 55.105, total_loss = -431.27, entropy_loss = -8.7689, pg_loss = -565.39, baseline_loss = 142.89, learner_queue_size = 32, _tick = 63, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:43,560[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 574.3, step = 166400, mean_episode_return = 0.13164, mean_episode_step = 69.936, total_loss = 408.65, entropy_loss = -8.7418, pg_loss = 238.32, baseline_loss = 179.07, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:48,565[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 579.3, step = 166400, mean_episode_return = 0.13164, mean_episode_step = 69.936, total_loss = 408.65, entropy_loss = -8.7418, pg_loss = 238.32, baseline_loss = 179.07, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:53,570[0m][[34mroot[0m][[32mINFO[0m] - Step 168960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 584.3, step = 168960, mean_episode_return = 0.13382, mean_episode_step = 71.99, total_loss = 84.353, entropy_loss = -8.8218, pg_loss = -109.94, baseline_loss = 203.11, learner_queue_size = 32, _tick = 65, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:11:58,575[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 589.3, step = 171520, mean_episode_return = 0.14826, mean_episode_step = 69.57, total_loss = 539.06, entropy_loss = -8.7608, pg_loss = 334.21, baseline_loss = 213.61, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:03,580[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 594.3, step = 171520, mean_episode_return = 0.14826, mean_episode_step = 69.57, total_loss = 539.06, entropy_loss = -8.7608, pg_loss = 334.21, baseline_loss = 213.61, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:08,587[0m][[34mroot[0m][[32mINFO[0m] - Step 174080 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 599.4, step = 174080, mean_episode_return = 0.16971, mean_episode_step = 70.198, total_loss = 242.99, entropy_loss = -8.7677, pg_loss = 54.518, baseline_loss = 197.24, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:13,592[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-17 21:12:13,622[0m][[34mroot[0m][[32mINFO[0m] - Step 176640 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 604.4, step = 176640, mean_episode_return = 0.16552, mean_episode_step = 62.696, total_loss = -211.19, entropy_loss = -8.7574, pg_loss = -355.92, baseline_loss = 153.48, learner_queue_size = 32, _tick = 68, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:18,627[0m][[34mroot[0m][[32mINFO[0m] - Step 176640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 609.4, step = 176640, mean_episode_return = 0.16552, mean_episode_step = 62.696, total_loss = -211.19, entropy_loss = -8.7574, pg_loss = -355.92, baseline_loss = 153.48, learner_queue_size = 32, _tick = 68, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:23,632[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 614.4, step = 179200, mean_episode_return = 0.13331, mean_episode_step = 73.818, total_loss = 521.94, entropy_loss = -8.7373, pg_loss = 317.37, baseline_loss = 213.3, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:28,637[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 619.4, step = 179200, mean_episode_return = 0.13331, mean_episode_step = 73.818, total_loss = 521.94, entropy_loss = -8.7373, pg_loss = 317.37, baseline_loss = 213.3, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:33,644[0m][[34mroot[0m][[32mINFO[0m] - Step 181760 @ 511.3 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 624.4, step = 181760, mean_episode_return = 0.21752, mean_episode_step = 83.111, total_loss = 531.32, entropy_loss = -8.7873, pg_loss = 340.54, baseline_loss = 199.57, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:38,651[0m][[34mroot[0m][[32mINFO[0m] - Step 184320 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 629.4, step = 184320, mean_episode_return = 0.19959, mean_episode_step = 66.48, total_loss = -168.23, entropy_loss = -8.8026, pg_loss = -349.74, baseline_loss = 190.32, learner_queue_size = 32, _tick = 71, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:43,656[0m][[34mroot[0m][[32mINFO[0m] - Step 184320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 634.4, step = 184320, mean_episode_return = 0.19959, mean_episode_step = 66.48, total_loss = -168.23, entropy_loss = -8.8026, pg_loss = -349.74, baseline_loss = 190.32, learner_queue_size = 32, _tick = 71, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:48,664[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 511.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 639.4, step = 186880, mean_episode_return = 0.18239, mean_episode_step = 73.161, total_loss = -274.72, entropy_loss = -8.7678, pg_loss = -467.37, baseline_loss = 201.42, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:53,669[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 644.4, step = 186880, mean_episode_return = 0.18239, mean_episode_step = 73.161, total_loss = -274.72, entropy_loss = -8.7678, pg_loss = -467.37, baseline_loss = 201.42, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:12:58,674[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 649.4, step = 189440, mean_episode_return = 0.12143, mean_episode_step = 79.879, total_loss = -810.15, entropy_loss = -8.7957, pg_loss = -901.54, baseline_loss = 100.19, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:03,679[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 654.4, step = 192000, mean_episode_return = 0.11563, mean_episode_step = 78.699, total_loss = 4.202, entropy_loss = -8.7964, pg_loss = -177.38, baseline_loss = 190.38, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:08,684[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 659.4, step = 192000, mean_episode_return = 0.11563, mean_episode_step = 78.699, total_loss = 4.202, entropy_loss = -8.7964, pg_loss = -177.38, baseline_loss = 190.38, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:13,689[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 664.5, step = 194560, mean_episode_return = 0.23137, mean_episode_step = 63.53, total_loss = 680.07, entropy_loss = -8.816, pg_loss = 501.24, baseline_loss = 187.64, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:18,694[0m][[34mroot[0m][[32mINFO[0m] - Step 197120 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 669.5, step = 197120, mean_episode_return = 0.23094, mean_episode_step = 74.434, total_loss = 804.41, entropy_loss = -8.7686, pg_loss = 585.76, baseline_loss = 227.42, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:23,699[0m][[34mroot[0m][[32mINFO[0m] - Step 197120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 674.5, step = 197120, mean_episode_return = 0.23094, mean_episode_step = 74.434, total_loss = 804.41, entropy_loss = -8.7686, pg_loss = 585.76, baseline_loss = 227.42, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:28,704[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 679.5, step = 199680, mean_episode_return = 0.10622, mean_episode_step = 68.329, total_loss = -278.65, entropy_loss = -8.7085, pg_loss = -417.12, baseline_loss = 147.17, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:33,709[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 684.5, step = 199680, mean_episode_return = 0.10622, mean_episode_step = 68.329, total_loss = -278.65, entropy_loss = -8.7085, pg_loss = -417.12, baseline_loss = 147.17, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:38,714[0m][[34mroot[0m][[32mINFO[0m] - Step 202240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 689.5, step = 202240, mean_episode_return = 0.21415, mean_episode_step = 66.602, total_loss = 372.12, entropy_loss = -8.6943, pg_loss = 162.48, baseline_loss = 218.33, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:43,719[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 694.5, step = 204800, mean_episode_return = 0.18471, mean_episode_step = 60.781, total_loss = -95.447, entropy_loss = -8.696, pg_loss = -264.57, baseline_loss = 177.82, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:48,720[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 699.5, step = 204800, mean_episode_return = 0.18471, mean_episode_step = 60.781, total_loss = -95.447, entropy_loss = -8.696, pg_loss = -264.57, baseline_loss = 177.82, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:53,725[0m][[34mroot[0m][[32mINFO[0m] - Step 207360 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 704.5, step = 207360, mean_episode_return = 0.16288, mean_episode_step = 80.154, total_loss = -680.64, entropy_loss = -8.6862, pg_loss = -755.01, baseline_loss = 83.054, learner_queue_size = 32, _tick = 80, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:13:58,730[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 709.5, step = 209920, mean_episode_return = 0.3295, mean_episode_step = 83.036, total_loss = 493.24, entropy_loss = -8.6762, pg_loss = 314.53, baseline_loss = 187.38, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:03,735[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 714.5, step = 209920, mean_episode_return = 0.3295, mean_episode_step = 83.036, total_loss = 493.24, entropy_loss = -8.6762, pg_loss = 314.53, baseline_loss = 187.38, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:08,740[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 719.5, step = 212480, mean_episode_return = 0.16118, mean_episode_step = 69.021, total_loss = -629.88, entropy_loss = -8.6471, pg_loss = -744.69, baseline_loss = 123.46, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:13,745[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 724.5, step = 212480, mean_episode_return = 0.16118, mean_episode_step = 69.021, total_loss = -629.88, entropy_loss = -8.6471, pg_loss = -744.69, baseline_loss = 123.46, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:18,750[0m][[34mroot[0m][[32mINFO[0m] - Step 215040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 729.5, step = 215040, mean_episode_return = 0.12069, mean_episode_step = 76.193, total_loss = -73.588, entropy_loss = -8.6525, pg_loss = -195.6, baseline_loss = 130.66, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:23,755[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 734.5, step = 217600, mean_episode_return = 0.13697, mean_episode_step = 73.943, total_loss = 388.79, entropy_loss = -8.6929, pg_loss = 230.23, baseline_loss = 167.25, learner_queue_size = 32, _tick = 84, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:28,760[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 739.5, step = 217600, mean_episode_return = 0.13697, mean_episode_step = 73.943, total_loss = 388.79, entropy_loss = -8.6929, pg_loss = 230.23, baseline_loss = 167.25, learner_queue_size = 32, _tick = 84, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:33,765[0m][[34mroot[0m][[32mINFO[0m] - Step 220160 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 744.5, step = 220160, mean_episode_return = 0.18341, mean_episode_step = 69.817, total_loss = -997.24, entropy_loss = -8.688, pg_loss = -1093.9, baseline_loss = 105.37, learner_queue_size = 32, _tick = 85, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:38,770[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 749.5, step = 222720, mean_episode_return = 0.25042, mean_episode_step = 75.107, total_loss = -247.58, entropy_loss = -8.6945, pg_loss = -395.91, baseline_loss = 157.03, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:43,776[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 754.5, step = 222720, mean_episode_return = 0.25042, mean_episode_step = 75.107, total_loss = -247.58, entropy_loss = -8.6945, pg_loss = -395.91, baseline_loss = 157.03, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:48,783[0m][[34mroot[0m][[32mINFO[0m] - Step 225280 @ 511.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 759.5, step = 225280, mean_episode_return = 0.31727, mean_episode_step = 57.716, total_loss = 896.58, entropy_loss = -8.7082, pg_loss = 667.39, baseline_loss = 237.9, learner_queue_size = 32, _tick = 87, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:53,804[0m][[34mroot[0m][[32mINFO[0m] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 764.6, step = 225280, mean_episode_return = 0.31727, mean_episode_step = 57.716, total_loss = 896.58, entropy_loss = -8.7082, pg_loss = 667.39, baseline_loss = 237.9, learner_queue_size = 32, _tick = 87, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:14:58,810[0m][[34mroot[0m][[32mINFO[0m] - Step 227840 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 769.6, step = 227840, mean_episode_return = 0.22829, mean_episode_step = 78.057, total_loss = 1300.2, entropy_loss = -8.6756, pg_loss = 1027.6, baseline_loss = 281.32, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:03,816[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 774.6, step = 230400, mean_episode_return = 0.22178, mean_episode_step = 65.854, total_loss = 218.15, entropy_loss = -8.671, pg_loss = -10.378, baseline_loss = 237.2, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:08,821[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 779.6, step = 230400, mean_episode_return = 0.22178, mean_episode_step = 65.854, total_loss = 218.15, entropy_loss = -8.671, pg_loss = -10.378, baseline_loss = 237.2, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:13,826[0m][[34mroot[0m][[32mINFO[0m] - Step 232960 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 784.6, step = 232960, mean_episode_return = 0.15504, mean_episode_step = 74.762, total_loss = -59.61, entropy_loss = -8.6159, pg_loss = -212.34, baseline_loss = 161.34, learner_queue_size = 32, _tick = 90, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:18,831[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 789.6, step = 235520, mean_episode_return = 0.15468, mean_episode_step = 72.396, total_loss = 304.38, entropy_loss = -8.6314, pg_loss = 117.05, baseline_loss = 195.96, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:23,837[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 794.6, step = 235520, mean_episode_return = 0.15468, mean_episode_step = 72.396, total_loss = 304.38, entropy_loss = -8.6314, pg_loss = 117.05, baseline_loss = 195.96, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:28,843[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 799.6, step = 238080, mean_episode_return = 0.26324, mean_episode_step = 85.86, total_loss = 445.03, entropy_loss = -8.5841, pg_loss = 271.31, baseline_loss = 182.3, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:33,849[0m][[34mroot[0m][[32mINFO[0m] - Step 240640 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 804.6, step = 240640, mean_episode_return = 0.13463, mean_episode_step = 71.434, total_loss = -689.87, entropy_loss = -8.582, pg_loss = -791.21, baseline_loss = 109.91, learner_queue_size = 32, _tick = 93, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:38,854[0m][[34mroot[0m][[32mINFO[0m] - Step 240640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 809.6, step = 240640, mean_episode_return = 0.13463, mean_episode_step = 71.434, total_loss = -689.87, entropy_loss = -8.582, pg_loss = -791.21, baseline_loss = 109.91, learner_queue_size = 32, _tick = 93, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:43,861[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 511.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 814.6, step = 243200, mean_episode_return = 0.20362, mean_episode_step = 83.165, total_loss = 856.99, entropy_loss = -8.5818, pg_loss = 660.53, baseline_loss = 205.04, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:48,866[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 819.6, step = 243200, mean_episode_return = 0.20362, mean_episode_step = 83.165, total_loss = 856.99, entropy_loss = -8.5818, pg_loss = 660.53, baseline_loss = 205.04, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:53,875[0m][[34mroot[0m][[32mINFO[0m] - Step 245760 @ 511.1 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 824.6, step = 245760, mean_episode_return = 0.15959, mean_episode_step = 66.861, total_loss = -787.0, entropy_loss = -8.5753, pg_loss = -899.16, baseline_loss = 120.74, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:15:58,880[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 829.6, step = 248320, mean_episode_return = 0.090703, mean_episode_step = 78.641, total_loss = -279.59, entropy_loss = -8.5776, pg_loss = -424.93, baseline_loss = 153.92, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:03,885[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 834.7, step = 248320, mean_episode_return = 0.090703, mean_episode_step = 78.641, total_loss = -279.59, entropy_loss = -8.5776, pg_loss = -424.93, baseline_loss = 153.92, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:08,890[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar[0m
[[36m2025-01-17 21:16:08,922[0m][[34mroot[0m][[32mINFO[0m] - Step 250880 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 839.7, step = 250880, mean_episode_return = 0.18411, mean_episode_step = 68.448, total_loss = 209.33, entropy_loss = -8.5859, pg_loss = 43.158, baseline_loss = 174.76, learner_queue_size = 32, _tick = 97, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:13,927[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 508.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 844.7, step = 253440, mean_episode_return = 0.17464, mean_episode_step = 77.434, total_loss = -457.95, entropy_loss = -8.5683, pg_loss = -555.78, baseline_loss = 106.4, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:18,932[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 849.7, step = 253440, mean_episode_return = 0.17464, mean_episode_step = 77.434, total_loss = -457.95, entropy_loss = -8.5683, pg_loss = -555.78, baseline_loss = 106.4, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:23,937[0m][[34mroot[0m][[32mINFO[0m] - Step 256000 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 854.7, step = 256000, mean_episode_return = 0.24655, mean_episode_step = 64.039, total_loss = -176.0, entropy_loss = -8.5754, pg_loss = -284.43, baseline_loss = 117.01, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:28,942[0m][[34mroot[0m][[32mINFO[0m] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 859.7, step = 256000, mean_episode_return = 0.24655, mean_episode_step = 64.039, total_loss = -176.0, entropy_loss = -8.5754, pg_loss = -284.43, baseline_loss = 117.01, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:33,947[0m][[34mroot[0m][[32mINFO[0m] - Step 258560 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 864.7, step = 258560, mean_episode_return = 0.15909, mean_episode_step = 77.726, total_loss = -149.62, entropy_loss = -8.613, pg_loss = -263.44, baseline_loss = 122.43, learner_queue_size = 32, _tick = 100, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:38,954[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 869.7, step = 261120, mean_episode_return = 0.1575, mean_episode_step = 57.466, total_loss = -204.89, entropy_loss = -8.5796, pg_loss = -322.94, baseline_loss = 126.63, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:43,960[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 874.7, step = 261120, mean_episode_return = 0.1575, mean_episode_step = 57.466, total_loss = -204.89, entropy_loss = -8.5796, pg_loss = -322.94, baseline_loss = 126.63, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:48,966[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 879.7, step = 263680, mean_episode_return = 0.17182, mean_episode_step = 81.37, total_loss = -573.98, entropy_loss = -8.5369, pg_loss = -614.18, baseline_loss = 48.738, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:53,971[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 884.7, step = 263680, mean_episode_return = 0.17182, mean_episode_step = 81.37, total_loss = -573.98, entropy_loss = -8.5369, pg_loss = -614.18, baseline_loss = 48.738, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:16:58,976[0m][[34mroot[0m][[32mINFO[0m] - Step 266240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 889.7, step = 266240, mean_episode_return = 0.31793, mean_episode_step = 76.395, total_loss = 622.16, entropy_loss = -8.4956, pg_loss = 511.24, baseline_loss = 119.42, learner_queue_size = 32, _tick = 103, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:03,981[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 894.7, step = 268800, mean_episode_return = 0.21359, mean_episode_step = 73.428, total_loss = 832.66, entropy_loss = -8.5154, pg_loss = 675.15, baseline_loss = 166.02, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:08,986[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 899.8, step = 268800, mean_episode_return = 0.21359, mean_episode_step = 73.428, total_loss = 832.66, entropy_loss = -8.5154, pg_loss = 675.15, baseline_loss = 166.02, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:13,991[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 904.8, step = 271360, mean_episode_return = 0.22268, mean_episode_step = 63.052, total_loss = 543.79, entropy_loss = -8.5244, pg_loss = 388.58, baseline_loss = 163.74, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:18,996[0m][[34mroot[0m][[32mINFO[0m] - Step 273920 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 909.8, step = 273920, mean_episode_return = 0.19562, mean_episode_step = 71.718, total_loss = 1265.9, entropy_loss = -8.5738, pg_loss = 1028.9, baseline_loss = 245.52, learner_queue_size = 32, _tick = 106, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:24,002[0m][[34mroot[0m][[32mINFO[0m] - Step 273920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 914.8, step = 273920, mean_episode_return = 0.19562, mean_episode_step = 71.718, total_loss = 1265.9, entropy_loss = -8.5738, pg_loss = 1028.9, baseline_loss = 245.52, learner_queue_size = 32, _tick = 106, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:29,008[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 919.8, step = 276480, mean_episode_return = 0.17659, mean_episode_step = 71.395, total_loss = -466.3, entropy_loss = -8.5737, pg_loss = -571.43, baseline_loss = 113.7, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:34,013[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 924.8, step = 276480, mean_episode_return = 0.17659, mean_episode_step = 71.395, total_loss = -466.3, entropy_loss = -8.5737, pg_loss = -571.43, baseline_loss = 113.7, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:39,018[0m][[34mroot[0m][[32mINFO[0m] - Step 279040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 929.8, step = 279040, mean_episode_return = 0.17617, mean_episode_step = 67.411, total_loss = 376.65, entropy_loss = -8.5931, pg_loss = 200.48, baseline_loss = 184.76, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:44,024[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 934.8, step = 281600, mean_episode_return = 0.25388, mean_episode_step = 85.21, total_loss = -804.21, entropy_loss = -8.5448, pg_loss = -878.82, baseline_loss = 83.155, learner_queue_size = 32, _tick = 109, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:49,029[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 939.8, step = 281600, mean_episode_return = 0.25388, mean_episode_step = 85.21, total_loss = -804.21, entropy_loss = -8.5448, pg_loss = -878.82, baseline_loss = 83.155, learner_queue_size = 32, _tick = 109, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:54,035[0m][[34mroot[0m][[32mINFO[0m] - Step 284160 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 944.8, step = 284160, mean_episode_return = 0.22135, mean_episode_step = 75.165, total_loss = 339.98, entropy_loss = -8.5383, pg_loss = 200.17, baseline_loss = 148.35, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:17:59,041[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 949.8, step = 286720, mean_episode_return = 0.083244, mean_episode_step = 59.584, total_loss = -97.784, entropy_loss = -8.5082, pg_loss = -216.34, baseline_loss = 127.06, learner_queue_size = 32, _tick = 111, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:04,046[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 954.8, step = 286720, mean_episode_return = 0.083244, mean_episode_step = 59.584, total_loss = -97.784, entropy_loss = -8.5082, pg_loss = -216.34, baseline_loss = 127.06, learner_queue_size = 32, _tick = 111, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:09,051[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 959.8, step = 289280, mean_episode_return = 0.24055, mean_episode_step = 70.929, total_loss = 1264.7, entropy_loss = -8.5127, pg_loss = 1018.7, baseline_loss = 254.55, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:14,056[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 964.8, step = 289280, mean_episode_return = 0.24055, mean_episode_step = 70.929, total_loss = 1264.7, entropy_loss = -8.5127, pg_loss = 1018.7, baseline_loss = 254.55, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:19,061[0m][[34mroot[0m][[32mINFO[0m] - Step 291840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 969.8, step = 291840, mean_episode_return = 0.16205, mean_episode_step = 70.215, total_loss = 27.763, entropy_loss = -8.5448, pg_loss = -126.1, baseline_loss = 162.41, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:24,067[0m][[34mroot[0m][[32mINFO[0m] - Step 294400 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 974.8, step = 294400, mean_episode_return = 0.24672, mean_episode_step = 73.765, total_loss = 39.3, entropy_loss = -8.5788, pg_loss = -107.17, baseline_loss = 155.05, learner_queue_size = 32, _tick = 114, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:29,073[0m][[34mroot[0m][[32mINFO[0m] - Step 294400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 979.8, step = 294400, mean_episode_return = 0.24672, mean_episode_step = 73.765, total_loss = 39.3, entropy_loss = -8.5788, pg_loss = -107.17, baseline_loss = 155.05, learner_queue_size = 32, _tick = 114, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:34,078[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 984.8, step = 296960, mean_episode_return = 0.14623, mean_episode_step = 68.739, total_loss = 100.3, entropy_loss = -8.5254, pg_loss = -58.294, baseline_loss = 167.11, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:39,085[0m][[34mroot[0m][[32mINFO[0m] - Step 299520 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 989.8, step = 299520, mean_episode_return = 0.22272, mean_episode_step = 59.306, total_loss = 178.43, entropy_loss = -8.4736, pg_loss = 39.295, baseline_loss = 147.61, learner_queue_size = 32, _tick = 116, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:44,090[0m][[34mroot[0m][[32mINFO[0m] - Step 299520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 994.9, step = 299520, mean_episode_return = 0.22272, mean_episode_step = 59.306, total_loss = 178.43, entropy_loss = -8.4736, pg_loss = 39.295, baseline_loss = 147.61, learner_queue_size = 32, _tick = 116, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:49,096[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 999.9, step = 302080, mean_episode_return = 0.084161, mean_episode_step = 75.934, total_loss = -30.492, entropy_loss = -8.4477, pg_loss = -135.65, baseline_loss = 113.61, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:54,101[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1004.9, step = 302080, mean_episode_return = 0.084161, mean_episode_step = 75.934, total_loss = -30.492, entropy_loss = -8.4477, pg_loss = -135.65, baseline_loss = 113.61, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:18:59,106[0m][[34mroot[0m][[32mINFO[0m] - Step 304640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1009.9, step = 304640, mean_episode_return = 0.26707, mean_episode_step = 89.505, total_loss = 677.97, entropy_loss = -8.424, pg_loss = 530.45, baseline_loss = 155.94, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:04,112[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1014.9, step = 307200, mean_episode_return = 0.1678, mean_episode_step = 71.234, total_loss = 81.867, entropy_loss = -8.4412, pg_loss = -25.895, baseline_loss = 116.2, learner_queue_size = 32, _tick = 119, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:09,119[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1019.9, step = 307200, mean_episode_return = 0.1678, mean_episode_step = 71.234, total_loss = 81.867, entropy_loss = -8.4412, pg_loss = -25.895, baseline_loss = 116.2, learner_queue_size = 32, _tick = 119, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:14,124[0m][[34mroot[0m][[32mINFO[0m] - Step 309760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1024.9, step = 309760, mean_episode_return = 0.10676, mean_episode_step = 60.146, total_loss = 354.61, entropy_loss = -8.4747, pg_loss = 233.7, baseline_loss = 129.39, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:19,132[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 511.2 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1029.9, step = 312320, mean_episode_return = 0.26713, mean_episode_step = 74.139, total_loss = -21.406, entropy_loss = -8.4735, pg_loss = -136.94, baseline_loss = 124.01, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:24,137[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1034.9, step = 312320, mean_episode_return = 0.26713, mean_episode_step = 74.139, total_loss = -21.406, entropy_loss = -8.4735, pg_loss = -136.94, baseline_loss = 124.01, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:29,142[0m][[34mroot[0m][[32mINFO[0m] - Step 314880 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1039.9, step = 314880, mean_episode_return = 0.34348, mean_episode_step = 71.371, total_loss = 574.07, entropy_loss = -8.4402, pg_loss = 393.36, baseline_loss = 189.15, learner_queue_size = 32, _tick = 122, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:34,148[0m][[34mroot[0m][[32mINFO[0m] - Step 314880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1044.9, step = 314880, mean_episode_return = 0.34348, mean_episode_step = 71.371, total_loss = 574.07, entropy_loss = -8.4402, pg_loss = 393.36, baseline_loss = 189.15, learner_queue_size = 32, _tick = 122, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:39,153[0m][[34mroot[0m][[32mINFO[0m] - Step 317440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1049.9, step = 317440, mean_episode_return = 0.12479, mean_episode_step = 78.741, total_loss = -569.76, entropy_loss = -8.4183, pg_loss = -637.96, baseline_loss = 76.612, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:44,159[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1054.9, step = 320000, mean_episode_return = 0.35865, mean_episode_step = 89.834, total_loss = 1750.2, entropy_loss = -8.3972, pg_loss = 1493.6, baseline_loss = 265.01, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:49,164[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1059.9, step = 320000, mean_episode_return = 0.35865, mean_episode_step = 89.834, total_loss = 1750.2, entropy_loss = -8.3972, pg_loss = 1493.6, baseline_loss = 265.01, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:54,169[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1064.9, step = 322560, mean_episode_return = 0.2444, mean_episode_step = 71.724, total_loss = 186.99, entropy_loss = -8.4157, pg_loss = 5.4397, baseline_loss = 189.96, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:19:59,174[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1069.9, step = 322560, mean_episode_return = 0.2444, mean_episode_step = 71.724, total_loss = 186.99, entropy_loss = -8.4157, pg_loss = 5.4397, baseline_loss = 189.96, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:04,180[0m][[34mroot[0m][[32mINFO[0m] - Step 325120 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1074.9, step = 325120, mean_episode_return = 0.27659, mean_episode_step = 91.185, total_loss = 31.174, entropy_loss = -8.405, pg_loss = -86.432, baseline_loss = 126.01, learner_queue_size = 32, _tick = 126, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:09,186[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1080.0, step = 327680, mean_episode_return = 0.24566, mean_episode_step = 76.957, total_loss = 859.08, entropy_loss = -8.4108, pg_loss = 656.33, baseline_loss = 211.16, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:14,191[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1085.0, step = 327680, mean_episode_return = 0.24566, mean_episode_step = 76.957, total_loss = 859.08, entropy_loss = -8.4108, pg_loss = 656.33, baseline_loss = 211.16, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:19,196[0m][[34mroot[0m][[32mINFO[0m] - Step 330240 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1090.0, step = 330240, mean_episode_return = 0.2775, mean_episode_step = 80.564, total_loss = 824.79, entropy_loss = -8.393, pg_loss = 638.63, baseline_loss = 194.55, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:24,203[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 511.3 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (train_seconds = 1095.0, step = 332800, mean_episode_return = 0.17112, mean_episode_step = 68.854, total_loss = -192.69, entropy_loss = -8.4049, pg_loss = -312.14, baseline_loss = 127.86, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:29,208[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1100.0, step = 332800, mean_episode_return = 0.17112, mean_episode_step = 68.854, total_loss = -192.69, entropy_loss = -8.4049, pg_loss = -312.14, baseline_loss = 127.86, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:34,213[0m][[34mroot[0m][[32mINFO[0m] - Step 335360 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1105.0, step = 335360, mean_episode_return = 0.2195, mean_episode_step = 67.379, total_loss = 306.63, entropy_loss = -8.4211, pg_loss = 120.2, baseline_loss = 194.85, learner_queue_size = 32, _tick = 130, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:39,218[0m][[34mroot[0m][[32mINFO[0m] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1110.0, step = 335360, mean_episode_return = 0.2195, mean_episode_step = 67.379, total_loss = 306.63, entropy_loss = -8.4211, pg_loss = 120.2, baseline_loss = 194.85, learner_queue_size = 32, _tick = 130, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:44,223[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1115.0, step = 337920, mean_episode_return = 0.26274, mean_episode_step = 75.135, total_loss = -39.79, entropy_loss = -8.3819, pg_loss = -178.02, baseline_loss = 146.61, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:49,230[0m][[34mroot[0m][[32mINFO[0m] - Step 340480 @ 511.3 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1120.0, step = 340480, mean_episode_return = 0.23184, mean_episode_step = 70.278, total_loss = -196.57, entropy_loss = -8.394, pg_loss = -311.53, baseline_loss = 123.35, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:54,237[0m][[34mroot[0m][[32mINFO[0m] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1125.0, step = 340480, mean_episode_return = 0.23184, mean_episode_step = 70.278, total_loss = -196.57, entropy_loss = -8.394, pg_loss = -311.53, baseline_loss = 123.35, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:20:59,242[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1130.0, step = 343040, mean_episode_return = 0.31242, mean_episode_step = 79.592, total_loss = 4.3361, entropy_loss = -8.3568, pg_loss = -131.02, baseline_loss = 143.72, learner_queue_size = 32, _tick = 133, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:04,247[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1135.0, step = 343040, mean_episode_return = 0.31242, mean_episode_step = 79.592, total_loss = 4.3361, entropy_loss = -8.3568, pg_loss = -131.02, baseline_loss = 143.72, learner_queue_size = 32, _tick = 133, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:09,252[0m][[34mroot[0m][[32mINFO[0m] - Step 345600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1140.0, step = 345600, mean_episode_return = 0.2839, mean_episode_step = 78.209, total_loss = 475.01, entropy_loss = -8.3552, pg_loss = 297.25, baseline_loss = 186.12, learner_queue_size = 32, _tick = 134, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:14,257[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 511.5 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1145.0, step = 348160, mean_episode_return = 0.19718, mean_episode_step = 62.147, total_loss = 9.3615, entropy_loss = -8.3419, pg_loss = -123.15, baseline_loss = 140.85, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:19,262[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1150.0, step = 348160, mean_episode_return = 0.19718, mean_episode_step = 62.147, total_loss = 9.3615, entropy_loss = -8.3419, pg_loss = -123.15, baseline_loss = 140.85, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:24,267[0m][[34mroot[0m][[32mINFO[0m] - Step 350720 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1155.0, step = 350720, mean_episode_return = 0.1983, mean_episode_step = 73.923, total_loss = 55.851, entropy_loss = -8.2993, pg_loss = -59.302, baseline_loss = 123.45, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:29,272[0m][[34mroot[0m][[32mINFO[0m] - Step 353280 @ 511.5 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (train_seconds = 1160.0, step = 353280, mean_episode_return = 0.16578, mean_episode_step = 80.811, total_loss = -322.06, entropy_loss = -8.2716, pg_loss = -403.74, baseline_loss = 89.953, learner_queue_size = 32, _tick = 137, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:34,277[0m][[34mroot[0m][[32mINFO[0m] - Step 353280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1165.0, step = 353280, mean_episode_return = 0.16578, mean_episode_step = 80.811, total_loss = -322.06, entropy_loss = -8.2716, pg_loss = -403.74, baseline_loss = 89.953, learner_queue_size = 32, _tick = 137, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:39,283[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1170.0, step = 355840, mean_episode_return = 0.20636, mean_episode_step = 87.34, total_loss = 189.67, entropy_loss = -8.2628, pg_loss = 89.706, baseline_loss = 108.23, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:44,288[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1175.1, step = 355840, mean_episode_return = 0.20636, mean_episode_step = 87.34, total_loss = 189.67, entropy_loss = -8.2628, pg_loss = 89.706, baseline_loss = 108.23, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:49,293[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1180.1, step = 358400, mean_episode_return = 0.26826, mean_episode_step = 75.661, total_loss = 889.69, entropy_loss = -8.2828, pg_loss = 708.56, baseline_loss = 189.41, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:54,298[0m][[34mroot[0m][[32mINFO[0m] - Step 360960 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1185.1, step = 360960, mean_episode_return = 0.12237, mean_episode_step = 64.716, total_loss = 1020.0, entropy_loss = -8.2834, pg_loss = 798.46, baseline_loss = 229.84, learner_queue_size = 32, _tick = 140, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:21:59,303[0m][[34mroot[0m][[32mINFO[0m] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1190.1, step = 360960, mean_episode_return = 0.12237, mean_episode_step = 64.716, total_loss = 1020.0, entropy_loss = -8.2834, pg_loss = 798.46, baseline_loss = 229.84, learner_queue_size = 32, _tick = 140, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:04,308[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1195.1, step = 363520, mean_episode_return = 0.27261, mean_episode_step = 74.658, total_loss = 602.22, entropy_loss = -8.2874, pg_loss = 413.64, baseline_loss = 196.87, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:09,314[0m][[34mroot[0m][[32mINFO[0m] - Step 366080 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1200.1, step = 366080, mean_episode_return = 0.25046, mean_episode_step = 82.321, total_loss = -425.69, entropy_loss = -8.2903, pg_loss = -551.66, baseline_loss = 134.26, learner_queue_size = 32, _tick = 142, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:14,319[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-17 21:22:14,446[0m][[34mroot[0m][[32mINFO[0m] - Step 366080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1205.1, step = 366080, mean_episode_return = 0.25046, mean_episode_step = 82.321, total_loss = -425.69, entropy_loss = -8.2903, pg_loss = -551.66, baseline_loss = 134.26, learner_queue_size = 32, _tick = 142, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:19,454[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 498.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1210.2, step = 368640, mean_episode_return = 0.3269, mean_episode_step = 82.5, total_loss = 585.89, entropy_loss = -8.2743, pg_loss = 398.65, baseline_loss = 195.52, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:24,459[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1215.2, step = 368640, mean_episode_return = 0.3269, mean_episode_step = 82.5, total_loss = 585.89, entropy_loss = -8.2743, pg_loss = 398.65, baseline_loss = 195.52, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:29,464[0m][[34mroot[0m][[32mINFO[0m] - Step 371200 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1220.2, step = 371200, mean_episode_return = 0.11573, mean_episode_step = 71.082, total_loss = -368.72, entropy_loss = -8.2872, pg_loss = -481.5, baseline_loss = 121.07, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:34,469[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1225.2, step = 373760, mean_episode_return = 0.29524, mean_episode_step = 76.062, total_loss = -216.39, entropy_loss = -8.2937, pg_loss = -351.21, baseline_loss = 143.11, learner_queue_size = 32, _tick = 145, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:39,474[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1230.2, step = 373760, mean_episode_return = 0.29524, mean_episode_step = 76.062, total_loss = -216.39, entropy_loss = -8.2937, pg_loss = -351.21, baseline_loss = 143.11, learner_queue_size = 32, _tick = 145, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:44,479[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar[0m
[[36m2025-01-17 21:22:44,518[0m][[34mroot[0m][[32mINFO[0m] - Step 376320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1235.2, step = 376320, mean_episode_return = 0.24121, mean_episode_step = 85.862, total_loss = 99.576, entropy_loss = -8.2721, pg_loss = -78.389, baseline_loss = 186.24, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:49,524[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 507.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1240.3, step = 378880, mean_episode_return = 0.27023, mean_episode_step = 74.825, total_loss = 340.23, entropy_loss = -8.2284, pg_loss = 198.3, baseline_loss = 150.16, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:54,530[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1245.3, step = 378880, mean_episode_return = 0.27023, mean_episode_step = 74.825, total_loss = 340.23, entropy_loss = -8.2284, pg_loss = 198.3, baseline_loss = 150.16, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:22:59,535[0m][[34mroot[0m][[32mINFO[0m] - Step 381440 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1250.3, step = 381440, mean_episode_return = 0.28759, mean_episode_step = 72.11, total_loss = 1255.7, entropy_loss = -8.241, pg_loss = 1024.5, baseline_loss = 239.41, learner_queue_size = 32, _tick = 148, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:04,540[0m][[34mroot[0m][[32mINFO[0m] - Step 384000 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1255.3, step = 384000, mean_episode_return = 0.30803, mean_episode_step = 82.398, total_loss = 569.04, entropy_loss = -8.2401, pg_loss = 390.03, baseline_loss = 187.25, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:09,546[0m][[34mroot[0m][[32mINFO[0m] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1260.3, step = 384000, mean_episode_return = 0.30803, mean_episode_step = 82.398, total_loss = 569.04, entropy_loss = -8.2401, pg_loss = 390.03, baseline_loss = 187.25, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:14,551[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1265.3, step = 386560, mean_episode_return = 0.24241, mean_episode_step = 87.063, total_loss = -717.98, entropy_loss = -8.2214, pg_loss = -777.35, baseline_loss = 67.59, learner_queue_size = 32, _tick = 150, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:19,556[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1270.3, step = 386560, mean_episode_return = 0.24241, mean_episode_step = 87.063, total_loss = -717.98, entropy_loss = -8.2214, pg_loss = -777.35, baseline_loss = 67.59, learner_queue_size = 32, _tick = 150, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:24,563[0m][[34mroot[0m][[32mINFO[0m] - Step 389120 @ 511.3 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1275.3, step = 389120, mean_episode_return = 0.31998, mean_episode_step = 72.076, total_loss = 29.404, entropy_loss = -8.2447, pg_loss = -138.41, baseline_loss = 176.06, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:29,568[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1280.3, step = 391680, mean_episode_return = 0.19167, mean_episode_step = 82.279, total_loss = 165.09, entropy_loss = -8.2477, pg_loss = -8.775, baseline_loss = 182.11, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:34,573[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1285.3, step = 391680, mean_episode_return = 0.19167, mean_episode_step = 82.279, total_loss = 165.09, entropy_loss = -8.2477, pg_loss = -8.775, baseline_loss = 182.11, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:39,578[0m][[34mroot[0m][[32mINFO[0m] - Step 394240 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1290.3, step = 394240, mean_episode_return = 0.25813, mean_episode_step = 82.065, total_loss = -614.31, entropy_loss = -8.2657, pg_loss = -702.08, baseline_loss = 96.037, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:44,583[0m][[34mroot[0m][[32mINFO[0m] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1295.3, step = 394240, mean_episode_return = 0.25813, mean_episode_step = 82.065, total_loss = -614.31, entropy_loss = -8.2657, pg_loss = -702.08, baseline_loss = 96.037, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:49,588[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1300.4, step = 396800, mean_episode_return = 0.21363, mean_episode_step = 68.391, total_loss = 1235.3, entropy_loss = -8.2606, pg_loss = 998.54, baseline_loss = 245.0, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:54,594[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1305.4, step = 399360, mean_episode_return = 0.17873, mean_episode_step = 74.963, total_loss = 167.93, entropy_loss = -8.2488, pg_loss = 27.719, baseline_loss = 148.46, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:23:59,599[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1310.4, step = 399360, mean_episode_return = 0.17873, mean_episode_step = 74.963, total_loss = 167.93, entropy_loss = -8.2488, pg_loss = 27.719, baseline_loss = 148.46, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:04,604[0m][[34mroot[0m][[32mINFO[0m] - Step 401920 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1315.4, step = 401920, mean_episode_return = 0.28925, mean_episode_step = 90.735, total_loss = -31.78, entropy_loss = -8.2264, pg_loss = -138.34, baseline_loss = 114.79, learner_queue_size = 32, _tick = 156, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:09,609[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1320.4, step = 404480, mean_episode_return = 0.33126, mean_episode_step = 70.732, total_loss = 1091.1, entropy_loss = -8.2305, pg_loss = 883.48, baseline_loss = 215.83, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:14,615[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1325.4, step = 404480, mean_episode_return = 0.33126, mean_episode_step = 70.732, total_loss = 1091.1, entropy_loss = -8.2305, pg_loss = 883.48, baseline_loss = 215.83, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:19,620[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1330.4, step = 407040, mean_episode_return = 0.26863, mean_episode_step = 88.369, total_loss = -446.36, entropy_loss = -8.2275, pg_loss = -543.71, baseline_loss = 105.57, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:24,626[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1335.4, step = 407040, mean_episode_return = 0.26863, mean_episode_step = 88.369, total_loss = -446.36, entropy_loss = -8.2275, pg_loss = -543.71, baseline_loss = 105.57, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:29,631[0m][[34mroot[0m][[32mINFO[0m] - Step 409600 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1340.4, step = 409600, mean_episode_return = 0.24315, mean_episode_step = 84.858, total_loss = -684.88, entropy_loss = -8.2254, pg_loss = -744.54, baseline_loss = 67.885, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:34,637[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1345.4, step = 412160, mean_episode_return = 0.23063, mean_episode_step = 68.097, total_loss = 1355.0, entropy_loss = -8.2308, pg_loss = 1142.8, baseline_loss = 220.47, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:39,643[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1350.4, step = 412160, mean_episode_return = 0.23063, mean_episode_step = 68.097, total_loss = 1355.0, entropy_loss = -8.2308, pg_loss = 1142.8, baseline_loss = 220.47, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:44,648[0m][[34mroot[0m][[32mINFO[0m] - Step 414720 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1355.4, step = 414720, mean_episode_return = 0.23447, mean_episode_step = 66.987, total_loss = -337.49, entropy_loss = -8.2483, pg_loss = -462.53, baseline_loss = 133.29, learner_queue_size = 32, _tick = 161, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:49,653[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1360.4, step = 417280, mean_episode_return = 0.42655, mean_episode_step = 89.995, total_loss = 626.33, entropy_loss = -8.2175, pg_loss = 481.91, baseline_loss = 152.64, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:54,658[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1365.4, step = 417280, mean_episode_return = 0.42655, mean_episode_step = 89.995, total_loss = 626.33, entropy_loss = -8.2175, pg_loss = 481.91, baseline_loss = 152.64, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:24:59,663[0m][[34mroot[0m][[32mINFO[0m] - Step 419840 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1370.4, step = 419840, mean_episode_return = 0.23868, mean_episode_step = 82.532, total_loss = -78.718, entropy_loss = -8.2214, pg_loss = -172.52, baseline_loss = 102.02, learner_queue_size = 32, _tick = 163, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:04,668[0m][[34mroot[0m][[32mINFO[0m] - Step 419840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1375.4, step = 419840, mean_episode_return = 0.23868, mean_episode_step = 82.532, total_loss = -78.718, entropy_loss = -8.2214, pg_loss = -172.52, baseline_loss = 102.02, learner_queue_size = 32, _tick = 163, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:09,673[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1380.4, step = 422400, mean_episode_return = 0.23681, mean_episode_step = 78.746, total_loss = 878.28, entropy_loss = -8.2224, pg_loss = 678.44, baseline_loss = 208.07, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:14,679[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1385.4, step = 424960, mean_episode_return = 0.23373, mean_episode_step = 79.652, total_loss = 375.24, entropy_loss = -8.234, pg_loss = 192.18, baseline_loss = 191.29, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:19,685[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1390.5, step = 424960, mean_episode_return = 0.23373, mean_episode_step = 79.652, total_loss = 375.24, entropy_loss = -8.234, pg_loss = 192.18, baseline_loss = 191.29, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:24,690[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1395.5, step = 427520, mean_episode_return = 0.14941, mean_episode_step = 68.203, total_loss = -83.39, entropy_loss = -8.2185, pg_loss = -209.16, baseline_loss = 133.99, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:29,695[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1400.5, step = 427520, mean_episode_return = 0.14941, mean_episode_step = 68.203, total_loss = -83.39, entropy_loss = -8.2185, pg_loss = -209.16, baseline_loss = 133.99, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:34,700[0m][[34mroot[0m][[32mINFO[0m] - Step 430080 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1405.5, step = 430080, mean_episode_return = 0.35025, mean_episode_step = 72.529, total_loss = 303.42, entropy_loss = -8.2135, pg_loss = 156.44, baseline_loss = 155.2, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:39,705[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1410.5, step = 432640, mean_episode_return = 0.17133, mean_episode_step = 72.018, total_loss = -786.26, entropy_loss = -8.2379, pg_loss = -895.68, baseline_loss = 117.66, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:44,710[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1415.5, step = 432640, mean_episode_return = 0.17133, mean_episode_step = 72.018, total_loss = -786.26, entropy_loss = -8.2379, pg_loss = -895.68, baseline_loss = 117.66, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:49,715[0m][[34mroot[0m][[32mINFO[0m] - Step 435200 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1420.5, step = 435200, mean_episode_return = 0.3132, mean_episode_step = 80.074, total_loss = -266.94, entropy_loss = -8.2167, pg_loss = -379.27, baseline_loss = 120.54, learner_queue_size = 32, _tick = 169, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:54,720[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1425.5, step = 437760, mean_episode_return = 0.26434, mean_episode_step = 72.77, total_loss = 785.49, entropy_loss = -8.2154, pg_loss = 581.13, baseline_loss = 212.57, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:25:59,727[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1430.5, step = 437760, mean_episode_return = 0.26434, mean_episode_step = 72.77, total_loss = 785.49, entropy_loss = -8.2154, pg_loss = 581.13, baseline_loss = 212.57, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:04,732[0m][[34mroot[0m][[32mINFO[0m] - Step 440320 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1435.5, step = 440320, mean_episode_return = 0.20992, mean_episode_step = 81.259, total_loss = 607.41, entropy_loss = -8.2106, pg_loss = 436.48, baseline_loss = 179.14, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:09,737[0m][[34mroot[0m][[32mINFO[0m] - Step 440320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1440.5, step = 440320, mean_episode_return = 0.20992, mean_episode_step = 81.259, total_loss = 607.41, entropy_loss = -8.2106, pg_loss = 436.48, baseline_loss = 179.14, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:14,742[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1445.5, step = 442880, mean_episode_return = 0.29715, mean_episode_step = 80.487, total_loss = -5.5288, entropy_loss = -8.2149, pg_loss = -158.89, baseline_loss = 161.57, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:19,748[0m][[34mroot[0m][[32mINFO[0m] - Step 445440 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1450.5, step = 445440, mean_episode_return = 0.19907, mean_episode_step = 64.849, total_loss = 792.28, entropy_loss = -8.2381, pg_loss = 567.29, baseline_loss = 233.23, learner_queue_size = 32, _tick = 173, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:24,753[0m][[34mroot[0m][[32mINFO[0m] - Step 445440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1455.5, step = 445440, mean_episode_return = 0.19907, mean_episode_step = 64.849, total_loss = 792.28, entropy_loss = -8.2381, pg_loss = 567.29, baseline_loss = 233.23, learner_queue_size = 32, _tick = 173, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:29,759[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1460.5, step = 448000, mean_episode_return = 0.269, mean_episode_step = 80.782, total_loss = -39.296, entropy_loss = -8.2195, pg_loss = -154.16, baseline_loss = 123.09, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:34,764[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1465.5, step = 448000, mean_episode_return = 0.269, mean_episode_step = 80.782, total_loss = -39.296, entropy_loss = -8.2195, pg_loss = -154.16, baseline_loss = 123.09, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:39,769[0m][[34mroot[0m][[32mINFO[0m] - Step 450560 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1470.5, step = 450560, mean_episode_return = 0.27731, mean_episode_step = 86.321, total_loss = -116.9, entropy_loss = -8.2322, pg_loss = -242.58, baseline_loss = 133.91, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:44,774[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1475.5, step = 453120, mean_episode_return = 0.20305, mean_episode_step = 77.017, total_loss = 69.373, entropy_loss = -8.2496, pg_loss = -99.888, baseline_loss = 177.51, learner_queue_size = 32, _tick = 176, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:49,780[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1480.5, step = 453120, mean_episode_return = 0.20305, mean_episode_step = 77.017, total_loss = 69.373, entropy_loss = -8.2496, pg_loss = -99.888, baseline_loss = 177.51, learner_queue_size = 32, _tick = 176, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:54,785[0m][[34mroot[0m][[32mINFO[0m] - Step 455680 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1485.6, step = 455680, mean_episode_return = 0.22498, mean_episode_step = 59.802, total_loss = 102.78, entropy_loss = -8.2401, pg_loss = -59.801, baseline_loss = 170.82, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:26:59,790[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1490.6, step = 458240, mean_episode_return = 0.28137, mean_episode_step = 69.042, total_loss = 920.26, entropy_loss = -8.2181, pg_loss = 702.93, baseline_loss = 225.55, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:04,796[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1495.6, step = 458240, mean_episode_return = 0.28137, mean_episode_step = 69.042, total_loss = 920.26, entropy_loss = -8.2181, pg_loss = 702.93, baseline_loss = 225.55, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:09,801[0m][[34mroot[0m][[32mINFO[0m] - Step 460800 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1500.6, step = 460800, mean_episode_return = 0.4473, mean_episode_step = 76.661, total_loss = 1020.2, entropy_loss = -8.2225, pg_loss = 776.7, baseline_loss = 251.68, learner_queue_size = 32, _tick = 179, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:14,806[0m][[34mroot[0m][[32mINFO[0m] - Step 460800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1505.6, step = 460800, mean_episode_return = 0.4473, mean_episode_step = 76.661, total_loss = 1020.2, entropy_loss = -8.2225, pg_loss = 776.7, baseline_loss = 251.68, learner_queue_size = 32, _tick = 179, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:19,811[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1510.6, step = 463360, mean_episode_return = 0.27814, mean_episode_step = 73.229, total_loss = 1299.5, entropy_loss = -8.2137, pg_loss = 1061.0, baseline_loss = 246.72, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:24,817[0m][[34mroot[0m][[32mINFO[0m] - Step 465920 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1515.6, step = 465920, mean_episode_return = 0.1619, mean_episode_step = 87.236, total_loss = 279.72, entropy_loss = -8.2156, pg_loss = 120.77, baseline_loss = 167.16, learner_queue_size = 32, _tick = 181, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:29,822[0m][[34mroot[0m][[32mINFO[0m] - Step 465920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1520.6, step = 465920, mean_episode_return = 0.1619, mean_episode_step = 87.236, total_loss = 279.72, entropy_loss = -8.2156, pg_loss = 120.77, baseline_loss = 167.16, learner_queue_size = 32, _tick = 181, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:34,829[0m][[34mroot[0m][[32mINFO[0m] - Step 468480 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1525.6, step = 468480, mean_episode_return = 0.18759, mean_episode_step = 90.03, total_loss = 78.245, entropy_loss = -8.2197, pg_loss = -113.96, baseline_loss = 200.42, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:39,834[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1530.6, step = 471040, mean_episode_return = 0.20338, mean_episode_step = 75.375, total_loss = -54.619, entropy_loss = -8.2228, pg_loss = -197.95, baseline_loss = 151.55, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:44,839[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1535.6, step = 471040, mean_episode_return = 0.20338, mean_episode_step = 75.375, total_loss = -54.619, entropy_loss = -8.2228, pg_loss = -197.95, baseline_loss = 151.55, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:49,846[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 511.3 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1540.6, step = 473600, mean_episode_return = 0.28017, mean_episode_step = 70.85, total_loss = -150.38, entropy_loss = -8.2224, pg_loss = -302.32, baseline_loss = 160.16, learner_queue_size = 32, _tick = 184, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:54,851[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1545.6, step = 473600, mean_episode_return = 0.28017, mean_episode_step = 70.85, total_loss = -150.38, entropy_loss = -8.2224, pg_loss = -302.32, baseline_loss = 160.16, learner_queue_size = 32, _tick = 184, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:27:59,856[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1550.6, step = 476160, mean_episode_return = 0.25091, mean_episode_step = 92.664, total_loss = -100.09, entropy_loss = -8.1975, pg_loss = -218.12, baseline_loss = 126.23, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:04,861[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1555.6, step = 476160, mean_episode_return = 0.25091, mean_episode_step = 92.664, total_loss = -100.09, entropy_loss = -8.1975, pg_loss = -218.12, baseline_loss = 126.23, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:09,866[0m][[34mroot[0m][[32mINFO[0m] - Step 478720 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1560.6, step = 478720, mean_episode_return = 0.27306, mean_episode_step = 81.881, total_loss = 114.84, entropy_loss = -8.2139, pg_loss = -57.407, baseline_loss = 180.47, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:14,871[0m][[34mroot[0m][[32mINFO[0m] - Step 481280 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1565.6, step = 481280, mean_episode_return = 0.22748, mean_episode_step = 85.871, total_loss = 122.29, entropy_loss = -8.1945, pg_loss = 14.111, baseline_loss = 116.37, learner_queue_size = 32, _tick = 187, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:19,876[0m][[34mroot[0m][[32mINFO[0m] - Step 481280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1570.6, step = 481280, mean_episode_return = 0.22748, mean_episode_step = 85.871, total_loss = 122.29, entropy_loss = -8.1945, pg_loss = 14.111, baseline_loss = 116.37, learner_queue_size = 32, _tick = 187, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:24,882[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1575.6, step = 483840, mean_episode_return = 0.17803, mean_episode_step = 64.07, total_loss = 174.06, entropy_loss = -8.2189, pg_loss = 6.2348, baseline_loss = 176.04, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:29,887[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1580.7, step = 486400, mean_episode_return = 0.24632, mean_episode_step = 78.745, total_loss = -265.36, entropy_loss = -8.2268, pg_loss = -414.36, baseline_loss = 157.23, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:34,892[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1585.7, step = 486400, mean_episode_return = 0.24632, mean_episode_step = 78.745, total_loss = -265.36, entropy_loss = -8.2268, pg_loss = -414.36, baseline_loss = 157.23, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:39,897[0m][[34mroot[0m][[32mINFO[0m] - Step 488960 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1590.7, step = 488960, mean_episode_return = 0.24769, mean_episode_step = 77.666, total_loss = -786.15, entropy_loss = -8.2221, pg_loss = -858.86, baseline_loss = 80.929, learner_queue_size = 32, _tick = 190, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:44,902[0m][[34mroot[0m][[32mINFO[0m] - Step 488960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1595.7, step = 488960, mean_episode_return = 0.24769, mean_episode_step = 77.666, total_loss = -786.15, entropy_loss = -8.2221, pg_loss = -858.86, baseline_loss = 80.929, learner_queue_size = 32, _tick = 190, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:49,907[0m][[34mroot[0m][[32mINFO[0m] - Step 491520 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1600.7, step = 491520, mean_episode_return = 0.14121, mean_episode_step = 75.855, total_loss = 253.73, entropy_loss = -8.2164, pg_loss = 107.3, baseline_loss = 154.65, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:54,915[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1605.7, step = 494080, mean_episode_return = 0.26574, mean_episode_step = 70.055, total_loss = -539.72, entropy_loss = -8.2181, pg_loss = -644.16, baseline_loss = 112.67, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:28:59,920[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1610.7, step = 494080, mean_episode_return = 0.26574, mean_episode_step = 70.055, total_loss = -539.72, entropy_loss = -8.2181, pg_loss = -644.16, baseline_loss = 112.67, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:29:04,925[0m][[34mroot[0m][[32mINFO[0m] - Step 496640 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1615.7, step = 496640, mean_episode_return = 0.29074, mean_episode_step = 81.207, total_loss = -395.96, entropy_loss = -8.2155, pg_loss = -508.92, baseline_loss = 121.18, learner_queue_size = 32, _tick = 193, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:29:09,930[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1620.7, step = 499200, mean_episode_return = 0.19026, mean_episode_step = 81.141, total_loss = -329.36, entropy_loss = -8.2172, pg_loss = -451.52, baseline_loss = 130.37, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:29:14,935[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1625.7, step = 499200, mean_episode_return = 0.19026, mean_episode_step = 81.141, total_loss = -329.36, entropy_loss = -8.2172, pg_loss = -451.52, baseline_loss = 130.37, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:29:19,941[0m][[34mroot[0m][[32mINFO[0m] - Step 501760 @ 511.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1630.7, step = 501760, mean_episode_return = 0.24819, mean_episode_step = 64.341, total_loss = 996.87, entropy_loss = -8.2233, pg_loss = 739.76, baseline_loss = 265.34, learner_queue_size = 32, _tick = 195, _time = 1.7371e+09)[0m
[[36m2025-01-17 21:29:19,942[0m][[34mroot[0m][[32mINFO[0m] - Learning finished after 501760 steps.[0m
[[36m2025-01-17 21:29:19,942[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-17 21:33:01,759[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,789[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,791[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,763[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,733[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,759[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,758[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,727[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,727[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,750[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,736[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,788[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,781[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,729[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,756[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,831[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,727[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,827[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,730[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,742[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,730[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,839[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,812[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,862[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,766[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,800[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,802[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,861[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,792[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,807[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,836[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,744[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,822[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,843[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,727[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,772[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,772[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,741[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,771[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,867[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,799[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,667[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,797[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,791[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,880[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,792[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,588[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,732[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,805[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,788[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,813[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,869[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,878[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,799[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,867[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,851[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,818[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,884[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,791[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,805[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,787[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,908[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,840[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,871[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,894[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,808[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,120[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,863[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,907[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,132[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,867[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,817[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,869[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,896[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,828[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,932[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,901[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,846[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,895[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,906[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,910[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,969[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,074[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,916[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,863[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,914[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,845[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,924[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,066[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,898[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,962[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,069[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,115[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,958[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,801[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,958[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,914[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,911[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,969[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,869[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,125[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,882[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,156[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,126[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,906[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,124[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,801[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,149[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,148[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,131[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,124[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:01,912[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,132[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,128[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,129[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,071[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,125[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,874[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,154[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,152[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,129[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,336[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,096[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,155[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,138[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,154[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,154[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,129[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,153[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,168[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,056[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,149[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,149[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,136[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,141[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,208[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,158[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,128[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,830[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,159[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,152[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,153[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,208[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,171[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,164[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,199[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,142[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,212[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,225[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,122[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,276[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,169[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,171[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,155[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,150[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,142[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,720[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,154[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,156[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,263[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,155[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,122[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,786[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,210[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,323[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,788[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,336[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,150[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,191[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,187[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,783[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 21:33:01,857[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,156[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,878[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,787[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,282[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,785[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,169[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,158[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,803[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,849[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,900[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,873[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,279[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,892[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,156[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,780[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,939[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 21:33:02,963[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
