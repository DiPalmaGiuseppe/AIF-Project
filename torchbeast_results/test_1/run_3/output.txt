[[36m2025-01-18 16:36:33,667[0m][[34mroot[0m][[32mINFO[0m] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
[0m
[[36m2025-01-18 16:36:33,718[0m][[34mroot[0m][[32mINFO[0m] - Symlinked log directory: /opt/minihack/latest[0m
[[36m2025-01-18 16:36:33,718[0m][[34mroot[0m][[32mINFO[0m] - Found archive directory: /opt/minihack/archives[0m
[[36m2025-01-18 16:36:33,723[0m][[34mroot[0m][[32mINFO[0m] - Logging results to /opt/minihack[0m
[[36m2025-01-18 16:36:33,759[0m][[34mpalaas/out[0m][[32mINFO[0m] - Found log directory: /opt/minihack[0m
[[36m2025-01-18 16:36:33,759[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving arguments to /opt/minihack/meta.json[0m
[[36m2025-01-18 16:36:33,760[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving messages to /opt/minihack/out.log[0m
[[36m2025-01-18 16:36:33,760[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs data to /opt/minihack/logs.csv[0m
[[36m2025-01-18 16:36:33,760[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs' fields to /opt/minihack/fields.csv[0m
[[36m2025-01-18 16:36:33,761[0m][[34mroot[0m][[32mINFO[0m] - Not using CUDA.[0m
[[36m2025-01-18 16:36:33,770[0m][[34mroot[0m][[32mINFO[0m] - Using model baseline[0m
[[36m2025-01-18 16:36:33,770[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,863[0m][[34mroot[0m][[32mINFO[0m] - Number of model parameters: 4264078[0m
[[36m2025-01-18 16:36:33,864[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,937[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,937[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,937[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,939[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,939[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
First Environment waiting for connection to unix:/tmp/poly..opt.minihack.0 ... connection established.
[[36m2025-01-18 16:36:33,941[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,942[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,937[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,943[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,944[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,944[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,945[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,946[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,946[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,946[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,947[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,945[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,948[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,948[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,949[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,941[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,950[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,950[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,947[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,947[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,942[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,938[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,939[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,952[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,952[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,951[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,954[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,945[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,957[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,956[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,960[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,961[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,957[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,963[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,963[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,957[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,965[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,965[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,966[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,966[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,967[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,970[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,971[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,941[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,973[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,961[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,974[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,975[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,976[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,943[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,976[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,970[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:33,969[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,031[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,941[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,941[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,942[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,947[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,947[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,953[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,953[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,953[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,953[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,956[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,959[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,960[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,960[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,941[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,961[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,961[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,963[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,964[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,964[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,964[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,970[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,970[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,970[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,973[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,974[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,974[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,975[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,963[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,959[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,977[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,978[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,978[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,979[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,980[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,980[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,981[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,982[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,982[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,982[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,985[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,985[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,985[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,986[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,977[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,987[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,987[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,989[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,990[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,990[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,994[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,995[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,995[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,995[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,995[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,988[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,997[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,998[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,998[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,000[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,002[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,002[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,004[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,989[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,005[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,007[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,972[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,008[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,992[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,969[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,010[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,982[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,010[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,012[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,013[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,014[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,014[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,014[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,016[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,017[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,976[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,020[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,021[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,022[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,024[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,024[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,024[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,025[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,026[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,026[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,004[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,009[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,028[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,978[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,992[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,030[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,015[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,032[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,010[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,979[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,038[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,041[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,042[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,033[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,044[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,008[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,023[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,046[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,039[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,051[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,052[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,054[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,054[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,039[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,033[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,059[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,059[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,061[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,064[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,066[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,068[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,070[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,071[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,055[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,074[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,004[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,080[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,088[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,041[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,092[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,094[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,098[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,105[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,109[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,112[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,114[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,116[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:34,967[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,125[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,127[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,130[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,132[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,135[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,137[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,142[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,132[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,145[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,146[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,154[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,157[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,158[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,161[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,161[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,164[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,166[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,169[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,171[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,166[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,174[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,174[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,101[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,177[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,177[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,177[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,179[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,179[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,180[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,180[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,180[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,181[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,182[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,182[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,182[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,078[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,165[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,187[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,173[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,169[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,189[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,189[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,150[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:35,085[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,271[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,299[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,346[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,364[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,370[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,401[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,503[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,611[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,636[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,645[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,670[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,737[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,755[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,799[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,850[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:36,882[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-18 16:36:38,935[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 25. Learner queue size: 0. Other stats: (train_seconds = 5.0)[0m
[[36m2025-01-18 16:36:43,940[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 42. Learner queue size: 29. Other stats: (train_seconds = 10.0)[0m
[[36m2025-01-18 16:36:48,947[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 15.0)[0m
[[36m2025-01-18 16:36:52,421[0m][[34mpalaas/out[0m][[32mINFO[0m] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size'][0m
[[36m2025-01-18 16:36:53,954[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.tar[0m
[[36m2025-01-18 16:36:54,029[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 511.4 SPS. Inference batcher size: 79. Learner queue size: 2. Other stats: (train_seconds = 20.0, step = 2560, mean_episode_return = -0.052917, mean_episode_step = 36.412, total_loss = -2487.7, entropy_loss = -11.371, pg_loss = -2518.1, baseline_loss = 41.83, learner_queue_size = 32, _tick = 0, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:36:59,034[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 50. Learner queue size: 5. Other stats: (train_seconds = 25.1, step = 2560, mean_episode_return = -0.052917, mean_episode_step = 36.412, total_loss = -2487.7, entropy_loss = -11.371, pg_loss = -2518.1, baseline_loss = 41.83, learner_queue_size = 32, _tick = 0, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:04,040[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 511.5 SPS. Inference batcher size: 40. Learner queue size: 7. Other stats: (train_seconds = 30.1, step = 5120, mean_episode_return = -0.03495, mean_episode_step = 32.234, total_loss = 1001.9, entropy_loss = -11.347, pg_loss = 881.74, baseline_loss = 131.5, learner_queue_size = 6, _tick = 1, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:09,046[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 150. Learner queue size: 7. Other stats: (train_seconds = 35.1, step = 5120, mean_episode_return = -0.03495, mean_episode_step = 32.234, total_loss = 1001.9, entropy_loss = -11.347, pg_loss = 881.74, baseline_loss = 131.5, learner_queue_size = 6, _tick = 1, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:14,053[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (train_seconds = 40.1, step = 5120, mean_episode_return = -0.03495, mean_episode_step = 32.234, total_loss = 1001.9, entropy_loss = -11.347, pg_loss = 881.74, baseline_loss = 131.5, learner_queue_size = 6, _tick = 1, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:19,059[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 45.1, step = 5120, mean_episode_return = -0.03495, mean_episode_step = 32.234, total_loss = 1001.9, entropy_loss = -11.347, pg_loss = 881.74, baseline_loss = 131.5, learner_queue_size = 6, _tick = 1, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:24,064[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 50.1, step = 7680, mean_episode_return = -0.065296, mean_episode_step = 51.289, total_loss = -799.27, entropy_loss = -11.366, pg_loss = -794.83, baseline_loss = 6.9319, learner_queue_size = 32, _tick = 2, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:29,071[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 511.3 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 55.1, step = 10240, mean_episode_return = -0.084421, mean_episode_step = 67.814, total_loss = 970.51, entropy_loss = -11.29, pg_loss = 866.5, baseline_loss = 115.3, learner_queue_size = 32, _tick = 3, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:34,076[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 60.1, step = 10240, mean_episode_return = -0.084421, mean_episode_step = 67.814, total_loss = 970.51, entropy_loss = -11.29, pg_loss = 866.5, baseline_loss = 115.3, learner_queue_size = 32, _tick = 3, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:39,082[0m][[34mroot[0m][[32mINFO[0m] - Step 12800 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 65.2, step = 12800, mean_episode_return = 0.023692, mean_episode_step = 51.076, total_loss = -243.61, entropy_loss = -11.324, pg_loss = -242.79, baseline_loss = 10.502, learner_queue_size = 32, _tick = 4, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:44,087[0m][[34mroot[0m][[32mINFO[0m] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 70.2, step = 12800, mean_episode_return = 0.023692, mean_episode_step = 51.076, total_loss = -243.61, entropy_loss = -11.324, pg_loss = -242.79, baseline_loss = 10.502, learner_queue_size = 32, _tick = 4, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:49,092[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 75.2, step = 15360, mean_episode_return = -0.046233, mean_episode_step = 38.767, total_loss = 1612.7, entropy_loss = -11.321, pg_loss = 1514.6, baseline_loss = 109.44, learner_queue_size = 32, _tick = 5, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:54,098[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 80.2, step = 15360, mean_episode_return = -0.046233, mean_episode_step = 38.767, total_loss = 1612.7, entropy_loss = -11.321, pg_loss = 1514.6, baseline_loss = 109.44, learner_queue_size = 32, _tick = 5, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:37:59,103[0m][[34mroot[0m][[32mINFO[0m] - Step 17920 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 85.2, step = 17920, mean_episode_return = -0.0797, mean_episode_step = 56.136, total_loss = -461.46, entropy_loss = -11.356, pg_loss = -453.1, baseline_loss = 3.0026, learner_queue_size = 32, _tick = 6, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:04,109[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 90.2, step = 20480, mean_episode_return = -0.062433, mean_episode_step = 44.109, total_loss = 899.37, entropy_loss = -11.33, pg_loss = 863.15, baseline_loss = 47.548, learner_queue_size = 32, _tick = 7, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:09,114[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 95.2, step = 20480, mean_episode_return = -0.062433, mean_episode_step = 44.109, total_loss = 899.37, entropy_loss = -11.33, pg_loss = 863.15, baseline_loss = 47.548, learner_queue_size = 32, _tick = 7, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:14,119[0m][[34mroot[0m][[32mINFO[0m] - Step 23040 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 100.2, step = 23040, mean_episode_return = -0.021958, mean_episode_step = 52.742, total_loss = 1119.7, entropy_loss = -11.36, pg_loss = 918.83, baseline_loss = 212.2, learner_queue_size = 32, _tick = 8, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:19,125[0m][[34mroot[0m][[32mINFO[0m] - Step 23040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 105.2, step = 23040, mean_episode_return = -0.021958, mean_episode_step = 52.742, total_loss = 1119.7, entropy_loss = -11.36, pg_loss = 918.83, baseline_loss = 212.2, learner_queue_size = 32, _tick = 8, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:24,130[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 110.2, step = 25600, mean_episode_return = -0.081143, mean_episode_step = 50.623, total_loss = -586.05, entropy_loss = -11.365, pg_loss = -580.93, baseline_loss = 6.243, learner_queue_size = 32, _tick = 9, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:29,136[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 115.2, step = 25600, mean_episode_return = -0.081143, mean_episode_step = 50.623, total_loss = -586.05, entropy_loss = -11.365, pg_loss = -580.93, baseline_loss = 6.243, learner_queue_size = 32, _tick = 9, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:34,141[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 120.2, step = 28160, mean_episode_return = -0.013655, mean_episode_step = 45.039, total_loss = 1022.1, entropy_loss = -11.341, pg_loss = 919.22, baseline_loss = 114.23, learner_queue_size = 32, _tick = 10, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:39,147[0m][[34mroot[0m][[32mINFO[0m] - Step 30720 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 125.2, step = 30720, mean_episode_return = -0.013645, mean_episode_step = 45.437, total_loss = 22.929, entropy_loss = -11.36, pg_loss = -85.381, baseline_loss = 119.67, learner_queue_size = 32, _tick = 11, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:44,153[0m][[34mroot[0m][[32mINFO[0m] - Step 30720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 130.2, step = 30720, mean_episode_return = -0.013645, mean_episode_step = 45.437, total_loss = 22.929, entropy_loss = -11.36, pg_loss = -85.381, baseline_loss = 119.67, learner_queue_size = 32, _tick = 11, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:49,158[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 135.2, step = 33280, mean_episode_return = -0.073458, mean_episode_step = 57.111, total_loss = -52.16, entropy_loss = -11.331, pg_loss = -76.272, baseline_loss = 35.443, learner_queue_size = 32, _tick = 12, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:54,163[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 140.2, step = 33280, mean_episode_return = -0.073458, mean_episode_step = 57.111, total_loss = -52.16, entropy_loss = -11.331, pg_loss = -76.272, baseline_loss = 35.443, learner_queue_size = 32, _tick = 12, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:38:59,169[0m][[34mroot[0m][[32mINFO[0m] - Step 35840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 145.2, step = 35840, mean_episode_return = -0.04408, mean_episode_step = 69.94, total_loss = 265.69, entropy_loss = -11.243, pg_loss = 255.04, baseline_loss = 21.898, learner_queue_size = 32, _tick = 13, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:04,174[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 150.2, step = 38400, mean_episode_return = 0.017111, mean_episode_step = 54.016, total_loss = 815.4, entropy_loss = -11.261, pg_loss = 673.74, baseline_loss = 152.92, learner_queue_size = 32, _tick = 14, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:09,180[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 155.2, step = 38400, mean_episode_return = 0.017111, mean_episode_step = 54.016, total_loss = 815.4, entropy_loss = -11.261, pg_loss = 673.74, baseline_loss = 152.92, learner_queue_size = 32, _tick = 14, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:14,184[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 160.3, step = 40960, mean_episode_return = -0.086067, mean_episode_step = 54.086, total_loss = -261.37, entropy_loss = -11.252, pg_loss = -327.83, baseline_loss = 77.709, learner_queue_size = 32, _tick = 15, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:19,189[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 165.3, step = 40960, mean_episode_return = -0.086067, mean_episode_step = 54.086, total_loss = -261.37, entropy_loss = -11.252, pg_loss = -327.83, baseline_loss = 77.709, learner_queue_size = 32, _tick = 15, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:24,195[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 170.3, step = 43520, mean_episode_return = -0.0042308, mean_episode_step = 46.599, total_loss = 819.25, entropy_loss = -11.283, pg_loss = 633.85, baseline_loss = 196.68, learner_queue_size = 32, _tick = 16, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:29,200[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 175.3, step = 43520, mean_episode_return = -0.0042308, mean_episode_step = 46.599, total_loss = 819.25, entropy_loss = -11.283, pg_loss = 633.85, baseline_loss = 196.68, learner_queue_size = 32, _tick = 16, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:34,205[0m][[34mroot[0m][[32mINFO[0m] - Step 46080 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 180.3, step = 46080, mean_episode_return = -0.027914, mean_episode_step = 50.487, total_loss = -541.82, entropy_loss = -11.227, pg_loss = -533.01, baseline_loss = 2.4098, learner_queue_size = 32, _tick = 17, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:39,211[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 185.3, step = 48640, mean_episode_return = -0.068731, mean_episode_step = 57.993, total_loss = 403.44, entropy_loss = -11.244, pg_loss = 312.51, baseline_loss = 102.18, learner_queue_size = 32, _tick = 18, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:44,216[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 190.3, step = 48640, mean_episode_return = -0.068731, mean_episode_step = 57.993, total_loss = 403.44, entropy_loss = -11.244, pg_loss = 312.51, baseline_loss = 102.18, learner_queue_size = 32, _tick = 18, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:49,221[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 195.3, step = 51200, mean_episode_return = -0.034278, mean_episode_step = 49.784, total_loss = 351.33, entropy_loss = -11.207, pg_loss = 235.27, baseline_loss = 127.26, learner_queue_size = 32, _tick = 19, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:54,227[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 200.3, step = 51200, mean_episode_return = -0.034278, mean_episode_step = 49.784, total_loss = 351.33, entropy_loss = -11.207, pg_loss = 235.27, baseline_loss = 127.26, learner_queue_size = 32, _tick = 19, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:39:59,231[0m][[34mroot[0m][[32mINFO[0m] - Step 53760 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 205.3, step = 53760, mean_episode_return = -0.055161, mean_episode_step = 51.257, total_loss = -672.79, entropy_loss = -11.136, pg_loss = -665.67, baseline_loss = 4.0159, learner_queue_size = 32, _tick = 20, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:04,237[0m][[34mroot[0m][[32mINFO[0m] - Step 56320 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 210.3, step = 56320, mean_episode_return = -0.0097143, mean_episode_step = 44.316, total_loss = 386.09, entropy_loss = -11.158, pg_loss = 257.89, baseline_loss = 139.35, learner_queue_size = 32, _tick = 21, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:09,242[0m][[34mroot[0m][[32mINFO[0m] - Step 56320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 215.3, step = 56320, mean_episode_return = -0.0097143, mean_episode_step = 44.316, total_loss = 386.09, entropy_loss = -11.158, pg_loss = 257.89, baseline_loss = 139.35, learner_queue_size = 32, _tick = 21, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:14,247[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 220.3, step = 58880, mean_episode_return = -0.063833, mean_episode_step = 56.171, total_loss = -295.0, entropy_loss = -11.09, pg_loss = -329.34, baseline_loss = 45.43, learner_queue_size = 32, _tick = 22, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:19,252[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 225.3, step = 58880, mean_episode_return = -0.063833, mean_episode_step = 56.171, total_loss = -295.0, entropy_loss = -11.09, pg_loss = -329.34, baseline_loss = 45.43, learner_queue_size = 32, _tick = 22, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:24,257[0m][[34mroot[0m][[32mINFO[0m] - Step 61440 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 230.3, step = 61440, mean_episode_return = -0.023766, mean_episode_step = 49.254, total_loss = -8.9627, entropy_loss = -11.081, pg_loss = -40.619, baseline_loss = 42.737, learner_queue_size = 32, _tick = 23, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:29,264[0m][[34mroot[0m][[32mINFO[0m] - Step 61440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 235.3, step = 61440, mean_episode_return = -0.023766, mean_episode_step = 49.254, total_loss = -8.9627, entropy_loss = -11.081, pg_loss = -40.619, baseline_loss = 42.737, learner_queue_size = 32, _tick = 23, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:34,269[0m][[34mroot[0m][[32mINFO[0m] - Step 64000 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 240.3, step = 64000, mean_episode_return = -0.014, mean_episode_step = 42.768, total_loss = 386.59, entropy_loss = -11.073, pg_loss = 328.52, baseline_loss = 69.134, learner_queue_size = 32, _tick = 24, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:39,274[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 245.3, step = 66560, mean_episode_return = -0.013116, mean_episode_step = 53.663, total_loss = 556.9, entropy_loss = -11.059, pg_loss = 390.5, baseline_loss = 177.46, learner_queue_size = 32, _tick = 25, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:44,279[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 250.3, step = 66560, mean_episode_return = -0.013116, mean_episode_step = 53.663, total_loss = 556.9, entropy_loss = -11.059, pg_loss = 390.5, baseline_loss = 177.46, learner_queue_size = 32, _tick = 25, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:49,284[0m][[34mroot[0m][[32mINFO[0m] - Step 69120 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 255.4, step = 69120, mean_episode_return = -0.056302, mean_episode_step = 47.517, total_loss = -596.6, entropy_loss = -11.021, pg_loss = -588.25, baseline_loss = 2.6693, learner_queue_size = 32, _tick = 26, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:54,290[0m][[34mroot[0m][[32mINFO[0m] - Step 69120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 260.4, step = 69120, mean_episode_return = -0.056302, mean_episode_step = 47.517, total_loss = -596.6, entropy_loss = -11.021, pg_loss = -588.25, baseline_loss = 2.6693, learner_queue_size = 32, _tick = 26, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:40:59,296[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 265.4, step = 71680, mean_episode_return = -0.03802, mean_episode_step = 40.36, total_loss = -266.34, entropy_loss = -11.006, pg_loss = -257.33, baseline_loss = 1.988, learner_queue_size = 32, _tick = 27, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:04,301[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 270.4, step = 74240, mean_episode_return = -0.0147, mean_episode_step = 52.13, total_loss = 585.48, entropy_loss = -10.912, pg_loss = 488.67, baseline_loss = 107.72, learner_queue_size = 32, _tick = 28, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:09,306[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 275.4, step = 74240, mean_episode_return = -0.0147, mean_episode_step = 52.13, total_loss = 585.48, entropy_loss = -10.912, pg_loss = 488.67, baseline_loss = 107.72, learner_queue_size = 32, _tick = 28, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:14,312[0m][[34mroot[0m][[32mINFO[0m] - Step 76800 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 280.4, step = 76800, mean_episode_return = -0.042283, mean_episode_step = 39.497, total_loss = -75.338, entropy_loss = -10.905, pg_loss = -95.519, baseline_loss = 31.086, learner_queue_size = 32, _tick = 29, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:19,319[0m][[34mroot[0m][[32mINFO[0m] - Step 76800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 285.4, step = 76800, mean_episode_return = -0.042283, mean_episode_step = 39.497, total_loss = -75.338, entropy_loss = -10.905, pg_loss = -95.519, baseline_loss = 31.086, learner_queue_size = 32, _tick = 29, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:24,324[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 290.4, step = 79360, mean_episode_return = -0.0055098, mean_episode_step = 41.534, total_loss = 1057.5, entropy_loss = -10.803, pg_loss = 869.17, baseline_loss = 199.1, learner_queue_size = 32, _tick = 30, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:29,329[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 295.4, step = 79360, mean_episode_return = -0.0055098, mean_episode_step = 41.534, total_loss = 1057.5, entropy_loss = -10.803, pg_loss = 869.17, baseline_loss = 199.1, learner_queue_size = 32, _tick = 30, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:34,335[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 300.4, step = 81920, mean_episode_return = -0.04469, mean_episode_step = 48.06, total_loss = -277.25, entropy_loss = -10.823, pg_loss = -268.8, baseline_loss = 2.3691, learner_queue_size = 32, _tick = 31, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:39,340[0m][[34mroot[0m][[32mINFO[0m] - Step 84480 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 305.4, step = 84480, mean_episode_return = -0.020044, mean_episode_step = 43.384, total_loss = 564.71, entropy_loss = -10.73, pg_loss = 447.26, baseline_loss = 128.18, learner_queue_size = 32, _tick = 32, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:44,345[0m][[34mroot[0m][[32mINFO[0m] - Step 84480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 310.4, step = 84480, mean_episode_return = -0.020044, mean_episode_step = 43.384, total_loss = 564.71, entropy_loss = -10.73, pg_loss = 447.26, baseline_loss = 128.18, learner_queue_size = 32, _tick = 32, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:49,351[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 315.4, step = 87040, mean_episode_return = -0.023674, mean_episode_step = 48.062, total_loss = 560.7, entropy_loss = -10.739, pg_loss = 396.87, baseline_loss = 174.56, learner_queue_size = 32, _tick = 33, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:54,356[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 320.4, step = 87040, mean_episode_return = -0.023674, mean_episode_step = 48.062, total_loss = 560.7, entropy_loss = -10.739, pg_loss = 396.87, baseline_loss = 174.56, learner_queue_size = 32, _tick = 33, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:41:59,361[0m][[34mroot[0m][[32mINFO[0m] - Step 89600 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 325.4, step = 89600, mean_episode_return = 0.017258, mean_episode_step = 39.209, total_loss = 971.94, entropy_loss = -10.755, pg_loss = 664.1, baseline_loss = 318.6, learner_queue_size = 32, _tick = 34, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:04,367[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 330.4, step = 92160, mean_episode_return = -0.0030784, mean_episode_step = 44.078, total_loss = -37.34, entropy_loss = -10.694, pg_loss = -192.26, baseline_loss = 165.62, learner_queue_size = 32, _tick = 35, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:09,372[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 335.4, step = 92160, mean_episode_return = -0.0030784, mean_episode_step = 44.078, total_loss = -37.34, entropy_loss = -10.694, pg_loss = -192.26, baseline_loss = 165.62, learner_queue_size = 32, _tick = 35, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:14,378[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 340.4, step = 94720, mean_episode_return = -0.022348, mean_episode_step = 45.359, total_loss = 152.44, entropy_loss = -10.622, pg_loss = 9.2167, baseline_loss = 153.84, learner_queue_size = 32, _tick = 36, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:19,384[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 345.5, step = 94720, mean_episode_return = -0.022348, mean_episode_step = 45.359, total_loss = 152.44, entropy_loss = -10.622, pg_loss = 9.2167, baseline_loss = 153.84, learner_queue_size = 32, _tick = 36, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:24,390[0m][[34mroot[0m][[32mINFO[0m] - Step 97280 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 350.5, step = 97280, mean_episode_return = -0.016262, mean_episode_step = 41.425, total_loss = 106.22, entropy_loss = -10.43, pg_loss = 7.8573, baseline_loss = 108.8, learner_queue_size = 32, _tick = 37, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:29,395[0m][[34mroot[0m][[32mINFO[0m] - Step 97280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 355.5, step = 97280, mean_episode_return = -0.016262, mean_episode_step = 41.425, total_loss = 106.22, entropy_loss = -10.43, pg_loss = 7.8573, baseline_loss = 108.8, learner_queue_size = 32, _tick = 37, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:34,400[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 360.5, step = 99840, mean_episode_return = -0.017603, mean_episode_step = 48.027, total_loss = -170.43, entropy_loss = -10.446, pg_loss = -209.39, baseline_loss = 49.406, learner_queue_size = 32, _tick = 38, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:39,406[0m][[34mroot[0m][[32mINFO[0m] - Step 102400 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 365.5, step = 102400, mean_episode_return = -0.031892, mean_episode_step = 33.732, total_loss = -42.508, entropy_loss = -10.41, pg_loss = -60.696, baseline_loss = 28.598, learner_queue_size = 32, _tick = 39, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:44,411[0m][[34mroot[0m][[32mINFO[0m] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 370.5, step = 102400, mean_episode_return = -0.031892, mean_episode_step = 33.732, total_loss = -42.508, entropy_loss = -10.41, pg_loss = -60.696, baseline_loss = 28.598, learner_queue_size = 32, _tick = 39, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:49,417[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 375.5, step = 104960, mean_episode_return = -0.026131, mean_episode_step = 45.961, total_loss = 892.23, entropy_loss = -10.298, pg_loss = 709.1, baseline_loss = 193.42, learner_queue_size = 32, _tick = 40, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:54,422[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 380.5, step = 104960, mean_episode_return = -0.026131, mean_episode_step = 45.961, total_loss = 892.23, entropy_loss = -10.298, pg_loss = 709.1, baseline_loss = 193.42, learner_queue_size = 32, _tick = 40, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:42:59,429[0m][[34mroot[0m][[32mINFO[0m] - Step 107520 @ 511.3 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 385.5, step = 107520, mean_episode_return = -0.032411, mean_episode_step = 41.866, total_loss = 1206.5, entropy_loss = -10.269, pg_loss = 924.73, baseline_loss = 292.0, learner_queue_size = 32, _tick = 41, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:04,434[0m][[34mroot[0m][[32mINFO[0m] - Step 110080 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 390.5, step = 110080, mean_episode_return = 0.02753, mean_episode_step = 42.467, total_loss = -337.05, entropy_loss = -10.316, pg_loss = -438.48, baseline_loss = 111.74, learner_queue_size = 32, _tick = 42, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:09,439[0m][[34mroot[0m][[32mINFO[0m] - Step 110080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 395.5, step = 110080, mean_episode_return = 0.02753, mean_episode_step = 42.467, total_loss = -337.05, entropy_loss = -10.316, pg_loss = -438.48, baseline_loss = 111.74, learner_queue_size = 32, _tick = 42, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:14,444[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 400.5, step = 112640, mean_episode_return = -0.003948, mean_episode_step = 40.15, total_loss = -140.36, entropy_loss = -10.326, pg_loss = -210.23, baseline_loss = 80.196, learner_queue_size = 32, _tick = 43, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:19,449[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 405.5, step = 112640, mean_episode_return = -0.003948, mean_episode_step = 40.15, total_loss = -140.36, entropy_loss = -10.326, pg_loss = -210.23, baseline_loss = 80.196, learner_queue_size = 32, _tick = 43, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:24,455[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 410.5, step = 115200, mean_episode_return = -0.036333, mean_episode_step = 38.543, total_loss = 2224.8, entropy_loss = -10.292, pg_loss = 1721.4, baseline_loss = 513.69, learner_queue_size = 32, _tick = 44, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:29,460[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 415.5, step = 115200, mean_episode_return = -0.036333, mean_episode_step = 38.543, total_loss = 2224.8, entropy_loss = -10.292, pg_loss = 1721.4, baseline_loss = 513.69, learner_queue_size = 32, _tick = 44, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:34,466[0m][[34mroot[0m][[32mINFO[0m] - Step 117760 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 420.5, step = 117760, mean_episode_return = -0.00099995, mean_episode_step = 46.425, total_loss = -601.86, entropy_loss = -10.313, pg_loss = -595.04, baseline_loss = 3.4891, learner_queue_size = 32, _tick = 45, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:39,470[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 425.5, step = 120320, mean_episode_return = 0.043471, mean_episode_step = 32.119, total_loss = 504.2, entropy_loss = -10.326, pg_loss = 403.79, baseline_loss = 110.73, learner_queue_size = 32, _tick = 46, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:44,475[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 430.5, step = 120320, mean_episode_return = 0.043471, mean_episode_step = 32.119, total_loss = 504.2, entropy_loss = -10.326, pg_loss = 403.79, baseline_loss = 110.73, learner_queue_size = 32, _tick = 46, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:49,481[0m][[34mroot[0m][[32mINFO[0m] - Step 122880 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 435.5, step = 122880, mean_episode_return = -0.0071746, mean_episode_step = 43.892, total_loss = 983.29, entropy_loss = -10.328, pg_loss = 684.82, baseline_loss = 308.8, learner_queue_size = 32, _tick = 47, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:54,487[0m][[34mroot[0m][[32mINFO[0m] - Step 122880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 440.6, step = 122880, mean_episode_return = -0.0071746, mean_episode_step = 43.892, total_loss = 983.29, entropy_loss = -10.328, pg_loss = 684.82, baseline_loss = 308.8, learner_queue_size = 32, _tick = 47, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:43:59,492[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar[0m
[[36m2025-01-18 16:43:59,536[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 445.6, step = 125440, mean_episode_return = -0.011982, mean_episode_step = 42.246, total_loss = 279.76, entropy_loss = -10.273, pg_loss = 24.369, baseline_loss = 265.67, learner_queue_size = 32, _tick = 48, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:04,541[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 450.6, step = 125440, mean_episode_return = -0.011982, mean_episode_step = 42.246, total_loss = 279.76, entropy_loss = -10.273, pg_loss = 24.369, baseline_loss = 265.67, learner_queue_size = 32, _tick = 48, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:09,546[0m][[34mroot[0m][[32mINFO[0m] - Step 128000 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 455.6, step = 128000, mean_episode_return = -0.010034, mean_episode_step = 48.887, total_loss = -515.28, entropy_loss = -10.351, pg_loss = -563.82, baseline_loss = 58.889, learner_queue_size = 32, _tick = 49, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:14,551[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 460.6, step = 130560, mean_episode_return = 0.022654, mean_episode_step = 39.439, total_loss = 1285.4, entropy_loss = -10.389, pg_loss = 963.87, baseline_loss = 331.95, learner_queue_size = 32, _tick = 50, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:19,557[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 465.6, step = 130560, mean_episode_return = 0.022654, mean_episode_step = 39.439, total_loss = 1285.4, entropy_loss = -10.389, pg_loss = 963.87, baseline_loss = 331.95, learner_queue_size = 32, _tick = 50, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:24,562[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 470.6, step = 133120, mean_episode_return = -0.0070323, mean_episode_step = 37.455, total_loss = 42.447, entropy_loss = -10.387, pg_loss = -115.49, baseline_loss = 168.33, learner_queue_size = 32, _tick = 51, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:29,567[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 475.6, step = 133120, mean_episode_return = -0.0070323, mean_episode_step = 37.455, total_loss = 42.447, entropy_loss = -10.387, pg_loss = -115.49, baseline_loss = 168.33, learner_queue_size = 32, _tick = 51, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:34,572[0m][[34mroot[0m][[32mINFO[0m] - Step 135680 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 480.6, step = 135680, mean_episode_return = 0.045867, mean_episode_step = 47.073, total_loss = 140.71, entropy_loss = -10.249, pg_loss = 6.2023, baseline_loss = 144.76, learner_queue_size = 32, _tick = 52, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:39,578[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 485.6, step = 138240, mean_episode_return = -0.0023421, mean_episode_step = 41.285, total_loss = 290.13, entropy_loss = -10.332, pg_loss = 115.48, baseline_loss = 184.98, learner_queue_size = 32, _tick = 53, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:44,583[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 490.7, step = 138240, mean_episode_return = -0.0023421, mean_episode_step = 41.285, total_loss = 290.13, entropy_loss = -10.332, pg_loss = 115.48, baseline_loss = 184.98, learner_queue_size = 32, _tick = 53, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:49,588[0m][[34mroot[0m][[32mINFO[0m] - Step 140800 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 495.7, step = 140800, mean_episode_return = -0.0092647, mean_episode_step = 43.275, total_loss = -289.75, entropy_loss = -10.25, pg_loss = -366.93, baseline_loss = 87.427, learner_queue_size = 32, _tick = 54, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:54,593[0m][[34mroot[0m][[32mINFO[0m] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 500.7, step = 140800, mean_episode_return = -0.0092647, mean_episode_step = 43.275, total_loss = -289.75, entropy_loss = -10.25, pg_loss = -366.93, baseline_loss = 87.427, learner_queue_size = 32, _tick = 54, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:44:59,598[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 505.7, step = 143360, mean_episode_return = -0.0088889, mean_episode_step = 52.321, total_loss = 108.53, entropy_loss = -10.292, pg_loss = 23.864, baseline_loss = 94.961, learner_queue_size = 32, _tick = 55, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:04,604[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 510.7, step = 143360, mean_episode_return = -0.0088889, mean_episode_step = 52.321, total_loss = 108.53, entropy_loss = -10.292, pg_loss = 23.864, baseline_loss = 94.961, learner_queue_size = 32, _tick = 55, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:09,606[0m][[34mroot[0m][[32mINFO[0m] - Step 145920 @ 511.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 515.7, step = 145920, mean_episode_return = 0.044213, mean_episode_step = 36.557, total_loss = 135.41, entropy_loss = -10.224, pg_loss = -31.756, baseline_loss = 177.39, learner_queue_size = 32, _tick = 56, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:14,611[0m][[34mroot[0m][[32mINFO[0m] - Step 148480 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 520.7, step = 148480, mean_episode_return = -0.023123, mean_episode_step = 39.96, total_loss = -198.31, entropy_loss = -10.173, pg_loss = -255.24, baseline_loss = 67.102, learner_queue_size = 32, _tick = 57, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:19,616[0m][[34mroot[0m][[32mINFO[0m] - Step 148480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 525.7, step = 148480, mean_episode_return = -0.023123, mean_episode_step = 39.96, total_loss = -198.31, entropy_loss = -10.173, pg_loss = -255.24, baseline_loss = 67.102, learner_queue_size = 32, _tick = 57, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:24,621[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 530.7, step = 151040, mean_episode_return = -0.030585, mean_episode_step = 48.184, total_loss = -185.22, entropy_loss = -10.135, pg_loss = -201.0, baseline_loss = 25.92, learner_queue_size = 32, _tick = 58, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:29,626[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 535.7, step = 151040, mean_episode_return = -0.030585, mean_episode_step = 48.184, total_loss = -185.22, entropy_loss = -10.135, pg_loss = -201.0, baseline_loss = 25.92, learner_queue_size = 32, _tick = 58, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:34,631[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 540.7, step = 153600, mean_episode_return = 0.0080121, mean_episode_step = 50.987, total_loss = 1156.9, entropy_loss = -10.073, pg_loss = 955.34, baseline_loss = 211.66, learner_queue_size = 32, _tick = 59, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:39,636[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 545.7, step = 153600, mean_episode_return = 0.0080121, mean_episode_step = 50.987, total_loss = 1156.9, entropy_loss = -10.073, pg_loss = 955.34, baseline_loss = 211.66, learner_queue_size = 32, _tick = 59, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:44,641[0m][[34mroot[0m][[32mINFO[0m] - Step 156160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 550.7, step = 156160, mean_episode_return = 0.036, mean_episode_step = 45.959, total_loss = 1041.4, entropy_loss = -10.077, pg_loss = 746.47, baseline_loss = 305.02, learner_queue_size = 32, _tick = 60, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:49,646[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 555.7, step = 158720, mean_episode_return = 0.037222, mean_episode_step = 32.293, total_loss = 1118.9, entropy_loss = -10.073, pg_loss = 718.16, baseline_loss = 410.86, learner_queue_size = 32, _tick = 61, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:54,649[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 560.7, step = 158720, mean_episode_return = 0.037222, mean_episode_step = 32.293, total_loss = 1118.9, entropy_loss = -10.073, pg_loss = 718.16, baseline_loss = 410.86, learner_queue_size = 32, _tick = 61, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:45:59,656[0m][[34mroot[0m][[32mINFO[0m] - Step 161280 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 565.7, step = 161280, mean_episode_return = 0.024103, mean_episode_step = 58.334, total_loss = 1295.9, entropy_loss = -10.09, pg_loss = 877.32, baseline_loss = 428.66, learner_queue_size = 32, _tick = 62, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:04,661[0m][[34mroot[0m][[32mINFO[0m] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 570.7, step = 161280, mean_episode_return = 0.024103, mean_episode_step = 58.334, total_loss = 1295.9, entropy_loss = -10.09, pg_loss = 877.32, baseline_loss = 428.66, learner_queue_size = 32, _tick = 62, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:09,667[0m][[34mroot[0m][[32mINFO[0m] - Step 163840 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 575.7, step = 163840, mean_episode_return = 0.053788, mean_episode_step = 37.936, total_loss = 109.43, entropy_loss = -10.095, pg_loss = -186.16, baseline_loss = 305.68, learner_queue_size = 32, _tick = 63, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:14,673[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 580.7, step = 166400, mean_episode_return = 0.036048, mean_episode_step = 39.871, total_loss = -440.47, entropy_loss = -9.913, pg_loss = -579.6, baseline_loss = 149.04, learner_queue_size = 32, _tick = 64, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:19,678[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 585.7, step = 166400, mean_episode_return = 0.036048, mean_episode_step = 39.871, total_loss = -440.47, entropy_loss = -9.913, pg_loss = -579.6, baseline_loss = 149.04, learner_queue_size = 32, _tick = 64, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:24,683[0m][[34mroot[0m][[32mINFO[0m] - Step 168960 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 590.8, step = 168960, mean_episode_return = 0.01106, mean_episode_step = 56.248, total_loss = 450.22, entropy_loss = -9.9425, pg_loss = 221.62, baseline_loss = 238.55, learner_queue_size = 32, _tick = 65, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:29,688[0m][[34mroot[0m][[32mINFO[0m] - Step 168960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 595.8, step = 168960, mean_episode_return = 0.01106, mean_episode_step = 56.248, total_loss = 450.22, entropy_loss = -9.9425, pg_loss = 221.62, baseline_loss = 238.55, learner_queue_size = 32, _tick = 65, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:34,695[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-18 16:46:34,730[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 600.8, step = 171520, mean_episode_return = 0.027897, mean_episode_step = 41.155, total_loss = -685.99, entropy_loss = -9.9711, pg_loss = -789.31, baseline_loss = 113.29, learner_queue_size = 32, _tick = 66, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:39,736[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 605.8, step = 171520, mean_episode_return = 0.027897, mean_episode_step = 41.155, total_loss = -685.99, entropy_loss = -9.9711, pg_loss = -789.31, baseline_loss = 113.29, learner_queue_size = 32, _tick = 66, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:44,742[0m][[34mroot[0m][[32mINFO[0m] - Step 174080 @ 511.3 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 610.8, step = 174080, mean_episode_return = 0.085873, mean_episode_step = 41.057, total_loss = 851.66, entropy_loss = -9.987, pg_loss = 577.51, baseline_loss = 284.13, learner_queue_size = 32, _tick = 67, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:49,748[0m][[34mroot[0m][[32mINFO[0m] - Step 176640 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 615.8, step = 176640, mean_episode_return = 0.0037229, mean_episode_step = 41.146, total_loss = -883.99, entropy_loss = -9.9574, pg_loss = -953.76, baseline_loss = 79.726, learner_queue_size = 32, _tick = 68, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:54,753[0m][[34mroot[0m][[32mINFO[0m] - Step 176640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 620.8, step = 176640, mean_episode_return = 0.0037229, mean_episode_step = 41.146, total_loss = -883.99, entropy_loss = -9.9574, pg_loss = -953.76, baseline_loss = 79.726, learner_queue_size = 32, _tick = 68, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:46:59,758[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 625.8, step = 179200, mean_episode_return = 0.069047, mean_episode_step = 50.576, total_loss = 1936.0, entropy_loss = -9.9358, pg_loss = 1429.9, baseline_loss = 516.1, learner_queue_size = 32, _tick = 69, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:04,763[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 630.8, step = 179200, mean_episode_return = 0.069047, mean_episode_step = 50.576, total_loss = 1936.0, entropy_loss = -9.9358, pg_loss = 1429.9, baseline_loss = 516.1, learner_queue_size = 32, _tick = 69, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:09,768[0m][[34mroot[0m][[32mINFO[0m] - Step 181760 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 635.8, step = 181760, mean_episode_return = 0.033614, mean_episode_step = 32.612, total_loss = 1351.6, entropy_loss = -9.9532, pg_loss = 871.43, baseline_loss = 490.09, learner_queue_size = 32, _tick = 70, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:14,773[0m][[34mroot[0m][[32mINFO[0m] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 640.8, step = 181760, mean_episode_return = 0.033614, mean_episode_step = 32.612, total_loss = 1351.6, entropy_loss = -9.9532, pg_loss = 871.43, baseline_loss = 490.09, learner_queue_size = 32, _tick = 70, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:19,778[0m][[34mroot[0m][[32mINFO[0m] - Step 184320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 645.8, step = 184320, mean_episode_return = 0.044194, mean_episode_step = 53.593, total_loss = -1195.0, entropy_loss = -9.9223, pg_loss = -1271.8, baseline_loss = 86.688, learner_queue_size = 32, _tick = 71, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:24,784[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 650.9, step = 186880, mean_episode_return = 0.048184, mean_episode_step = 49.119, total_loss = -295.49, entropy_loss = -9.9506, pg_loss = -445.01, baseline_loss = 159.47, learner_queue_size = 32, _tick = 72, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:29,789[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 655.9, step = 186880, mean_episode_return = 0.048184, mean_episode_step = 49.119, total_loss = -295.49, entropy_loss = -9.9506, pg_loss = -445.01, baseline_loss = 159.47, learner_queue_size = 32, _tick = 72, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:34,796[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 660.9, step = 189440, mean_episode_return = 0.0027067, mean_episode_step = 36.965, total_loss = 484.96, entropy_loss = -9.983, pg_loss = 249.13, baseline_loss = 245.81, learner_queue_size = 32, _tick = 73, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:39,801[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 665.9, step = 189440, mean_episode_return = 0.0027067, mean_episode_step = 36.965, total_loss = 484.96, entropy_loss = -9.983, pg_loss = 249.13, baseline_loss = 245.81, learner_queue_size = 32, _tick = 73, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:44,806[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 670.9, step = 192000, mean_episode_return = 0.0438, mean_episode_step = 54.721, total_loss = 839.15, entropy_loss = -9.8793, pg_loss = 521.92, baseline_loss = 327.11, learner_queue_size = 32, _tick = 74, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:49,811[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 675.9, step = 192000, mean_episode_return = 0.0438, mean_episode_step = 54.721, total_loss = 839.15, entropy_loss = -9.8793, pg_loss = 521.92, baseline_loss = 327.11, learner_queue_size = 32, _tick = 74, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:54,816[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 680.9, step = 194560, mean_episode_return = -0.021718, mean_episode_step = 36.077, total_loss = -817.72, entropy_loss = -9.8941, pg_loss = -914.06, baseline_loss = 106.23, learner_queue_size = 32, _tick = 75, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:47:59,822[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 685.9, step = 194560, mean_episode_return = -0.021718, mean_episode_step = 36.077, total_loss = -817.72, entropy_loss = -9.8941, pg_loss = -914.06, baseline_loss = 106.23, learner_queue_size = 32, _tick = 75, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:04,830[0m][[34mroot[0m][[32mINFO[0m] - Step 197120 @ 511.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 690.9, step = 197120, mean_episode_return = -0.012797, mean_episode_step = 48.33, total_loss = -372.04, entropy_loss = -9.8889, pg_loss = -485.82, baseline_loss = 123.66, learner_queue_size = 32, _tick = 76, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:09,834[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 695.9, step = 199680, mean_episode_return = 0.067792, mean_episode_step = 39.7, total_loss = 1236.4, entropy_loss = -9.8861, pg_loss = 855.78, baseline_loss = 390.46, learner_queue_size = 32, _tick = 77, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:14,839[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 700.9, step = 199680, mean_episode_return = 0.067792, mean_episode_step = 39.7, total_loss = 1236.4, entropy_loss = -9.8861, pg_loss = 855.78, baseline_loss = 390.46, learner_queue_size = 32, _tick = 77, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:19,844[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 705.9, step = 199680, mean_episode_return = 0.067792, mean_episode_step = 39.7, total_loss = 1236.4, entropy_loss = -9.8861, pg_loss = 855.78, baseline_loss = 390.46, learner_queue_size = 32, _tick = 77, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:24,849[0m][[34mroot[0m][[32mINFO[0m] - Step 202240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 710.9, step = 202240, mean_episode_return = 0.0098955, mean_episode_step = 57.313, total_loss = 292.46, entropy_loss = -9.8593, pg_loss = 54.385, baseline_loss = 247.93, learner_queue_size = 32, _tick = 78, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:29,854[0m][[34mroot[0m][[32mINFO[0m] - Step 202240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 715.9, step = 202240, mean_episode_return = 0.0098955, mean_episode_step = 57.313, total_loss = 292.46, entropy_loss = -9.8593, pg_loss = 54.385, baseline_loss = 247.93, learner_queue_size = 32, _tick = 78, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:34,859[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 720.9, step = 204800, mean_episode_return = -0.0068642, mean_episode_step = 33.917, total_loss = -247.42, entropy_loss = -9.8232, pg_loss = -413.81, baseline_loss = 176.21, learner_queue_size = 32, _tick = 79, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:39,865[0m][[34mroot[0m][[32mINFO[0m] - Step 207360 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 725.9, step = 207360, mean_episode_return = 0.0056227, mean_episode_step = 51.839, total_loss = -207.29, entropy_loss = -9.8029, pg_loss = -308.01, baseline_loss = 110.53, learner_queue_size = 32, _tick = 80, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:44,871[0m][[34mroot[0m][[32mINFO[0m] - Step 207360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 730.9, step = 207360, mean_episode_return = 0.0056227, mean_episode_step = 51.839, total_loss = -207.29, entropy_loss = -9.8029, pg_loss = -308.01, baseline_loss = 110.53, learner_queue_size = 32, _tick = 80, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:49,878[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 735.9, step = 209920, mean_episode_return = 0.056329, mean_episode_step = 47.116, total_loss = 499.96, entropy_loss = -9.8628, pg_loss = 293.09, baseline_loss = 216.74, learner_queue_size = 32, _tick = 81, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:54,883[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 741.0, step = 209920, mean_episode_return = 0.056329, mean_episode_step = 47.116, total_loss = 499.96, entropy_loss = -9.8628, pg_loss = 293.09, baseline_loss = 216.74, learner_queue_size = 32, _tick = 81, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:48:59,888[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 746.0, step = 212480, mean_episode_return = -0.014882, mean_episode_step = 53.107, total_loss = 361.62, entropy_loss = -9.8896, pg_loss = 169.72, baseline_loss = 201.79, learner_queue_size = 32, _tick = 82, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:04,893[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 751.0, step = 212480, mean_episode_return = -0.014882, mean_episode_step = 53.107, total_loss = 361.62, entropy_loss = -9.8896, pg_loss = 169.72, baseline_loss = 201.79, learner_queue_size = 32, _tick = 82, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:09,898[0m][[34mroot[0m][[32mINFO[0m] - Step 215040 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 756.0, step = 215040, mean_episode_return = 0.03966, mean_episode_step = 50.395, total_loss = -366.13, entropy_loss = -9.8236, pg_loss = -473.39, baseline_loss = 117.08, learner_queue_size = 32, _tick = 83, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:14,903[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 761.0, step = 217600, mean_episode_return = 0.033607, mean_episode_step = 60.071, total_loss = 328.81, entropy_loss = -9.8404, pg_loss = 94.225, baseline_loss = 244.43, learner_queue_size = 32, _tick = 84, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:19,908[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 766.0, step = 217600, mean_episode_return = 0.033607, mean_episode_step = 60.071, total_loss = 328.81, entropy_loss = -9.8404, pg_loss = 94.225, baseline_loss = 244.43, learner_queue_size = 32, _tick = 84, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:24,913[0m][[34mroot[0m][[32mINFO[0m] - Step 220160 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 771.0, step = 220160, mean_episode_return = 0.064906, mean_episode_step = 58.34, total_loss = -382.85, entropy_loss = -9.8909, pg_loss = -472.42, baseline_loss = 99.459, learner_queue_size = 32, _tick = 85, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:29,918[0m][[34mroot[0m][[32mINFO[0m] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 776.0, step = 220160, mean_episode_return = 0.064906, mean_episode_step = 58.34, total_loss = -382.85, entropy_loss = -9.8909, pg_loss = -472.42, baseline_loss = 99.459, learner_queue_size = 32, _tick = 85, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:34,924[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 781.0, step = 222720, mean_episode_return = 0.029286, mean_episode_step = 50.374, total_loss = 1052.8, entropy_loss = -9.8695, pg_loss = 768.84, baseline_loss = 293.8, learner_queue_size = 32, _tick = 86, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:39,929[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 786.0, step = 222720, mean_episode_return = 0.029286, mean_episode_step = 50.374, total_loss = 1052.8, entropy_loss = -9.8695, pg_loss = 768.84, baseline_loss = 293.8, learner_queue_size = 32, _tick = 86, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:44,935[0m][[34mroot[0m][[32mINFO[0m] - Step 225280 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 791.0, step = 225280, mean_episode_return = 0.084551, mean_episode_step = 52.858, total_loss = 1195.3, entropy_loss = -9.8876, pg_loss = 887.47, baseline_loss = 317.71, learner_queue_size = 32, _tick = 87, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:49,940[0m][[34mroot[0m][[32mINFO[0m] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 796.0, step = 225280, mean_episode_return = 0.084551, mean_episode_step = 52.858, total_loss = 1195.3, entropy_loss = -9.8876, pg_loss = 887.47, baseline_loss = 317.71, learner_queue_size = 32, _tick = 87, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:54,945[0m][[34mroot[0m][[32mINFO[0m] - Step 227840 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 801.0, step = 227840, mean_episode_return = 0.057138, mean_episode_step = 62.875, total_loss = 1414.9, entropy_loss = -9.8494, pg_loss = 992.54, baseline_loss = 432.21, learner_queue_size = 32, _tick = 88, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:49:59,950[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 806.0, step = 230400, mean_episode_return = 0.062313, mean_episode_step = 52.02, total_loss = 915.27, entropy_loss = -9.8774, pg_loss = 517.87, baseline_loss = 407.28, learner_queue_size = 32, _tick = 89, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:04,955[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 811.0, step = 230400, mean_episode_return = 0.062313, mean_episode_step = 52.02, total_loss = 915.27, entropy_loss = -9.8774, pg_loss = 517.87, baseline_loss = 407.28, learner_queue_size = 32, _tick = 89, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:09,961[0m][[34mroot[0m][[32mINFO[0m] - Step 232960 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 816.0, step = 232960, mean_episode_return = 0.052903, mean_episode_step = 44.287, total_loss = -492.24, entropy_loss = -9.912, pg_loss = -721.03, baseline_loss = 238.7, learner_queue_size = 32, _tick = 90, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:14,966[0m][[34mroot[0m][[32mINFO[0m] - Step 232960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 821.0, step = 232960, mean_episode_return = 0.052903, mean_episode_step = 44.287, total_loss = -492.24, entropy_loss = -9.912, pg_loss = -721.03, baseline_loss = 238.7, learner_queue_size = 32, _tick = 90, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:19,972[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 826.0, step = 235520, mean_episode_return = 0.022542, mean_episode_step = 45.838, total_loss = 253.21, entropy_loss = -9.9015, pg_loss = -6.0205, baseline_loss = 269.13, learner_queue_size = 32, _tick = 91, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:24,977[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 831.0, step = 235520, mean_episode_return = 0.022542, mean_episode_step = 45.838, total_loss = 253.21, entropy_loss = -9.9015, pg_loss = -6.0205, baseline_loss = 269.13, learner_queue_size = 32, _tick = 91, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:29,990[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 510.7 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 836.1, step = 238080, mean_episode_return = 0.1573, mean_episode_step = 66.026, total_loss = 1036.3, entropy_loss = -9.8128, pg_loss = 672.49, baseline_loss = 373.67, learner_queue_size = 32, _tick = 92, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:34,995[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 841.1, step = 238080, mean_episode_return = 0.1573, mean_episode_step = 66.026, total_loss = 1036.3, entropy_loss = -9.8128, pg_loss = 672.49, baseline_loss = 373.67, learner_queue_size = 32, _tick = 92, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:40,000[0m][[34mroot[0m][[32mINFO[0m] - Step 240640 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 846.1, step = 240640, mean_episode_return = 0.051129, mean_episode_step = 43.638, total_loss = 1408.7, entropy_loss = -9.8147, pg_loss = 985.33, baseline_loss = 433.17, learner_queue_size = 32, _tick = 93, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:45,007[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 851.1, step = 243200, mean_episode_return = 0.024271, mean_episode_step = 41.243, total_loss = -1017.5, entropy_loss = -9.7565, pg_loss = -1175.2, baseline_loss = 167.46, learner_queue_size = 32, _tick = 94, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:50,013[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 856.1, step = 243200, mean_episode_return = 0.024271, mean_episode_step = 41.243, total_loss = -1017.5, entropy_loss = -9.7565, pg_loss = -1175.2, baseline_loss = 167.46, learner_queue_size = 32, _tick = 94, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:50:55,019[0m][[34mroot[0m][[32mINFO[0m] - Step 245760 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 861.1, step = 245760, mean_episode_return = 0.072965, mean_episode_step = 55.661, total_loss = -453.05, entropy_loss = -9.7399, pg_loss = -580.58, baseline_loss = 137.27, learner_queue_size = 32, _tick = 95, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:00,024[0m][[34mroot[0m][[32mINFO[0m] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 866.1, step = 245760, mean_episode_return = 0.072965, mean_episode_step = 55.661, total_loss = -453.05, entropy_loss = -9.7399, pg_loss = -580.58, baseline_loss = 137.27, learner_queue_size = 32, _tick = 95, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:05,030[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 511.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 871.1, step = 248320, mean_episode_return = 0.011785, mean_episode_step = 48.445, total_loss = 298.06, entropy_loss = -9.7661, pg_loss = 43.589, baseline_loss = 264.24, learner_queue_size = 32, _tick = 96, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:10,035[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 876.1, step = 248320, mean_episode_return = 0.011785, mean_episode_step = 48.445, total_loss = 298.06, entropy_loss = -9.7661, pg_loss = 43.589, baseline_loss = 264.24, learner_queue_size = 32, _tick = 96, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:15,040[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar[0m
[[36m2025-01-18 16:51:15,084[0m][[34mroot[0m][[32mINFO[0m] - Step 250880 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 881.1, step = 250880, mean_episode_return = 0.071824, mean_episode_step = 55.205, total_loss = 52.385, entropy_loss = -9.7683, pg_loss = -141.39, baseline_loss = 203.54, learner_queue_size = 32, _tick = 97, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:20,089[0m][[34mroot[0m][[32mINFO[0m] - Step 250880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 886.2, step = 250880, mean_episode_return = 0.071824, mean_episode_step = 55.205, total_loss = 52.385, entropy_loss = -9.7683, pg_loss = -141.39, baseline_loss = 203.54, learner_queue_size = 32, _tick = 97, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:25,095[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 891.2, step = 253440, mean_episode_return = 0.086884, mean_episode_step = 51.095, total_loss = 758.49, entropy_loss = -9.7852, pg_loss = 489.13, baseline_loss = 279.14, learner_queue_size = 32, _tick = 98, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:30,099[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 896.2, step = 253440, mean_episode_return = 0.086884, mean_episode_step = 51.095, total_loss = 758.49, entropy_loss = -9.7852, pg_loss = 489.13, baseline_loss = 279.14, learner_queue_size = 32, _tick = 98, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:35,107[0m][[34mroot[0m][[32mINFO[0m] - Step 256000 @ 511.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 901.2, step = 256000, mean_episode_return = 0.08125, mean_episode_step = 50.959, total_loss = 645.48, entropy_loss = -9.7327, pg_loss = 338.64, baseline_loss = 316.58, learner_queue_size = 32, _tick = 99, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:40,113[0m][[34mroot[0m][[32mINFO[0m] - Step 258560 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 906.2, step = 258560, mean_episode_return = 0.057231, mean_episode_step = 53.181, total_loss = -74.911, entropy_loss = -9.6675, pg_loss = -271.25, baseline_loss = 206.01, learner_queue_size = 32, _tick = 100, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:45,118[0m][[34mroot[0m][[32mINFO[0m] - Step 258560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 911.2, step = 258560, mean_episode_return = 0.057231, mean_episode_step = 53.181, total_loss = -74.911, entropy_loss = -9.6675, pg_loss = -271.25, baseline_loss = 206.01, learner_queue_size = 32, _tick = 100, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:50,124[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 916.2, step = 261120, mean_episode_return = 0.10014, mean_episode_step = 67.019, total_loss = 444.81, entropy_loss = -9.6426, pg_loss = 240.89, baseline_loss = 213.57, learner_queue_size = 32, _tick = 101, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:51:55,129[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 921.2, step = 261120, mean_episode_return = 0.10014, mean_episode_step = 67.019, total_loss = 444.81, entropy_loss = -9.6426, pg_loss = 240.89, baseline_loss = 213.57, learner_queue_size = 32, _tick = 101, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:00,134[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 926.2, step = 263680, mean_episode_return = 0.043033, mean_episode_step = 52.73, total_loss = -114.87, entropy_loss = -9.6129, pg_loss = -275.02, baseline_loss = 169.77, learner_queue_size = 32, _tick = 102, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:05,139[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 931.2, step = 263680, mean_episode_return = 0.043033, mean_episode_step = 52.73, total_loss = -114.87, entropy_loss = -9.6129, pg_loss = -275.02, baseline_loss = 169.77, learner_queue_size = 32, _tick = 102, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:10,144[0m][[34mroot[0m][[32mINFO[0m] - Step 266240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 936.2, step = 266240, mean_episode_return = 0.11018, mean_episode_step = 58.418, total_loss = 455.78, entropy_loss = -9.6677, pg_loss = 190.43, baseline_loss = 275.02, learner_queue_size = 32, _tick = 103, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:15,150[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 941.2, step = 268800, mean_episode_return = 0.08018, mean_episode_step = 40.784, total_loss = -566.77, entropy_loss = -9.6631, pg_loss = -710.01, baseline_loss = 152.9, learner_queue_size = 32, _tick = 104, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:20,155[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 946.2, step = 268800, mean_episode_return = 0.08018, mean_episode_step = 40.784, total_loss = -566.77, entropy_loss = -9.6631, pg_loss = -710.01, baseline_loss = 152.9, learner_queue_size = 32, _tick = 104, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:25,160[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 951.2, step = 271360, mean_episode_return = 0.072654, mean_episode_step = 52.58, total_loss = 595.14, entropy_loss = -9.6444, pg_loss = 343.03, baseline_loss = 261.75, learner_queue_size = 32, _tick = 105, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:30,166[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 956.2, step = 271360, mean_episode_return = 0.072654, mean_episode_step = 52.58, total_loss = 595.14, entropy_loss = -9.6444, pg_loss = 343.03, baseline_loss = 261.75, learner_queue_size = 32, _tick = 105, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:35,171[0m][[34mroot[0m][[32mINFO[0m] - Step 273920 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 961.2, step = 273920, mean_episode_return = 0.046346, mean_episode_step = 70.7, total_loss = -482.04, entropy_loss = -9.6601, pg_loss = -602.04, baseline_loss = 129.66, learner_queue_size = 32, _tick = 106, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:40,177[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 966.2, step = 276480, mean_episode_return = 0.015095, mean_episode_step = 33.693, total_loss = -183.75, entropy_loss = -9.7045, pg_loss = -390.53, baseline_loss = 216.49, learner_queue_size = 32, _tick = 107, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:45,182[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 971.3, step = 276480, mean_episode_return = 0.015095, mean_episode_step = 33.693, total_loss = -183.75, entropy_loss = -9.7045, pg_loss = -390.53, baseline_loss = 216.49, learner_queue_size = 32, _tick = 107, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:50,188[0m][[34mroot[0m][[32mINFO[0m] - Step 279040 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 976.3, step = 279040, mean_episode_return = 0.025304, mean_episode_step = 65.699, total_loss = 205.48, entropy_loss = -9.6823, pg_loss = 26.172, baseline_loss = 189.0, learner_queue_size = 32, _tick = 108, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:52:55,193[0m][[34mroot[0m][[32mINFO[0m] - Step 279040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 981.3, step = 279040, mean_episode_return = 0.025304, mean_episode_step = 65.699, total_loss = 205.48, entropy_loss = -9.6823, pg_loss = 26.172, baseline_loss = 189.0, learner_queue_size = 32, _tick = 108, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:00,198[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 986.3, step = 281600, mean_episode_return = 0.026333, mean_episode_step = 43.777, total_loss = -386.7, entropy_loss = -9.6398, pg_loss = -509.75, baseline_loss = 132.69, learner_queue_size = 32, _tick = 109, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:05,205[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 991.3, step = 281600, mean_episode_return = 0.026333, mean_episode_step = 43.777, total_loss = -386.7, entropy_loss = -9.6398, pg_loss = -509.75, baseline_loss = 132.69, learner_queue_size = 32, _tick = 109, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:10,212[0m][[34mroot[0m][[32mINFO[0m] - Step 284160 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 996.3, step = 284160, mean_episode_return = 0.056127, mean_episode_step = 51.734, total_loss = -470.76, entropy_loss = -9.6492, pg_loss = -577.84, baseline_loss = 116.73, learner_queue_size = 32, _tick = 110, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:15,217[0m][[34mroot[0m][[32mINFO[0m] - Step 284160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1001.3, step = 284160, mean_episode_return = 0.056127, mean_episode_step = 51.734, total_loss = -470.76, entropy_loss = -9.6492, pg_loss = -577.84, baseline_loss = 116.73, learner_queue_size = 32, _tick = 110, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:20,222[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1006.3, step = 286720, mean_episode_return = 0.089591, mean_episode_step = 56.967, total_loss = 227.96, entropy_loss = -9.6514, pg_loss = 48.778, baseline_loss = 188.83, learner_queue_size = 32, _tick = 111, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:25,227[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1011.3, step = 286720, mean_episode_return = 0.089591, mean_episode_step = 56.967, total_loss = 227.96, entropy_loss = -9.6514, pg_loss = 48.778, baseline_loss = 188.83, learner_queue_size = 32, _tick = 111, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:30,240[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1016.3, step = 289280, mean_episode_return = 0.06466, mean_episode_step = 54.631, total_loss = 568.09, entropy_loss = -9.6234, pg_loss = 406.76, baseline_loss = 170.95, learner_queue_size = 32, _tick = 112, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:35,246[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1021.3, step = 289280, mean_episode_return = 0.06466, mean_episode_step = 54.631, total_loss = 568.09, entropy_loss = -9.6234, pg_loss = 406.76, baseline_loss = 170.95, learner_queue_size = 32, _tick = 112, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:40,251[0m][[34mroot[0m][[32mINFO[0m] - Step 291840 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1026.3, step = 291840, mean_episode_return = -0.010429, mean_episode_step = 60.162, total_loss = -517.91, entropy_loss = -9.6101, pg_loss = -588.97, baseline_loss = 80.667, learner_queue_size = 32, _tick = 113, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:45,257[0m][[34mroot[0m][[32mINFO[0m] - Step 294400 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1031.3, step = 294400, mean_episode_return = 0.063118, mean_episode_step = 59.044, total_loss = 72.353, entropy_loss = -9.618, pg_loss = -77.252, baseline_loss = 159.22, learner_queue_size = 32, _tick = 114, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:50,262[0m][[34mroot[0m][[32mINFO[0m] - Step 294400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1036.3, step = 294400, mean_episode_return = 0.063118, mean_episode_step = 59.044, total_loss = 72.353, entropy_loss = -9.618, pg_loss = -77.252, baseline_loss = 159.22, learner_queue_size = 32, _tick = 114, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:53:55,268[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 511.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1041.3, step = 296960, mean_episode_return = 0.071304, mean_episode_step = 61.268, total_loss = 806.42, entropy_loss = -9.5321, pg_loss = 561.31, baseline_loss = 254.64, learner_queue_size = 32, _tick = 115, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:00,273[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1046.3, step = 296960, mean_episode_return = 0.071304, mean_episode_step = 61.268, total_loss = 806.42, entropy_loss = -9.5321, pg_loss = 561.31, baseline_loss = 254.64, learner_queue_size = 32, _tick = 115, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:05,278[0m][[34mroot[0m][[32mINFO[0m] - Step 299520 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1051.3, step = 299520, mean_episode_return = 0.030417, mean_episode_step = 59.732, total_loss = 3.8573, entropy_loss = -9.5563, pg_loss = -176.14, baseline_loss = 189.55, learner_queue_size = 32, _tick = 116, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:10,283[0m][[34mroot[0m][[32mINFO[0m] - Step 299520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1056.4, step = 299520, mean_episode_return = 0.030417, mean_episode_step = 59.732, total_loss = 3.8573, entropy_loss = -9.5563, pg_loss = -176.14, baseline_loss = 189.55, learner_queue_size = 32, _tick = 116, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:15,288[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1061.4, step = 302080, mean_episode_return = 0.22898, mean_episode_step = 79.133, total_loss = 890.33, entropy_loss = -9.5281, pg_loss = 602.61, baseline_loss = 297.24, learner_queue_size = 32, _tick = 117, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:20,293[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1066.4, step = 302080, mean_episode_return = 0.22898, mean_episode_step = 79.133, total_loss = 890.33, entropy_loss = -9.5281, pg_loss = 602.61, baseline_loss = 297.24, learner_queue_size = 32, _tick = 117, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:25,299[0m][[34mroot[0m][[32mINFO[0m] - Step 304640 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1071.4, step = 304640, mean_episode_return = 0.11124, mean_episode_step = 48.046, total_loss = 1538.1, entropy_loss = -9.517, pg_loss = 1165.7, baseline_loss = 381.91, learner_queue_size = 32, _tick = 118, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:30,306[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 511.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1076.4, step = 307200, mean_episode_return = 0.03147, mean_episode_step = 45.809, total_loss = 26.517, entropy_loss = -9.4889, pg_loss = -144.88, baseline_loss = 180.88, learner_queue_size = 32, _tick = 119, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:35,310[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1081.4, step = 307200, mean_episode_return = 0.03147, mean_episode_step = 45.809, total_loss = 26.517, entropy_loss = -9.4889, pg_loss = -144.88, baseline_loss = 180.88, learner_queue_size = 32, _tick = 119, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:40,315[0m][[34mroot[0m][[32mINFO[0m] - Step 309760 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1086.4, step = 309760, mean_episode_return = 0.084627, mean_episode_step = 64.562, total_loss = 979.33, entropy_loss = -9.5257, pg_loss = 681.35, baseline_loss = 307.51, learner_queue_size = 32, _tick = 120, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:45,321[0m][[34mroot[0m][[32mINFO[0m] - Step 309760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1091.4, step = 309760, mean_episode_return = 0.084627, mean_episode_step = 64.562, total_loss = 979.33, entropy_loss = -9.5257, pg_loss = 681.35, baseline_loss = 307.51, learner_queue_size = 32, _tick = 120, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:50,326[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1096.4, step = 312320, mean_episode_return = 0.052195, mean_episode_step = 44.2, total_loss = -766.44, entropy_loss = -9.5276, pg_loss = -892.61, baseline_loss = 135.7, learner_queue_size = 32, _tick = 121, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:54:55,331[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1101.4, step = 312320, mean_episode_return = 0.052195, mean_episode_step = 44.2, total_loss = -766.44, entropy_loss = -9.5276, pg_loss = -892.61, baseline_loss = 135.7, learner_queue_size = 32, _tick = 121, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:00,336[0m][[34mroot[0m][[32mINFO[0m] - Step 314880 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1106.4, step = 314880, mean_episode_return = 0.066622, mean_episode_step = 43.897, total_loss = -320.79, entropy_loss = -9.5313, pg_loss = -480.48, baseline_loss = 169.22, learner_queue_size = 32, _tick = 122, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:05,341[0m][[34mroot[0m][[32mINFO[0m] - Step 314880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1111.4, step = 314880, mean_episode_return = 0.066622, mean_episode_step = 43.897, total_loss = -320.79, entropy_loss = -9.5313, pg_loss = -480.48, baseline_loss = 169.22, learner_queue_size = 32, _tick = 122, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:10,346[0m][[34mroot[0m][[32mINFO[0m] - Step 317440 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1116.4, step = 317440, mean_episode_return = 0.073275, mean_episode_step = 49.346, total_loss = 751.06, entropy_loss = -9.5202, pg_loss = 481.38, baseline_loss = 279.19, learner_queue_size = 32, _tick = 123, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:15,354[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1121.4, step = 320000, mean_episode_return = 0.049929, mean_episode_step = 51.688, total_loss = 0.057451, entropy_loss = -9.4913, pg_loss = -154.12, baseline_loss = 163.67, learner_queue_size = 32, _tick = 124, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:20,359[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1126.4, step = 320000, mean_episode_return = 0.049929, mean_episode_step = 51.688, total_loss = 0.057451, entropy_loss = -9.4913, pg_loss = -154.12, baseline_loss = 163.67, learner_queue_size = 32, _tick = 124, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:25,365[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1131.4, step = 322560, mean_episode_return = 0.12194, mean_episode_step = 51.344, total_loss = 486.02, entropy_loss = -9.4965, pg_loss = 236.13, baseline_loss = 259.39, learner_queue_size = 32, _tick = 125, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:30,369[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1136.4, step = 322560, mean_episode_return = 0.12194, mean_episode_step = 51.344, total_loss = 486.02, entropy_loss = -9.4965, pg_loss = 236.13, baseline_loss = 259.39, learner_queue_size = 32, _tick = 125, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:35,375[0m][[34mroot[0m][[32mINFO[0m] - Step 325120 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1141.4, step = 325120, mean_episode_return = 0.040881, mean_episode_step = 57.832, total_loss = 1189.2, entropy_loss = -9.4426, pg_loss = 854.92, baseline_loss = 343.68, learner_queue_size = 32, _tick = 126, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:40,380[0m][[34mroot[0m][[32mINFO[0m] - Step 325120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1146.4, step = 325120, mean_episode_return = 0.040881, mean_episode_step = 57.832, total_loss = 1189.2, entropy_loss = -9.4426, pg_loss = 854.92, baseline_loss = 343.68, learner_queue_size = 32, _tick = 126, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:45,386[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1151.5, step = 327680, mean_episode_return = 0.080279, mean_episode_step = 47.319, total_loss = 775.89, entropy_loss = -9.4465, pg_loss = 485.36, baseline_loss = 299.98, learner_queue_size = 32, _tick = 127, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:50,391[0m][[34mroot[0m][[32mINFO[0m] - Step 330240 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1156.5, step = 330240, mean_episode_return = 0.057053, mean_episode_step = 66.065, total_loss = -730.42, entropy_loss = -9.4263, pg_loss = -842.92, baseline_loss = 121.93, learner_queue_size = 32, _tick = 128, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:55:55,397[0m][[34mroot[0m][[32mINFO[0m] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1161.5, step = 330240, mean_episode_return = 0.057053, mean_episode_step = 66.065, total_loss = -730.42, entropy_loss = -9.4263, pg_loss = -842.92, baseline_loss = 121.93, learner_queue_size = 32, _tick = 128, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:00,402[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1166.5, step = 332800, mean_episode_return = 0.13908, mean_episode_step = 65.461, total_loss = 594.55, entropy_loss = -9.4368, pg_loss = 329.46, baseline_loss = 274.52, learner_queue_size = 32, _tick = 129, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:05,407[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1171.5, step = 332800, mean_episode_return = 0.13908, mean_episode_step = 65.461, total_loss = 594.55, entropy_loss = -9.4368, pg_loss = 329.46, baseline_loss = 274.52, learner_queue_size = 32, _tick = 129, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:10,413[0m][[34mroot[0m][[32mINFO[0m] - Step 335360 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1176.5, step = 335360, mean_episode_return = 0.064321, mean_episode_step = 57.691, total_loss = -24.428, entropy_loss = -9.4465, pg_loss = -237.2, baseline_loss = 222.22, learner_queue_size = 32, _tick = 130, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:15,418[0m][[34mroot[0m][[32mINFO[0m] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1181.5, step = 335360, mean_episode_return = 0.064321, mean_episode_step = 57.691, total_loss = -24.428, entropy_loss = -9.4465, pg_loss = -237.2, baseline_loss = 222.22, learner_queue_size = 32, _tick = 130, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:20,423[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1186.5, step = 337920, mean_episode_return = 0.11256, mean_episode_step = 49.398, total_loss = -169.84, entropy_loss = -9.4362, pg_loss = -342.26, baseline_loss = 181.86, learner_queue_size = 32, _tick = 131, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:25,427[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1191.5, step = 337920, mean_episode_return = 0.11256, mean_episode_step = 49.398, total_loss = -169.84, entropy_loss = -9.4362, pg_loss = -342.26, baseline_loss = 181.86, learner_queue_size = 32, _tick = 131, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:30,434[0m][[34mroot[0m][[32mINFO[0m] - Step 340480 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1196.5, step = 340480, mean_episode_return = 0.15211, mean_episode_step = 75.059, total_loss = 72.561, entropy_loss = -9.4251, pg_loss = -107.48, baseline_loss = 189.47, learner_queue_size = 32, _tick = 132, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:35,439[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-18 16:56:35,559[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1201.5, step = 343040, mean_episode_return = 0.03353, mean_episode_step = 45.879, total_loss = -640.07, entropy_loss = -9.4388, pg_loss = -703.03, baseline_loss = 72.394, learner_queue_size = 32, _tick = 133, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:40,565[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1206.6, step = 343040, mean_episode_return = 0.03353, mean_episode_step = 45.879, total_loss = -640.07, entropy_loss = -9.4388, pg_loss = -703.03, baseline_loss = 72.394, learner_queue_size = 32, _tick = 133, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:45,570[0m][[34mroot[0m][[32mINFO[0m] - Step 345600 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1211.6, step = 345600, mean_episode_return = 0.039525, mean_episode_step = 40.858, total_loss = 459.46, entropy_loss = -9.4623, pg_loss = 212.66, baseline_loss = 256.27, learner_queue_size = 32, _tick = 134, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:50,575[0m][[34mroot[0m][[32mINFO[0m] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1216.6, step = 345600, mean_episode_return = 0.039525, mean_episode_step = 40.858, total_loss = 459.46, entropy_loss = -9.4623, pg_loss = 212.66, baseline_loss = 256.27, learner_queue_size = 32, _tick = 134, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:56:55,581[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1221.6, step = 348160, mean_episode_return = 0.028043, mean_episode_step = 56.136, total_loss = -280.39, entropy_loss = -9.3893, pg_loss = -432.27, baseline_loss = 161.27, learner_queue_size = 32, _tick = 135, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:00,587[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1226.7, step = 348160, mean_episode_return = 0.028043, mean_episode_step = 56.136, total_loss = -280.39, entropy_loss = -9.3893, pg_loss = -432.27, baseline_loss = 161.27, learner_queue_size = 32, _tick = 135, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:05,592[0m][[34mroot[0m][[32mINFO[0m] - Step 350720 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1231.7, step = 350720, mean_episode_return = 0.1048, mean_episode_step = 50.183, total_loss = 18.917, entropy_loss = -9.3999, pg_loss = -160.51, baseline_loss = 188.82, learner_queue_size = 32, _tick = 136, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:10,597[0m][[34mroot[0m][[32mINFO[0m] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1236.7, step = 350720, mean_episode_return = 0.1048, mean_episode_step = 50.183, total_loss = 18.917, entropy_loss = -9.3999, pg_loss = -160.51, baseline_loss = 188.82, learner_queue_size = 32, _tick = 136, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:15,602[0m][[34mroot[0m][[32mINFO[0m] - Step 353280 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1241.7, step = 353280, mean_episode_return = 0.084645, mean_episode_step = 45.257, total_loss = 1021.6, entropy_loss = -9.3551, pg_loss = 752.91, baseline_loss = 278.07, learner_queue_size = 32, _tick = 137, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:20,607[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1246.7, step = 355840, mean_episode_return = 0.095743, mean_episode_step = 52.52, total_loss = 156.6, entropy_loss = -9.3467, pg_loss = -26.871, baseline_loss = 192.81, learner_queue_size = 32, _tick = 138, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:25,612[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1251.7, step = 355840, mean_episode_return = 0.095743, mean_episode_step = 52.52, total_loss = 156.6, entropy_loss = -9.3467, pg_loss = -26.871, baseline_loss = 192.81, learner_queue_size = 32, _tick = 138, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:30,618[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1256.7, step = 358400, mean_episode_return = 0.080708, mean_episode_step = 56.976, total_loss = -87.451, entropy_loss = -9.3877, pg_loss = -252.64, baseline_loss = 174.57, learner_queue_size = 32, _tick = 139, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:35,623[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1261.7, step = 358400, mean_episode_return = 0.080708, mean_episode_step = 56.976, total_loss = -87.451, entropy_loss = -9.3877, pg_loss = -252.64, baseline_loss = 174.57, learner_queue_size = 32, _tick = 139, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:40,628[0m][[34mroot[0m][[32mINFO[0m] - Step 360960 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1266.7, step = 360960, mean_episode_return = 0.11876, mean_episode_step = 46.114, total_loss = 663.02, entropy_loss = -9.4032, pg_loss = 445.71, baseline_loss = 226.71, learner_queue_size = 32, _tick = 140, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:45,637[0m][[34mroot[0m][[32mINFO[0m] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1271.7, step = 360960, mean_episode_return = 0.11876, mean_episode_step = 46.114, total_loss = 663.02, entropy_loss = -9.4032, pg_loss = 445.71, baseline_loss = 226.71, learner_queue_size = 32, _tick = 140, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:50,650[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 510.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1276.7, step = 363520, mean_episode_return = 0.07956, mean_episode_step = 50.157, total_loss = -687.37, entropy_loss = -9.4076, pg_loss = -811.83, baseline_loss = 133.86, learner_queue_size = 32, _tick = 141, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:57:55,665[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1281.7, step = 363520, mean_episode_return = 0.07956, mean_episode_step = 50.157, total_loss = -687.37, entropy_loss = -9.4076, pg_loss = -811.83, baseline_loss = 133.86, learner_queue_size = 32, _tick = 141, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:00,670[0m][[34mroot[0m][[32mINFO[0m] - Step 366080 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1286.7, step = 366080, mean_episode_return = 0.018441, mean_episode_step = 48.885, total_loss = 455.49, entropy_loss = -9.3984, pg_loss = 242.87, baseline_loss = 222.01, learner_queue_size = 32, _tick = 142, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:05,675[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1291.7, step = 368640, mean_episode_return = 0.083927, mean_episode_step = 62.189, total_loss = -189.78, entropy_loss = -9.4089, pg_loss = -348.5, baseline_loss = 168.13, learner_queue_size = 32, _tick = 143, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:10,681[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1296.7, step = 368640, mean_episode_return = 0.083927, mean_episode_step = 62.189, total_loss = -189.78, entropy_loss = -9.4089, pg_loss = -348.5, baseline_loss = 168.13, learner_queue_size = 32, _tick = 143, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:15,686[0m][[34mroot[0m][[32mINFO[0m] - Step 371200 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1301.8, step = 371200, mean_episode_return = 0.03579, mean_episode_step = 53.286, total_loss = 960.2, entropy_loss = -9.3769, pg_loss = 690.76, baseline_loss = 278.81, learner_queue_size = 32, _tick = 144, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:20,691[0m][[34mroot[0m][[32mINFO[0m] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1306.8, step = 371200, mean_episode_return = 0.03579, mean_episode_step = 53.286, total_loss = 960.2, entropy_loss = -9.3769, pg_loss = 690.76, baseline_loss = 278.81, learner_queue_size = 32, _tick = 144, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:25,696[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1311.8, step = 373760, mean_episode_return = 0.018275, mean_episode_step = 70.666, total_loss = 616.31, entropy_loss = -9.3527, pg_loss = 408.9, baseline_loss = 216.76, learner_queue_size = 32, _tick = 145, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:30,701[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1316.8, step = 373760, mean_episode_return = 0.018275, mean_episode_step = 70.666, total_loss = 616.31, entropy_loss = -9.3527, pg_loss = 408.9, baseline_loss = 216.76, learner_queue_size = 32, _tick = 145, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:35,706[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar[0m
[[36m2025-01-18 16:58:35,751[0m][[34mroot[0m][[32mINFO[0m] - Step 376320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1321.8, step = 376320, mean_episode_return = 0.1914, mean_episode_step = 61.029, total_loss = -21.336, entropy_loss = -9.3668, pg_loss = -206.19, baseline_loss = 194.22, learner_queue_size = 32, _tick = 146, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:40,756[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 506.9 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1326.8, step = 378880, mean_episode_return = 0.10358, mean_episode_step = 58.713, total_loss = -269.67, entropy_loss = -9.3976, pg_loss = -440.64, baseline_loss = 180.36, learner_queue_size = 32, _tick = 147, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:45,761[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1331.8, step = 378880, mean_episode_return = 0.10358, mean_episode_step = 58.713, total_loss = -269.67, entropy_loss = -9.3976, pg_loss = -440.64, baseline_loss = 180.36, learner_queue_size = 32, _tick = 147, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:50,776[0m][[34mroot[0m][[32mINFO[0m] - Step 381440 @ 510.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1336.8, step = 381440, mean_episode_return = 0.10493, mean_episode_step = 66.159, total_loss = 1884.6, entropy_loss = -9.3855, pg_loss = 1477.8, baseline_loss = 416.11, learner_queue_size = 32, _tick = 148, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:58:55,780[0m][[34mroot[0m][[32mINFO[0m] - Step 381440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1341.8, step = 381440, mean_episode_return = 0.10493, mean_episode_step = 66.159, total_loss = 1884.6, entropy_loss = -9.3855, pg_loss = 1477.8, baseline_loss = 416.11, learner_queue_size = 32, _tick = 148, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:00,793[0m][[34mroot[0m][[32mINFO[0m] - Step 384000 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1346.9, step = 384000, mean_episode_return = 0.025633, mean_episode_step = 48.291, total_loss = 276.77, entropy_loss = -9.3976, pg_loss = 49.761, baseline_loss = 236.41, learner_queue_size = 32, _tick = 149, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:05,805[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 510.7 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (train_seconds = 1351.9, step = 386560, mean_episode_return = 0.044222, mean_episode_step = 63.768, total_loss = 1243.6, entropy_loss = -9.4179, pg_loss = 902.24, baseline_loss = 350.78, learner_queue_size = 32, _tick = 150, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:10,818[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1356.9, step = 386560, mean_episode_return = 0.044222, mean_episode_step = 63.768, total_loss = 1243.6, entropy_loss = -9.4179, pg_loss = 902.24, baseline_loss = 350.78, learner_queue_size = 32, _tick = 150, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:15,832[0m][[34mroot[0m][[32mINFO[0m] - Step 389120 @ 510.6 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1361.9, step = 389120, mean_episode_return = 0.014146, mean_episode_step = 71.354, total_loss = -867.1, entropy_loss = -9.4025, pg_loss = -944.43, baseline_loss = 86.723, learner_queue_size = 32, _tick = 151, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:20,837[0m][[34mroot[0m][[32mINFO[0m] - Step 389120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1366.9, step = 389120, mean_episode_return = 0.014146, mean_episode_step = 71.354, total_loss = -867.1, entropy_loss = -9.4025, pg_loss = -944.43, baseline_loss = 86.723, learner_queue_size = 32, _tick = 151, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:25,843[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1371.9, step = 391680, mean_episode_return = 0.099492, mean_episode_step = 46.324, total_loss = 929.7, entropy_loss = -9.4365, pg_loss = 607.38, baseline_loss = 331.76, learner_queue_size = 32, _tick = 152, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:30,848[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1376.9, step = 391680, mean_episode_return = 0.099492, mean_episode_step = 46.324, total_loss = 929.7, entropy_loss = -9.4365, pg_loss = 607.38, baseline_loss = 331.76, learner_queue_size = 32, _tick = 152, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:35,853[0m][[34mroot[0m][[32mINFO[0m] - Step 394240 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1381.9, step = 394240, mean_episode_return = 0.14064, mean_episode_step = 68.537, total_loss = -29.059, entropy_loss = -9.4395, pg_loss = -236.23, baseline_loss = 216.61, learner_queue_size = 32, _tick = 153, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:40,859[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1386.9, step = 396800, mean_episode_return = 0.10932, mean_episode_step = 66.952, total_loss = -638.93, entropy_loss = -9.4019, pg_loss = -748.61, baseline_loss = 119.08, learner_queue_size = 32, _tick = 154, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:45,865[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1391.9, step = 396800, mean_episode_return = 0.10932, mean_episode_step = 66.952, total_loss = -638.93, entropy_loss = -9.4019, pg_loss = -748.61, baseline_loss = 119.08, learner_queue_size = 32, _tick = 154, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:50,869[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1396.9, step = 399360, mean_episode_return = 0.072803, mean_episode_step = 47.029, total_loss = 744.46, entropy_loss = -9.4234, pg_loss = 426.36, baseline_loss = 327.53, learner_queue_size = 32, _tick = 155, _time = 1.7372e+09)[0m
[[36m2025-01-18 16:59:55,874[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1401.9, step = 399360, mean_episode_return = 0.072803, mean_episode_step = 47.029, total_loss = 744.46, entropy_loss = -9.4234, pg_loss = 426.36, baseline_loss = 327.53, learner_queue_size = 32, _tick = 155, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:00,881[0m][[34mroot[0m][[32mINFO[0m] - Step 401920 @ 511.3 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1406.9, step = 401920, mean_episode_return = 0.12482, mean_episode_step = 67.004, total_loss = 483.38, entropy_loss = -9.4238, pg_loss = 206.2, baseline_loss = 286.61, learner_queue_size = 32, _tick = 156, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:05,886[0m][[34mroot[0m][[32mINFO[0m] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1412.0, step = 401920, mean_episode_return = 0.12482, mean_episode_step = 67.004, total_loss = 483.38, entropy_loss = -9.4238, pg_loss = 206.2, baseline_loss = 286.61, learner_queue_size = 32, _tick = 156, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:10,891[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1417.0, step = 404480, mean_episode_return = 0.050481, mean_episode_step = 49.324, total_loss = -362.2, entropy_loss = -9.4334, pg_loss = -549.82, baseline_loss = 197.06, learner_queue_size = 32, _tick = 157, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:15,894[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1422.0, step = 404480, mean_episode_return = 0.050481, mean_episode_step = 49.324, total_loss = -362.2, entropy_loss = -9.4334, pg_loss = -549.82, baseline_loss = 197.06, learner_queue_size = 32, _tick = 157, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:20,899[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1427.0, step = 407040, mean_episode_return = 0.11945, mean_episode_step = 70.378, total_loss = 653.22, entropy_loss = -9.4057, pg_loss = 344.43, baseline_loss = 318.19, learner_queue_size = 32, _tick = 158, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:25,904[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1432.0, step = 407040, mean_episode_return = 0.11945, mean_episode_step = 70.378, total_loss = 653.22, entropy_loss = -9.4057, pg_loss = 344.43, baseline_loss = 318.19, learner_queue_size = 32, _tick = 158, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:30,910[0m][[34mroot[0m][[32mINFO[0m] - Step 409600 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1437.0, step = 409600, mean_episode_return = 0.065887, mean_episode_step = 57.189, total_loss = -986.64, entropy_loss = -9.4111, pg_loss = -1088.8, baseline_loss = 111.53, learner_queue_size = 32, _tick = 159, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:35,916[0m][[34mroot[0m][[32mINFO[0m] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1442.0, step = 409600, mean_episode_return = 0.065887, mean_episode_step = 57.189, total_loss = -986.64, entropy_loss = -9.4111, pg_loss = -1088.8, baseline_loss = 111.53, learner_queue_size = 32, _tick = 159, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:40,921[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1447.0, step = 412160, mean_episode_return = 0.12648, mean_episode_step = 63.754, total_loss = 2146.1, entropy_loss = -9.4027, pg_loss = 1689.4, baseline_loss = 466.11, learner_queue_size = 32, _tick = 160, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:45,934[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1452.0, step = 412160, mean_episode_return = 0.12648, mean_episode_step = 63.754, total_loss = 2146.1, entropy_loss = -9.4027, pg_loss = 1689.4, baseline_loss = 466.11, learner_queue_size = 32, _tick = 160, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:50,939[0m][[34mroot[0m][[32mINFO[0m] - Step 414720 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1457.0, step = 414720, mean_episode_return = 0.077246, mean_episode_step = 49.314, total_loss = 1191.6, entropy_loss = -9.4254, pg_loss = 783.07, baseline_loss = 417.95, learner_queue_size = 32, _tick = 161, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:00:55,952[0m][[34mroot[0m][[32mINFO[0m] - Step 414720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1462.0, step = 414720, mean_episode_return = 0.077246, mean_episode_step = 49.314, total_loss = 1191.6, entropy_loss = -9.4254, pg_loss = 783.07, baseline_loss = 417.95, learner_queue_size = 32, _tick = 161, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:00,962[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 511.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1467.0, step = 417280, mean_episode_return = 0.068372, mean_episode_step = 80.871, total_loss = -504.33, entropy_loss = -9.3852, pg_loss = -648.23, baseline_loss = 153.28, learner_queue_size = 32, _tick = 162, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:05,968[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1472.0, step = 417280, mean_episode_return = 0.068372, mean_episode_step = 80.871, total_loss = -504.33, entropy_loss = -9.3852, pg_loss = -648.23, baseline_loss = 153.28, learner_queue_size = 32, _tick = 162, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:10,981[0m][[34mroot[0m][[32mINFO[0m] - Step 419840 @ 510.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1477.1, step = 419840, mean_episode_return = 0.092643, mean_episode_step = 68.773, total_loss = -46.554, entropy_loss = -9.3975, pg_loss = -264.98, baseline_loss = 227.82, learner_queue_size = 32, _tick = 163, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:15,995[0m][[34mroot[0m][[32mINFO[0m] - Step 419840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1482.1, step = 419840, mean_episode_return = 0.092643, mean_episode_step = 68.773, total_loss = -46.554, entropy_loss = -9.3975, pg_loss = -264.98, baseline_loss = 227.82, learner_queue_size = 32, _tick = 163, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:21,008[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1487.1, step = 422400, mean_episode_return = 0.18415, mean_episode_step = 60.884, total_loss = -671.41, entropy_loss = -9.4059, pg_loss = -795.21, baseline_loss = 133.2, learner_queue_size = 32, _tick = 164, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:26,013[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1492.1, step = 422400, mean_episode_return = 0.18415, mean_episode_step = 60.884, total_loss = -671.41, entropy_loss = -9.4059, pg_loss = -795.21, baseline_loss = 133.2, learner_queue_size = 32, _tick = 164, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:31,019[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1497.1, step = 424960, mean_episode_return = 0.16182, mean_episode_step = 58.938, total_loss = -84.888, entropy_loss = -9.4212, pg_loss = -297.2, baseline_loss = 221.73, learner_queue_size = 32, _tick = 165, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:36,024[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1502.1, step = 424960, mean_episode_return = 0.16182, mean_episode_step = 58.938, total_loss = -84.888, entropy_loss = -9.4212, pg_loss = -297.2, baseline_loss = 221.73, learner_queue_size = 32, _tick = 165, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:41,029[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1507.1, step = 427520, mean_episode_return = 0.030041, mean_episode_step = 64.863, total_loss = 114.99, entropy_loss = -9.3982, pg_loss = -101.15, baseline_loss = 225.54, learner_queue_size = 32, _tick = 166, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:46,034[0m][[34mroot[0m][[32mINFO[0m] - Step 430080 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1512.1, step = 430080, mean_episode_return = 0.13649, mean_episode_step = 60.115, total_loss = 611.29, entropy_loss = -9.407, pg_loss = 354.79, baseline_loss = 265.91, learner_queue_size = 32, _tick = 167, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:51,039[0m][[34mroot[0m][[32mINFO[0m] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1517.1, step = 430080, mean_episode_return = 0.13649, mean_episode_step = 60.115, total_loss = 611.29, entropy_loss = -9.407, pg_loss = 354.79, baseline_loss = 265.91, learner_queue_size = 32, _tick = 167, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:01:56,044[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1522.1, step = 432640, mean_episode_return = 0.073817, mean_episode_step = 48.461, total_loss = -160.77, entropy_loss = -9.4114, pg_loss = -336.75, baseline_loss = 185.39, learner_queue_size = 32, _tick = 168, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:01,049[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1527.1, step = 432640, mean_episode_return = 0.073817, mean_episode_step = 48.461, total_loss = -160.77, entropy_loss = -9.4114, pg_loss = -336.75, baseline_loss = 185.39, learner_queue_size = 32, _tick = 168, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:06,056[0m][[34mroot[0m][[32mINFO[0m] - Step 435200 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1532.1, step = 435200, mean_episode_return = 0.098896, mean_episode_step = 57.959, total_loss = -334.15, entropy_loss = -9.398, pg_loss = -454.09, baseline_loss = 129.34, learner_queue_size = 32, _tick = 169, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:11,069[0m][[34mroot[0m][[32mINFO[0m] - Step 435200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1537.1, step = 435200, mean_episode_return = 0.098896, mean_episode_step = 57.959, total_loss = -334.15, entropy_loss = -9.398, pg_loss = -454.09, baseline_loss = 129.34, learner_queue_size = 32, _tick = 169, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:16,074[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1542.1, step = 437760, mean_episode_return = 0.16618, mean_episode_step = 81.453, total_loss = 439.53, entropy_loss = -9.3802, pg_loss = 243.94, baseline_loss = 204.97, learner_queue_size = 32, _tick = 170, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:21,079[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1547.1, step = 437760, mean_episode_return = 0.16618, mean_episode_step = 81.453, total_loss = 439.53, entropy_loss = -9.3802, pg_loss = 243.94, baseline_loss = 204.97, learner_queue_size = 32, _tick = 170, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:26,084[0m][[34mroot[0m][[32mINFO[0m] - Step 440320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1552.2, step = 440320, mean_episode_return = 0.079706, mean_episode_step = 64.747, total_loss = -1012.8, entropy_loss = -9.3965, pg_loss = -1075.5, baseline_loss = 72.092, learner_queue_size = 32, _tick = 171, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:31,089[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1557.2, step = 442880, mean_episode_return = 0.097048, mean_episode_step = 49.309, total_loss = 567.22, entropy_loss = -9.411, pg_loss = 322.78, baseline_loss = 253.85, learner_queue_size = 32, _tick = 172, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:36,094[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1562.2, step = 442880, mean_episode_return = 0.097048, mean_episode_step = 49.309, total_loss = 567.22, entropy_loss = -9.411, pg_loss = 322.78, baseline_loss = 253.85, learner_queue_size = 32, _tick = 172, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:41,101[0m][[34mroot[0m][[32mINFO[0m] - Step 445440 @ 511.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1567.2, step = 445440, mean_episode_return = 0.047152, mean_episode_step = 51.808, total_loss = -68.088, entropy_loss = -9.4177, pg_loss = -289.38, baseline_loss = 230.7, learner_queue_size = 32, _tick = 173, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:46,106[0m][[34mroot[0m][[32mINFO[0m] - Step 445440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1572.2, step = 445440, mean_episode_return = 0.047152, mean_episode_step = 51.808, total_loss = -68.088, entropy_loss = -9.4177, pg_loss = -289.38, baseline_loss = 230.7, learner_queue_size = 32, _tick = 173, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:51,111[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1577.2, step = 448000, mean_episode_return = 0.051691, mean_episode_step = 65.128, total_loss = -1135.5, entropy_loss = -9.3984, pg_loss = -1213.4, baseline_loss = 87.364, learner_queue_size = 32, _tick = 174, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:02:56,116[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1582.2, step = 448000, mean_episode_return = 0.051691, mean_episode_step = 65.128, total_loss = -1135.5, entropy_loss = -9.3984, pg_loss = -1213.4, baseline_loss = 87.364, learner_queue_size = 32, _tick = 174, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:01,122[0m][[34mroot[0m][[32mINFO[0m] - Step 450560 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1587.2, step = 450560, mean_episode_return = 0.088171, mean_episode_step = 85.217, total_loss = 954.15, entropy_loss = -9.3858, pg_loss = 678.65, baseline_loss = 284.88, learner_queue_size = 32, _tick = 175, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:06,127[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1592.2, step = 453120, mean_episode_return = 0.075696, mean_episode_step = 64.295, total_loss = 669.42, entropy_loss = -9.3935, pg_loss = 388.28, baseline_loss = 290.53, learner_queue_size = 32, _tick = 176, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:11,132[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1597.2, step = 453120, mean_episode_return = 0.075696, mean_episode_step = 64.295, total_loss = 669.42, entropy_loss = -9.3935, pg_loss = 388.28, baseline_loss = 290.53, learner_queue_size = 32, _tick = 176, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:16,138[0m][[34mroot[0m][[32mINFO[0m] - Step 455680 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1602.2, step = 455680, mean_episode_return = 0.10099, mean_episode_step = 57.295, total_loss = 221.48, entropy_loss = -9.4225, pg_loss = -25.597, baseline_loss = 256.5, learner_queue_size = 32, _tick = 177, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:21,143[0m][[34mroot[0m][[32mINFO[0m] - Step 455680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1607.2, step = 455680, mean_episode_return = 0.10099, mean_episode_step = 57.295, total_loss = 221.48, entropy_loss = -9.4225, pg_loss = -25.597, baseline_loss = 256.5, learner_queue_size = 32, _tick = 177, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:26,148[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1612.2, step = 458240, mean_episode_return = 0.093625, mean_episode_step = 72.887, total_loss = -60.576, entropy_loss = -9.3825, pg_loss = -248.15, baseline_loss = 196.95, learner_queue_size = 32, _tick = 178, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:31,153[0m][[34mroot[0m][[32mINFO[0m] - Step 460800 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1617.2, step = 460800, mean_episode_return = 0.13228, mean_episode_step = 64.331, total_loss = 1427.2, entropy_loss = -9.3839, pg_loss = 1078.8, baseline_loss = 357.8, learner_queue_size = 32, _tick = 179, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:36,158[0m][[34mroot[0m][[32mINFO[0m] - Step 460800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1622.2, step = 460800, mean_episode_return = 0.13228, mean_episode_step = 64.331, total_loss = 1427.2, entropy_loss = -9.3839, pg_loss = 1078.8, baseline_loss = 357.8, learner_queue_size = 32, _tick = 179, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:41,164[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1627.2, step = 463360, mean_episode_return = 0.064894, mean_episode_step = 50.201, total_loss = 86.64, entropy_loss = -9.3891, pg_loss = -134.06, baseline_loss = 230.09, learner_queue_size = 32, _tick = 180, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:46,169[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1632.2, step = 463360, mean_episode_return = 0.064894, mean_episode_step = 50.201, total_loss = 86.64, entropy_loss = -9.3891, pg_loss = -134.06, baseline_loss = 230.09, learner_queue_size = 32, _tick = 180, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:51,176[0m][[34mroot[0m][[32mINFO[0m] - Step 465920 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1637.2, step = 465920, mean_episode_return = 0.16121, mean_episode_step = 52.353, total_loss = 791.75, entropy_loss = -9.3894, pg_loss = 479.22, baseline_loss = 321.92, learner_queue_size = 32, _tick = 181, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:03:56,181[0m][[34mroot[0m][[32mINFO[0m] - Step 465920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1642.3, step = 465920, mean_episode_return = 0.16121, mean_episode_step = 52.353, total_loss = 791.75, entropy_loss = -9.3894, pg_loss = 479.22, baseline_loss = 321.92, learner_queue_size = 32, _tick = 181, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:01,186[0m][[34mroot[0m][[32mINFO[0m] - Step 468480 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1647.3, step = 468480, mean_episode_return = 0.068929, mean_episode_step = 57.725, total_loss = 76.86, entropy_loss = -9.3681, pg_loss = -122.13, baseline_loss = 208.36, learner_queue_size = 32, _tick = 182, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:06,191[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1652.3, step = 471040, mean_episode_return = 0.092546, mean_episode_step = 63.6, total_loss = -38.457, entropy_loss = -9.3682, pg_loss = -221.26, baseline_loss = 192.18, learner_queue_size = 32, _tick = 183, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:11,196[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1657.3, step = 471040, mean_episode_return = 0.092546, mean_episode_step = 63.6, total_loss = -38.457, entropy_loss = -9.3682, pg_loss = -221.26, baseline_loss = 192.18, learner_queue_size = 32, _tick = 183, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:16,201[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1662.3, step = 473600, mean_episode_return = 0.14607, mean_episode_step = 56.202, total_loss = -180.36, entropy_loss = -9.3877, pg_loss = -351.43, baseline_loss = 180.46, learner_queue_size = 32, _tick = 184, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:21,206[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1667.3, step = 473600, mean_episode_return = 0.14607, mean_episode_step = 56.202, total_loss = -180.36, entropy_loss = -9.3877, pg_loss = -351.43, baseline_loss = 180.46, learner_queue_size = 32, _tick = 184, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:26,212[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1672.3, step = 476160, mean_episode_return = 0.14594, mean_episode_step = 62.626, total_loss = 719.82, entropy_loss = -9.3758, pg_loss = 438.49, baseline_loss = 290.71, learner_queue_size = 32, _tick = 185, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:31,216[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1677.3, step = 476160, mean_episode_return = 0.14594, mean_episode_step = 62.626, total_loss = 719.82, entropy_loss = -9.3758, pg_loss = 438.49, baseline_loss = 290.71, learner_queue_size = 32, _tick = 185, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:36,221[0m][[34mroot[0m][[32mINFO[0m] - Step 478720 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1682.3, step = 478720, mean_episode_return = 0.074308, mean_episode_step = 63.724, total_loss = 239.18, entropy_loss = -9.3796, pg_loss = -17.854, baseline_loss = 266.41, learner_queue_size = 32, _tick = 186, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:41,227[0m][[34mroot[0m][[32mINFO[0m] - Step 481280 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1687.3, step = 481280, mean_episode_return = 0.11812, mean_episode_step = 62.414, total_loss = -202.88, entropy_loss = -9.3902, pg_loss = -393.78, baseline_loss = 200.29, learner_queue_size = 32, _tick = 187, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:46,232[0m][[34mroot[0m][[32mINFO[0m] - Step 481280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1692.3, step = 481280, mean_episode_return = 0.11812, mean_episode_step = 62.414, total_loss = -202.88, entropy_loss = -9.3902, pg_loss = -393.78, baseline_loss = 200.29, learner_queue_size = 32, _tick = 187, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:51,237[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1697.3, step = 483840, mean_episode_return = 0.14296, mean_episode_step = 70.01, total_loss = 210.26, entropy_loss = -9.3696, pg_loss = -8.1464, baseline_loss = 227.77, learner_queue_size = 32, _tick = 188, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:04:56,243[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1702.3, step = 483840, mean_episode_return = 0.14296, mean_episode_step = 70.01, total_loss = 210.26, entropy_loss = -9.3696, pg_loss = -8.1464, baseline_loss = 227.77, learner_queue_size = 32, _tick = 188, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:01,247[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1707.3, step = 486400, mean_episode_return = 0.098528, mean_episode_step = 67.198, total_loss = -814.78, entropy_loss = -9.378, pg_loss = -904.73, baseline_loss = 99.322, learner_queue_size = 32, _tick = 189, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:06,253[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1712.3, step = 486400, mean_episode_return = 0.098528, mean_episode_step = 67.198, total_loss = -814.78, entropy_loss = -9.378, pg_loss = -904.73, baseline_loss = 99.322, learner_queue_size = 32, _tick = 189, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:11,261[0m][[34mroot[0m][[32mINFO[0m] - Step 488960 @ 511.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1717.3, step = 488960, mean_episode_return = 0.061727, mean_episode_step = 53.998, total_loss = -220.44, entropy_loss = -9.3787, pg_loss = -393.49, baseline_loss = 182.43, learner_queue_size = 32, _tick = 190, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:16,266[0m][[34mroot[0m][[32mINFO[0m] - Step 491520 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1722.3, step = 491520, mean_episode_return = 0.15419, mean_episode_step = 82.192, total_loss = 1824.6, entropy_loss = -9.3661, pg_loss = 1367.4, baseline_loss = 466.51, learner_queue_size = 32, _tick = 191, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:21,271[0m][[34mroot[0m][[32mINFO[0m] - Step 491520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1727.3, step = 491520, mean_episode_return = 0.15419, mean_episode_step = 82.192, total_loss = 1824.6, entropy_loss = -9.3661, pg_loss = 1367.4, baseline_loss = 466.51, learner_queue_size = 32, _tick = 191, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:26,277[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1732.3, step = 494080, mean_episode_return = 0.099074, mean_episode_step = 54.496, total_loss = -887.68, entropy_loss = -9.384, pg_loss = -962.81, baseline_loss = 84.521, learner_queue_size = 32, _tick = 192, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:31,282[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1737.4, step = 494080, mean_episode_return = 0.099074, mean_episode_step = 54.496, total_loss = -887.68, entropy_loss = -9.384, pg_loss = -962.81, baseline_loss = 84.521, learner_queue_size = 32, _tick = 192, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:36,288[0m][[34mroot[0m][[32mINFO[0m] - Step 496640 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1742.4, step = 496640, mean_episode_return = 0.10275, mean_episode_step = 53.988, total_loss = -240.81, entropy_loss = -9.3917, pg_loss = -446.06, baseline_loss = 214.63, learner_queue_size = 32, _tick = 193, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:41,294[0m][[34mroot[0m][[32mINFO[0m] - Step 496640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1747.4, step = 496640, mean_episode_return = 0.10275, mean_episode_step = 53.988, total_loss = -240.81, entropy_loss = -9.3917, pg_loss = -446.06, baseline_loss = 214.63, learner_queue_size = 32, _tick = 193, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:46,299[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1752.4, step = 499200, mean_episode_return = 0.097933, mean_episode_step = 72.057, total_loss = 1674.8, entropy_loss = -9.3715, pg_loss = 1249.5, baseline_loss = 434.59, learner_queue_size = 32, _tick = 194, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:51,304[0m][[34mroot[0m][[32mINFO[0m] - Step 501760 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1757.4, step = 501760, mean_episode_return = 0.0925, mean_episode_step = 49.229, total_loss = 1636.2, entropy_loss = -9.3862, pg_loss = 1189.6, baseline_loss = 455.96, learner_queue_size = 32, _tick = 195, _time = 1.7372e+09)[0m
[[36m2025-01-18 17:05:51,305[0m][[34mroot[0m][[32mINFO[0m] - Learning finished after 501760 steps.[0m
[[36m2025-01-18 17:05:51,305[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,545[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,545[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,547[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,548[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,548[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,548[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,551[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,551[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,552[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,553[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,553[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,554[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,555[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,557[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,558[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,561[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,562[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,562[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,565[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,565[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,557[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,567[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,568[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,569[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,571[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,571[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,572[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,572[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,572[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,573[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,574[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,574[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,575[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,576[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,577[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,577[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,578[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,578[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,578[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,578[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,579[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,579[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,579[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,579[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,580[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,580[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,580[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,580[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,580[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,581[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,581[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,581[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,584[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,585[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,585[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,585[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,587[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,588[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,588[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,589[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,589[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,589[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,589[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,590[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,590[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,590[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,590[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,591[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,591[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,591[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,592[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,592[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,593[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,593[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,593[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,594[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,594[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,594[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,594[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,595[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,596[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,596[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,597[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,597[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,597[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,597[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,598[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,598[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,598[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,598[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,599[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,599[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,599[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,600[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,600[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,600[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,601[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,601[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,601[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,602[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,602[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,602[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,603[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,604[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,604[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,605[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,605[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,605[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,606[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,602[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,608[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,599[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,608[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,608[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,610[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,612[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,613[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,615[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,615[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,616[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,619[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,619[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,619[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,619[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,621[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,621[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,623[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,624[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,625[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,625[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,626[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,626[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,628[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,628[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,628[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,629[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,630[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,632[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,633[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,634[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,634[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,634[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,636[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,636[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,636[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,638[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,638[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,638[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,639[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,639[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,640[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,640[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,642[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,644[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,645[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,645[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,647[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,648[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,648[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,648[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,650[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,652[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,654[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,654[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,655[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,655[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,656[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,657[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,658[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,658[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,661[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,662[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,663[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,664[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,665[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,666[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,667[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,667[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,669[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,671[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,671[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,672[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,672[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,673[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,673[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,675[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,676[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,678[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,680[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,682[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,683[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,686[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,689[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,689[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,692[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,698[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,706[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,709[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,715[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,725[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,729[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,735[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,735[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-18 17:09:43,737[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
