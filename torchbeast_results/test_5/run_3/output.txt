[[36m2025-01-20 14:51:06,463[0m][[34mroot[0m][[32mINFO[0m] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
[0m
[[36m2025-01-20 14:51:06,511[0m][[34mroot[0m][[32mINFO[0m] - Symlinked log directory: /opt/minihack/latest[0m
[[36m2025-01-20 14:51:06,512[0m][[34mroot[0m][[32mINFO[0m] - Found archive directory: /opt/minihack/archives[0m
[[36m2025-01-20 14:51:06,516[0m][[34mroot[0m][[32mINFO[0m] - Logging results to /opt/minihack[0m
[[36m2025-01-20 14:51:06,547[0m][[34mpalaas/out[0m][[32mINFO[0m] - Found log directory: /opt/minihack[0m
[[36m2025-01-20 14:51:06,547[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving arguments to /opt/minihack/meta.json[0m
[[36m2025-01-20 14:51:06,548[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving messages to /opt/minihack/out.log[0m
[[36m2025-01-20 14:51:06,548[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs data to /opt/minihack/logs.csv[0m
[[36m2025-01-20 14:51:06,548[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs' fields to /opt/minihack/fields.csv[0m
[[36m2025-01-20 14:51:06,549[0m][[34mroot[0m][[32mINFO[0m] - Not using CUDA.[0m
[[36m2025-01-20 14:51:06,558[0m][[34mroot[0m][[32mINFO[0m] - Using model baseline[0m
[[36m2025-01-20 14:51:06,558[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,632[0m][[34mroot[0m][[32mINFO[0m] - Number of model parameters: 4264078[0m
[[36m2025-01-20 14:51:06,633[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,690[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,690[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,692[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,692[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,691[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,695[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,695[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,695[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,695[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,697[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,697[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,697[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,698[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,698[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,699[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,699[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,699[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,699[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,700[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,700[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,701[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,701[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,701[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,701[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,703[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,703[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,703[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,704[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,704[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,704[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,705[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,706[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,706[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,707[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,707[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,708[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,708[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,705[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,709[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,709[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,709[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,709[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,706[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,707[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,711[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
First Environment waiting for connection to unix:/tmp/poly..opt.minihack.0 ... connection established.
[[36m2025-01-20 14:51:06,711[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,712[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,708[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,714[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,712[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,714[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,715[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,716[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,717[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,710[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,717[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,719[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,719[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:06,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,691[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,693[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,694[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,695[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,695[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,697[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,698[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,698[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,696[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,699[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,700[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,705[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,713[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,715[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,717[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,717[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,717[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,718[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,715[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,723[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,723[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,723[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,724[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,724[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,724[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,725[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,725[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,725[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,726[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,726[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,726[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,726[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,726[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,726[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,727[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,727[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,729[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,729[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,729[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,730[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,730[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,730[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,731[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,731[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,731[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,731[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,731[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,731[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,732[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,732[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,732[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,733[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,733[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,733[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,733[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,728[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,733[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,734[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,734[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,723[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,734[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,722[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,734[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,734[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,721[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,735[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,735[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,725[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,736[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,736[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,736[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,738[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,737[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,737[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,738[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,738[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,718[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,738[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,739[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,724[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,739[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,739[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,739[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,740[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,740[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,740[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,738[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,741[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,739[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,742[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,742[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,742[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,742[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,743[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,743[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,743[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,744[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,744[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,744[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,746[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,746[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,746[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,747[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,747[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,747[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,736[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,735[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,749[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,744[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,738[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,751[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,745[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,752[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,747[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,755[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,756[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,757[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,757[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,758[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,758[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,759[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,757[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,761[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,760[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,762[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,762[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,762[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,763[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,764[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,764[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,765[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,766[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,766[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,772[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,779[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,765[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,781[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,784[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,784[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:07,788[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-20 14:51:11,691[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 13. Learner queue size: 20. Other stats: (train_seconds = 5.0)[0m
[[36m2025-01-20 14:51:16,696[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 81. Learner queue size: 9. Other stats: (train_seconds = 10.0)[0m
[[36m2025-01-20 14:51:21,702[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 122. Learner queue size: 12. Other stats: (train_seconds = 15.0)[0m
[[36m2025-01-20 14:51:21,860[0m][[34mpalaas/out[0m][[32mINFO[0m] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size'][0m
[[36m2025-01-20 14:51:26,707[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.tar[0m
[[36m2025-01-20 14:51:26,744[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 511.5 SPS. Inference batcher size: 117. Learner queue size: 13. Other stats: (train_seconds = 20.0, step = 2560, mean_episode_return = -0.052531, mean_episode_step = 42.279, total_loss = -716.8, entropy_loss = -11.371, pg_loss = -1007.7, baseline_loss = 302.24, learner_queue_size = 12, _tick = 0, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:51:31,749[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 104. Learner queue size: 29. Other stats: (train_seconds = 25.1, step = 2560, mean_episode_return = -0.052531, mean_episode_step = 42.279, total_loss = -716.8, entropy_loss = -11.371, pg_loss = -1007.7, baseline_loss = 302.24, learner_queue_size = 12, _tick = 0, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:51:36,754[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 39. Learner queue size: 32. Other stats: (train_seconds = 30.1, step = 2560, mean_episode_return = -0.052531, mean_episode_step = 42.279, total_loss = -716.8, entropy_loss = -11.371, pg_loss = -1007.7, baseline_loss = 302.24, learner_queue_size = 12, _tick = 0, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:51:41,766[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 510.8 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 35.1, step = 5120, mean_episode_return = 0.0095667, mean_episode_step = 44.154, total_loss = 2196.0, entropy_loss = -11.355, pg_loss = 1995.1, baseline_loss = 212.28, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:51:46,771[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 40.1, step = 5120, mean_episode_return = 0.0095667, mean_episode_step = 44.154, total_loss = 2196.0, entropy_loss = -11.355, pg_loss = 1995.1, baseline_loss = 212.28, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:51:51,777[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 45.1, step = 7680, mean_episode_return = 0.00070373, mean_episode_step = 30.583, total_loss = 1404.3, entropy_loss = -11.369, pg_loss = 1125.1, baseline_loss = 290.5, learner_queue_size = 32, _tick = 2, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:51:56,782[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 50.1, step = 10240, mean_episode_return = -0.039737, mean_episode_step = 32.945, total_loss = -915.03, entropy_loss = -11.369, pg_loss = -908.56, baseline_loss = 4.9002, learner_queue_size = 32, _tick = 3, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:01,787[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 55.1, step = 10240, mean_episode_return = -0.039737, mean_episode_step = 32.945, total_loss = -915.03, entropy_loss = -11.369, pg_loss = -908.56, baseline_loss = 4.9002, learner_queue_size = 32, _tick = 3, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:06,792[0m][[34mroot[0m][[32mINFO[0m] - Step 12800 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 60.1, step = 12800, mean_episode_return = 0.0054707, mean_episode_step = 46.778, total_loss = -82.788, entropy_loss = -11.364, pg_loss = -83.904, baseline_loss = 12.48, learner_queue_size = 32, _tick = 4, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:11,798[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 65.1, step = 15360, mean_episode_return = -0.04863, mean_episode_step = 47.374, total_loss = 1145.1, entropy_loss = -11.279, pg_loss = 1063.3, baseline_loss = 93.08, learner_queue_size = 32, _tick = 5, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:16,803[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 70.1, step = 15360, mean_episode_return = -0.04863, mean_episode_step = 47.374, total_loss = 1145.1, entropy_loss = -11.279, pg_loss = 1063.3, baseline_loss = 93.08, learner_queue_size = 32, _tick = 5, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:21,809[0m][[34mroot[0m][[32mINFO[0m] - Step 17920 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 75.1, step = 17920, mean_episode_return = -0.027143, mean_episode_step = 50.602, total_loss = 115.38, entropy_loss = -11.31, pg_loss = 55.178, baseline_loss = 71.515, learner_queue_size = 32, _tick = 6, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:26,814[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 80.1, step = 20480, mean_episode_return = -0.064035, mean_episode_step = 47.623, total_loss = -370.62, entropy_loss = -11.246, pg_loss = -373.67, baseline_loss = 14.3, learner_queue_size = 32, _tick = 7, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:31,819[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 85.1, step = 20480, mean_episode_return = -0.064035, mean_episode_step = 47.623, total_loss = -370.62, entropy_loss = -11.246, pg_loss = -373.67, baseline_loss = 14.3, learner_queue_size = 32, _tick = 7, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:36,824[0m][[34mroot[0m][[32mINFO[0m] - Step 23040 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 90.1, step = 23040, mean_episode_return = -0.02963, mean_episode_step = 47.842, total_loss = 455.77, entropy_loss = -11.217, pg_loss = 415.22, baseline_loss = 51.765, learner_queue_size = 32, _tick = 8, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:41,830[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 95.1, step = 25600, mean_episode_return = -0.027607, mean_episode_step = 52.721, total_loss = -118.23, entropy_loss = -11.257, pg_loss = -116.2, baseline_loss = 9.2244, learner_queue_size = 32, _tick = 9, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:46,835[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 100.1, step = 25600, mean_episode_return = -0.027607, mean_episode_step = 52.721, total_loss = -118.23, entropy_loss = -11.257, pg_loss = -116.2, baseline_loss = 9.2244, learner_queue_size = 32, _tick = 9, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:51,841[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 105.2, step = 28160, mean_episode_return = -0.027697, mean_episode_step = 41.103, total_loss = 1067.3, entropy_loss = -11.216, pg_loss = 946.99, baseline_loss = 131.56, learner_queue_size = 32, _tick = 10, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:52:56,846[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 110.2, step = 28160, mean_episode_return = -0.027697, mean_episode_step = 41.103, total_loss = 1067.3, entropy_loss = -11.216, pg_loss = 946.99, baseline_loss = 131.56, learner_queue_size = 32, _tick = 10, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:01,850[0m][[34mroot[0m][[32mINFO[0m] - Step 30720 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 115.2, step = 30720, mean_episode_return = -0.025607, mean_episode_step = 46.725, total_loss = 194.94, entropy_loss = -11.229, pg_loss = 153.13, baseline_loss = 53.037, learner_queue_size = 32, _tick = 11, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:06,855[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 120.2, step = 33280, mean_episode_return = -0.0042647, mean_episode_step = 49.907, total_loss = 76.491, entropy_loss = -11.227, pg_loss = -13.197, baseline_loss = 100.92, learner_queue_size = 32, _tick = 12, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:11,861[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 125.2, step = 33280, mean_episode_return = -0.0042647, mean_episode_step = 49.907, total_loss = 76.491, entropy_loss = -11.227, pg_loss = -13.197, baseline_loss = 100.92, learner_queue_size = 32, _tick = 12, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:16,865[0m][[34mroot[0m][[32mINFO[0m] - Step 35840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 130.2, step = 35840, mean_episode_return = 0.039895, mean_episode_step = 46.328, total_loss = 258.3, entropy_loss = -11.168, pg_loss = 149.23, baseline_loss = 120.24, learner_queue_size = 32, _tick = 13, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:21,870[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 135.2, step = 38400, mean_episode_return = -0.055871, mean_episode_step = 42.006, total_loss = -360.43, entropy_loss = -11.135, pg_loss = -385.38, baseline_loss = 36.088, learner_queue_size = 32, _tick = 14, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:26,875[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 140.2, step = 38400, mean_episode_return = -0.055871, mean_episode_step = 42.006, total_loss = -360.43, entropy_loss = -11.135, pg_loss = -385.38, baseline_loss = 36.088, learner_queue_size = 32, _tick = 14, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:31,881[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 145.2, step = 40960, mean_episode_return = 0.017625, mean_episode_step = 52.059, total_loss = -196.48, entropy_loss = -11.115, pg_loss = -195.39, baseline_loss = 10.025, learner_queue_size = 32, _tick = 15, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:36,885[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 150.2, step = 43520, mean_episode_return = -0.010135, mean_episode_step = 53.163, total_loss = 744.83, entropy_loss = -11.064, pg_loss = 649.99, baseline_loss = 105.9, learner_queue_size = 32, _tick = 16, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:41,890[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 155.2, step = 43520, mean_episode_return = -0.010135, mean_episode_step = 53.163, total_loss = 744.83, entropy_loss = -11.064, pg_loss = 649.99, baseline_loss = 105.9, learner_queue_size = 32, _tick = 16, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:46,896[0m][[34mroot[0m][[32mINFO[0m] - Step 46080 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 160.2, step = 46080, mean_episode_return = -0.021419, mean_episode_step = 50.175, total_loss = 976.61, entropy_loss = -11.076, pg_loss = 818.06, baseline_loss = 169.63, learner_queue_size = 32, _tick = 17, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:51,901[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 165.2, step = 48640, mean_episode_return = -0.056094, mean_episode_step = 48.001, total_loss = 1056.2, entropy_loss = -11.084, pg_loss = 835.93, baseline_loss = 231.33, learner_queue_size = 32, _tick = 18, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:53:56,906[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 170.2, step = 48640, mean_episode_return = -0.056094, mean_episode_step = 48.001, total_loss = 1056.2, entropy_loss = -11.084, pg_loss = 835.93, baseline_loss = 231.33, learner_queue_size = 32, _tick = 18, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:01,911[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 175.2, step = 51200, mean_episode_return = -0.020844, mean_episode_step = 55.397, total_loss = -397.77, entropy_loss = -11.086, pg_loss = -472.7, baseline_loss = 86.016, learner_queue_size = 32, _tick = 19, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:06,916[0m][[34mroot[0m][[32mINFO[0m] - Step 53760 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 180.2, step = 53760, mean_episode_return = -0.035152, mean_episode_step = 47.652, total_loss = -255.41, entropy_loss = -11.078, pg_loss = -302.72, baseline_loss = 58.388, learner_queue_size = 32, _tick = 20, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:11,922[0m][[34mroot[0m][[32mINFO[0m] - Step 53760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 185.2, step = 53760, mean_episode_return = -0.035152, mean_episode_step = 47.652, total_loss = -255.41, entropy_loss = -11.078, pg_loss = -302.72, baseline_loss = 58.388, learner_queue_size = 32, _tick = 20, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:16,926[0m][[34mroot[0m][[32mINFO[0m] - Step 56320 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 190.2, step = 56320, mean_episode_return = 0.015837, mean_episode_step = 51.177, total_loss = 461.72, entropy_loss = -11.054, pg_loss = 380.49, baseline_loss = 92.276, learner_queue_size = 32, _tick = 21, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:21,931[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 195.2, step = 58880, mean_episode_return = -0.030278, mean_episode_step = 52.706, total_loss = 791.25, entropy_loss = -11.021, pg_loss = 538.2, baseline_loss = 264.07, learner_queue_size = 32, _tick = 22, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:26,936[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 200.3, step = 58880, mean_episode_return = -0.030278, mean_episode_step = 52.706, total_loss = 791.25, entropy_loss = -11.021, pg_loss = 538.2, baseline_loss = 264.07, learner_queue_size = 32, _tick = 22, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:31,941[0m][[34mroot[0m][[32mINFO[0m] - Step 61440 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 205.3, step = 61440, mean_episode_return = -0.0051087, mean_episode_step = 44.217, total_loss = 424.0, entropy_loss = -10.983, pg_loss = 221.78, baseline_loss = 213.2, learner_queue_size = 32, _tick = 23, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:36,946[0m][[34mroot[0m][[32mINFO[0m] - Step 64000 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 210.3, step = 64000, mean_episode_return = 0.029192, mean_episode_step = 51.165, total_loss = -298.37, entropy_loss = -10.942, pg_loss = -415.52, baseline_loss = 128.09, learner_queue_size = 32, _tick = 24, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:41,952[0m][[34mroot[0m][[32mINFO[0m] - Step 64000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 215.3, step = 64000, mean_episode_return = 0.029192, mean_episode_step = 51.165, total_loss = -298.37, entropy_loss = -10.942, pg_loss = -415.52, baseline_loss = 128.09, learner_queue_size = 32, _tick = 24, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:46,957[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 220.3, step = 66560, mean_episode_return = 0.032333, mean_episode_step = 49.13, total_loss = 643.91, entropy_loss = -10.945, pg_loss = 450.72, baseline_loss = 204.14, learner_queue_size = 32, _tick = 25, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:51,962[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 225.3, step = 66560, mean_episode_return = 0.032333, mean_episode_step = 49.13, total_loss = 643.91, entropy_loss = -10.945, pg_loss = 450.72, baseline_loss = 204.14, learner_queue_size = 32, _tick = 25, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:54:56,967[0m][[34mroot[0m][[32mINFO[0m] - Step 69120 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 230.3, step = 69120, mean_episode_return = 0.08805, mean_episode_step = 52.079, total_loss = -31.58, entropy_loss = -10.934, pg_loss = -236.05, baseline_loss = 215.4, learner_queue_size = 32, _tick = 26, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:01,972[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 235.3, step = 71680, mean_episode_return = 0.060132, mean_episode_step = 55.389, total_loss = 1484.5, entropy_loss = -10.855, pg_loss = 1089.5, baseline_loss = 405.8, learner_queue_size = 32, _tick = 27, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:06,977[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 240.3, step = 71680, mean_episode_return = 0.060132, mean_episode_step = 55.389, total_loss = 1484.5, entropy_loss = -10.855, pg_loss = 1089.5, baseline_loss = 405.8, learner_queue_size = 32, _tick = 27, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:11,982[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 245.3, step = 74240, mean_episode_return = 0.044619, mean_episode_step = 52.822, total_loss = -30.566, entropy_loss = -10.823, pg_loss = -153.82, baseline_loss = 134.07, learner_queue_size = 32, _tick = 28, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:16,987[0m][[34mroot[0m][[32mINFO[0m] - Step 76800 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 250.3, step = 76800, mean_episode_return = -0.047512, mean_episode_step = 43.485, total_loss = 486.33, entropy_loss = -10.794, pg_loss = 326.04, baseline_loss = 171.08, learner_queue_size = 32, _tick = 29, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:21,992[0m][[34mroot[0m][[32mINFO[0m] - Step 76800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 255.3, step = 76800, mean_episode_return = -0.047512, mean_episode_step = 43.485, total_loss = 486.33, entropy_loss = -10.794, pg_loss = 326.04, baseline_loss = 171.08, learner_queue_size = 32, _tick = 29, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:26,998[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 260.3, step = 79360, mean_episode_return = 0.048842, mean_episode_step = 47.738, total_loss = 782.32, entropy_loss = -10.758, pg_loss = 595.24, baseline_loss = 197.83, learner_queue_size = 32, _tick = 30, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:32,002[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 265.3, step = 81920, mean_episode_return = 0.020219, mean_episode_step = 54.046, total_loss = -707.79, entropy_loss = -10.761, pg_loss = -797.62, baseline_loss = 100.59, learner_queue_size = 32, _tick = 31, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:37,008[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 270.3, step = 81920, mean_episode_return = 0.020219, mean_episode_step = 54.046, total_loss = -707.79, entropy_loss = -10.761, pg_loss = -797.62, baseline_loss = 100.59, learner_queue_size = 32, _tick = 31, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:42,013[0m][[34mroot[0m][[32mINFO[0m] - Step 84480 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 275.3, step = 84480, mean_episode_return = 0.053522, mean_episode_step = 56.091, total_loss = 174.78, entropy_loss = -10.755, pg_loss = 13.589, baseline_loss = 171.94, learner_queue_size = 32, _tick = 32, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:47,019[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 280.3, step = 87040, mean_episode_return = 0.037091, mean_episode_step = 55.791, total_loss = -98.654, entropy_loss = -10.726, pg_loss = -233.54, baseline_loss = 145.62, learner_queue_size = 32, _tick = 33, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:52,024[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 285.3, step = 87040, mean_episode_return = 0.037091, mean_episode_step = 55.791, total_loss = -98.654, entropy_loss = -10.726, pg_loss = -233.54, baseline_loss = 145.62, learner_queue_size = 32, _tick = 33, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:55:57,029[0m][[34mroot[0m][[32mINFO[0m] - Step 89600 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 290.3, step = 89600, mean_episode_return = 0.064, mean_episode_step = 52.714, total_loss = 968.22, entropy_loss = -10.707, pg_loss = 712.19, baseline_loss = 266.74, learner_queue_size = 32, _tick = 34, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:02,035[0m][[34mroot[0m][[32mINFO[0m] - Step 89600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 295.3, step = 89600, mean_episode_return = 0.064, mean_episode_step = 52.714, total_loss = 968.22, entropy_loss = -10.707, pg_loss = 712.19, baseline_loss = 266.74, learner_queue_size = 32, _tick = 34, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:07,037[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 511.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 300.4, step = 92160, mean_episode_return = 0.042512, mean_episode_step = 55.12, total_loss = 445.59, entropy_loss = -10.679, pg_loss = 261.92, baseline_loss = 194.35, learner_queue_size = 32, _tick = 35, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:12,042[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 305.4, step = 94720, mean_episode_return = 0.065364, mean_episode_step = 51.114, total_loss = -831.38, entropy_loss = -10.66, pg_loss = -923.57, baseline_loss = 102.85, learner_queue_size = 32, _tick = 36, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:17,047[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 310.4, step = 94720, mean_episode_return = 0.065364, mean_episode_step = 51.114, total_loss = -831.38, entropy_loss = -10.66, pg_loss = -923.57, baseline_loss = 102.85, learner_queue_size = 32, _tick = 36, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:22,052[0m][[34mroot[0m][[32mINFO[0m] - Step 97280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 315.4, step = 97280, mean_episode_return = 0.14109, mean_episode_step = 56.535, total_loss = -533.9, entropy_loss = -10.625, pg_loss = -621.17, baseline_loss = 97.896, learner_queue_size = 32, _tick = 37, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:27,058[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 320.4, step = 99840, mean_episode_return = 0.073333, mean_episode_step = 53.987, total_loss = -477.49, entropy_loss = -10.595, pg_loss = -529.13, baseline_loss = 62.236, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:32,065[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 325.4, step = 99840, mean_episode_return = 0.073333, mean_episode_step = 53.987, total_loss = -477.49, entropy_loss = -10.595, pg_loss = -529.13, baseline_loss = 62.236, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:37,071[0m][[34mroot[0m][[32mINFO[0m] - Step 102400 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 330.4, step = 102400, mean_episode_return = 0.2112, mean_episode_step = 52.22, total_loss = 1145.2, entropy_loss = -10.562, pg_loss = 922.94, baseline_loss = 232.86, learner_queue_size = 32, _tick = 39, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:42,075[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 335.4, step = 104960, mean_episode_return = 0.14573, mean_episode_step = 62.796, total_loss = -1010.4, entropy_loss = -10.551, pg_loss = -1040.1, baseline_loss = 40.28, learner_queue_size = 32, _tick = 40, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:47,080[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 340.4, step = 104960, mean_episode_return = 0.14573, mean_episode_step = 62.796, total_loss = -1010.4, entropy_loss = -10.551, pg_loss = -1040.1, baseline_loss = 40.28, learner_queue_size = 32, _tick = 40, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:52,100[0m][[34mroot[0m][[32mINFO[0m] - Step 107520 @ 510.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 345.4, step = 107520, mean_episode_return = 0.053895, mean_episode_step = 54.668, total_loss = 983.14, entropy_loss = -10.547, pg_loss = 776.44, baseline_loss = 217.25, learner_queue_size = 32, _tick = 41, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:56:57,110[0m][[34mroot[0m][[32mINFO[0m] - Step 110080 @ 511.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 350.4, step = 110080, mean_episode_return = 0.15389, mean_episode_step = 56.169, total_loss = -184.11, entropy_loss = -10.545, pg_loss = -332.94, baseline_loss = 159.38, learner_queue_size = 32, _tick = 42, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:02,115[0m][[34mroot[0m][[32mINFO[0m] - Step 110080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 355.4, step = 110080, mean_episode_return = 0.15389, mean_episode_step = 56.169, total_loss = -184.11, entropy_loss = -10.545, pg_loss = -332.94, baseline_loss = 159.38, learner_queue_size = 32, _tick = 42, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:07,133[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 510.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 360.4, step = 112640, mean_episode_return = 0.17115, mean_episode_step = 52.874, total_loss = 380.6, entropy_loss = -10.506, pg_loss = 152.78, baseline_loss = 238.32, learner_queue_size = 32, _tick = 43, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:12,140[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 511.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 365.5, step = 115200, mean_episode_return = 0.074733, mean_episode_step = 50.488, total_loss = -35.39, entropy_loss = -10.444, pg_loss = -119.44, baseline_loss = 94.495, learner_queue_size = 32, _tick = 44, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:17,142[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 370.5, step = 115200, mean_episode_return = 0.074733, mean_episode_step = 50.488, total_loss = -35.39, entropy_loss = -10.444, pg_loss = -119.44, baseline_loss = 94.495, learner_queue_size = 32, _tick = 44, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:22,148[0m][[34mroot[0m][[32mINFO[0m] - Step 117760 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 375.5, step = 117760, mean_episode_return = 0.14831, mean_episode_step = 49.256, total_loss = 714.24, entropy_loss = -10.433, pg_loss = 572.24, baseline_loss = 152.43, learner_queue_size = 32, _tick = 45, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:27,153[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 380.5, step = 120320, mean_episode_return = 0.098333, mean_episode_step = 47.377, total_loss = -53.166, entropy_loss = -10.398, pg_loss = -155.85, baseline_loss = 113.08, learner_queue_size = 32, _tick = 46, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:32,159[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 385.5, step = 120320, mean_episode_return = 0.098333, mean_episode_step = 47.377, total_loss = -53.166, entropy_loss = -10.398, pg_loss = -155.85, baseline_loss = 113.08, learner_queue_size = 32, _tick = 46, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:37,165[0m][[34mroot[0m][[32mINFO[0m] - Step 122880 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 390.5, step = 122880, mean_episode_return = 0.17942, mean_episode_step = 49.306, total_loss = 144.76, entropy_loss = -10.343, pg_loss = -25.968, baseline_loss = 181.07, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:42,170[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar[0m
[[36m2025-01-20 14:57:42,216[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 395.5, step = 125440, mean_episode_return = 0.11788, mean_episode_step = 53.731, total_loss = 395.89, entropy_loss = -10.267, pg_loss = 279.51, baseline_loss = 126.65, learner_queue_size = 32, _tick = 48, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:47,221[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 400.5, step = 125440, mean_episode_return = 0.11788, mean_episode_step = 53.731, total_loss = 395.89, entropy_loss = -10.267, pg_loss = 279.51, baseline_loss = 126.65, learner_queue_size = 32, _tick = 48, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:52,227[0m][[34mroot[0m][[32mINFO[0m] - Step 128000 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 405.5, step = 128000, mean_episode_return = 0.043489, mean_episode_step = 45.86, total_loss = -304.54, entropy_loss = -10.243, pg_loss = -378.02, baseline_loss = 83.722, learner_queue_size = 32, _tick = 49, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:57:57,233[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 511.3 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 410.5, step = 130560, mean_episode_return = 0.19026, mean_episode_step = 52.957, total_loss = 490.81, entropy_loss = -10.18, pg_loss = 355.09, baseline_loss = 145.9, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:02,238[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 415.6, step = 130560, mean_episode_return = 0.19026, mean_episode_step = 52.957, total_loss = 490.81, entropy_loss = -10.18, pg_loss = 355.09, baseline_loss = 145.9, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:07,245[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 420.6, step = 133120, mean_episode_return = 0.054488, mean_episode_step = 59.827, total_loss = 336.84, entropy_loss = -10.199, pg_loss = 234.81, baseline_loss = 112.23, learner_queue_size = 32, _tick = 51, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:12,249[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 425.6, step = 133120, mean_episode_return = 0.054488, mean_episode_step = 59.827, total_loss = 336.84, entropy_loss = -10.199, pg_loss = 234.81, baseline_loss = 112.23, learner_queue_size = 32, _tick = 51, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:17,255[0m][[34mroot[0m][[32mINFO[0m] - Step 135680 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 430.6, step = 135680, mean_episode_return = 0.221, mean_episode_step = 59.225, total_loss = 1236.8, entropy_loss = -10.224, pg_loss = 1032.8, baseline_loss = 214.24, learner_queue_size = 32, _tick = 52, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:22,261[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 511.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 435.6, step = 138240, mean_episode_return = 0.25743, mean_episode_step = 62.341, total_loss = -71.235, entropy_loss = -10.24, pg_loss = -205.34, baseline_loss = 144.35, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:27,266[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 440.6, step = 138240, mean_episode_return = 0.25743, mean_episode_step = 62.341, total_loss = -71.235, entropy_loss = -10.24, pg_loss = -205.34, baseline_loss = 144.35, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:32,271[0m][[34mroot[0m][[32mINFO[0m] - Step 140800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 445.6, step = 140800, mean_episode_return = 0.18018, mean_episode_step = 51.121, total_loss = 366.65, entropy_loss = -10.217, pg_loss = 206.79, baseline_loss = 170.08, learner_queue_size = 32, _tick = 54, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:37,276[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 450.6, step = 143360, mean_episode_return = 0.076582, mean_episode_step = 53.55, total_loss = 314.88, entropy_loss = -10.2, pg_loss = 142.21, baseline_loss = 182.87, learner_queue_size = 32, _tick = 55, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:42,281[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 455.6, step = 143360, mean_episode_return = 0.076582, mean_episode_step = 53.55, total_loss = 314.88, entropy_loss = -10.2, pg_loss = 142.21, baseline_loss = 182.87, learner_queue_size = 32, _tick = 55, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:47,286[0m][[34mroot[0m][[32mINFO[0m] - Step 145920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 460.6, step = 145920, mean_episode_return = 0.22766, mean_episode_step = 68.363, total_loss = -381.72, entropy_loss = -10.189, pg_loss = -504.39, baseline_loss = 132.87, learner_queue_size = 32, _tick = 56, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:52,292[0m][[34mroot[0m][[32mINFO[0m] - Step 148480 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 465.6, step = 148480, mean_episode_return = 0.25051, mean_episode_step = 55.927, total_loss = 627.12, entropy_loss = -10.169, pg_loss = 410.93, baseline_loss = 226.36, learner_queue_size = 32, _tick = 57, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:58:57,297[0m][[34mroot[0m][[32mINFO[0m] - Step 148480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 470.6, step = 148480, mean_episode_return = 0.25051, mean_episode_step = 55.927, total_loss = 627.12, entropy_loss = -10.169, pg_loss = 410.93, baseline_loss = 226.36, learner_queue_size = 32, _tick = 57, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:02,302[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 475.6, step = 151040, mean_episode_return = 0.072225, mean_episode_step = 63.427, total_loss = -1343.5, entropy_loss = -10.161, pg_loss = -1395.3, baseline_loss = 61.94, learner_queue_size = 32, _tick = 58, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:07,309[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 480.6, step = 153600, mean_episode_return = 0.13859, mean_episode_step = 67.523, total_loss = 480.97, entropy_loss = -10.14, pg_loss = 285.17, baseline_loss = 205.95, learner_queue_size = 32, _tick = 59, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:12,315[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 485.6, step = 153600, mean_episode_return = 0.13859, mean_episode_step = 67.523, total_loss = 480.97, entropy_loss = -10.14, pg_loss = 285.17, baseline_loss = 205.95, learner_queue_size = 32, _tick = 59, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:17,321[0m][[34mroot[0m][[32mINFO[0m] - Step 156160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 490.6, step = 156160, mean_episode_return = 0.32581, mean_episode_step = 64.912, total_loss = 373.43, entropy_loss = -10.111, pg_loss = 163.61, baseline_loss = 219.93, learner_queue_size = 32, _tick = 60, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:22,325[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 495.6, step = 158720, mean_episode_return = 0.19617, mean_episode_step = 60.465, total_loss = 1016.9, entropy_loss = -10.153, pg_loss = 829.03, baseline_loss = 197.98, learner_queue_size = 32, _tick = 61, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:27,330[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 500.6, step = 158720, mean_episode_return = 0.19617, mean_episode_step = 60.465, total_loss = 1016.9, entropy_loss = -10.153, pg_loss = 829.03, baseline_loss = 197.98, learner_queue_size = 32, _tick = 61, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:32,335[0m][[34mroot[0m][[32mINFO[0m] - Step 161280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 505.6, step = 161280, mean_episode_return = 0.24675, mean_episode_step = 61.108, total_loss = 620.12, entropy_loss = -10.163, pg_loss = 419.79, baseline_loss = 210.49, learner_queue_size = 32, _tick = 62, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:37,341[0m][[34mroot[0m][[32mINFO[0m] - Step 163840 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 510.7, step = 163840, mean_episode_return = 0.18502, mean_episode_step = 61.618, total_loss = -1320.2, entropy_loss = -10.158, pg_loss = -1424.3, baseline_loss = 114.25, learner_queue_size = 32, _tick = 63, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:42,346[0m][[34mroot[0m][[32mINFO[0m] - Step 163840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 515.7, step = 163840, mean_episode_return = 0.18502, mean_episode_step = 61.618, total_loss = -1320.2, entropy_loss = -10.158, pg_loss = -1424.3, baseline_loss = 114.25, learner_queue_size = 32, _tick = 63, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:47,351[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 520.7, step = 166400, mean_episode_return = 0.14724, mean_episode_step = 46.658, total_loss = -461.77, entropy_loss = -10.153, pg_loss = -596.61, baseline_loss = 144.99, learner_queue_size = 32, _tick = 64, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:52,357[0m][[34mroot[0m][[32mINFO[0m] - Step 168960 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 525.7, step = 168960, mean_episode_return = 0.33295, mean_episode_step = 55.344, total_loss = 948.96, entropy_loss = -10.135, pg_loss = 670.66, baseline_loss = 288.43, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)[0m
[[36m2025-01-20 14:59:57,361[0m][[34mroot[0m][[32mINFO[0m] - Step 168960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 530.7, step = 168960, mean_episode_return = 0.33295, mean_episode_step = 55.344, total_loss = 948.96, entropy_loss = -10.135, pg_loss = 670.66, baseline_loss = 288.43, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:02,366[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 535.7, step = 171520, mean_episode_return = 0.14356, mean_episode_step = 53.946, total_loss = -567.9, entropy_loss = -10.146, pg_loss = -739.55, baseline_loss = 181.79, learner_queue_size = 32, _tick = 66, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:07,372[0m][[34mroot[0m][[32mINFO[0m] - Step 174080 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 540.7, step = 174080, mean_episode_return = 0.26047, mean_episode_step = 66.004, total_loss = -1695.5, entropy_loss = -10.137, pg_loss = -1837.8, baseline_loss = 152.46, learner_queue_size = 32, _tick = 67, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:12,377[0m][[34mroot[0m][[32mINFO[0m] - Step 174080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 545.7, step = 174080, mean_episode_return = 0.26047, mean_episode_step = 66.004, total_loss = -1695.5, entropy_loss = -10.137, pg_loss = -1837.8, baseline_loss = 152.46, learner_queue_size = 32, _tick = 67, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:17,383[0m][[34mroot[0m][[32mINFO[0m] - Step 176640 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 550.7, step = 176640, mean_episode_return = 0.18379, mean_episode_step = 57.975, total_loss = -626.4, entropy_loss = -10.12, pg_loss = -777.52, baseline_loss = 161.24, learner_queue_size = 32, _tick = 68, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:22,388[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 555.7, step = 179200, mean_episode_return = 0.21941, mean_episode_step = 67.529, total_loss = 241.71, entropy_loss = -10.091, pg_loss = 64.409, baseline_loss = 187.4, learner_queue_size = 32, _tick = 69, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:27,393[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 560.7, step = 179200, mean_episode_return = 0.21941, mean_episode_step = 67.529, total_loss = 241.71, entropy_loss = -10.091, pg_loss = 64.409, baseline_loss = 187.4, learner_queue_size = 32, _tick = 69, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:32,399[0m][[34mroot[0m][[32mINFO[0m] - Step 181760 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 565.7, step = 181760, mean_episode_return = 0.25646, mean_episode_step = 55.868, total_loss = -755.99, entropy_loss = -10.052, pg_loss = -851.43, baseline_loss = 105.5, learner_queue_size = 32, _tick = 70, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:37,404[0m][[34mroot[0m][[32mINFO[0m] - Step 184320 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 570.7, step = 184320, mean_episode_return = 0.23136, mean_episode_step = 63.739, total_loss = -40.91, entropy_loss = -10.023, pg_loss = -161.4, baseline_loss = 130.51, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:42,409[0m][[34mroot[0m][[32mINFO[0m] - Step 184320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 575.7, step = 184320, mean_episode_return = 0.23136, mean_episode_step = 63.739, total_loss = -40.91, entropy_loss = -10.023, pg_loss = -161.4, baseline_loss = 130.51, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:47,415[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 580.7, step = 186880, mean_episode_return = 0.24873, mean_episode_step = 55.989, total_loss = -130.72, entropy_loss = -9.9681, pg_loss = -205.24, baseline_loss = 84.49, learner_queue_size = 32, _tick = 72, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:52,422[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 585.7, step = 189440, mean_episode_return = 0.28795, mean_episode_step = 56.338, total_loss = -221.15, entropy_loss = -9.9897, pg_loss = -333.84, baseline_loss = 122.68, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:00:57,427[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 590.7, step = 189440, mean_episode_return = 0.28795, mean_episode_step = 56.338, total_loss = -221.15, entropy_loss = -9.9897, pg_loss = -333.84, baseline_loss = 122.68, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:02,432[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 595.7, step = 192000, mean_episode_return = 0.084024, mean_episode_step = 55.181, total_loss = 226.83, entropy_loss = -9.9066, pg_loss = 154.54, baseline_loss = 82.193, learner_queue_size = 32, _tick = 74, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:07,438[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-20 15:01:07,467[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 600.8, step = 194560, mean_episode_return = 0.315, mean_episode_step = 70.788, total_loss = 972.27, entropy_loss = -9.9577, pg_loss = 836.35, baseline_loss = 145.88, learner_queue_size = 32, _tick = 75, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:12,471[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 605.8, step = 194560, mean_episode_return = 0.315, mean_episode_step = 70.788, total_loss = 972.27, entropy_loss = -9.9577, pg_loss = 836.35, baseline_loss = 145.88, learner_queue_size = 32, _tick = 75, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:17,476[0m][[34mroot[0m][[32mINFO[0m] - Step 197120 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 610.8, step = 197120, mean_episode_return = 0.15515, mean_episode_step = 49.93, total_loss = -370.81, entropy_loss = -10.026, pg_loss = -462.55, baseline_loss = 101.77, learner_queue_size = 32, _tick = 76, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:22,483[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 615.8, step = 199680, mean_episode_return = 0.33017, mean_episode_step = 61.465, total_loss = -246.59, entropy_loss = -9.9622, pg_loss = -358.22, baseline_loss = 121.6, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:27,488[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 620.8, step = 199680, mean_episode_return = 0.33017, mean_episode_step = 61.465, total_loss = -246.59, entropy_loss = -9.9622, pg_loss = -358.22, baseline_loss = 121.6, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:32,493[0m][[34mroot[0m][[32mINFO[0m] - Step 202240 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 625.8, step = 202240, mean_episode_return = 0.37578, mean_episode_step = 69.743, total_loss = 1589.8, entropy_loss = -9.9621, pg_loss = 1366.8, baseline_loss = 232.98, learner_queue_size = 32, _tick = 78, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:37,498[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 630.8, step = 204800, mean_episode_return = 0.16638, mean_episode_step = 49.867, total_loss = -478.47, entropy_loss = -9.9768, pg_loss = -603.55, baseline_loss = 135.06, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:42,504[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 635.8, step = 204800, mean_episode_return = 0.16638, mean_episode_step = 49.867, total_loss = -478.47, entropy_loss = -9.9768, pg_loss = -603.55, baseline_loss = 135.06, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:47,509[0m][[34mroot[0m][[32mINFO[0m] - Step 207360 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 640.8, step = 207360, mean_episode_return = 0.37437, mean_episode_step = 69.475, total_loss = 789.69, entropy_loss = -9.9438, pg_loss = 645.41, baseline_loss = 154.23, learner_queue_size = 32, _tick = 80, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:52,514[0m][[34mroot[0m][[32mINFO[0m] - Step 207360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 645.8, step = 207360, mean_episode_return = 0.37437, mean_episode_step = 69.475, total_loss = 789.69, entropy_loss = -9.9438, pg_loss = 645.41, baseline_loss = 154.23, learner_queue_size = 32, _tick = 80, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:01:57,519[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 650.8, step = 209920, mean_episode_return = 0.3146, mean_episode_step = 67.134, total_loss = 1302.5, entropy_loss = -9.9562, pg_loss = 1115.2, baseline_loss = 197.31, learner_queue_size = 32, _tick = 81, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:02,526[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 655.8, step = 212480, mean_episode_return = 0.30829, mean_episode_step = 63.557, total_loss = -514.52, entropy_loss = -9.9592, pg_loss = -595.21, baseline_loss = 90.653, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:07,531[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 660.8, step = 212480, mean_episode_return = 0.30829, mean_episode_step = 63.557, total_loss = -514.52, entropy_loss = -9.9592, pg_loss = -595.21, baseline_loss = 90.653, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:12,536[0m][[34mroot[0m][[32mINFO[0m] - Step 215040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 665.9, step = 215040, mean_episode_return = 0.27546, mean_episode_step = 78.216, total_loss = 118.6, entropy_loss = -9.9455, pg_loss = -28.031, baseline_loss = 156.57, learner_queue_size = 32, _tick = 83, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:17,541[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 670.9, step = 217600, mean_episode_return = 0.32758, mean_episode_step = 75.424, total_loss = -84.172, entropy_loss = -9.9482, pg_loss = -216.18, baseline_loss = 141.95, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:22,546[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 675.9, step = 217600, mean_episode_return = 0.32758, mean_episode_step = 75.424, total_loss = -84.172, entropy_loss = -9.9482, pg_loss = -216.18, baseline_loss = 141.95, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:27,551[0m][[34mroot[0m][[32mINFO[0m] - Step 220160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 680.9, step = 220160, mean_episode_return = 0.25873, mean_episode_step = 84.086, total_loss = -693.26, entropy_loss = -9.9455, pg_loss = -768.13, baseline_loss = 84.816, learner_queue_size = 32, _tick = 85, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:32,557[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 685.9, step = 222720, mean_episode_return = 0.36618, mean_episode_step = 69.35, total_loss = 213.97, entropy_loss = -9.9257, pg_loss = 87.457, baseline_loss = 136.44, learner_queue_size = 32, _tick = 86, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:37,561[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 690.9, step = 222720, mean_episode_return = 0.36618, mean_episode_step = 69.35, total_loss = 213.97, entropy_loss = -9.9257, pg_loss = 87.457, baseline_loss = 136.44, learner_queue_size = 32, _tick = 86, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:42,567[0m][[34mroot[0m][[32mINFO[0m] - Step 225280 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 695.9, step = 225280, mean_episode_return = 0.42803, mean_episode_step = 81.749, total_loss = -1089.2, entropy_loss = -9.9006, pg_loss = -1119.1, baseline_loss = 39.776, learner_queue_size = 32, _tick = 87, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:47,572[0m][[34mroot[0m][[32mINFO[0m] - Step 227840 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 700.9, step = 227840, mean_episode_return = 0.36386, mean_episode_step = 67.622, total_loss = -524.84, entropy_loss = -9.9057, pg_loss = -615.79, baseline_loss = 100.86, learner_queue_size = 32, _tick = 88, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:02:52,577[0m][[34mroot[0m][[32mINFO[0m] - Step 227840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 705.9, step = 227840, mean_episode_return = 0.36386, mean_episode_step = 67.622, total_loss = -524.84, entropy_loss = -9.9057, pg_loss = -615.79, baseline_loss = 100.86, learner_queue_size = 32, _tick = 88, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:05,539[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 197.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 718.9, step = 230400, mean_episode_return = 0.31374, mean_episode_step = 60.016, total_loss = -350.14, entropy_loss = -9.8853, pg_loss = -445.24, baseline_loss = 104.99, learner_queue_size = 32, _tick = 89, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:10,545[0m][[34mroot[0m][[32mINFO[0m] - Step 232960 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 723.9, step = 232960, mean_episode_return = 0.1924, mean_episode_step = 71.436, total_loss = -576.87, entropy_loss = -9.8821, pg_loss = -630.25, baseline_loss = 63.259, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:15,549[0m][[34mroot[0m][[32mINFO[0m] - Step 232960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 728.9, step = 232960, mean_episode_return = 0.1924, mean_episode_step = 71.436, total_loss = -576.87, entropy_loss = -9.8821, pg_loss = -630.25, baseline_loss = 63.259, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:20,557[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 511.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 733.9, step = 235520, mean_episode_return = 0.2481, mean_episode_step = 66.789, total_loss = 620.53, entropy_loss = -9.8571, pg_loss = 512.85, baseline_loss = 117.54, learner_queue_size = 32, _tick = 91, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:25,565[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 511.2 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 738.9, step = 238080, mean_episode_return = 0.24688, mean_episode_step = 55.841, total_loss = -407.97, entropy_loss = -9.8787, pg_loss = -485.0, baseline_loss = 86.905, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:30,570[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 743.9, step = 238080, mean_episode_return = 0.24688, mean_episode_step = 55.841, total_loss = -407.97, entropy_loss = -9.8787, pg_loss = -485.0, baseline_loss = 86.905, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:35,575[0m][[34mroot[0m][[32mINFO[0m] - Step 240640 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 748.9, step = 240640, mean_episode_return = 0.38035, mean_episode_step = 62.802, total_loss = 58.106, entropy_loss = -9.8472, pg_loss = -45.584, baseline_loss = 113.54, learner_queue_size = 32, _tick = 93, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:40,581[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 753.9, step = 243200, mean_episode_return = 0.34919, mean_episode_step = 65.568, total_loss = 528.21, entropy_loss = -9.8041, pg_loss = 421.52, baseline_loss = 116.49, learner_queue_size = 32, _tick = 94, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:45,587[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 758.9, step = 243200, mean_episode_return = 0.34919, mean_episode_step = 65.568, total_loss = 528.21, entropy_loss = -9.8041, pg_loss = 421.52, baseline_loss = 116.49, learner_queue_size = 32, _tick = 94, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:50,592[0m][[34mroot[0m][[32mINFO[0m] - Step 245760 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 763.9, step = 245760, mean_episode_return = 0.49471, mean_episode_step = 70.531, total_loss = 455.2, entropy_loss = -9.8103, pg_loss = 343.5, baseline_loss = 121.51, learner_queue_size = 32, _tick = 95, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:03:55,600[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 511.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 768.9, step = 248320, mean_episode_return = 0.23576, mean_episode_step = 59.044, total_loss = -411.25, entropy_loss = -9.8269, pg_loss = -497.65, baseline_loss = 96.224, learner_queue_size = 32, _tick = 96, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:00,604[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 773.9, step = 248320, mean_episode_return = 0.23576, mean_episode_step = 59.044, total_loss = -411.25, entropy_loss = -9.8269, pg_loss = -497.65, baseline_loss = 96.224, learner_queue_size = 32, _tick = 96, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:05,610[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar[0m
[[36m2025-01-20 15:04:05,649[0m][[34mroot[0m][[32mINFO[0m] - Step 250880 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 778.9, step = 250880, mean_episode_return = 0.23564, mean_episode_step = 55.855, total_loss = -765.6, entropy_loss = -9.815, pg_loss = -818.72, baseline_loss = 62.943, learner_queue_size = 32, _tick = 97, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:10,654[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 507.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 784.0, step = 253440, mean_episode_return = 0.25898, mean_episode_step = 58.66, total_loss = 183.82, entropy_loss = -9.8042, pg_loss = 77.501, baseline_loss = 116.12, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:15,659[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 789.0, step = 253440, mean_episode_return = 0.25898, mean_episode_step = 58.66, total_loss = 183.82, entropy_loss = -9.8042, pg_loss = 77.501, baseline_loss = 116.12, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:20,666[0m][[34mroot[0m][[32mINFO[0m] - Step 256000 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 794.0, step = 256000, mean_episode_return = 0.21504, mean_episode_step = 59.355, total_loss = -29.348, entropy_loss = -9.7942, pg_loss = -122.02, baseline_loss = 102.47, learner_queue_size = 32, _tick = 99, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:25,672[0m][[34mroot[0m][[32mINFO[0m] - Step 258560 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 799.0, step = 258560, mean_episode_return = 0.50483, mean_episode_step = 74.944, total_loss = -27.453, entropy_loss = -9.7836, pg_loss = -94.423, baseline_loss = 76.754, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:30,677[0m][[34mroot[0m][[32mINFO[0m] - Step 258560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 804.0, step = 258560, mean_episode_return = 0.50483, mean_episode_step = 74.944, total_loss = -27.453, entropy_loss = -9.7836, pg_loss = -94.423, baseline_loss = 76.754, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:35,682[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 809.0, step = 261120, mean_episode_return = 0.20403, mean_episode_step = 58.92, total_loss = 589.07, entropy_loss = -9.8111, pg_loss = 488.82, baseline_loss = 110.06, learner_queue_size = 32, _tick = 101, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:40,687[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 814.0, step = 263680, mean_episode_return = 0.27474, mean_episode_step = 66.516, total_loss = 322.87, entropy_loss = -9.8237, pg_loss = 202.82, baseline_loss = 129.87, learner_queue_size = 32, _tick = 102, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:45,693[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 819.0, step = 263680, mean_episode_return = 0.27474, mean_episode_step = 66.516, total_loss = 322.87, entropy_loss = -9.8237, pg_loss = 202.82, baseline_loss = 129.87, learner_queue_size = 32, _tick = 102, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:50,698[0m][[34mroot[0m][[32mINFO[0m] - Step 266240 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 824.0, step = 266240, mean_episode_return = 0.23104, mean_episode_step = 64.265, total_loss = 679.41, entropy_loss = -9.793, pg_loss = 533.48, baseline_loss = 155.72, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:04:55,704[0m][[34mroot[0m][[32mINFO[0m] - Step 266240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 829.0, step = 266240, mean_episode_return = 0.23104, mean_episode_step = 64.265, total_loss = 679.41, entropy_loss = -9.793, pg_loss = 533.48, baseline_loss = 155.72, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:00,706[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 511.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 834.0, step = 268800, mean_episode_return = 0.14996, mean_episode_step = 68.83, total_loss = -117.04, entropy_loss = -9.8042, pg_loss = -189.89, baseline_loss = 82.656, learner_queue_size = 32, _tick = 104, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:05,713[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 511.3 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 839.0, step = 271360, mean_episode_return = 0.24562, mean_episode_step = 57.341, total_loss = 396.55, entropy_loss = -9.8155, pg_loss = 261.42, baseline_loss = 144.95, learner_queue_size = 32, _tick = 105, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:10,718[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 844.0, step = 271360, mean_episode_return = 0.24562, mean_episode_step = 57.341, total_loss = 396.55, entropy_loss = -9.8155, pg_loss = 261.42, baseline_loss = 144.95, learner_queue_size = 32, _tick = 105, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:15,723[0m][[34mroot[0m][[32mINFO[0m] - Step 273920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 849.0, step = 273920, mean_episode_return = 0.20049, mean_episode_step = 55.064, total_loss = 570.51, entropy_loss = -9.8334, pg_loss = 432.49, baseline_loss = 147.85, learner_queue_size = 32, _tick = 106, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:20,730[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 854.0, step = 276480, mean_episode_return = 0.33415, mean_episode_step = 62.777, total_loss = 595.77, entropy_loss = -9.8336, pg_loss = 457.04, baseline_loss = 148.56, learner_queue_size = 32, _tick = 107, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:25,734[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 859.0, step = 276480, mean_episode_return = 0.33415, mean_episode_step = 62.777, total_loss = 595.77, entropy_loss = -9.8336, pg_loss = 457.04, baseline_loss = 148.56, learner_queue_size = 32, _tick = 107, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:30,740[0m][[34mroot[0m][[32mINFO[0m] - Step 279040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 864.1, step = 279040, mean_episode_return = 0.47511, mean_episode_step = 69.223, total_loss = 28.674, entropy_loss = -9.882, pg_loss = -119.44, baseline_loss = 157.99, learner_queue_size = 32, _tick = 108, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:35,746[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 869.1, step = 281600, mean_episode_return = 0.1504, mean_episode_step = 60.648, total_loss = 366.1, entropy_loss = -9.8016, pg_loss = 231.17, baseline_loss = 144.73, learner_queue_size = 32, _tick = 109, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:40,751[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 874.1, step = 281600, mean_episode_return = 0.1504, mean_episode_step = 60.648, total_loss = 366.1, entropy_loss = -9.8016, pg_loss = 231.17, baseline_loss = 144.73, learner_queue_size = 32, _tick = 109, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:45,756[0m][[34mroot[0m][[32mINFO[0m] - Step 284160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 879.1, step = 284160, mean_episode_return = 0.43641, mean_episode_step = 68.02, total_loss = -194.36, entropy_loss = -9.8172, pg_loss = -300.32, baseline_loss = 115.79, learner_queue_size = 32, _tick = 110, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:50,761[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 884.1, step = 286720, mean_episode_return = 0.33324, mean_episode_step = 66.808, total_loss = 56.455, entropy_loss = -9.7987, pg_loss = -58.813, baseline_loss = 125.07, learner_queue_size = 32, _tick = 111, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:05:55,766[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 889.1, step = 286720, mean_episode_return = 0.33324, mean_episode_step = 66.808, total_loss = 56.455, entropy_loss = -9.7987, pg_loss = -58.813, baseline_loss = 125.07, learner_queue_size = 32, _tick = 111, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:00,772[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 894.1, step = 289280, mean_episode_return = 0.32876, mean_episode_step = 69.633, total_loss = -484.3, entropy_loss = -9.7728, pg_loss = -551.44, baseline_loss = 76.916, learner_queue_size = 32, _tick = 112, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:05,778[0m][[34mroot[0m][[32mINFO[0m] - Step 291840 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 899.1, step = 291840, mean_episode_return = 0.32617, mean_episode_step = 62.1, total_loss = -826.56, entropy_loss = -9.7641, pg_loss = -899.63, baseline_loss = 82.836, learner_queue_size = 32, _tick = 113, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:10,783[0m][[34mroot[0m][[32mINFO[0m] - Step 291840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 904.1, step = 291840, mean_episode_return = 0.32617, mean_episode_step = 62.1, total_loss = -826.56, entropy_loss = -9.7641, pg_loss = -899.63, baseline_loss = 82.836, learner_queue_size = 32, _tick = 113, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:15,788[0m][[34mroot[0m][[32mINFO[0m] - Step 294400 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 909.1, step = 294400, mean_episode_return = 0.1922, mean_episode_step = 66.51, total_loss = -647.82, entropy_loss = -9.737, pg_loss = -713.26, baseline_loss = 75.176, learner_queue_size = 32, _tick = 114, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:20,793[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 914.1, step = 296960, mean_episode_return = 0.34033, mean_episode_step = 63.943, total_loss = 595.72, entropy_loss = -9.7344, pg_loss = 446.71, baseline_loss = 158.74, learner_queue_size = 32, _tick = 115, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:25,798[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 919.1, step = 296960, mean_episode_return = 0.34033, mean_episode_step = 63.943, total_loss = 595.72, entropy_loss = -9.7344, pg_loss = 446.71, baseline_loss = 158.74, learner_queue_size = 32, _tick = 115, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:30,804[0m][[34mroot[0m][[32mINFO[0m] - Step 299520 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 924.1, step = 299520, mean_episode_return = 0.41087, mean_episode_step = 76.369, total_loss = -540.45, entropy_loss = -9.7134, pg_loss = -621.93, baseline_loss = 91.198, learner_queue_size = 32, _tick = 116, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:35,809[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 929.1, step = 302080, mean_episode_return = 0.24873, mean_episode_step = 68.066, total_loss = 126.64, entropy_loss = -9.7198, pg_loss = 30.889, baseline_loss = 105.47, learner_queue_size = 32, _tick = 117, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:40,814[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 934.1, step = 302080, mean_episode_return = 0.24873, mean_episode_step = 68.066, total_loss = 126.64, entropy_loss = -9.7198, pg_loss = 30.889, baseline_loss = 105.47, learner_queue_size = 32, _tick = 117, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:45,820[0m][[34mroot[0m][[32mINFO[0m] - Step 304640 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 939.1, step = 304640, mean_episode_return = 0.27192, mean_episode_step = 67.073, total_loss = -745.74, entropy_loss = -9.7604, pg_loss = -805.51, baseline_loss = 69.532, learner_queue_size = 32, _tick = 118, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:50,826[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 944.1, step = 307200, mean_episode_return = 0.1569, mean_episode_step = 54.983, total_loss = -546.45, entropy_loss = -9.7565, pg_loss = -603.43, baseline_loss = 66.738, learner_queue_size = 32, _tick = 119, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:06:55,831[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 949.1, step = 307200, mean_episode_return = 0.1569, mean_episode_step = 54.983, total_loss = -546.45, entropy_loss = -9.7565, pg_loss = -603.43, baseline_loss = 66.738, learner_queue_size = 32, _tick = 119, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:00,836[0m][[34mroot[0m][[32mINFO[0m] - Step 309760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 954.2, step = 309760, mean_episode_return = 0.25192, mean_episode_step = 55.712, total_loss = -80.434, entropy_loss = -9.7451, pg_loss = -164.3, baseline_loss = 93.613, learner_queue_size = 32, _tick = 120, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:05,841[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 959.2, step = 312320, mean_episode_return = 0.41437, mean_episode_step = 76.104, total_loss = 922.12, entropy_loss = -9.7202, pg_loss = 757.33, baseline_loss = 174.52, learner_queue_size = 32, _tick = 121, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:10,847[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 964.2, step = 312320, mean_episode_return = 0.41437, mean_episode_step = 76.104, total_loss = 922.12, entropy_loss = -9.7202, pg_loss = 757.33, baseline_loss = 174.52, learner_queue_size = 32, _tick = 121, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:15,852[0m][[34mroot[0m][[32mINFO[0m] - Step 314880 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 969.2, step = 314880, mean_episode_return = 0.21589, mean_episode_step = 61.884, total_loss = 300.3, entropy_loss = -9.7375, pg_loss = 164.14, baseline_loss = 145.9, learner_queue_size = 32, _tick = 122, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:20,865[0m][[34mroot[0m][[32mINFO[0m] - Step 317440 @ 510.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 974.2, step = 317440, mean_episode_return = 0.32759, mean_episode_step = 70.353, total_loss = 65.911, entropy_loss = -9.7392, pg_loss = -54.727, baseline_loss = 130.38, learner_queue_size = 32, _tick = 123, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:25,869[0m][[34mroot[0m][[32mINFO[0m] - Step 317440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 979.2, step = 317440, mean_episode_return = 0.32759, mean_episode_step = 70.353, total_loss = 65.911, entropy_loss = -9.7392, pg_loss = -54.727, baseline_loss = 130.38, learner_queue_size = 32, _tick = 123, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:30,875[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 984.2, step = 320000, mean_episode_return = 0.387, mean_episode_step = 66.873, total_loss = 674.61, entropy_loss = -9.7296, pg_loss = 508.97, baseline_loss = 175.37, learner_queue_size = 32, _tick = 124, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:35,881[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 989.2, step = 322560, mean_episode_return = 0.20871, mean_episode_step = 65.913, total_loss = 548.67, entropy_loss = -9.7571, pg_loss = 438.46, baseline_loss = 119.96, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:40,886[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 994.2, step = 322560, mean_episode_return = 0.20871, mean_episode_step = 65.913, total_loss = 548.67, entropy_loss = -9.7571, pg_loss = 438.46, baseline_loss = 119.96, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:45,891[0m][[34mroot[0m][[32mINFO[0m] - Step 325120 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 999.2, step = 325120, mean_episode_return = 0.11808, mean_episode_step = 57.915, total_loss = 233.12, entropy_loss = -9.758, pg_loss = 106.91, baseline_loss = 135.96, learner_queue_size = 32, _tick = 126, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:50,896[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1004.2, step = 327680, mean_episode_return = 0.2968, mean_episode_step = 74.393, total_loss = -737.63, entropy_loss = -9.7292, pg_loss = -818.53, baseline_loss = 90.621, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:07:55,901[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1009.2, step = 327680, mean_episode_return = 0.2968, mean_episode_step = 74.393, total_loss = -737.63, entropy_loss = -9.7292, pg_loss = -818.53, baseline_loss = 90.621, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:00,907[0m][[34mroot[0m][[32mINFO[0m] - Step 330240 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1014.2, step = 330240, mean_episode_return = 0.50542, mean_episode_step = 67.773, total_loss = 24.918, entropy_loss = -9.7258, pg_loss = -106.09, baseline_loss = 140.73, learner_queue_size = 32, _tick = 128, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:05,913[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1019.2, step = 332800, mean_episode_return = 0.23186, mean_episode_step = 63.357, total_loss = -17.679, entropy_loss = -9.7302, pg_loss = -124.6, baseline_loss = 116.65, learner_queue_size = 32, _tick = 129, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:10,914[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1024.2, step = 332800, mean_episode_return = 0.23186, mean_episode_step = 63.357, total_loss = -17.679, entropy_loss = -9.7302, pg_loss = -124.6, baseline_loss = 116.65, learner_queue_size = 32, _tick = 129, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:15,919[0m][[34mroot[0m][[32mINFO[0m] - Step 335360 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1029.2, step = 335360, mean_episode_return = 0.19747, mean_episode_step = 51.588, total_loss = -23.307, entropy_loss = -9.7522, pg_loss = -150.52, baseline_loss = 136.96, learner_queue_size = 32, _tick = 130, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:20,925[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1034.2, step = 337920, mean_episode_return = 0.60882, mean_episode_step = 77.398, total_loss = -185.19, entropy_loss = -9.6997, pg_loss = -242.23, baseline_loss = 66.742, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:25,930[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1039.2, step = 337920, mean_episode_return = 0.60882, mean_episode_step = 77.398, total_loss = -185.19, entropy_loss = -9.6997, pg_loss = -242.23, baseline_loss = 66.742, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:30,936[0m][[34mroot[0m][[32mINFO[0m] - Step 340480 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1044.3, step = 340480, mean_episode_return = 0.46409, mean_episode_step = 73.005, total_loss = -236.68, entropy_loss = -9.7034, pg_loss = -314.48, baseline_loss = 87.505, learner_queue_size = 32, _tick = 132, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:35,941[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1049.3, step = 343040, mean_episode_return = 0.38535, mean_episode_step = 77.216, total_loss = 13.343, entropy_loss = -9.6813, pg_loss = -77.209, baseline_loss = 100.23, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:40,947[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1054.3, step = 343040, mean_episode_return = 0.38535, mean_episode_step = 77.216, total_loss = 13.343, entropy_loss = -9.6813, pg_loss = -77.209, baseline_loss = 100.23, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:45,952[0m][[34mroot[0m][[32mINFO[0m] - Step 345600 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1059.3, step = 345600, mean_episode_return = 0.43572, mean_episode_step = 73.133, total_loss = -580.13, entropy_loss = -9.6698, pg_loss = -622.69, baseline_loss = 52.229, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:50,959[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1064.3, step = 348160, mean_episode_return = 0.25723, mean_episode_step = 63.557, total_loss = -287.89, entropy_loss = -9.6803, pg_loss = -343.72, baseline_loss = 65.51, learner_queue_size = 32, _tick = 135, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:08:55,965[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1069.3, step = 348160, mean_episode_return = 0.25723, mean_episode_step = 63.557, total_loss = -287.89, entropy_loss = -9.6803, pg_loss = -343.72, baseline_loss = 65.51, learner_queue_size = 32, _tick = 135, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:00,970[0m][[34mroot[0m][[32mINFO[0m] - Step 350720 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1074.3, step = 350720, mean_episode_return = 0.31459, mean_episode_step = 75.231, total_loss = 138.29, entropy_loss = -9.6356, pg_loss = 81.31, baseline_loss = 66.621, learner_queue_size = 32, _tick = 136, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:05,978[0m][[34mroot[0m][[32mINFO[0m] - Step 353280 @ 511.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1079.3, step = 353280, mean_episode_return = 0.43529, mean_episode_step = 75.711, total_loss = 1297.9, entropy_loss = -9.6287, pg_loss = 1141.8, baseline_loss = 165.68, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:10,982[0m][[34mroot[0m][[32mINFO[0m] - Step 353280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1084.3, step = 353280, mean_episode_return = 0.43529, mean_episode_step = 75.711, total_loss = 1297.9, entropy_loss = -9.6287, pg_loss = 1141.8, baseline_loss = 165.68, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:15,987[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1089.3, step = 355840, mean_episode_return = 0.48068, mean_episode_step = 72.563, total_loss = -504.16, entropy_loss = -9.6631, pg_loss = -555.82, baseline_loss = 61.326, learner_queue_size = 32, _tick = 138, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:20,992[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1094.3, step = 358400, mean_episode_return = 0.37311, mean_episode_step = 69.96, total_loss = 388.4, entropy_loss = -9.6503, pg_loss = 303.49, baseline_loss = 94.563, learner_queue_size = 32, _tick = 139, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:25,998[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1099.3, step = 358400, mean_episode_return = 0.37311, mean_episode_step = 69.96, total_loss = 388.4, entropy_loss = -9.6503, pg_loss = 303.49, baseline_loss = 94.563, learner_queue_size = 32, _tick = 139, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:31,006[0m][[34mroot[0m][[32mINFO[0m] - Step 360960 @ 511.2 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1104.3, step = 360960, mean_episode_return = 0.27893, mean_episode_step = 55.38, total_loss = -155.32, entropy_loss = -9.6987, pg_loss = -249.3, baseline_loss = 103.69, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:36,011[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1109.3, step = 363520, mean_episode_return = 0.37963, mean_episode_step = 64.26, total_loss = -294.61, entropy_loss = -9.7041, pg_loss = -367.84, baseline_loss = 82.938, learner_queue_size = 32, _tick = 141, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:41,017[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1114.3, step = 363520, mean_episode_return = 0.37963, mean_episode_step = 64.26, total_loss = -294.61, entropy_loss = -9.7041, pg_loss = -367.84, baseline_loss = 82.938, learner_queue_size = 32, _tick = 141, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:46,022[0m][[34mroot[0m][[32mINFO[0m] - Step 366080 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1119.3, step = 366080, mean_episode_return = 0.3026, mean_episode_step = 75.307, total_loss = -184.28, entropy_loss = -9.6782, pg_loss = -259.3, baseline_loss = 84.7, learner_queue_size = 32, _tick = 142, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:51,028[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1124.3, step = 368640, mean_episode_return = 0.23106, mean_episode_step = 63.984, total_loss = 291.75, entropy_loss = -9.6796, pg_loss = 177.41, baseline_loss = 124.01, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:09:56,034[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1129.3, step = 368640, mean_episode_return = 0.23106, mean_episode_step = 63.984, total_loss = 291.75, entropy_loss = -9.6796, pg_loss = 177.41, baseline_loss = 124.01, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:01,040[0m][[34mroot[0m][[32mINFO[0m] - Step 371200 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1134.4, step = 371200, mean_episode_return = 0.5009, mean_episode_step = 78.129, total_loss = 442.72, entropy_loss = -9.6738, pg_loss = 357.5, baseline_loss = 94.899, learner_queue_size = 32, _tick = 144, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:06,046[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1139.4, step = 373760, mean_episode_return = 0.24256, mean_episode_step = 70.215, total_loss = 595.98, entropy_loss = -9.6779, pg_loss = 416.91, baseline_loss = 188.75, learner_queue_size = 32, _tick = 145, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:11,051[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1144.4, step = 373760, mean_episode_return = 0.24256, mean_episode_step = 70.215, total_loss = 595.98, entropy_loss = -9.6779, pg_loss = 416.91, baseline_loss = 188.75, learner_queue_size = 32, _tick = 145, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:16,056[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar[0m
[[36m2025-01-20 15:10:16,099[0m][[34mroot[0m][[32mINFO[0m] - Step 376320 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1149.4, step = 376320, mean_episode_return = 0.50267, mean_episode_step = 71.553, total_loss = -174.43, entropy_loss = -9.6858, pg_loss = -259.41, baseline_loss = 94.66, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:21,104[0m][[34mroot[0m][[32mINFO[0m] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1154.4, step = 376320, mean_episode_return = 0.50267, mean_episode_step = 71.553, total_loss = -174.43, entropy_loss = -9.6858, pg_loss = -259.41, baseline_loss = 94.66, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:26,109[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1159.4, step = 378880, mean_episode_return = 0.33956, mean_episode_step = 63.041, total_loss = 87.374, entropy_loss = -9.6824, pg_loss = -3.8359, baseline_loss = 100.89, learner_queue_size = 32, _tick = 147, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:31,116[0m][[34mroot[0m][[32mINFO[0m] - Step 381440 @ 511.3 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1164.4, step = 381440, mean_episode_return = 0.43964, mean_episode_step = 56.455, total_loss = 533.88, entropy_loss = -9.7099, pg_loss = 388.81, baseline_loss = 154.78, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:36,121[0m][[34mroot[0m][[32mINFO[0m] - Step 381440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1169.4, step = 381440, mean_episode_return = 0.43964, mean_episode_step = 56.455, total_loss = 533.88, entropy_loss = -9.7099, pg_loss = 388.81, baseline_loss = 154.78, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:41,127[0m][[34mroot[0m][[32mINFO[0m] - Step 384000 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1174.4, step = 384000, mean_episode_return = 0.26013, mean_episode_step = 54.332, total_loss = 458.87, entropy_loss = -9.7068, pg_loss = 305.86, baseline_loss = 162.73, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:46,133[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1179.4, step = 386560, mean_episode_return = 0.23672, mean_episode_step = 53.732, total_loss = 234.24, entropy_loss = -9.7152, pg_loss = 79.412, baseline_loss = 164.54, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:51,138[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1184.5, step = 386560, mean_episode_return = 0.23672, mean_episode_step = 53.732, total_loss = 234.24, entropy_loss = -9.7152, pg_loss = 79.412, baseline_loss = 164.54, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:10:56,142[0m][[34mroot[0m][[32mINFO[0m] - Step 389120 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1189.5, step = 389120, mean_episode_return = 0.27837, mean_episode_step = 67.268, total_loss = 1100.4, entropy_loss = -9.6928, pg_loss = 907.1, baseline_loss = 202.99, learner_queue_size = 32, _tick = 151, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:01,148[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1194.5, step = 391680, mean_episode_return = 0.25785, mean_episode_step = 68.272, total_loss = 90.391, entropy_loss = -9.6919, pg_loss = -0.92606, baseline_loss = 101.01, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:06,153[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1199.5, step = 391680, mean_episode_return = 0.25785, mean_episode_step = 68.272, total_loss = 90.391, entropy_loss = -9.6919, pg_loss = -0.92606, baseline_loss = 101.01, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:11,158[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-20 15:11:11,273[0m][[34mroot[0m][[32mINFO[0m] - Step 394240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1204.5, step = 394240, mean_episode_return = 0.55756, mean_episode_step = 72.634, total_loss = 1050.4, entropy_loss = -9.674, pg_loss = 889.75, baseline_loss = 170.33, learner_queue_size = 32, _tick = 153, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:16,277[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 500.1 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1209.6, step = 396800, mean_episode_return = 0.36654, mean_episode_step = 65.052, total_loss = 447.19, entropy_loss = -9.689, pg_loss = 309.07, baseline_loss = 147.82, learner_queue_size = 32, _tick = 154, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:21,283[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1214.6, step = 396800, mean_episode_return = 0.36654, mean_episode_step = 65.052, total_loss = 447.19, entropy_loss = -9.689, pg_loss = 309.07, baseline_loss = 147.82, learner_queue_size = 32, _tick = 154, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:26,288[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1219.6, step = 399360, mean_episode_return = 0.39803, mean_episode_step = 71.788, total_loss = 283.19, entropy_loss = -9.6827, pg_loss = 171.79, baseline_loss = 121.09, learner_queue_size = 32, _tick = 155, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:31,293[0m][[34mroot[0m][[32mINFO[0m] - Step 401920 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1224.6, step = 401920, mean_episode_return = 0.32914, mean_episode_step = 56.785, total_loss = 197.31, entropy_loss = -9.7044, pg_loss = 63.898, baseline_loss = 143.12, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:36,298[0m][[34mroot[0m][[32mINFO[0m] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1229.6, step = 401920, mean_episode_return = 0.32914, mean_episode_step = 56.785, total_loss = 197.31, entropy_loss = -9.7044, pg_loss = 63.898, baseline_loss = 143.12, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:41,304[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1234.6, step = 404480, mean_episode_return = 0.3131, mean_episode_step = 73.301, total_loss = -653.18, entropy_loss = -9.6937, pg_loss = -721.82, baseline_loss = 78.33, learner_queue_size = 32, _tick = 157, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:46,308[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1239.6, step = 407040, mean_episode_return = 0.43272, mean_episode_step = 73.075, total_loss = 136.57, entropy_loss = -9.684, pg_loss = 16.155, baseline_loss = 130.1, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:51,314[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1244.6, step = 407040, mean_episode_return = 0.43272, mean_episode_step = 73.075, total_loss = 136.57, entropy_loss = -9.684, pg_loss = 16.155, baseline_loss = 130.1, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:11:56,319[0m][[34mroot[0m][[32mINFO[0m] - Step 409600 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1249.6, step = 409600, mean_episode_return = 0.42362, mean_episode_step = 56.203, total_loss = -396.49, entropy_loss = -9.686, pg_loss = -478.08, baseline_loss = 91.284, learner_queue_size = 32, _tick = 159, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:01,324[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1254.6, step = 412160, mean_episode_return = 0.32185, mean_episode_step = 63.039, total_loss = 1728.1, entropy_loss = -9.6884, pg_loss = 1495.7, baseline_loss = 242.11, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:06,329[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1259.6, step = 412160, mean_episode_return = 0.32185, mean_episode_step = 63.039, total_loss = 1728.1, entropy_loss = -9.6884, pg_loss = 1495.7, baseline_loss = 242.11, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:11,334[0m][[34mroot[0m][[32mINFO[0m] - Step 414720 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1264.6, step = 414720, mean_episode_return = 0.27054, mean_episode_step = 62.607, total_loss = -382.48, entropy_loss = -9.6687, pg_loss = -460.41, baseline_loss = 87.6, learner_queue_size = 32, _tick = 161, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:16,339[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1269.7, step = 417280, mean_episode_return = 0.28096, mean_episode_step = 53.643, total_loss = -630.74, entropy_loss = -9.7025, pg_loss = -739.87, baseline_loss = 118.83, learner_queue_size = 32, _tick = 162, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:21,344[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1274.7, step = 417280, mean_episode_return = 0.28096, mean_episode_step = 53.643, total_loss = -630.74, entropy_loss = -9.7025, pg_loss = -739.87, baseline_loss = 118.83, learner_queue_size = 32, _tick = 162, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:26,349[0m][[34mroot[0m][[32mINFO[0m] - Step 419840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1279.7, step = 419840, mean_episode_return = 0.34637, mean_episode_step = 57.672, total_loss = -26.497, entropy_loss = -9.691, pg_loss = -139.52, baseline_loss = 122.71, learner_queue_size = 32, _tick = 163, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:31,354[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1284.7, step = 422400, mean_episode_return = 0.25153, mean_episode_step = 66.385, total_loss = 1401.0, entropy_loss = -9.6822, pg_loss = 1171.0, baseline_loss = 239.68, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:36,359[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1289.7, step = 422400, mean_episode_return = 0.25153, mean_episode_step = 66.385, total_loss = 1401.0, entropy_loss = -9.6822, pg_loss = 1171.0, baseline_loss = 239.68, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:41,364[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1294.7, step = 424960, mean_episode_return = 0.35979, mean_episode_step = 67.084, total_loss = -693.46, entropy_loss = -9.6853, pg_loss = -758.27, baseline_loss = 74.493, learner_queue_size = 32, _tick = 165, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:46,371[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1299.7, step = 427520, mean_episode_return = 0.22981, mean_episode_step = 62.648, total_loss = 340.93, entropy_loss = -9.6937, pg_loss = 201.61, baseline_loss = 149.02, learner_queue_size = 32, _tick = 166, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:51,376[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1304.7, step = 427520, mean_episode_return = 0.22981, mean_episode_step = 62.648, total_loss = 340.93, entropy_loss = -9.6937, pg_loss = 201.61, baseline_loss = 149.02, learner_queue_size = 32, _tick = 166, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:12:56,380[0m][[34mroot[0m][[32mINFO[0m] - Step 430080 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1309.7, step = 430080, mean_episode_return = 0.31092, mean_episode_step = 66.606, total_loss = 311.25, entropy_loss = -9.6924, pg_loss = 146.78, baseline_loss = 174.16, learner_queue_size = 32, _tick = 167, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:01,385[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1314.7, step = 432640, mean_episode_return = 0.24063, mean_episode_step = 62.047, total_loss = -199.5, entropy_loss = -9.6788, pg_loss = -332.09, baseline_loss = 142.27, learner_queue_size = 32, _tick = 168, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:06,391[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1319.7, step = 432640, mean_episode_return = 0.24063, mean_episode_step = 62.047, total_loss = -199.5, entropy_loss = -9.6788, pg_loss = -332.09, baseline_loss = 142.27, learner_queue_size = 32, _tick = 168, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:11,396[0m][[34mroot[0m][[32mINFO[0m] - Step 435200 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1324.7, step = 435200, mean_episode_return = 0.38831, mean_episode_step = 77.621, total_loss = -237.4, entropy_loss = -9.68, pg_loss = -340.82, baseline_loss = 113.1, learner_queue_size = 32, _tick = 169, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:16,402[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1329.7, step = 437760, mean_episode_return = 0.31491, mean_episode_step = 62.295, total_loss = -456.88, entropy_loss = -9.6787, pg_loss = -564.71, baseline_loss = 117.51, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:21,406[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1334.7, step = 437760, mean_episode_return = 0.31491, mean_episode_step = 62.295, total_loss = -456.88, entropy_loss = -9.6787, pg_loss = -564.71, baseline_loss = 117.51, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:26,411[0m][[34mroot[0m][[32mINFO[0m] - Step 440320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1339.7, step = 440320, mean_episode_return = 0.19068, mean_episode_step = 52.805, total_loss = -821.84, entropy_loss = -9.6941, pg_loss = -943.11, baseline_loss = 130.96, learner_queue_size = 32, _tick = 171, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:31,416[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1344.7, step = 442880, mean_episode_return = 0.47015, mean_episode_step = 56.518, total_loss = -442.42, entropy_loss = -9.6856, pg_loss = -545.98, baseline_loss = 113.25, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:36,421[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1349.7, step = 442880, mean_episode_return = 0.47015, mean_episode_step = 56.518, total_loss = -442.42, entropy_loss = -9.6856, pg_loss = -545.98, baseline_loss = 113.25, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:41,426[0m][[34mroot[0m][[32mINFO[0m] - Step 445440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1354.7, step = 445440, mean_episode_return = 0.46644, mean_episode_step = 66.701, total_loss = 731.49, entropy_loss = -9.68, pg_loss = 560.51, baseline_loss = 180.66, learner_queue_size = 32, _tick = 173, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:46,435[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 511.1 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 1359.8, step = 448000, mean_episode_return = 0.5171, mean_episode_step = 65.716, total_loss = -297.22, entropy_loss = -9.6804, pg_loss = -464.16, baseline_loss = 176.61, learner_queue_size = 32, _tick = 174, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:51,441[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1364.8, step = 448000, mean_episode_return = 0.5171, mean_episode_step = 65.716, total_loss = -297.22, entropy_loss = -9.6804, pg_loss = -464.16, baseline_loss = 176.61, learner_queue_size = 32, _tick = 174, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:13:56,446[0m][[34mroot[0m][[32mINFO[0m] - Step 450560 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1369.8, step = 450560, mean_episode_return = 0.26403, mean_episode_step = 63.705, total_loss = 43.261, entropy_loss = -9.6686, pg_loss = -86.432, baseline_loss = 139.36, learner_queue_size = 32, _tick = 175, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:01,452[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1374.8, step = 453120, mean_episode_return = 0.1927, mean_episode_step = 55.036, total_loss = -804.38, entropy_loss = -9.6742, pg_loss = -904.76, baseline_loss = 110.05, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:06,457[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1379.8, step = 453120, mean_episode_return = 0.1927, mean_episode_step = 55.036, total_loss = -804.38, entropy_loss = -9.6742, pg_loss = -904.76, baseline_loss = 110.05, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:11,462[0m][[34mroot[0m][[32mINFO[0m] - Step 455680 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1384.8, step = 455680, mean_episode_return = 0.18419, mean_episode_step = 55.657, total_loss = -121.38, entropy_loss = -9.6709, pg_loss = -244.53, baseline_loss = 132.82, learner_queue_size = 32, _tick = 177, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:16,468[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1389.8, step = 458240, mean_episode_return = 0.28024, mean_episode_step = 70.4, total_loss = -532.24, entropy_loss = -9.6536, pg_loss = -609.97, baseline_loss = 87.385, learner_queue_size = 32, _tick = 178, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:21,472[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1394.8, step = 458240, mean_episode_return = 0.28024, mean_episode_step = 70.4, total_loss = -532.24, entropy_loss = -9.6536, pg_loss = -609.97, baseline_loss = 87.385, learner_queue_size = 32, _tick = 178, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:26,477[0m][[34mroot[0m][[32mINFO[0m] - Step 460800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1399.8, step = 460800, mean_episode_return = 0.38296, mean_episode_step = 78.174, total_loss = 160.45, entropy_loss = -9.63, pg_loss = 61.64, baseline_loss = 108.44, learner_queue_size = 32, _tick = 179, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:31,484[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1404.8, step = 463360, mean_episode_return = 0.26056, mean_episode_step = 78.399, total_loss = -45.003, entropy_loss = -9.6451, pg_loss = -146.13, baseline_loss = 110.78, learner_queue_size = 32, _tick = 180, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:36,489[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1409.8, step = 463360, mean_episode_return = 0.26056, mean_episode_step = 78.399, total_loss = -45.003, entropy_loss = -9.6451, pg_loss = -146.13, baseline_loss = 110.78, learner_queue_size = 32, _tick = 180, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:41,494[0m][[34mroot[0m][[32mINFO[0m] - Step 465920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1414.8, step = 465920, mean_episode_return = 0.22365, mean_episode_step = 59.182, total_loss = 1061.2, entropy_loss = -9.6423, pg_loss = 898.6, baseline_loss = 172.21, learner_queue_size = 32, _tick = 181, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:46,501[0m][[34mroot[0m][[32mINFO[0m] - Step 468480 @ 511.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1419.8, step = 468480, mean_episode_return = 0.2348, mean_episode_step = 63.548, total_loss = -1094.1, entropy_loss = -9.6495, pg_loss = -1157.1, baseline_loss = 72.631, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:51,507[0m][[34mroot[0m][[32mINFO[0m] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1424.8, step = 468480, mean_episode_return = 0.2348, mean_episode_step = 63.548, total_loss = -1094.1, entropy_loss = -9.6495, pg_loss = -1157.1, baseline_loss = 72.631, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:14:56,511[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1429.8, step = 471040, mean_episode_return = 0.45661, mean_episode_step = 74.051, total_loss = -449.07, entropy_loss = -9.6418, pg_loss = -533.18, baseline_loss = 93.749, learner_queue_size = 32, _tick = 183, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:01,516[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1434.8, step = 473600, mean_episode_return = 0.38862, mean_episode_step = 52.602, total_loss = 194.69, entropy_loss = -9.6416, pg_loss = 57.391, baseline_loss = 146.94, learner_queue_size = 32, _tick = 184, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:06,521[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1439.8, step = 473600, mean_episode_return = 0.38862, mean_episode_step = 52.602, total_loss = 194.69, entropy_loss = -9.6416, pg_loss = 57.391, baseline_loss = 146.94, learner_queue_size = 32, _tick = 184, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:11,526[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1444.8, step = 476160, mean_episode_return = 0.3893, mean_episode_step = 56.642, total_loss = 311.59, entropy_loss = -9.6401, pg_loss = 178.99, baseline_loss = 142.24, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:16,531[0m][[34mroot[0m][[32mINFO[0m] - Step 478720 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1449.8, step = 478720, mean_episode_return = 0.31129, mean_episode_step = 67.401, total_loss = -149.95, entropy_loss = -9.6363, pg_loss = -238.25, baseline_loss = 97.94, learner_queue_size = 32, _tick = 186, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:21,536[0m][[34mroot[0m][[32mINFO[0m] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1454.9, step = 478720, mean_episode_return = 0.31129, mean_episode_step = 67.401, total_loss = -149.95, entropy_loss = -9.6363, pg_loss = -238.25, baseline_loss = 97.94, learner_queue_size = 32, _tick = 186, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:26,541[0m][[34mroot[0m][[32mINFO[0m] - Step 481280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1459.9, step = 481280, mean_episode_return = 0.31831, mean_episode_step = 89.185, total_loss = -665.49, entropy_loss = -9.6151, pg_loss = -742.62, baseline_loss = 86.742, learner_queue_size = 32, _tick = 187, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:31,546[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1464.9, step = 483840, mean_episode_return = 0.48403, mean_episode_step = 82.232, total_loss = -8.0136, entropy_loss = -9.6202, pg_loss = -138.64, baseline_loss = 140.24, learner_queue_size = 32, _tick = 188, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:36,551[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1469.9, step = 483840, mean_episode_return = 0.48403, mean_episode_step = 82.232, total_loss = -8.0136, entropy_loss = -9.6202, pg_loss = -138.64, baseline_loss = 140.24, learner_queue_size = 32, _tick = 188, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:41,557[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1474.9, step = 486400, mean_episode_return = 0.24787, mean_episode_step = 73.683, total_loss = -35.714, entropy_loss = -9.6189, pg_loss = -138.12, baseline_loss = 112.03, learner_queue_size = 32, _tick = 189, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:46,563[0m][[34mroot[0m][[32mINFO[0m] - Step 488960 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1479.9, step = 488960, mean_episode_return = 0.41975, mean_episode_step = 76.65, total_loss = 741.81, entropy_loss = -9.6166, pg_loss = 608.95, baseline_loss = 142.47, learner_queue_size = 32, _tick = 190, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:51,568[0m][[34mroot[0m][[32mINFO[0m] - Step 488960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1484.9, step = 488960, mean_episode_return = 0.41975, mean_episode_step = 76.65, total_loss = 741.81, entropy_loss = -9.6166, pg_loss = 608.95, baseline_loss = 142.47, learner_queue_size = 32, _tick = 190, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:15:56,573[0m][[34mroot[0m][[32mINFO[0m] - Step 491520 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1489.9, step = 491520, mean_episode_return = 0.41733, mean_episode_step = 75.358, total_loss = 1164.7, entropy_loss = -9.6154, pg_loss = 978.89, baseline_loss = 195.42, learner_queue_size = 32, _tick = 191, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:01,578[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1494.9, step = 494080, mean_episode_return = 0.36917, mean_episode_step = 61.974, total_loss = 376.38, entropy_loss = -9.6344, pg_loss = 208.08, baseline_loss = 177.93, learner_queue_size = 32, _tick = 192, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:06,584[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1499.9, step = 494080, mean_episode_return = 0.36917, mean_episode_step = 61.974, total_loss = 376.38, entropy_loss = -9.6344, pg_loss = 208.08, baseline_loss = 177.93, learner_queue_size = 32, _tick = 192, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:11,590[0m][[34mroot[0m][[32mINFO[0m] - Step 496640 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1504.9, step = 496640, mean_episode_return = 0.36308, mean_episode_step = 61.441, total_loss = 164.71, entropy_loss = -9.6304, pg_loss = 42.443, baseline_loss = 131.9, learner_queue_size = 32, _tick = 193, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:16,595[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1509.9, step = 499200, mean_episode_return = 0.45946, mean_episode_step = 67.361, total_loss = 204.17, entropy_loss = -9.6263, pg_loss = 75.801, baseline_loss = 138.0, learner_queue_size = 32, _tick = 194, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:21,600[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1514.9, step = 499200, mean_episode_return = 0.45946, mean_episode_step = 67.361, total_loss = 204.17, entropy_loss = -9.6263, pg_loss = 75.801, baseline_loss = 138.0, learner_queue_size = 32, _tick = 194, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:26,606[0m][[34mroot[0m][[32mINFO[0m] - Step 501760 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1519.9, step = 501760, mean_episode_return = 0.43744, mean_episode_step = 72.871, total_loss = 124.87, entropy_loss = -9.6263, pg_loss = -11.379, baseline_loss = 145.87, learner_queue_size = 32, _tick = 195, _time = 1.7374e+09)[0m
[[36m2025-01-20 15:16:26,606[0m][[34mroot[0m][[32mINFO[0m] - Learning finished after 501760 steps.[0m
[[36m2025-01-20 15:16:26,607[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
