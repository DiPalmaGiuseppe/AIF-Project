[[36m2025-01-17 18:01:58,911[0m][[34mroot[0m][[32mINFO[0m] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
[0m
[[36m2025-01-17 18:01:58,977[0m][[34mroot[0m][[32mINFO[0m] - Symlinked log directory: /opt/minihack/latest[0m
[[36m2025-01-17 18:01:58,978[0m][[34mroot[0m][[32mINFO[0m] - Found archive directory: /opt/minihack/archives[0m
[[36m2025-01-17 18:01:58,984[0m][[34mroot[0m][[32mINFO[0m] - Logging results to /opt/minihack[0m
[[36m2025-01-17 18:01:59,048[0m][[34mpalaas/out[0m][[32mINFO[0m] - Found log directory: /opt/minihack[0m
[[36m2025-01-17 18:01:59,049[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving arguments to /opt/minihack/meta.json[0m
[[36m2025-01-17 18:01:59,050[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving messages to /opt/minihack/out.log[0m
[[36m2025-01-17 18:01:59,050[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs data to /opt/minihack/logs.csv[0m
[[36m2025-01-17 18:01:59,050[0m][[34mpalaas/out[0m][[32mINFO[0m] - Saving logs' fields to /opt/minihack/fields.csv[0m
[[36m2025-01-17 18:01:59,052[0m][[34mroot[0m][[32mINFO[0m] - Not using CUDA.[0m
[[36m2025-01-17 18:01:59,060[0m][[34mroot[0m][[32mINFO[0m] - Using model baseline[0m
{'staircase': <class 'nle.env.tasks.NetHackStaircase'>, 'score': <class 'nle.env.tasks.NetHackScore'>, 'pet': <class 'nle.env.tasks.NetHackStaircasePet'>, 'oracle': <class 'nle.env.tasks.NetHackOracle'>, 'gold': <class 'nle.env.tasks.NetHackGold'>, 'eat': <class 'nle.env.tasks.NetHackEat'>, 'scout': <class 'nle.env.tasks.NetHackScout'>, 'small_room': <class 'minihack.envs.room.MiniHackRoom5x5'>, 'small_room_random': <class 'minihack.envs.room.MiniHackRoom5x5Random'>, 'small_room_dark': <class 'minihack.envs.room.MiniHackRoom5x5Dark'>, 'small_room_monster': <class 'minihack.envs.room.MiniHackRoom5x5Monster'>, 'small_room_trap': <class 'minihack.envs.room.MiniHackRoom5x5Trap'>, 'small_room_ultimate': <class 'minihack.envs.room.MiniHackRoom5x5Ultimate'>, 'big_room': <class 'minihack.envs.room.MiniHackRoom15x15'>, 'big_room_random': <class 'minihack.envs.room.MiniHackRoom15x15Random'>, 'big_room_dark': <class 'minihack.envs.room.MiniHackRoom15x15Dark'>, 'big_room_monster': <class 'minihack.envs.room.MiniHackRoom15x15Monster'>, 'big_room_trap': <class 'minihack.envs.room.MiniHackRoom15x15Trap'>, 'big_room_ultimate': <class 'minihack.envs.room.MiniHackRoom15x15Ultimate'>, 'corridor2': <class 'minihack.envs.corridor.MiniHackCorridor2'>, 'corridor3': <class 'minihack.envs.corridor.MiniHackCorridor3'>, 'corridor5': <class 'minihack.envs.corridor.MiniHackCorridor5'>, 'keyroom_small_fixed': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Fixed'>, 'keyroom_small': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5'>, 'keyroom_small_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Dark'>, 'keyroom_big': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15'>, 'keyroom_big_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15Dark'>, 'mazewalk_small': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9'>, 'mazewalk_small_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9Premapped'>, 'mazewalk_big': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15'>, 'mazewalk_big_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15Premapped'>, 'mazewalk_huge': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19'>, 'mazewalk_huge_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19Premapped'>, 'fight_corridor': <class 'minihack.envs.fightcorridor.MiniHackFightCorridor'>, 'fight_corridor_dark': <class 'minihack.envs.fightcorridor.MiniHackFightCorridorDark'>, 'river': <class 'minihack.envs.river.MiniHackRiver'>, 'river_lava': <class 'minihack.envs.river.MiniHackRiverLava'>, 'river_monster': <class 'minihack.envs.river.MiniHackRiverMonster'>, 'river_monsterlava': <class 'minihack.envs.river.MiniHackRiverMonsterLava'>, 'river_narrow': <class 'minihack.envs.river.MiniHackRiverNarrow'>, 'memento_short': <class 'minihack.envs.memento.MiniHackMementoShortF2'>, 'memento': <class 'minihack.envs.memento.MiniHackMementoF2'>, 'memento_hard': <class 'minihack.envs.memento.MiniHackMementoF4'>, 'hidenseek': <class 'minihack.envs.hidenseek.MiniHackHideAndSeek'>, 'hidenseek_mapped': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekMapped'>, 'hidenseek_lava': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekLava'>, 'hidenseek_big': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekBig'>, 'explore_easy': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasy'>, 'explore_easy_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasyMapped'>, 'explore_hard': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHard'>, 'explore_hard_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHardMapped'>, 'multiroom_2': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2'>, 'multiroom_4': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4'>, 'multiroom_6': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6'>, 'multiroom_2_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Locked'>, 'multiroom_4_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Locked'>, 'multiroom_6_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Locked'>, 'multiroom_2_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Lava'>, 'multiroom_4_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Lava'>, 'multiroom_6_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Lava'>, 'multiroom_2_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Monster'>, 'multiroom_4_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Monster'>, 'multiroom_6_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Monster'>, 'multiroom_2_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Extreme'>, 'multiroom_4_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Extreme'>, 'multiroom_6_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Extreme'>, 'boxoban_unfiltered': <class 'minihack.envs.boxohack.MiniHackBoxobanUnfiltered'>, 'boxoban_hard': <class 'minihack.envs.boxohack.MiniHackBoxobanHard'>, 'boxoban_medium': <class 'minihack.envs.boxohack.MiniHackBoxobanMedium'>, 'mini_eat': <class 'minihack.envs.skills_simple.MiniHackEat'>, 'mini_pray': <class 'minihack.envs.skills_simple.MiniHackPray'>, 'mini_sink': <class 'minihack.envs.skills_simple.MiniHackSink'>, 'mini_read': <class 'minihack.envs.skills_simple.MiniHackRead'>, 'mini_zap': <class 'minihack.envs.skills_simple.MiniHackZap'>, 'mini_puton': <class 'minihack.envs.skills_simple.MiniHackPutOn'>, 'mini_wear': <class 'minihack.envs.skills_simple.MiniHackWear'>, 'mini_wield': <class 'minihack.envs.skills_simple.MiniHackWield'>, 'mini_locked': <class 'minihack.envs.skills_simple.MiniHackLockedDoor'>, 'mini_eat_fixed': <class 'minihack.envs.skills_simple.MiniHackEatFixed'>, 'mini_pray_fixed': <class 'minihack.envs.skills_simple.MiniHackPrayFixed'>, 'mini_sink_fixed': <class 'minihack.envs.skills_simple.MiniHackSinkFixed'>, 'mini_read_fixed': <class 'minihack.envs.skills_simple.MiniHackReadFixed'>, 'mini_zap_fixed': <class 'minihack.envs.skills_simple.MiniHackZapFixed'>, 'mini_puton_fixed': <class 'minihack.envs.skills_simple.MiniHackPutOnFixed'>, 'mini_wear_fixed': <class 'minihack.envs.skills_simple.MiniHackWearFixed'>, 'mini_wield_fixed': <class 'minihack.envs.skills_simple.MiniHackWieldFixed'>, 'mini_locked_fixed': <class 'minihack.envs.skills_simple.MiniHackLockedDoorFixed'>, 'mini_eat_distr': <class 'minihack.envs.skills_simple.MiniHackEatDistr'>, 'mini_pray_distr': <class 'minihack.envs.skills_simple.MiniHackPrayDistr'>, 'mini_sink_distr': <class 'minihack.envs.skills_simple.MiniHackSinkDistr'>, 'mini_read_distr': <class 'minihack.envs.skills_simple.MiniHackReadDistr'>, 'mini_zap_distr': <class 'minihack.envs.skills_simple.MiniHackZapDistr'>, 'mini_puton_distr': <class 'minihack.envs.skills_simple.MiniHackPutOnDistr'>, 'mini_wear_distr': <class 'minihack.envs.skills_simple.MiniHackWearDistr'>, 'mini_wield_distr': <class 'minihack.envs.skills_simple.MiniHackWieldDistr'>, 'wod_easy': <class 'minihack.envs.skills_wod.MiniHackWoDEasy'>, 'wod_medium': <class 'minihack.envs.skills_wod.MiniHackWoDMedium'>, 'wod_hard': <class 'minihack.envs.skills_wod.MiniHackWoDHard'>, 'wod_pro': <class 'minihack.envs.skills_wod.MiniHackWoDPro'>, 'lava': <class 'minihack.envs.skills_lava.MiniHackLC'>, 'lava_lev': <class 'minihack.envs.skills_lava.MiniHackLCLevitate'>, 'lava_lev_potion_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionInv'>, 'lava_lev_potion_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionPickup'>, 'lava_lev_ring_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingInv'>, 'lava_lev_ring_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingPickup'>, 'quest_easy': <class 'minihack.envs.skills_quest.MiniHackQuestEasy'>, 'quest_medium': <class 'minihack.envs.skills_quest.MiniHackQuestMedium'>, 'quest_hard': <class 'minihack.envs.skills_quest.MiniHackQuestHard'>, 'custom_skills': <class 'minihack.envs.custom_skills_combat.MiniHackCombatSkill'>}
custom_skills
[[36m2025-01-17 18:01:59,061[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
(<CompassDirection.N: 107>, <CompassDirection.E: 108>, <CompassDirection.S: 106>, <CompassDirection.W: 104>, <CompassDirection.NE: 117>, <CompassDirection.SE: 110>, <CompassDirection.SW: 98>, <CompassDirection.NW: 121>, <CompassDirectionLonger.N: 75>, <CompassDirectionLonger.E: 76>, <CompassDirectionLonger.S: 74>, <CompassDirectionLonger.W: 72>, <CompassDirectionLonger.NE: 85>, <CompassDirectionLonger.SE: 78>, <CompassDirectionLonger.SW: 66>, <CompassDirectionLonger.NW: 89>, <MiscDirection.DOWN: 62>, <MiscDirection.WAIT: 46>, <MiscAction.MORE: 13>, <Command.ADJUST: 225>, <Command.APPLY: 97>, <Command.ATTRIBUTES: 24>, <Command.CALL: 67>, <Command.CAST: 90>, <Command.CHAT: 227>, <Command.CLOSE: 99>, <Command.DIP: 228>, <Command.DROP: 100>, <Command.DROPTYPE: 68>, <Command.EAT: 101>, <Command.ENGRAVE: 69>, <Command.ENHANCE: 229>, <Command.ESC: 27>, <Command.FIGHT: 70>, <Command.FIRE: 102>, <Command.FORCE: 230>, <Command.INVENTORY: 105>, <Command.INVENTTYPE: 73>, <Command.INVOKE: 233>, <Command.JUMP: 234>, <Command.KICK: 4>, <Command.LOOK: 58>, <Command.LOOT: 236>, <Command.MONSTER: 237>, <Command.MOVE: 109>, <Command.MOVEFAR: 77>, <Command.OFFER: 239>, <Command.OPEN: 111>, <Command.PAY: 112>, <Command.PICKUP: 44>, <Command.PRAY: 240>, <Command.PUTON: 80>, <Command.QUAFF: 113>, <Command.QUIVER: 81>, <Command.READ: 114>, <Command.REMOVE: 82>, <Command.RIDE: 210>, <Command.RUB: 242>, <Command.RUSH: 103>, <Command.RUSH2: 71>, <Command.SEARCH: 115>, <Command.SEEARMOR: 91>, <Command.SEERINGS: 61>, <Command.SEETOOLS: 40>, <Command.SEETRAP: 94>, <Command.SEEWEAPON: 41>, <Command.SHELL: 33>, <Command.SIT: 243>, <Command.SWAP: 120>, <Command.TAKEOFF: 84>, <Command.TAKEOFFALL: 65>, <Command.THROW: 116>, <Command.TIP: 212>, <Command.TURN: 244>, <Command.TWOWEAPON: 88>, <Command.UNTRAP: 245>, <Command.VERSIONSHORT: 118>, <Command.WEAR: 87>, <Command.WIELD: 119>, <Command.WIPE: 247>, <Command.ZAP: 122>, <TextCharacters.PLUS: 43>, <TextCharacters.QUOTE: 34>, <TextCharacters.DOLLAR: 36>, <TextCharacters.SPACE: 32>)
[[36m2025-01-17 18:01:59,094[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,165[0m][[34mroot[0m][[32mINFO[0m] - Number of model parameters: 4264078[0m
{'staircase': <class 'nle.env.tasks.NetHackStaircase'>, 'score': <class 'nle.env.tasks.NetHackScore'>, 'pet': <class 'nle.env.tasks.NetHackStaircasePet'>, 'oracle': <class 'nle.env.tasks.NetHackOracle'>, 'gold': <class 'nle.env.tasks.NetHackGold'>, 'eat': <class 'nle.env.tasks.NetHackEat'>, 'scout': <class 'nle.env.tasks.NetHackScout'>, 'small_room': <class 'minihack.envs.room.MiniHackRoom5x5'>, 'small_room_random': <class 'minihack.envs.room.MiniHackRoom5x5Random'>, 'small_room_dark': <class 'minihack.envs.room.MiniHackRoom5x5Dark'>, 'small_room_monster': <class 'minihack.envs.room.MiniHackRoom5x5Monster'>, 'small_room_trap': <class 'minihack.envs.room.MiniHackRoom5x5Trap'>, 'small_room_ultimate': <class 'minihack.envs.room.MiniHackRoom5x5Ultimate'>, 'big_room': <class 'minihack.envs.room.MiniHackRoom15x15'>, 'big_room_random': <class 'minihack.envs.room.MiniHackRoom15x15Random'>, 'big_room_dark': <class 'minihack.envs.room.MiniHackRoom15x15Dark'>, 'big_room_monster': <class 'minihack.envs.room.MiniHackRoom15x15Monster'>, 'big_room_trap': <class 'minihack.envs.room.MiniHackRoom15x15Trap'>, 'big_room_ultimate': <class 'minihack.envs.room.MiniHackRoom15x15Ultimate'>, 'corridor2': <class 'minihack.envs.corridor.MiniHackCorridor2'>, 'corridor3': <class 'minihack.envs.corridor.MiniHackCorridor3'>, 'corridor5': <class 'minihack.envs.corridor.MiniHackCorridor5'>, 'keyroom_small_fixed': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Fixed'>, 'keyroom_small': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5'>, 'keyroom_small_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom5x5Dark'>, 'keyroom_big': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15'>, 'keyroom_big_dark': <class 'minihack.envs.keyroom.MiniHackKeyRoom15x15Dark'>, 'mazewalk_small': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9'>, 'mazewalk_small_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk9x9Premapped'>, 'mazewalk_big': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15'>, 'mazewalk_big_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk15x15Premapped'>, 'mazewalk_huge': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19'>, 'mazewalk_huge_mapped': <class 'minihack.envs.mazewalk.MiniHackMazeWalk45x19Premapped'>, 'fight_corridor': <class 'minihack.envs.fightcorridor.MiniHackFightCorridor'>, 'fight_corridor_dark': <class 'minihack.envs.fightcorridor.MiniHackFightCorridorDark'>, 'river': <class 'minihack.envs.river.MiniHackRiver'>, 'river_lava': <class 'minihack.envs.river.MiniHackRiverLava'>, 'river_monster': <class 'minihack.envs.river.MiniHackRiverMonster'>, 'river_monsterlava': <class 'minihack.envs.river.MiniHackRiverMonsterLava'>, 'river_narrow': <class 'minihack.envs.river.MiniHackRiverNarrow'>, 'memento_short': <class 'minihack.envs.memento.MiniHackMementoShortF2'>, 'memento': <class 'minihack.envs.memento.MiniHackMementoF2'>, 'memento_hard': <class 'minihack.envs.memento.MiniHackMementoF4'>, 'hidenseek': <class 'minihack.envs.hidenseek.MiniHackHideAndSeek'>, 'hidenseek_mapped': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekMapped'>, 'hidenseek_lava': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekLava'>, 'hidenseek_big': <class 'minihack.envs.hidenseek.MiniHackHideAndSeekBig'>, 'explore_easy': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasy'>, 'explore_easy_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeEasyMapped'>, 'explore_hard': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHard'>, 'explore_hard_map': <class 'minihack.envs.exploremaze.MiniHackExploreMazeHardMapped'>, 'multiroom_2': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2'>, 'multiroom_4': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4'>, 'multiroom_6': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6'>, 'multiroom_2_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Locked'>, 'multiroom_4_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Locked'>, 'multiroom_6_locked': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Locked'>, 'multiroom_2_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Lava'>, 'multiroom_4_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Lava'>, 'multiroom_6_lava': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Lava'>, 'multiroom_2_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Monster'>, 'multiroom_4_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Monster'>, 'multiroom_6_monster': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Monster'>, 'multiroom_2_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN2Extreme'>, 'multiroom_4_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN4Extreme'>, 'multiroom_6_extreme': <class 'minihack.envs.minigrid.MiniHackMultiRoomN6Extreme'>, 'boxoban_unfiltered': <class 'minihack.envs.boxohack.MiniHackBoxobanUnfiltered'>, 'boxoban_hard': <class 'minihack.envs.boxohack.MiniHackBoxobanHard'>, 'boxoban_medium': <class 'minihack.envs.boxohack.MiniHackBoxobanMedium'>, 'mini_eat': <class 'minihack.envs.skills_simple.MiniHackEat'>, 'mini_pray': <class 'minihack.envs.skills_simple.MiniHackPray'>, 'mini_sink': <class 'minihack.envs.skills_simple.MiniHackSink'>, 'mini_read': <class 'minihack.envs.skills_simple.MiniHackRead'>, 'mini_zap': <class 'minihack.envs.skills_simple.MiniHackZap'>, 'mini_puton': <class 'minihack.envs.skills_simple.MiniHackPutOn'>, 'mini_wear': <class 'minihack.envs.skills_simple.MiniHackWear'>, 'mini_wield': <class 'minihack.envs.skills_simple.MiniHackWield'>, 'mini_locked': <class 'minihack.envs.skills_simple.MiniHackLockedDoor'>, 'mini_eat_fixed': <class 'minihack.envs.skills_simple.MiniHackEatFixed'>, 'mini_pray_fixed': <class 'minihack.envs.skills_simple.MiniHackPrayFixed'>, 'mini_sink_fixed': <class 'minihack.envs.skills_simple.MiniHackSinkFixed'>, 'mini_read_fixed': <class 'minihack.envs.skills_simple.MiniHackReadFixed'>, 'mini_zap_fixed': <class 'minihack.envs.skills_simple.MiniHackZapFixed'>, 'mini_puton_fixed': <class 'minihack.envs.skills_simple.MiniHackPutOnFixed'>, 'mini_wear_fixed': <class 'minihack.envs.skills_simple.MiniHackWearFixed'>, 'mini_wield_fixed': <class 'minihack.envs.skills_simple.MiniHackWieldFixed'>, 'mini_locked_fixed': <class 'minihack.envs.skills_simple.MiniHackLockedDoorFixed'>, 'mini_eat_distr': <class 'minihack.envs.skills_simple.MiniHackEatDistr'>, 'mini_pray_distr': <class 'minihack.envs.skills_simple.MiniHackPrayDistr'>, 'mini_sink_distr': <class 'minihack.envs.skills_simple.MiniHackSinkDistr'>, 'mini_read_distr': <class 'minihack.envs.skills_simple.MiniHackReadDistr'>, 'mini_zap_distr': <class 'minihack.envs.skills_simple.MiniHackZapDistr'>, 'mini_puton_distr': <class 'minihack.envs.skills_simple.MiniHackPutOnDistr'>, 'mini_wear_distr': <class 'minihack.envs.skills_simple.MiniHackWearDistr'>, 'mini_wield_distr': <class 'minihack.envs.skills_simple.MiniHackWieldDistr'>, 'wod_easy': <class 'minihack.envs.skills_wod.MiniHackWoDEasy'>, 'wod_medium': <class 'minihack.envs.skills_wod.MiniHackWoDMedium'>, 'wod_hard': <class 'minihack.envs.skills_wod.MiniHackWoDHard'>, 'wod_pro': <class 'minihack.envs.skills_wod.MiniHackWoDPro'>, 'lava': <class 'minihack.envs.skills_lava.MiniHackLC'>, 'lava_lev': <class 'minihack.envs.skills_lava.MiniHackLCLevitate'>, 'lava_lev_potion_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionInv'>, 'lava_lev_potion_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitatePotionPickup'>, 'lava_lev_ring_inv': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingInv'>, 'lava_lev_ring_pick': <class 'minihack.envs.skills_lava.MiniHackLCLevitateRingPickup'>, 'quest_easy': <class 'minihack.envs.skills_quest.MiniHackQuestEasy'>, 'quest_medium': <class 'minihack.envs.skills_quest.MiniHackQuestMedium'>, 'quest_hard': <class 'minihack.envs.skills_quest.MiniHackQuestHard'>, 'custom_skills': <class 'minihack.envs.custom_skills_combat.MiniHackCombatSkill'>}
custom_skills
[[36m2025-01-17 18:01:59,166[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
(<CompassDirection.N: 107>, <CompassDirection.E: 108>, <CompassDirection.S: 106>, <CompassDirection.W: 104>, <CompassDirection.NE: 117>, <CompassDirection.SE: 110>, <CompassDirection.SW: 98>, <CompassDirection.NW: 121>, <CompassDirectionLonger.N: 75>, <CompassDirectionLonger.E: 76>, <CompassDirectionLonger.S: 74>, <CompassDirectionLonger.W: 72>, <CompassDirectionLonger.NE: 85>, <CompassDirectionLonger.SE: 78>, <CompassDirectionLonger.SW: 66>, <CompassDirectionLonger.NW: 89>, <MiscDirection.DOWN: 62>, <MiscDirection.WAIT: 46>, <MiscAction.MORE: 13>, <Command.ADJUST: 225>, <Command.APPLY: 97>, <Command.ATTRIBUTES: 24>, <Command.CALL: 67>, <Command.CAST: 90>, <Command.CHAT: 227>, <Command.CLOSE: 99>, <Command.DIP: 228>, <Command.DROP: 100>, <Command.DROPTYPE: 68>, <Command.EAT: 101>, <Command.ENGRAVE: 69>, <Command.ENHANCE: 229>, <Command.ESC: 27>, <Command.FIGHT: 70>, <Command.FIRE: 102>, <Command.FORCE: 230>, <Command.INVENTORY: 105>, <Command.INVENTTYPE: 73>, <Command.INVOKE: 233>, <Command.JUMP: 234>, <Command.KICK: 4>, <Command.LOOK: 58>, <Command.LOOT: 236>, <Command.MONSTER: 237>, <Command.MOVE: 109>, <Command.MOVEFAR: 77>, <Command.OFFER: 239>, <Command.OPEN: 111>, <Command.PAY: 112>, <Command.PICKUP: 44>, <Command.PRAY: 240>, <Command.PUTON: 80>, <Command.QUAFF: 113>, <Command.QUIVER: 81>, <Command.READ: 114>, <Command.REMOVE: 82>, <Command.RIDE: 210>, <Command.RUB: 242>, <Command.RUSH: 103>, <Command.RUSH2: 71>, <Command.SEARCH: 115>, <Command.SEEARMOR: 91>, <Command.SEERINGS: 61>, <Command.SEETOOLS: 40>, <Command.SEETRAP: 94>, <Command.SEEWEAPON: 41>, <Command.SHELL: 33>, <Command.SIT: 243>, <Command.SWAP: 120>, <Command.TAKEOFF: 84>, <Command.TAKEOFFALL: 65>, <Command.THROW: 116>, <Command.TIP: 212>, <Command.TURN: 244>, <Command.TWOWEAPON: 88>, <Command.UNTRAP: 245>, <Command.VERSIONSHORT: 118>, <Command.WEAR: 87>, <Command.WIELD: 119>, <Command.WIPE: 247>, <Command.ZAP: 122>, <TextCharacters.PLUS: 43>, <TextCharacters.QUOTE: 34>, <TextCharacters.DOLLAR: 36>, <TextCharacters.SPACE: 32>)
[[36m2025-01-17 18:01:59,192[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
First Environment waiting for connection to unix:/tmp/poly..opt.minihack.0 ... connection established.
[[36m2025-01-17 18:01:59,262[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,264[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,266[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,267[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,267[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,269[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,269[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,269[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,262[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,261[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,263[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,272[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,264[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,273[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,273[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,274[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,267[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,276[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,276[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,276[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,274[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,277[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,278[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,270[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,284[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,290[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,291[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,291[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,292[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,294[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,294[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,295[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,296[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,276[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,282[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,262[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,307[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,310[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,310[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,312[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,318[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,322[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,326[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,290[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,295[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,282[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,330[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,336[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,280[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,339[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,337[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,343[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,343[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,344[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,345[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,346[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,351[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:01:59,341[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 18:02:04,261[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 0. Other stats: (train_seconds = 5.0)[0m
[[36m2025-01-17 18:02:09,266[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 30. Learner queue size: 26. Other stats: (train_seconds = 10.0)[0m
[[36m2025-01-17 18:02:14,271[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 114. Learner queue size: 28. Other stats: (train_seconds = 15.0)[0m
[[36m2025-01-17 18:02:19,279[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 76. Learner queue size: 28. Other stats: (train_seconds = 20.0)[0m
[[36m2025-01-17 18:02:24,295[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 138. Learner queue size: 30. Other stats: (train_seconds = 25.0)[0m
[[36m2025-01-17 18:02:29,300[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (train_seconds = 30.0)[0m
[[36m2025-01-17 18:02:34,302[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (train_seconds = 35.0)[0m
[[36m2025-01-17 18:02:39,307[0m][[34mroot[0m][[32mINFO[0m] - Step 0 @ 0.0 SPS. Inference batcher size: 117. Learner queue size: 32. Other stats: (train_seconds = 40.1)[0m
[[36m2025-01-17 18:02:41,817[0m][[34mpalaas/out[0m][[32mINFO[0m] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size'][0m
[[36m2025-01-17 18:02:44,313[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.tar[0m
[[36m2025-01-17 18:02:44,398[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 511.5 SPS. Inference batcher size: 122. Learner queue size: 5. Other stats: (train_seconds = 45.1, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:02:49,403[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 55. Learner queue size: 7. Other stats: (train_seconds = 50.1, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:02:54,409[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 53. Learner queue size: 8. Other stats: (train_seconds = 55.2, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:02:59,414[0m][[34mroot[0m][[32mINFO[0m] - Step 2560 @ 0.0 SPS. Inference batcher size: 147. Learner queue size: 10. Other stats: (train_seconds = 60.2, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:04,420[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 511.4 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (train_seconds = 65.2, step = 5120, mean_episode_return = 0.067211, mean_episode_step = 33.455, total_loss = 1759.5, entropy_loss = -11.368, pg_loss = 1393.4, baseline_loss = 377.51, learner_queue_size = 10, _tick = 1, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:09,426[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (train_seconds = 70.2, step = 5120, mean_episode_return = 0.067211, mean_episode_step = 33.455, total_loss = 1759.5, entropy_loss = -11.368, pg_loss = 1393.4, baseline_loss = 377.51, learner_queue_size = 10, _tick = 1, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:14,431[0m][[34mroot[0m][[32mINFO[0m] - Step 5120 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 75.2, step = 5120, mean_episode_return = 0.067211, mean_episode_step = 33.455, total_loss = 1759.5, entropy_loss = -11.368, pg_loss = 1393.4, baseline_loss = 377.51, learner_queue_size = 10, _tick = 1, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:19,436[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 80.2, step = 7680, mean_episode_return = -0.06844, mean_episode_step = 54.49, total_loss = 1098.2, entropy_loss = -11.362, pg_loss = 830.52, baseline_loss = 279.05, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:24,769[0m][[34mroot[0m][[32mINFO[0m] - Step 7680 @ 0.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (train_seconds = 85.2, step = 7680, mean_episode_return = -0.06844, mean_episode_step = 54.49, total_loss = 1098.2, entropy_loss = -11.362, pg_loss = 830.52, baseline_loss = 279.05, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:29,774[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 480.0 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 90.5, step = 10240, mean_episode_return = -0.069286, mean_episode_step = 60.793, total_loss = -781.47, entropy_loss = -11.366, pg_loss = -946.52, baseline_loss = 176.42, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:34,779[0m][[34mroot[0m][[32mINFO[0m] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 95.5, step = 10240, mean_episode_return = -0.069286, mean_episode_step = 60.793, total_loss = -781.47, entropy_loss = -11.366, pg_loss = -946.52, baseline_loss = 176.42, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:39,784[0m][[34mroot[0m][[32mINFO[0m] - Step 12800 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 100.5, step = 12800, mean_episode_return = -0.04281, mean_episode_step = 43.145, total_loss = -230.64, entropy_loss = -11.356, pg_loss = -352.3, baseline_loss = 133.01, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:44,795[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 510.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 105.5, step = 15360, mean_episode_return = 0.0119, mean_episode_step = 32.635, total_loss = 1629.4, entropy_loss = -11.341, pg_loss = 1390.7, baseline_loss = 249.99, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:49,801[0m][[34mroot[0m][[32mINFO[0m] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 110.5, step = 15360, mean_episode_return = 0.0119, mean_episode_step = 32.635, total_loss = 1629.4, entropy_loss = -11.341, pg_loss = 1390.7, baseline_loss = 249.99, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:54,807[0m][[34mroot[0m][[32mINFO[0m] - Step 17920 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 115.6, step = 17920, mean_episode_return = -0.06, mean_episode_step = 45.371, total_loss = 219.97, entropy_loss = -11.37, pg_loss = 56.303, baseline_loss = 175.03, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:03:59,813[0m][[34mroot[0m][[32mINFO[0m] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 120.6, step = 17920, mean_episode_return = -0.06, mean_episode_step = 45.371, total_loss = 219.97, entropy_loss = -11.37, pg_loss = 56.303, baseline_loss = 175.03, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:04,818[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 125.6, step = 20480, mean_episode_return = -0.052913, mean_episode_step = 49.192, total_loss = 18.312, entropy_loss = -11.365, pg_loss = -147.36, baseline_loss = 177.04, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:09,824[0m][[34mroot[0m][[32mINFO[0m] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 130.6, step = 20480, mean_episode_return = -0.052913, mean_episode_step = 49.192, total_loss = 18.312, entropy_loss = -11.365, pg_loss = -147.36, baseline_loss = 177.04, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:14,829[0m][[34mroot[0m][[32mINFO[0m] - Step 23040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 135.6, step = 23040, mean_episode_return = 0.005, mean_episode_step = 57.084, total_loss = -478.77, entropy_loss = -11.347, pg_loss = -471.66, baseline_loss = 4.2365, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:19,834[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 140.6, step = 25600, mean_episode_return = 0.041637, mean_episode_step = 64.602, total_loss = 1065.8, entropy_loss = -11.333, pg_loss = 919.92, baseline_loss = 157.2, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:24,839[0m][[34mroot[0m][[32mINFO[0m] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 145.6, step = 25600, mean_episode_return = 0.041637, mean_episode_step = 64.602, total_loss = 1065.8, entropy_loss = -11.333, pg_loss = 919.92, baseline_loss = 157.2, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:29,845[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 150.6, step = 28160, mean_episode_return = -0.066037, mean_episode_step = 57.186, total_loss = 738.02, entropy_loss = -11.363, pg_loss = 558.06, baseline_loss = 191.33, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:34,850[0m][[34mroot[0m][[32mINFO[0m] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 155.6, step = 28160, mean_episode_return = -0.066037, mean_episode_step = 57.186, total_loss = 738.02, entropy_loss = -11.363, pg_loss = 558.06, baseline_loss = 191.33, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:39,855[0m][[34mroot[0m][[32mINFO[0m] - Step 30720 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 160.6, step = 30720, mean_episode_return = -0.080667, mean_episode_step = 55.76, total_loss = 1144.0, entropy_loss = -11.37, pg_loss = 825.19, baseline_loss = 330.19, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:44,862[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 511.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 165.6, step = 33280, mean_episode_return = 0.043179, mean_episode_step = 56.377, total_loss = 1277.9, entropy_loss = -11.369, pg_loss = 883.3, baseline_loss = 405.92, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:49,868[0m][[34mroot[0m][[32mINFO[0m] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 170.6, step = 33280, mean_episode_return = 0.043179, mean_episode_step = 56.377, total_loss = 1277.9, entropy_loss = -11.369, pg_loss = 883.3, baseline_loss = 405.92, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:54,873[0m][[34mroot[0m][[32mINFO[0m] - Step 35840 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 175.6, step = 35840, mean_episode_return = 0.01481, mean_episode_step = 62.737, total_loss = 183.48, entropy_loss = -11.353, pg_loss = -28.097, baseline_loss = 222.93, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:04:59,879[0m][[34mroot[0m][[32mINFO[0m] - Step 35840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 180.6, step = 35840, mean_episode_return = 0.01481, mean_episode_step = 62.737, total_loss = 183.48, entropy_loss = -11.353, pg_loss = -28.097, baseline_loss = 222.93, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:04,884[0m][[34mroot[0m][[32mINFO[0m] - Step 38400 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 185.6, step = 38400, mean_episode_return = -0.016613, mean_episode_step = 57.034, total_loss = -502.79, entropy_loss = -11.36, pg_loss = -639.2, baseline_loss = 147.77, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:09,889[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 190.6, step = 40960, mean_episode_return = -0.049138, mean_episode_step = 73.154, total_loss = 1109.9, entropy_loss = -11.368, pg_loss = 747.3, baseline_loss = 374.0, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:14,895[0m][[34mroot[0m][[32mINFO[0m] - Step 40960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 195.6, step = 40960, mean_episode_return = -0.049138, mean_episode_step = 73.154, total_loss = 1109.9, entropy_loss = -11.368, pg_loss = 747.3, baseline_loss = 374.0, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:19,900[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 511.5 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (train_seconds = 200.6, step = 43520, mean_episode_return = -0.044037, mean_episode_step = 57.02, total_loss = -194.53, entropy_loss = -11.366, pg_loss = -379.49, baseline_loss = 196.32, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:24,905[0m][[34mroot[0m][[32mINFO[0m] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 205.6, step = 43520, mean_episode_return = -0.044037, mean_episode_step = 57.02, total_loss = -194.53, entropy_loss = -11.366, pg_loss = -379.49, baseline_loss = 196.32, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:29,910[0m][[34mroot[0m][[32mINFO[0m] - Step 46080 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 210.7, step = 46080, mean_episode_return = -0.044407, mean_episode_step = 60.467, total_loss = -80.787, entropy_loss = -11.368, pg_loss = -277.12, baseline_loss = 207.71, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:34,915[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 215.7, step = 48640, mean_episode_return = 0.048044, mean_episode_step = 62.993, total_loss = 1934.2, entropy_loss = -11.368, pg_loss = 1460.1, baseline_loss = 485.44, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:39,921[0m][[34mroot[0m][[32mINFO[0m] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 220.7, step = 48640, mean_episode_return = 0.048044, mean_episode_step = 62.993, total_loss = 1934.2, entropy_loss = -11.368, pg_loss = 1460.1, baseline_loss = 485.44, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:44,926[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 225.7, step = 51200, mean_episode_return = -0.03096, mean_episode_step = 57.375, total_loss = -1225.6, entropy_loss = -11.367, pg_loss = -1223.9, baseline_loss = 9.7212, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:49,931[0m][[34mroot[0m][[32mINFO[0m] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 230.7, step = 51200, mean_episode_return = -0.03096, mean_episode_step = 57.375, total_loss = -1225.6, entropy_loss = -11.367, pg_loss = -1223.9, baseline_loss = 9.7212, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:54,936[0m][[34mroot[0m][[32mINFO[0m] - Step 53760 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 235.7, step = 53760, mean_episode_return = 0.051478, mean_episode_step = 57.998, total_loss = -676.09, entropy_loss = -11.369, pg_loss = -724.45, baseline_loss = 59.725, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:05:59,941[0m][[34mroot[0m][[32mINFO[0m] - Step 56320 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 240.7, step = 56320, mean_episode_return = 0.010667, mean_episode_step = 68.332, total_loss = 785.3, entropy_loss = -11.364, pg_loss = 505.47, baseline_loss = 291.2, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:04,947[0m][[34mroot[0m][[32mINFO[0m] - Step 56320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 245.7, step = 56320, mean_episode_return = 0.010667, mean_episode_step = 68.332, total_loss = 785.3, entropy_loss = -11.364, pg_loss = 505.47, baseline_loss = 291.2, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:09,952[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 250.7, step = 58880, mean_episode_return = -0.0076071, mean_episode_step = 57.213, total_loss = 264.23, entropy_loss = -11.367, pg_loss = 62.439, baseline_loss = 213.15, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:14,957[0m][[34mroot[0m][[32mINFO[0m] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 255.7, step = 58880, mean_episode_return = -0.0076071, mean_episode_step = 57.213, total_loss = 264.23, entropy_loss = -11.367, pg_loss = 62.439, baseline_loss = 213.15, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:19,962[0m][[34mroot[0m][[32mINFO[0m] - Step 61440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 260.7, step = 61440, mean_episode_return = 0.12016, mean_episode_step = 70.821, total_loss = 250.4, entropy_loss = -11.359, pg_loss = 84.143, baseline_loss = 177.61, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:24,967[0m][[34mroot[0m][[32mINFO[0m] - Step 64000 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 265.7, step = 64000, mean_episode_return = -0.0725, mean_episode_step = 69.196, total_loss = 846.86, entropy_loss = -11.364, pg_loss = 548.54, baseline_loss = 309.68, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:29,972[0m][[34mroot[0m][[32mINFO[0m] - Step 64000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 270.7, step = 64000, mean_episode_return = -0.0725, mean_episode_step = 69.196, total_loss = 846.86, entropy_loss = -11.364, pg_loss = 548.54, baseline_loss = 309.68, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:34,978[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 275.7, step = 66560, mean_episode_return = 0.037548, mean_episode_step = 73.16, total_loss = -419.03, entropy_loss = -11.366, pg_loss = -575.47, baseline_loss = 167.8, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:39,989[0m][[34mroot[0m][[32mINFO[0m] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 280.7, step = 66560, mean_episode_return = 0.037548, mean_episode_step = 73.16, total_loss = -419.03, entropy_loss = -11.366, pg_loss = -575.47, baseline_loss = 167.8, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:44,994[0m][[34mroot[0m][[32mINFO[0m] - Step 69120 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 285.7, step = 69120, mean_episode_return = -0.063219, mean_episode_step = 61.133, total_loss = 933.21, entropy_loss = -11.369, pg_loss = 590.93, baseline_loss = 353.64, learner_queue_size = 32, _tick = 26, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:49,999[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 290.7, step = 71680, mean_episode_return = -0.003074, mean_episode_step = 54.397, total_loss = -638.34, entropy_loss = -11.364, pg_loss = -711.9, baseline_loss = 84.927, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:06:55,004[0m][[34mroot[0m][[32mINFO[0m] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 295.7, step = 71680, mean_episode_return = -0.003074, mean_episode_step = 54.397, total_loss = -638.34, entropy_loss = -11.364, pg_loss = -711.9, baseline_loss = 84.927, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:00,009[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 300.8, step = 74240, mean_episode_return = -0.06532, mean_episode_step = 64.674, total_loss = 1859.3, entropy_loss = -11.366, pg_loss = 1355.3, baseline_loss = 515.41, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:05,014[0m][[34mroot[0m][[32mINFO[0m] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 305.8, step = 74240, mean_episode_return = -0.06532, mean_episode_step = 64.674, total_loss = 1859.3, entropy_loss = -11.366, pg_loss = 1355.3, baseline_loss = 515.41, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:10,020[0m][[34mroot[0m][[32mINFO[0m] - Step 76800 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 310.8, step = 76800, mean_episode_return = 0.0664, mean_episode_step = 66.662, total_loss = 132.59, entropy_loss = -11.367, pg_loss = -134.7, baseline_loss = 278.65, learner_queue_size = 32, _tick = 29, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:15,027[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 511.2 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 315.8, step = 79360, mean_episode_return = -0.077788, mean_episode_step = 53.53, total_loss = 444.17, entropy_loss = -11.364, pg_loss = 177.89, baseline_loss = 277.64, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:20,033[0m][[34mroot[0m][[32mINFO[0m] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 320.8, step = 79360, mean_episode_return = -0.077788, mean_episode_step = 53.53, total_loss = 444.17, entropy_loss = -11.364, pg_loss = 177.89, baseline_loss = 277.64, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:25,038[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 325.8, step = 81920, mean_episode_return = 0.039125, mean_episode_step = 65.099, total_loss = -62.695, entropy_loss = -11.36, pg_loss = -250.53, baseline_loss = 199.19, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:30,043[0m][[34mroot[0m][[32mINFO[0m] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 330.8, step = 81920, mean_episode_return = 0.039125, mean_episode_step = 65.099, total_loss = -62.695, entropy_loss = -11.36, pg_loss = -250.53, baseline_loss = 199.19, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:35,048[0m][[34mroot[0m][[32mINFO[0m] - Step 84480 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 335.8, step = 84480, mean_episode_return = 0.14945, mean_episode_step = 69.829, total_loss = 1114.2, entropy_loss = -11.36, pg_loss = 789.18, baseline_loss = 336.36, learner_queue_size = 32, _tick = 32, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:40,055[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 340.8, step = 87040, mean_episode_return = 0.030926, mean_episode_step = 70.166, total_loss = 781.8, entropy_loss = -11.359, pg_loss = 424.9, baseline_loss = 368.26, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:45,060[0m][[34mroot[0m][[32mINFO[0m] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 345.8, step = 87040, mean_episode_return = 0.030926, mean_episode_step = 70.166, total_loss = 781.8, entropy_loss = -11.359, pg_loss = 424.9, baseline_loss = 368.26, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:50,065[0m][[34mroot[0m][[32mINFO[0m] - Step 89600 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 350.8, step = 89600, mean_episode_return = -0.052704, mean_episode_step = 64.535, total_loss = -1094.3, entropy_loss = -11.348, pg_loss = -1090.4, baseline_loss = 7.4686, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:07:55,071[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 355.8, step = 92160, mean_episode_return = 0.04071, mean_episode_step = 64.198, total_loss = -657.75, entropy_loss = -11.358, pg_loss = -729.35, baseline_loss = 82.956, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:00,076[0m][[34mroot[0m][[32mINFO[0m] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 360.8, step = 92160, mean_episode_return = 0.04071, mean_episode_step = 64.198, total_loss = -657.75, entropy_loss = -11.358, pg_loss = -729.35, baseline_loss = 82.956, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:05,081[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 365.8, step = 94720, mean_episode_return = -0.043136, mean_episode_step = 68.748, total_loss = 3158.6, entropy_loss = -11.36, pg_loss = 2411.0, baseline_loss = 759.02, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:10,082[0m][[34mroot[0m][[32mINFO[0m] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 370.8, step = 94720, mean_episode_return = -0.043136, mean_episode_step = 68.748, total_loss = 3158.6, entropy_loss = -11.36, pg_loss = 2411.0, baseline_loss = 759.02, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:15,087[0m][[34mroot[0m][[32mINFO[0m] - Step 97280 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 375.8, step = 97280, mean_episode_return = 0.012147, mean_episode_step = 61.171, total_loss = 1390.5, entropy_loss = -11.36, pg_loss = 951.14, baseline_loss = 450.7, learner_queue_size = 32, _tick = 37, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:20,093[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 380.8, step = 99840, mean_episode_return = -0.018064, mean_episode_step = 66.664, total_loss = 67.577, entropy_loss = -11.352, pg_loss = -137.36, baseline_loss = 216.29, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:25,098[0m][[34mroot[0m][[32mINFO[0m] - Step 99840 @ 0.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 385.8, step = 99840, mean_episode_return = -0.018064, mean_episode_step = 66.664, total_loss = 67.577, entropy_loss = -11.352, pg_loss = -137.36, baseline_loss = 216.29, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:30,105[0m][[34mroot[0m][[32mINFO[0m] - Step 102400 @ 511.3 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 390.8, step = 102400, mean_episode_return = 0.055552, mean_episode_step = 62.088, total_loss = 755.39, entropy_loss = -11.354, pg_loss = 456.86, baseline_loss = 309.88, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:35,110[0m][[34mroot[0m][[32mINFO[0m] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 395.9, step = 102400, mean_episode_return = 0.055552, mean_episode_step = 62.088, total_loss = 755.39, entropy_loss = -11.354, pg_loss = 456.86, baseline_loss = 309.88, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:40,115[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 400.9, step = 104960, mean_episode_return = -0.082407, mean_episode_step = 60.548, total_loss = -311.83, entropy_loss = -11.346, pg_loss = -440.12, baseline_loss = 139.64, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:45,120[0m][[34mroot[0m][[32mINFO[0m] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 405.9, step = 104960, mean_episode_return = -0.082407, mean_episode_step = 60.548, total_loss = -311.83, entropy_loss = -11.346, pg_loss = -440.12, baseline_loss = 139.64, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:50,125[0m][[34mroot[0m][[32mINFO[0m] - Step 107520 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 410.9, step = 107520, mean_episode_return = -0.02084, mean_episode_step = 69.917, total_loss = 340.96, entropy_loss = -11.352, pg_loss = 119.99, baseline_loss = 232.31, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:08:55,131[0m][[34mroot[0m][[32mINFO[0m] - Step 107520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 415.9, step = 107520, mean_episode_return = -0.02084, mean_episode_step = 69.917, total_loss = 340.96, entropy_loss = -11.352, pg_loss = 119.99, baseline_loss = 232.31, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:00,136[0m][[34mroot[0m][[32mINFO[0m] - Step 110080 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 420.9, step = 110080, mean_episode_return = 0.0564, mean_episode_step = 61.817, total_loss = 781.05, entropy_loss = -11.342, pg_loss = 475.17, baseline_loss = 317.22, learner_queue_size = 32, _tick = 42, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:05,142[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 425.9, step = 112640, mean_episode_return = -0.04231, mean_episode_step = 62.315, total_loss = -1161.6, entropy_loss = -11.324, pg_loss = -1159.5, baseline_loss = 9.2178, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:10,147[0m][[34mroot[0m][[32mINFO[0m] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 430.9, step = 112640, mean_episode_return = -0.04231, mean_episode_step = 62.315, total_loss = -1161.6, entropy_loss = -11.324, pg_loss = -1159.5, baseline_loss = 9.2178, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:15,152[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 435.9, step = 115200, mean_episode_return = 0.027208, mean_episode_step = 64.82, total_loss = 170.52, entropy_loss = -11.337, pg_loss = -37.996, baseline_loss = 219.85, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:20,157[0m][[34mroot[0m][[32mINFO[0m] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 440.9, step = 115200, mean_episode_return = 0.027208, mean_episode_step = 64.82, total_loss = 170.52, entropy_loss = -11.337, pg_loss = -37.996, baseline_loss = 219.85, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:25,162[0m][[34mroot[0m][[32mINFO[0m] - Step 117760 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 445.9, step = 117760, mean_episode_return = -0.023975, mean_episode_step = 60.404, total_loss = 615.04, entropy_loss = -11.336, pg_loss = 329.39, baseline_loss = 296.98, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:30,168[0m][[34mroot[0m][[32mINFO[0m] - Step 117760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 450.9, step = 117760, mean_episode_return = -0.023975, mean_episode_step = 60.404, total_loss = 615.04, entropy_loss = -11.336, pg_loss = 329.39, baseline_loss = 296.98, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:35,173[0m][[34mroot[0m][[32mINFO[0m] - Step 120320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 455.9, step = 120320, mean_episode_return = 0.075423, mean_episode_step = 65.495, total_loss = 3983.0, entropy_loss = -11.326, pg_loss = 3099.3, baseline_loss = 894.97, learner_queue_size = 32, _tick = 46, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:40,178[0m][[34mroot[0m][[32mINFO[0m] - Step 122880 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 460.9, step = 122880, mean_episode_return = 0.0094376, mean_episode_step = 59.306, total_loss = -520.01, entropy_loss = -11.31, pg_loss = -629.3, baseline_loss = 120.6, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:45,184[0m][[34mroot[0m][[32mINFO[0m] - Step 122880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 465.9, step = 122880, mean_episode_return = 0.0094376, mean_episode_step = 59.306, total_loss = -520.01, entropy_loss = -11.31, pg_loss = -629.3, baseline_loss = 120.6, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:50,189[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar[0m
[[36m2025-01-17 18:09:50,267[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 470.9, step = 125440, mean_episode_return = 0.1102, mean_episode_step = 72.786, total_loss = 114.15, entropy_loss = -11.317, pg_loss = -90.068, baseline_loss = 215.54, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:09:55,272[0m][[34mroot[0m][[32mINFO[0m] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 476.0, step = 125440, mean_episode_return = 0.1102, mean_episode_step = 72.786, total_loss = 114.15, entropy_loss = -11.317, pg_loss = -90.068, baseline_loss = 215.54, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:00,277[0m][[34mroot[0m][[32mINFO[0m] - Step 128000 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 481.0, step = 128000, mean_episode_return = 0.065185, mean_episode_step = 60.648, total_loss = -179.41, entropy_loss = -11.278, pg_loss = -269.38, baseline_loss = 101.24, learner_queue_size = 32, _tick = 49, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:05,282[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 486.0, step = 130560, mean_episode_return = 0.029345, mean_episode_step = 57.268, total_loss = 336.44, entropy_loss = -11.267, pg_loss = 206.63, baseline_loss = 141.07, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:10,288[0m][[34mroot[0m][[32mINFO[0m] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 491.0, step = 130560, mean_episode_return = 0.029345, mean_episode_step = 57.268, total_loss = 336.44, entropy_loss = -11.267, pg_loss = 206.63, baseline_loss = 141.07, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:15,293[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 496.0, step = 133120, mean_episode_return = -0.010556, mean_episode_step = 59.157, total_loss = -210.06, entropy_loss = -11.251, pg_loss = -287.06, baseline_loss = 88.255, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:20,298[0m][[34mroot[0m][[32mINFO[0m] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 501.0, step = 133120, mean_episode_return = -0.010556, mean_episode_step = 59.157, total_loss = -210.06, entropy_loss = -11.251, pg_loss = -287.06, baseline_loss = 88.255, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:25,298[0m][[34mroot[0m][[32mINFO[0m] - Step 135680 @ 511.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 506.0, step = 135680, mean_episode_return = 0.080834, mean_episode_step = 53.483, total_loss = -618.69, entropy_loss = -11.236, pg_loss = -609.81, baseline_loss = 2.361, learner_queue_size = 32, _tick = 52, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:30,304[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 511.0, step = 138240, mean_episode_return = 0.025242, mean_episode_step = 64.955, total_loss = -421.74, entropy_loss = -11.225, pg_loss = -412.12, baseline_loss = 1.6127, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:35,309[0m][[34mroot[0m][[32mINFO[0m] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 516.1, step = 138240, mean_episode_return = 0.025242, mean_episode_step = 64.955, total_loss = -421.74, entropy_loss = -11.225, pg_loss = -412.12, baseline_loss = 1.6127, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:40,314[0m][[34mroot[0m][[32mINFO[0m] - Step 140800 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 521.1, step = 140800, mean_episode_return = -0.010939, mean_episode_step = 63.856, total_loss = 1086.3, entropy_loss = -11.198, pg_loss = 906.56, baseline_loss = 190.93, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:45,321[0m][[34mroot[0m][[32mINFO[0m] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 526.1, step = 140800, mean_episode_return = -0.010939, mean_episode_step = 63.856, total_loss = 1086.3, entropy_loss = -11.198, pg_loss = 906.56, baseline_loss = 190.93, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:50,327[0m][[34mroot[0m][[32mINFO[0m] - Step 143360 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 531.1, step = 143360, mean_episode_return = -0.024613, mean_episode_step = 60.233, total_loss = 1355.3, entropy_loss = -11.219, pg_loss = 1069.1, baseline_loss = 297.33, learner_queue_size = 32, _tick = 55, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:10:55,332[0m][[34mroot[0m][[32mINFO[0m] - Step 145920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 536.1, step = 145920, mean_episode_return = 0.05085, mean_episode_step = 48.075, total_loss = 1519.0, entropy_loss = -11.228, pg_loss = 1151.6, baseline_loss = 378.64, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:00,338[0m][[34mroot[0m][[32mINFO[0m] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 541.1, step = 145920, mean_episode_return = 0.05085, mean_episode_step = 48.075, total_loss = 1519.0, entropy_loss = -11.228, pg_loss = 1151.6, baseline_loss = 378.64, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:05,343[0m][[34mroot[0m][[32mINFO[0m] - Step 148480 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 546.1, step = 148480, mean_episode_return = 0.020742, mean_episode_step = 63.641, total_loss = 1434.5, entropy_loss = -11.208, pg_loss = 1096.8, baseline_loss = 348.87, learner_queue_size = 32, _tick = 57, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:10,348[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 551.1, step = 151040, mean_episode_return = 0.010475, mean_episode_step = 55.537, total_loss = 812.5, entropy_loss = -11.183, pg_loss = 540.27, baseline_loss = 283.42, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:15,354[0m][[34mroot[0m][[32mINFO[0m] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 556.1, step = 151040, mean_episode_return = 0.010475, mean_episode_step = 55.537, total_loss = 812.5, entropy_loss = -11.183, pg_loss = 540.27, baseline_loss = 283.42, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:20,359[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 561.1, step = 153600, mean_episode_return = 0.22021, mean_episode_step = 57.641, total_loss = 515.23, entropy_loss = -11.152, pg_loss = 285.72, baseline_loss = 240.67, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:25,366[0m][[34mroot[0m][[32mINFO[0m] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 566.1, step = 153600, mean_episode_return = 0.22021, mean_episode_step = 57.641, total_loss = 515.23, entropy_loss = -11.152, pg_loss = 285.72, baseline_loss = 240.67, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:30,371[0m][[34mroot[0m][[32mINFO[0m] - Step 156160 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 571.1, step = 156160, mean_episode_return = 0.036267, mean_episode_step = 57.745, total_loss = -260.61, entropy_loss = -11.044, pg_loss = -347.45, baseline_loss = 97.88, learner_queue_size = 32, _tick = 60, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:35,377[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 576.1, step = 158720, mean_episode_return = 0.19148, mean_episode_step = 64.486, total_loss = 2039.5, entropy_loss = -11.058, pg_loss = 1661.3, baseline_loss = 389.3, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:40,383[0m][[34mroot[0m][[32mINFO[0m] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 581.1, step = 158720, mean_episode_return = 0.19148, mean_episode_step = 64.486, total_loss = 2039.5, entropy_loss = -11.058, pg_loss = 1661.3, baseline_loss = 389.3, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:45,388[0m][[34mroot[0m][[32mINFO[0m] - Step 161280 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 586.1, step = 161280, mean_episode_return = -0.042743, mean_episode_step = 52.986, total_loss = -400.8, entropy_loss = -11.003, pg_loss = -472.23, baseline_loss = 82.433, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:50,394[0m][[34mroot[0m][[32mINFO[0m] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 591.1, step = 161280, mean_episode_return = -0.042743, mean_episode_step = 52.986, total_loss = -400.8, entropy_loss = -11.003, pg_loss = -472.23, baseline_loss = 82.433, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:11:55,399[0m][[34mroot[0m][[32mINFO[0m] - Step 163840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 596.1, step = 163840, mean_episode_return = 0.093132, mean_episode_step = 52.506, total_loss = 112.7, entropy_loss = -11.037, pg_loss = -82.962, baseline_loss = 206.69, learner_queue_size = 32, _tick = 63, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:00,404[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-17 18:12:00,450[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 601.1, step = 166400, mean_episode_return = 0.12558, mean_episode_step = 59.141, total_loss = 1558.2, entropy_loss = -10.875, pg_loss = 1293.2, baseline_loss = 275.91, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:05,456[0m][[34mroot[0m][[32mINFO[0m] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 606.2, step = 166400, mean_episode_return = 0.12558, mean_episode_step = 59.141, total_loss = 1558.2, entropy_loss = -10.875, pg_loss = 1293.2, baseline_loss = 275.91, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:10,461[0m][[34mroot[0m][[32mINFO[0m] - Step 168960 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 611.2, step = 168960, mean_episode_return = 0.067973, mean_episode_step = 51.294, total_loss = 321.26, entropy_loss = -10.835, pg_loss = 172.96, baseline_loss = 159.13, learner_queue_size = 32, _tick = 65, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:15,466[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 616.2, step = 171520, mean_episode_return = -0.00031245, mean_episode_step = 61.387, total_loss = -186.94, entropy_loss = -10.677, pg_loss = -255.76, baseline_loss = 79.5, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:20,472[0m][[34mroot[0m][[32mINFO[0m] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 621.2, step = 171520, mean_episode_return = -0.00031245, mean_episode_step = 61.387, total_loss = -186.94, entropy_loss = -10.677, pg_loss = -255.76, baseline_loss = 79.5, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:25,478[0m][[34mroot[0m][[32mINFO[0m] - Step 174080 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 626.2, step = 174080, mean_episode_return = 0.12403, mean_episode_step = 60.633, total_loss = 1206.4, entropy_loss = -10.65, pg_loss = 961.38, baseline_loss = 255.72, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:30,483[0m][[34mroot[0m][[32mINFO[0m] - Step 174080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 631.2, step = 174080, mean_episode_return = 0.12403, mean_episode_step = 60.633, total_loss = 1206.4, entropy_loss = -10.65, pg_loss = 961.38, baseline_loss = 255.72, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:35,488[0m][[34mroot[0m][[32mINFO[0m] - Step 176640 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 636.2, step = 176640, mean_episode_return = 0.12303, mean_episode_step = 60.887, total_loss = 197.96, entropy_loss = -10.588, pg_loss = 91.395, baseline_loss = 117.15, learner_queue_size = 32, _tick = 68, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:40,493[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 641.2, step = 179200, mean_episode_return = 0.27272, mean_episode_step = 59.371, total_loss = 1279.5, entropy_loss = -10.654, pg_loss = 1036.4, baseline_loss = 253.72, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:45,498[0m][[34mroot[0m][[32mINFO[0m] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 646.2, step = 179200, mean_episode_return = 0.27272, mean_episode_step = 59.371, total_loss = 1279.5, entropy_loss = -10.654, pg_loss = 1036.4, baseline_loss = 253.72, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:50,504[0m][[34mroot[0m][[32mINFO[0m] - Step 181760 @ 511.4 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 651.2, step = 181760, mean_episode_return = -0.0024166, mean_episode_step = 56.783, total_loss = -344.67, entropy_loss = -10.573, pg_loss = -504.87, baseline_loss = 170.77, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:12:55,510[0m][[34mroot[0m][[32mINFO[0m] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 656.3, step = 181760, mean_episode_return = -0.0024166, mean_episode_step = 56.783, total_loss = -344.67, entropy_loss = -10.573, pg_loss = -504.87, baseline_loss = 170.77, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:00,515[0m][[34mroot[0m][[32mINFO[0m] - Step 184320 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 661.3, step = 184320, mean_episode_return = 0.075912, mean_episode_step = 55.075, total_loss = 759.15, entropy_loss = -10.513, pg_loss = 502.06, baseline_loss = 267.6, learner_queue_size = 32, _tick = 71, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:05,520[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 666.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:10,527[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 0.0 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 671.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:15,533[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 676.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:20,536[0m][[34mroot[0m][[32mINFO[0m] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 681.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:25,542[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 686.3, step = 189440, mean_episode_return = 0.14233, mean_episode_step = 64.236, total_loss = -30.257, entropy_loss = -10.309, pg_loss = -175.95, baseline_loss = 156.0, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:30,548[0m][[34mroot[0m][[32mINFO[0m] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 691.3, step = 189440, mean_episode_return = 0.14233, mean_episode_step = 64.236, total_loss = -30.257, entropy_loss = -10.309, pg_loss = -175.95, baseline_loss = 156.0, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:35,555[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 511.3 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 696.3, step = 192000, mean_episode_return = 0.14649, mean_episode_step = 61.934, total_loss = -372.83, entropy_loss = -10.182, pg_loss = -483.84, baseline_loss = 121.2, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:40,560[0m][[34mroot[0m][[32mINFO[0m] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 701.3, step = 192000, mean_episode_return = 0.14649, mean_episode_step = 61.934, total_loss = -372.83, entropy_loss = -10.182, pg_loss = -483.84, baseline_loss = 121.2, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:45,566[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 706.3, step = 194560, mean_episode_return = 0.075, mean_episode_step = 54.571, total_loss = -453.12, entropy_loss = -10.162, pg_loss = -507.83, baseline_loss = 64.876, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:50,571[0m][[34mroot[0m][[32mINFO[0m] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 711.3, step = 194560, mean_episode_return = 0.075, mean_episode_step = 54.571, total_loss = -453.12, entropy_loss = -10.162, pg_loss = -507.83, baseline_loss = 64.876, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:13:55,576[0m][[34mroot[0m][[32mINFO[0m] - Step 197120 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 716.3, step = 197120, mean_episode_return = 0.077563, mean_episode_step = 43.183, total_loss = -627.1, entropy_loss = -10.165, pg_loss = -736.49, baseline_loss = 119.55, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:00,581[0m][[34mroot[0m][[32mINFO[0m] - Step 197120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 721.3, step = 197120, mean_episode_return = 0.077563, mean_episode_step = 43.183, total_loss = -627.1, entropy_loss = -10.165, pg_loss = -736.49, baseline_loss = 119.55, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:05,586[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 726.3, step = 199680, mean_episode_return = 0.23849, mean_episode_step = 68.365, total_loss = 434.76, entropy_loss = -10.117, pg_loss = 258.71, baseline_loss = 186.17, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:10,592[0m][[34mroot[0m][[32mINFO[0m] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 731.3, step = 199680, mean_episode_return = 0.23849, mean_episode_step = 68.365, total_loss = 434.76, entropy_loss = -10.117, pg_loss = 258.71, baseline_loss = 186.17, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:15,598[0m][[34mroot[0m][[32mINFO[0m] - Step 202240 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 736.3, step = 202240, mean_episode_return = 0.1378, mean_episode_step = 62.961, total_loss = 33.169, entropy_loss = -10.199, pg_loss = -110.2, baseline_loss = 153.57, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:20,604[0m][[34mroot[0m][[32mINFO[0m] - Step 202240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 741.3, step = 202240, mean_episode_return = 0.1378, mean_episode_step = 62.961, total_loss = 33.169, entropy_loss = -10.199, pg_loss = -110.2, baseline_loss = 153.57, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:25,609[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 746.4, step = 204800, mean_episode_return = 0.13494, mean_episode_step = 63.545, total_loss = 654.5, entropy_loss = -10.17, pg_loss = 503.27, baseline_loss = 161.4, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:30,614[0m][[34mroot[0m][[32mINFO[0m] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 751.4, step = 204800, mean_episode_return = 0.13494, mean_episode_step = 63.545, total_loss = 654.5, entropy_loss = -10.17, pg_loss = 503.27, baseline_loss = 161.4, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:35,619[0m][[34mroot[0m][[32mINFO[0m] - Step 207360 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 756.4, step = 207360, mean_episode_return = 0.14333, mean_episode_step = 48.68, total_loss = 42.056, entropy_loss = -10.094, pg_loss = -147.23, baseline_loss = 199.38, learner_queue_size = 32, _tick = 80, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:40,625[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 761.4, step = 209920, mean_episode_return = 0.18814, mean_episode_step = 44.525, total_loss = 738.83, entropy_loss = -10.02, pg_loss = 581.69, baseline_loss = 167.15, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:45,630[0m][[34mroot[0m][[32mINFO[0m] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 766.4, step = 209920, mean_episode_return = 0.18814, mean_episode_step = 44.525, total_loss = 738.83, entropy_loss = -10.02, pg_loss = 581.69, baseline_loss = 167.15, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:50,635[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 771.4, step = 212480, mean_episode_return = 0.23, mean_episode_step = 64.675, total_loss = 489.43, entropy_loss = -9.9421, pg_loss = 360.58, baseline_loss = 138.8, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:14:55,641[0m][[34mroot[0m][[32mINFO[0m] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 776.4, step = 212480, mean_episode_return = 0.23, mean_episode_step = 64.675, total_loss = 489.43, entropy_loss = -9.9421, pg_loss = 360.58, baseline_loss = 138.8, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:00,647[0m][[34mroot[0m][[32mINFO[0m] - Step 215040 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 781.4, step = 215040, mean_episode_return = 0.38211, mean_episode_step = 64.161, total_loss = -97.698, entropy_loss = -9.9075, pg_loss = -223.08, baseline_loss = 135.29, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:05,652[0m][[34mroot[0m][[32mINFO[0m] - Step 215040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 786.4, step = 215040, mean_episode_return = 0.38211, mean_episode_step = 64.161, total_loss = -97.698, entropy_loss = -9.9075, pg_loss = -223.08, baseline_loss = 135.29, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:10,657[0m][[34mroot[0m][[32mINFO[0m] - Step 217600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 791.4, step = 217600, mean_episode_return = 0.15408, mean_episode_step = 48.889, total_loss = -349.13, entropy_loss = -9.8463, pg_loss = -499.94, baseline_loss = 160.66, learner_queue_size = 32, _tick = 84, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:15,663[0m][[34mroot[0m][[32mINFO[0m] - Step 220160 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 796.4, step = 220160, mean_episode_return = 0.26249, mean_episode_step = 53.889, total_loss = 1356.2, entropy_loss = -9.8245, pg_loss = 1085.3, baseline_loss = 280.71, learner_queue_size = 32, _tick = 85, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:20,668[0m][[34mroot[0m][[32mINFO[0m] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 801.4, step = 220160, mean_episode_return = 0.26249, mean_episode_step = 53.889, total_loss = 1356.2, entropy_loss = -9.8245, pg_loss = 1085.3, baseline_loss = 280.71, learner_queue_size = 32, _tick = 85, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:25,674[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 806.4, step = 222720, mean_episode_return = 0.1569, mean_episode_step = 53.521, total_loss = -943.53, entropy_loss = -9.7846, pg_loss = -1067.1, baseline_loss = 133.37, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:30,679[0m][[34mroot[0m][[32mINFO[0m] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 811.4, step = 222720, mean_episode_return = 0.1569, mean_episode_step = 53.521, total_loss = -943.53, entropy_loss = -9.7846, pg_loss = -1067.1, baseline_loss = 133.37, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:35,684[0m][[34mroot[0m][[32mINFO[0m] - Step 225280 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 816.4, step = 225280, mean_episode_return = 0.27845, mean_episode_step = 51.148, total_loss = -314.11, entropy_loss = -9.7898, pg_loss = -405.39, baseline_loss = 101.06, learner_queue_size = 32, _tick = 87, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:40,691[0m][[34mroot[0m][[32mINFO[0m] - Step 227840 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 821.4, step = 227840, mean_episode_return = 0.40123, mean_episode_step = 58.596, total_loss = 1249.2, entropy_loss = -9.751, pg_loss = 1042.1, baseline_loss = 216.8, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:45,696[0m][[34mroot[0m][[32mINFO[0m] - Step 227840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 826.4, step = 227840, mean_episode_return = 0.40123, mean_episode_step = 58.596, total_loss = 1249.2, entropy_loss = -9.751, pg_loss = 1042.1, baseline_loss = 216.8, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:50,701[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 831.4, step = 230400, mean_episode_return = 0.37115, mean_episode_step = 59.54, total_loss = 58.035, entropy_loss = -9.7323, pg_loss = -109.31, baseline_loss = 177.07, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:15:55,707[0m][[34mroot[0m][[32mINFO[0m] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 836.5, step = 230400, mean_episode_return = 0.37115, mean_episode_step = 59.54, total_loss = 58.035, entropy_loss = -9.7323, pg_loss = -109.31, baseline_loss = 177.07, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:00,712[0m][[34mroot[0m][[32mINFO[0m] - Step 232960 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 841.5, step = 232960, mean_episode_return = 0.22951, mean_episode_step = 51.53, total_loss = -62.962, entropy_loss = -9.7472, pg_loss = -180.86, baseline_loss = 127.64, learner_queue_size = 32, _tick = 90, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:05,717[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 846.5, step = 235520, mean_episode_return = 0.342, mean_episode_step = 50.352, total_loss = 919.37, entropy_loss = -9.7094, pg_loss = 762.81, baseline_loss = 166.27, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:10,722[0m][[34mroot[0m][[32mINFO[0m] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 851.5, step = 235520, mean_episode_return = 0.342, mean_episode_step = 50.352, total_loss = 919.37, entropy_loss = -9.7094, pg_loss = 762.81, baseline_loss = 166.27, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:15,727[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 856.5, step = 238080, mean_episode_return = 0.29711, mean_episode_step = 50.217, total_loss = 721.16, entropy_loss = -9.6938, pg_loss = 576.54, baseline_loss = 154.32, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:20,733[0m][[34mroot[0m][[32mINFO[0m] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 861.5, step = 238080, mean_episode_return = 0.29711, mean_episode_step = 50.217, total_loss = 721.16, entropy_loss = -9.6938, pg_loss = 576.54, baseline_loss = 154.32, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:25,738[0m][[34mroot[0m][[32mINFO[0m] - Step 240640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 866.5, step = 240640, mean_episode_return = 0.17497, mean_episode_step = 45.375, total_loss = -372.65, entropy_loss = -9.6419, pg_loss = -499.94, baseline_loss = 136.93, learner_queue_size = 32, _tick = 93, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:30,743[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 871.5, step = 243200, mean_episode_return = 0.19326, mean_episode_step = 48.734, total_loss = -151.11, entropy_loss = -9.6095, pg_loss = -280.07, baseline_loss = 138.57, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:35,749[0m][[34mroot[0m][[32mINFO[0m] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 876.5, step = 243200, mean_episode_return = 0.19326, mean_episode_step = 48.734, total_loss = -151.11, entropy_loss = -9.6095, pg_loss = -280.07, baseline_loss = 138.57, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:40,755[0m][[34mroot[0m][[32mINFO[0m] - Step 245760 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 881.5, step = 245760, mean_episode_return = 0.489, mean_episode_step = 65.84, total_loss = 595.12, entropy_loss = -9.5248, pg_loss = 488.65, baseline_loss = 115.99, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:45,760[0m][[34mroot[0m][[32mINFO[0m] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 886.5, step = 245760, mean_episode_return = 0.489, mean_episode_step = 65.84, total_loss = 595.12, entropy_loss = -9.5248, pg_loss = 488.65, baseline_loss = 115.99, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:50,765[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 891.5, step = 248320, mean_episode_return = 0.38829, mean_episode_step = 44.141, total_loss = 283.03, entropy_loss = -9.5252, pg_loss = 144.2, baseline_loss = 148.35, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:16:55,771[0m][[34mroot[0m][[32mINFO[0m] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 896.5, step = 248320, mean_episode_return = 0.38829, mean_episode_step = 44.141, total_loss = 283.03, entropy_loss = -9.5252, pg_loss = 144.2, baseline_loss = 148.35, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:00,777[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar[0m
[[36m2025-01-17 18:17:00,879[0m][[34mroot[0m][[32mINFO[0m] - Step 250880 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 901.5, step = 250880, mean_episode_return = 0.34937, mean_episode_step = 58.879, total_loss = 313.75, entropy_loss = -9.596, pg_loss = 168.97, baseline_loss = 154.39, learner_queue_size = 32, _tick = 97, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:05,884[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 501.3 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 906.6, step = 253440, mean_episode_return = 0.20407, mean_episode_step = 57.029, total_loss = -287.37, entropy_loss = -9.518, pg_loss = -411.52, baseline_loss = 133.67, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:10,890[0m][[34mroot[0m][[32mINFO[0m] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 911.6, step = 253440, mean_episode_return = 0.20407, mean_episode_step = 57.029, total_loss = -287.37, entropy_loss = -9.518, pg_loss = -411.52, baseline_loss = 133.67, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:15,895[0m][[34mroot[0m][[32mINFO[0m] - Step 256000 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 916.6, step = 256000, mean_episode_return = 0.58354, mean_episode_step = 55.426, total_loss = 1004.2, entropy_loss = -9.5104, pg_loss = 830.36, baseline_loss = 183.35, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:20,900[0m][[34mroot[0m][[32mINFO[0m] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 921.6, step = 256000, mean_episode_return = 0.58354, mean_episode_step = 55.426, total_loss = 1004.2, entropy_loss = -9.5104, pg_loss = 830.36, baseline_loss = 183.35, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:25,905[0m][[34mroot[0m][[32mINFO[0m] - Step 258560 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 926.6, step = 258560, mean_episode_return = 0.36785, mean_episode_step = 55.766, total_loss = -338.07, entropy_loss = -9.4728, pg_loss = -427.86, baseline_loss = 99.265, learner_queue_size = 32, _tick = 100, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:30,911[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 931.7, step = 261120, mean_episode_return = 0.52406, mean_episode_step = 75.027, total_loss = -357.82, entropy_loss = -9.4846, pg_loss = -446.81, baseline_loss = 98.472, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:35,916[0m][[34mroot[0m][[32mINFO[0m] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 936.7, step = 261120, mean_episode_return = 0.52406, mean_episode_step = 75.027, total_loss = -357.82, entropy_loss = -9.4846, pg_loss = -446.81, baseline_loss = 98.472, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:40,922[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 941.7, step = 263680, mean_episode_return = 0.34775, mean_episode_step = 59.682, total_loss = 46.045, entropy_loss = -9.4921, pg_loss = -62.561, baseline_loss = 118.1, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:45,927[0m][[34mroot[0m][[32mINFO[0m] - Step 263680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 946.7, step = 263680, mean_episode_return = 0.34775, mean_episode_step = 59.682, total_loss = 46.045, entropy_loss = -9.4921, pg_loss = -62.561, baseline_loss = 118.1, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:50,933[0m][[34mroot[0m][[32mINFO[0m] - Step 266240 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 951.7, step = 266240, mean_episode_return = 0.37708, mean_episode_step = 63.895, total_loss = 760.7, entropy_loss = -9.3368, pg_loss = 638.74, baseline_loss = 131.3, learner_queue_size = 32, _tick = 103, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:17:55,939[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 956.7, step = 268800, mean_episode_return = 0.31818, mean_episode_step = 52.932, total_loss = -42.562, entropy_loss = -9.3482, pg_loss = -167.75, baseline_loss = 134.53, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:00,944[0m][[34mroot[0m][[32mINFO[0m] - Step 268800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 961.7, step = 268800, mean_episode_return = 0.31818, mean_episode_step = 52.932, total_loss = -42.562, entropy_loss = -9.3482, pg_loss = -167.75, baseline_loss = 134.53, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:05,949[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 966.7, step = 271360, mean_episode_return = 0.48183, mean_episode_step = 54.371, total_loss = 194.79, entropy_loss = -9.2629, pg_loss = 82.834, baseline_loss = 121.22, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:10,954[0m][[34mroot[0m][[32mINFO[0m] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 971.7, step = 271360, mean_episode_return = 0.48183, mean_episode_step = 54.371, total_loss = 194.79, entropy_loss = -9.2629, pg_loss = 82.834, baseline_loss = 121.22, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:15,959[0m][[34mroot[0m][[32mINFO[0m] - Step 273920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 976.7, step = 273920, mean_episode_return = 0.48223, mean_episode_step = 64.835, total_loss = -272.89, entropy_loss = -9.2682, pg_loss = -334.21, baseline_loss = 70.585, learner_queue_size = 32, _tick = 106, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:20,964[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 981.7, step = 276480, mean_episode_return = 0.43155, mean_episode_step = 55.625, total_loss = 145.93, entropy_loss = -9.2121, pg_loss = 56.78, baseline_loss = 98.363, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:25,970[0m][[34mroot[0m][[32mINFO[0m] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 986.7, step = 276480, mean_episode_return = 0.43155, mean_episode_step = 55.625, total_loss = 145.93, entropy_loss = -9.2121, pg_loss = 56.78, baseline_loss = 98.363, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:30,975[0m][[34mroot[0m][[32mINFO[0m] - Step 279040 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 991.7, step = 279040, mean_episode_return = 0.40798, mean_episode_step = 61.259, total_loss = 100.14, entropy_loss = -9.2027, pg_loss = 22.578, baseline_loss = 86.76, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:35,980[0m][[34mroot[0m][[32mINFO[0m] - Step 279040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 996.7, step = 279040, mean_episode_return = 0.40798, mean_episode_step = 61.259, total_loss = 100.14, entropy_loss = -9.2027, pg_loss = 22.578, baseline_loss = 86.76, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:40,985[0m][[34mroot[0m][[32mINFO[0m] - Step 281600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1001.7, step = 281600, mean_episode_return = 0.37289, mean_episode_step = 53.788, total_loss = -366.08, entropy_loss = -9.1371, pg_loss = -442.21, baseline_loss = 85.269, learner_queue_size = 32, _tick = 109, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:45,990[0m][[34mroot[0m][[32mINFO[0m] - Step 284160 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1006.7, step = 284160, mean_episode_return = 0.42381, mean_episode_step = 46.941, total_loss = -83.03, entropy_loss = -9.084, pg_loss = -144.68, baseline_loss = 70.734, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:50,995[0m][[34mroot[0m][[32mINFO[0m] - Step 284160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1011.7, step = 284160, mean_episode_return = 0.42381, mean_episode_step = 46.941, total_loss = -83.03, entropy_loss = -9.084, pg_loss = -144.68, baseline_loss = 70.734, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:18:56,001[0m][[34mroot[0m][[32mINFO[0m] - Step 286720 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1016.7, step = 286720, mean_episode_return = 0.41821, mean_episode_step = 52.918, total_loss = 521.23, entropy_loss = -9.0628, pg_loss = 421.86, baseline_loss = 108.43, learner_queue_size = 32, _tick = 111, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:01,006[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1021.7, step = 289280, mean_episode_return = 0.76215, mean_episode_step = 55.206, total_loss = 555.42, entropy_loss = -9.0335, pg_loss = 472.88, baseline_loss = 91.57, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:06,012[0m][[34mroot[0m][[32mINFO[0m] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1026.8, step = 289280, mean_episode_return = 0.76215, mean_episode_step = 55.206, total_loss = 555.42, entropy_loss = -9.0335, pg_loss = 472.88, baseline_loss = 91.57, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:11,017[0m][[34mroot[0m][[32mINFO[0m] - Step 291840 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1031.8, step = 291840, mean_episode_return = 0.18928, mean_episode_step = 49.827, total_loss = -495.91, entropy_loss = -9.0087, pg_loss = -566.53, baseline_loss = 79.628, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:16,023[0m][[34mroot[0m][[32mINFO[0m] - Step 291840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1036.8, step = 291840, mean_episode_return = 0.18928, mean_episode_step = 49.827, total_loss = -495.91, entropy_loss = -9.0087, pg_loss = -566.53, baseline_loss = 79.628, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:21,028[0m][[34mroot[0m][[32mINFO[0m] - Step 294400 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1041.8, step = 294400, mean_episode_return = 0.44108, mean_episode_step = 46.076, total_loss = 925.82, entropy_loss = -9.011, pg_loss = 727.13, baseline_loss = 207.7, learner_queue_size = 32, _tick = 114, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:26,034[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1046.8, step = 296960, mean_episode_return = 0.28483, mean_episode_step = 51.219, total_loss = -589.89, entropy_loss = -8.9899, pg_loss = -704.7, baseline_loss = 123.79, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:31,040[0m][[34mroot[0m][[32mINFO[0m] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1051.8, step = 296960, mean_episode_return = 0.28483, mean_episode_step = 51.219, total_loss = -589.89, entropy_loss = -8.9899, pg_loss = -704.7, baseline_loss = 123.79, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:36,045[0m][[34mroot[0m][[32mINFO[0m] - Step 299520 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1056.8, step = 299520, mean_episode_return = 0.42986, mean_episode_step = 60.256, total_loss = 374.06, entropy_loss = -8.9777, pg_loss = 233.57, baseline_loss = 149.46, learner_queue_size = 32, _tick = 116, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:41,051[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1061.8, step = 302080, mean_episode_return = 0.56551, mean_episode_step = 58.45, total_loss = 156.87, entropy_loss = -8.92, pg_loss = 56.38, baseline_loss = 109.41, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:46,056[0m][[34mroot[0m][[32mINFO[0m] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1066.8, step = 302080, mean_episode_return = 0.56551, mean_episode_step = 58.45, total_loss = 156.87, entropy_loss = -8.92, pg_loss = 56.38, baseline_loss = 109.41, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:51,062[0m][[34mroot[0m][[32mINFO[0m] - Step 304640 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1071.8, step = 304640, mean_episode_return = 0.75779, mean_episode_step = 70.6, total_loss = 35.129, entropy_loss = -8.8732, pg_loss = -47.894, baseline_loss = 91.896, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:19:56,068[0m][[34mroot[0m][[32mINFO[0m] - Step 304640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1076.8, step = 304640, mean_episode_return = 0.75779, mean_episode_step = 70.6, total_loss = 35.129, entropy_loss = -8.8732, pg_loss = -47.894, baseline_loss = 91.896, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:01,073[0m][[34mroot[0m][[32mINFO[0m] - Step 307200 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1081.8, step = 307200, mean_episode_return = 0.43789, mean_episode_step = 42.621, total_loss = -121.77, entropy_loss = -8.9038, pg_loss = -211.44, baseline_loss = 98.57, learner_queue_size = 32, _tick = 119, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:06,079[0m][[34mroot[0m][[32mINFO[0m] - Step 309760 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1086.8, step = 309760, mean_episode_return = 0.42893, mean_episode_step = 35.196, total_loss = 157.47, entropy_loss = -8.9169, pg_loss = 57.978, baseline_loss = 108.41, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:11,085[0m][[34mroot[0m][[32mINFO[0m] - Step 309760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1091.8, step = 309760, mean_episode_return = 0.42893, mean_episode_step = 35.196, total_loss = 157.47, entropy_loss = -8.9169, pg_loss = 57.978, baseline_loss = 108.41, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:16,090[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1096.8, step = 312320, mean_episode_return = 0.38813, mean_episode_step = 48.353, total_loss = -699.8, entropy_loss = -8.8185, pg_loss = -768.76, baseline_loss = 77.784, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:21,095[0m][[34mroot[0m][[32mINFO[0m] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1101.8, step = 312320, mean_episode_return = 0.38813, mean_episode_step = 48.353, total_loss = -699.8, entropy_loss = -8.8185, pg_loss = -768.76, baseline_loss = 77.784, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:26,100[0m][[34mroot[0m][[32mINFO[0m] - Step 314880 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1106.8, step = 314880, mean_episode_return = 0.44657, mean_episode_step = 41.751, total_loss = -135.16, entropy_loss = -8.8174, pg_loss = -200.24, baseline_loss = 73.894, learner_queue_size = 32, _tick = 122, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:31,105[0m][[34mroot[0m][[32mINFO[0m] - Step 317440 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1111.8, step = 317440, mean_episode_return = 0.58264, mean_episode_step = 51.417, total_loss = 301.24, entropy_loss = -8.7711, pg_loss = 215.77, baseline_loss = 94.246, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:36,111[0m][[34mroot[0m][[32mINFO[0m] - Step 317440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1116.9, step = 317440, mean_episode_return = 0.58264, mean_episode_step = 51.417, total_loss = 301.24, entropy_loss = -8.7711, pg_loss = 215.77, baseline_loss = 94.246, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:41,116[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1121.9, step = 320000, mean_episode_return = 0.52169, mean_episode_step = 54.019, total_loss = 21.964, entropy_loss = -8.8206, pg_loss = -33.675, baseline_loss = 64.46, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:46,121[0m][[34mroot[0m][[32mINFO[0m] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1126.9, step = 320000, mean_episode_return = 0.52169, mean_episode_step = 54.019, total_loss = 21.964, entropy_loss = -8.8206, pg_loss = -33.675, baseline_loss = 64.46, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:51,127[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1131.9, step = 322560, mean_episode_return = 0.51252, mean_episode_step = 62.162, total_loss = -44.464, entropy_loss = -8.7859, pg_loss = -91.845, baseline_loss = 56.166, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:20:56,133[0m][[34mroot[0m][[32mINFO[0m] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1136.9, step = 322560, mean_episode_return = 0.51252, mean_episode_step = 62.162, total_loss = -44.464, entropy_loss = -8.7859, pg_loss = -91.845, baseline_loss = 56.166, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:01,139[0m][[34mroot[0m][[32mINFO[0m] - Step 325120 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1141.9, step = 325120, mean_episode_return = 0.23273, mean_episode_step = 48.079, total_loss = -248.76, entropy_loss = -8.6956, pg_loss = -281.65, baseline_loss = 41.588, learner_queue_size = 32, _tick = 126, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:06,144[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1146.9, step = 327680, mean_episode_return = 0.5123, mean_episode_step = 50.603, total_loss = 124.35, entropy_loss = -8.6392, pg_loss = 83.41, baseline_loss = 49.58, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:11,150[0m][[34mroot[0m][[32mINFO[0m] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1151.9, step = 327680, mean_episode_return = 0.5123, mean_episode_step = 50.603, total_loss = 124.35, entropy_loss = -8.6392, pg_loss = 83.41, baseline_loss = 49.58, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:16,155[0m][[34mroot[0m][[32mINFO[0m] - Step 330240 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1156.9, step = 330240, mean_episode_return = 0.85473, mean_episode_step = 61.518, total_loss = 389.36, entropy_loss = -8.6199, pg_loss = 314.5, baseline_loss = 83.48, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:21,160[0m][[34mroot[0m][[32mINFO[0m] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1161.9, step = 330240, mean_episode_return = 0.85473, mean_episode_step = 61.518, total_loss = 389.36, entropy_loss = -8.6199, pg_loss = 314.5, baseline_loss = 83.48, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:26,165[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1166.9, step = 332800, mean_episode_return = 0.54911, mean_episode_step = 60.437, total_loss = -479.5, entropy_loss = -8.6202, pg_loss = -535.81, baseline_loss = 64.93, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:31,171[0m][[34mroot[0m][[32mINFO[0m] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1171.9, step = 332800, mean_episode_return = 0.54911, mean_episode_step = 60.437, total_loss = -479.5, entropy_loss = -8.6202, pg_loss = -535.81, baseline_loss = 64.93, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:36,176[0m][[34mroot[0m][[32mINFO[0m] - Step 335360 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1176.9, step = 335360, mean_episode_return = 0.35628, mean_episode_step = 50.716, total_loss = -332.39, entropy_loss = -8.6146, pg_loss = -381.44, baseline_loss = 57.665, learner_queue_size = 32, _tick = 130, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:41,181[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1181.9, step = 337920, mean_episode_return = 0.59502, mean_episode_step = 52.753, total_loss = 485.03, entropy_loss = -8.5614, pg_loss = 397.78, baseline_loss = 95.808, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:46,186[0m][[34mroot[0m][[32mINFO[0m] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1186.9, step = 337920, mean_episode_return = 0.59502, mean_episode_step = 52.753, total_loss = 485.03, entropy_loss = -8.5614, pg_loss = 397.78, baseline_loss = 95.808, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:51,191[0m][[34mroot[0m][[32mINFO[0m] - Step 340480 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1191.9, step = 340480, mean_episode_return = 0.56428, mean_episode_step = 69.907, total_loss = -327.12, entropy_loss = -8.5545, pg_loss = -391.32, baseline_loss = 72.748, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:21:56,197[0m][[34mroot[0m][[32mINFO[0m] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1196.9, step = 340480, mean_episode_return = 0.56428, mean_episode_step = 69.907, total_loss = -327.12, entropy_loss = -8.5545, pg_loss = -391.32, baseline_loss = 72.748, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:01,202[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-17 18:22:01,622[0m][[34mroot[0m][[32mINFO[0m] - Step 343040 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1201.9, step = 343040, mean_episode_return = 0.60411, mean_episode_step = 59.126, total_loss = 429.46, entropy_loss = -8.5485, pg_loss = 348.56, baseline_loss = 89.447, learner_queue_size = 32, _tick = 133, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:06,627[0m][[34mroot[0m][[32mINFO[0m] - Step 345600 @ 471.9 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1207.4, step = 345600, mean_episode_return = 0.5426, mean_episode_step = 44.628, total_loss = 318.98, entropy_loss = -8.5659, pg_loss = 191.06, baseline_loss = 136.49, learner_queue_size = 32, _tick = 134, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:11,633[0m][[34mroot[0m][[32mINFO[0m] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1212.4, step = 345600, mean_episode_return = 0.5426, mean_episode_step = 44.628, total_loss = 318.98, entropy_loss = -8.5659, pg_loss = 191.06, baseline_loss = 136.49, learner_queue_size = 32, _tick = 134, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:16,638[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1217.4, step = 348160, mean_episode_return = 0.49965, mean_episode_step = 57.497, total_loss = -425.88, entropy_loss = -8.5123, pg_loss = -504.67, baseline_loss = 87.31, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:21,644[0m][[34mroot[0m][[32mINFO[0m] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1222.4, step = 348160, mean_episode_return = 0.49965, mean_episode_step = 57.497, total_loss = -425.88, entropy_loss = -8.5123, pg_loss = -504.67, baseline_loss = 87.31, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:26,649[0m][[34mroot[0m][[32mINFO[0m] - Step 350720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1227.4, step = 350720, mean_episode_return = 0.38052, mean_episode_step = 52.53, total_loss = -92.328, entropy_loss = -8.5244, pg_loss = -168.69, baseline_loss = 84.889, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:31,654[0m][[34mroot[0m][[32mINFO[0m] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1232.4, step = 350720, mean_episode_return = 0.38052, mean_episode_step = 52.53, total_loss = -92.328, entropy_loss = -8.5244, pg_loss = -168.69, baseline_loss = 84.889, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:36,659[0m][[34mroot[0m][[32mINFO[0m] - Step 353280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1237.4, step = 353280, mean_episode_return = 0.60657, mean_episode_step = 56.152, total_loss = 279.09, entropy_loss = -8.5654, pg_loss = 182.24, baseline_loss = 105.41, learner_queue_size = 32, _tick = 137, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:41,664[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1242.4, step = 355840, mean_episode_return = 0.59932, mean_episode_step = 57.73, total_loss = 221.77, entropy_loss = -8.5, pg_loss = 113.72, baseline_loss = 116.55, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:46,669[0m][[34mroot[0m][[32mINFO[0m] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1247.4, step = 355840, mean_episode_return = 0.59932, mean_episode_step = 57.73, total_loss = 221.77, entropy_loss = -8.5, pg_loss = 113.72, baseline_loss = 116.55, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:51,674[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1252.4, step = 358400, mean_episode_return = 0.6706, mean_episode_step = 58.675, total_loss = 62.076, entropy_loss = -8.6025, pg_loss = -42.405, baseline_loss = 113.08, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:22:56,680[0m][[34mroot[0m][[32mINFO[0m] - Step 358400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1257.4, step = 358400, mean_episode_return = 0.6706, mean_episode_step = 58.675, total_loss = 62.076, entropy_loss = -8.6025, pg_loss = -42.405, baseline_loss = 113.08, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:01,685[0m][[34mroot[0m][[32mINFO[0m] - Step 360960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1262.4, step = 360960, mean_episode_return = 0.57908, mean_episode_step = 61.294, total_loss = -169.4, entropy_loss = -8.4854, pg_loss = -231.09, baseline_loss = 70.172, learner_queue_size = 32, _tick = 140, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:06,690[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1267.4, step = 363520, mean_episode_return = 0.4666, mean_episode_step = 54.418, total_loss = -145.92, entropy_loss = -8.4747, pg_loss = -240.39, baseline_loss = 102.94, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:11,695[0m][[34mroot[0m][[32mINFO[0m] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1272.4, step = 363520, mean_episode_return = 0.4666, mean_episode_step = 54.418, total_loss = -145.92, entropy_loss = -8.4747, pg_loss = -240.39, baseline_loss = 102.94, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:16,700[0m][[34mroot[0m][[32mINFO[0m] - Step 366080 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1277.4, step = 366080, mean_episode_return = 0.79907, mean_episode_step = 50.307, total_loss = 393.79, entropy_loss = -8.4316, pg_loss = 318.87, baseline_loss = 83.355, learner_queue_size = 32, _tick = 142, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:21,705[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1282.4, step = 368640, mean_episode_return = 0.7101, mean_episode_step = 63.855, total_loss = 76.382, entropy_loss = -8.4403, pg_loss = 11.673, baseline_loss = 73.149, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:26,712[0m][[34mroot[0m][[32mINFO[0m] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1287.5, step = 368640, mean_episode_return = 0.7101, mean_episode_step = 63.855, total_loss = 76.382, entropy_loss = -8.4403, pg_loss = 11.673, baseline_loss = 73.149, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:31,717[0m][[34mroot[0m][[32mINFO[0m] - Step 371200 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1292.5, step = 371200, mean_episode_return = 0.48907, mean_episode_step = 51.73, total_loss = -86.177, entropy_loss = -8.4199, pg_loss = -149.26, baseline_loss = 71.504, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:36,722[0m][[34mroot[0m][[32mINFO[0m] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1297.5, step = 371200, mean_episode_return = 0.48907, mean_episode_step = 51.73, total_loss = -86.177, entropy_loss = -8.4199, pg_loss = -149.26, baseline_loss = 71.504, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:41,727[0m][[34mroot[0m][[32mINFO[0m] - Step 373760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1302.5, step = 373760, mean_episode_return = 0.35034, mean_episode_step = 58.072, total_loss = -267.05, entropy_loss = -8.3605, pg_loss = -325.54, baseline_loss = 66.852, learner_queue_size = 32, _tick = 145, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:46,733[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar[0m
[[36m2025-01-17 18:23:46,783[0m][[34mroot[0m][[32mINFO[0m] - Step 376320 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1307.5, step = 376320, mean_episode_return = 0.59679, mean_episode_step = 48.446, total_loss = -84.187, entropy_loss = -8.3433, pg_loss = -144.02, baseline_loss = 68.174, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:51,790[0m][[34mroot[0m][[32mINFO[0m] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1312.5, step = 376320, mean_episode_return = 0.59679, mean_episode_step = 48.446, total_loss = -84.187, entropy_loss = -8.3433, pg_loss = -144.02, baseline_loss = 68.174, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:23:56,795[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1317.5, step = 378880, mean_episode_return = 0.37484, mean_episode_step = 58.068, total_loss = -290.12, entropy_loss = -8.2442, pg_loss = -321.51, baseline_loss = 39.632, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:01,800[0m][[34mroot[0m][[32mINFO[0m] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1322.5, step = 378880, mean_episode_return = 0.37484, mean_episode_step = 58.068, total_loss = -290.12, entropy_loss = -8.2442, pg_loss = -321.51, baseline_loss = 39.632, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:06,805[0m][[34mroot[0m][[32mINFO[0m] - Step 381440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1327.5, step = 381440, mean_episode_return = 0.8393, mean_episode_step = 47.686, total_loss = 654.72, entropy_loss = -8.237, pg_loss = 593.42, baseline_loss = 69.54, learner_queue_size = 32, _tick = 148, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:11,810[0m][[34mroot[0m][[32mINFO[0m] - Step 384000 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1332.6, step = 384000, mean_episode_return = 0.44164, mean_episode_step = 56.89, total_loss = -429.21, entropy_loss = -8.2382, pg_loss = -471.81, baseline_loss = 50.836, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:16,815[0m][[34mroot[0m][[32mINFO[0m] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1337.6, step = 384000, mean_episode_return = 0.44164, mean_episode_step = 56.89, total_loss = -429.21, entropy_loss = -8.2382, pg_loss = -471.81, baseline_loss = 50.836, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:21,820[0m][[34mroot[0m][[32mINFO[0m] - Step 386560 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1342.6, step = 386560, mean_episode_return = 0.55546, mean_episode_step = 47.366, total_loss = 174.65, entropy_loss = -8.25, pg_loss = 104.58, baseline_loss = 78.324, learner_queue_size = 32, _tick = 150, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:26,825[0m][[34mroot[0m][[32mINFO[0m] - Step 389120 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1347.6, step = 389120, mean_episode_return = 0.93674, mean_episode_step = 64.859, total_loss = 313.2, entropy_loss = -8.1678, pg_loss = 252.19, baseline_loss = 69.171, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:31,831[0m][[34mroot[0m][[32mINFO[0m] - Step 389120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1352.6, step = 389120, mean_episode_return = 0.93674, mean_episode_step = 64.859, total_loss = 313.2, entropy_loss = -8.1678, pg_loss = 252.19, baseline_loss = 69.171, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:36,837[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 511.3 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1357.6, step = 391680, mean_episode_return = 0.52058, mean_episode_step = 52.767, total_loss = 317.22, entropy_loss = -8.1407, pg_loss = 248.35, baseline_loss = 77.005, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:41,844[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1362.6, step = 391680, mean_episode_return = 0.52058, mean_episode_step = 52.767, total_loss = 317.22, entropy_loss = -8.1407, pg_loss = 248.35, baseline_loss = 77.005, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:46,849[0m][[34mroot[0m][[32mINFO[0m] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1367.6, step = 391680, mean_episode_return = 0.52058, mean_episode_step = 52.767, total_loss = 317.22, entropy_loss = -8.1407, pg_loss = 248.35, baseline_loss = 77.005, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:51,867[0m][[34mroot[0m][[32mINFO[0m] - Step 394240 @ 510.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1372.6, step = 394240, mean_episode_return = 0.57406, mean_episode_step = 59.602, total_loss = -93.814, entropy_loss = -8.1663, pg_loss = -157.71, baseline_loss = 72.059, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:24:56,872[0m][[34mroot[0m][[32mINFO[0m] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1377.6, step = 394240, mean_episode_return = 0.57406, mean_episode_step = 59.602, total_loss = -93.814, entropy_loss = -8.1663, pg_loss = -157.71, baseline_loss = 72.059, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:01,877[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 511.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1382.6, step = 396800, mean_episode_return = 0.5865, mean_episode_step = 54.799, total_loss = 79.683, entropy_loss = -8.0938, pg_loss = 19.505, baseline_loss = 68.272, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:06,883[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1387.6, step = 396800, mean_episode_return = 0.5865, mean_episode_step = 54.799, total_loss = 79.683, entropy_loss = -8.0938, pg_loss = 19.505, baseline_loss = 68.272, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:11,888[0m][[34mroot[0m][[32mINFO[0m] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1392.6, step = 396800, mean_episode_return = 0.5865, mean_episode_step = 54.799, total_loss = 79.683, entropy_loss = -8.0938, pg_loss = 19.505, baseline_loss = 68.272, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:16,893[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1397.6, step = 399360, mean_episode_return = 0.56054, mean_episode_step = 57.18, total_loss = 6.8394, entropy_loss = -8.0966, pg_loss = -78.711, baseline_loss = 93.647, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:21,898[0m][[34mroot[0m][[32mINFO[0m] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1402.6, step = 399360, mean_episode_return = 0.56054, mean_episode_step = 57.18, total_loss = 6.8394, entropy_loss = -8.0966, pg_loss = -78.711, baseline_loss = 93.647, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:26,903[0m][[34mroot[0m][[32mINFO[0m] - Step 401920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1407.6, step = 401920, mean_episode_return = 0.60432, mean_episode_step = 39.154, total_loss = -167.15, entropy_loss = -8.0524, pg_loss = -234.56, baseline_loss = 75.461, learner_queue_size = 32, _tick = 156, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:31,910[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1412.7, step = 404480, mean_episode_return = 0.56068, mean_episode_step = 66.292, total_loss = -269.58, entropy_loss = -8.0069, pg_loss = -319.16, baseline_loss = 57.592, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:36,919[0m][[34mroot[0m][[32mINFO[0m] - Step 404480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1417.7, step = 404480, mean_episode_return = 0.56068, mean_episode_step = 66.292, total_loss = -269.58, entropy_loss = -8.0069, pg_loss = -319.16, baseline_loss = 57.592, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:41,925[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1422.7, step = 407040, mean_episode_return = 0.74511, mean_episode_step = 51.795, total_loss = 618.56, entropy_loss = -7.9997, pg_loss = 553.4, baseline_loss = 73.165, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:46,930[0m][[34mroot[0m][[32mINFO[0m] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1427.7, step = 407040, mean_episode_return = 0.74511, mean_episode_step = 51.795, total_loss = 618.56, entropy_loss = -7.9997, pg_loss = 553.4, baseline_loss = 73.165, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:51,935[0m][[34mroot[0m][[32mINFO[0m] - Step 409600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1432.7, step = 409600, mean_episode_return = 0.2856, mean_episode_step = 57.842, total_loss = -68.726, entropy_loss = -7.9909, pg_loss = -125.11, baseline_loss = 64.376, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:25:56,940[0m][[34mroot[0m][[32mINFO[0m] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1437.7, step = 409600, mean_episode_return = 0.2856, mean_episode_step = 57.842, total_loss = -68.726, entropy_loss = -7.9909, pg_loss = -125.11, baseline_loss = 64.376, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:01,945[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1442.7, step = 412160, mean_episode_return = 0.5116, mean_episode_step = 50.58, total_loss = -164.16, entropy_loss = -8.0023, pg_loss = -229.9, baseline_loss = 73.745, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:06,950[0m][[34mroot[0m][[32mINFO[0m] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1447.7, step = 412160, mean_episode_return = 0.5116, mean_episode_step = 50.58, total_loss = -164.16, entropy_loss = -8.0023, pg_loss = -229.9, baseline_loss = 73.745, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:11,955[0m][[34mroot[0m][[32mINFO[0m] - Step 414720 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1452.7, step = 414720, mean_episode_return = 0.62592, mean_episode_step = 43.254, total_loss = 160.41, entropy_loss = -8.026, pg_loss = 91.374, baseline_loss = 77.064, learner_queue_size = 32, _tick = 161, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:16,961[0m][[34mroot[0m][[32mINFO[0m] - Step 414720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1457.7, step = 414720, mean_episode_return = 0.62592, mean_episode_step = 43.254, total_loss = 160.41, entropy_loss = -8.026, pg_loss = 91.374, baseline_loss = 77.064, learner_queue_size = 32, _tick = 161, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:21,966[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1462.7, step = 417280, mean_episode_return = 0.67697, mean_episode_step = 57.044, total_loss = 574.12, entropy_loss = -7.9703, pg_loss = 492.81, baseline_loss = 89.288, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:26,971[0m][[34mroot[0m][[32mINFO[0m] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1467.7, step = 417280, mean_episode_return = 0.67697, mean_episode_step = 57.044, total_loss = 574.12, entropy_loss = -7.9703, pg_loss = 492.81, baseline_loss = 89.288, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:31,976[0m][[34mroot[0m][[32mINFO[0m] - Step 419840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1472.7, step = 419840, mean_episode_return = 0.57927, mean_episode_step = 48.788, total_loss = -369.05, entropy_loss = -7.9862, pg_loss = -428.77, baseline_loss = 67.705, learner_queue_size = 32, _tick = 163, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:36,981[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1477.7, step = 422400, mean_episode_return = 0.59017, mean_episode_step = 51.814, total_loss = 473.33, entropy_loss = -7.9865, pg_loss = 401.01, baseline_loss = 80.308, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:41,987[0m][[34mroot[0m][[32mINFO[0m] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1482.7, step = 422400, mean_episode_return = 0.59017, mean_episode_step = 51.814, total_loss = 473.33, entropy_loss = -7.9865, pg_loss = 401.01, baseline_loss = 80.308, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:46,992[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1487.7, step = 424960, mean_episode_return = 0.46507, mean_episode_step = 52.909, total_loss = -469.04, entropy_loss = -7.9782, pg_loss = -525.01, baseline_loss = 63.948, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:51,997[0m][[34mroot[0m][[32mINFO[0m] - Step 424960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1492.7, step = 424960, mean_episode_return = 0.46507, mean_episode_step = 52.909, total_loss = -469.04, entropy_loss = -7.9782, pg_loss = -525.01, baseline_loss = 63.948, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:26:57,003[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1497.7, step = 427520, mean_episode_return = 0.4131, mean_episode_step = 64.487, total_loss = -300.73, entropy_loss = -7.9846, pg_loss = -354.56, baseline_loss = 61.818, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:02,008[0m][[34mroot[0m][[32mINFO[0m] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1502.8, step = 427520, mean_episode_return = 0.4131, mean_episode_step = 64.487, total_loss = -300.73, entropy_loss = -7.9846, pg_loss = -354.56, baseline_loss = 61.818, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:07,013[0m][[34mroot[0m][[32mINFO[0m] - Step 430080 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1507.8, step = 430080, mean_episode_return = 0.72156, mean_episode_step = 52.158, total_loss = 306.09, entropy_loss = -7.9943, pg_loss = 219.48, baseline_loss = 94.601, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:12,019[0m][[34mroot[0m][[32mINFO[0m] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1512.8, step = 430080, mean_episode_return = 0.72156, mean_episode_step = 52.158, total_loss = 306.09, entropy_loss = -7.9943, pg_loss = 219.48, baseline_loss = 94.601, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:17,024[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1517.8, step = 432640, mean_episode_return = 0.70506, mean_episode_step = 64.732, total_loss = 133.98, entropy_loss = -7.9832, pg_loss = 73.307, baseline_loss = 68.657, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:22,030[0m][[34mroot[0m][[32mINFO[0m] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1522.8, step = 432640, mean_episode_return = 0.70506, mean_episode_step = 64.732, total_loss = 133.98, entropy_loss = -7.9832, pg_loss = 73.307, baseline_loss = 68.657, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:27,035[0m][[34mroot[0m][[32mINFO[0m] - Step 435200 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1527.8, step = 435200, mean_episode_return = 0.67484, mean_episode_step = 45.946, total_loss = 32.055, entropy_loss = -8.0051, pg_loss = -39.034, baseline_loss = 79.094, learner_queue_size = 32, _tick = 169, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:32,041[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1532.8, step = 437760, mean_episode_return = 0.81102, mean_episode_step = 68.212, total_loss = -283.35, entropy_loss = -8.0123, pg_loss = -335.62, baseline_loss = 60.276, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:37,047[0m][[34mroot[0m][[32mINFO[0m] - Step 437760 @ 0.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1537.8, step = 437760, mean_episode_return = 0.81102, mean_episode_step = 68.212, total_loss = -283.35, entropy_loss = -8.0123, pg_loss = -335.62, baseline_loss = 60.276, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:42,054[0m][[34mroot[0m][[32mINFO[0m] - Step 440320 @ 511.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1542.8, step = 440320, mean_episode_return = 0.83983, mean_episode_step = 42.512, total_loss = 373.42, entropy_loss = -8.0334, pg_loss = 298.35, baseline_loss = 83.105, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:47,060[0m][[34mroot[0m][[32mINFO[0m] - Step 440320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1547.8, step = 440320, mean_episode_return = 0.83983, mean_episode_step = 42.512, total_loss = 373.42, entropy_loss = -8.0334, pg_loss = 298.35, baseline_loss = 83.105, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:52,065[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 511.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1552.8, step = 442880, mean_episode_return = 0.69635, mean_episode_step = 54.734, total_loss = -79.986, entropy_loss = -8.0083, pg_loss = -136.92, baseline_loss = 64.946, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:27:57,071[0m][[34mroot[0m][[32mINFO[0m] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1557.8, step = 442880, mean_episode_return = 0.69635, mean_episode_step = 54.734, total_loss = -79.986, entropy_loss = -8.0083, pg_loss = -136.92, baseline_loss = 64.946, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:02,076[0m][[34mroot[0m][[32mINFO[0m] - Step 445440 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1562.8, step = 445440, mean_episode_return = 0.59409, mean_episode_step = 55.553, total_loss = 64.529, entropy_loss = -7.9944, pg_loss = 3.6, baseline_loss = 68.924, learner_queue_size = 32, _tick = 173, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:07,082[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1567.8, step = 448000, mean_episode_return = 0.78624, mean_episode_step = 52.949, total_loss = 224.37, entropy_loss = -7.9772, pg_loss = 147.1, baseline_loss = 85.248, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:12,088[0m][[34mroot[0m][[32mINFO[0m] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1572.8, step = 448000, mean_episode_return = 0.78624, mean_episode_step = 52.949, total_loss = 224.37, entropy_loss = -7.9772, pg_loss = 147.1, baseline_loss = 85.248, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:17,093[0m][[34mroot[0m][[32mINFO[0m] - Step 450560 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1577.8, step = 450560, mean_episode_return = 0.81183, mean_episode_step = 59.116, total_loss = -273.49, entropy_loss = -7.9414, pg_loss = -336.88, baseline_loss = 71.331, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:22,098[0m][[34mroot[0m][[32mINFO[0m] - Step 450560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1582.8, step = 450560, mean_episode_return = 0.81183, mean_episode_step = 59.116, total_loss = -273.49, entropy_loss = -7.9414, pg_loss = -336.88, baseline_loss = 71.331, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:27,104[0m][[34mroot[0m][[32mINFO[0m] - Step 453120 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1587.8, step = 453120, mean_episode_return = 0.71696, mean_episode_step = 61.475, total_loss = -143.77, entropy_loss = -7.9314, pg_loss = -196.93, baseline_loss = 61.097, learner_queue_size = 32, _tick = 176, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:32,110[0m][[34mroot[0m][[32mINFO[0m] - Step 455680 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1592.9, step = 455680, mean_episode_return = 0.58804, mean_episode_step = 51.134, total_loss = -106.18, entropy_loss = -7.9522, pg_loss = -183.46, baseline_loss = 85.236, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:37,115[0m][[34mroot[0m][[32mINFO[0m] - Step 455680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1597.9, step = 455680, mean_episode_return = 0.58804, mean_episode_step = 51.134, total_loss = -106.18, entropy_loss = -7.9522, pg_loss = -183.46, baseline_loss = 85.236, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:42,120[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1602.9, step = 458240, mean_episode_return = 0.60043, mean_episode_step = 51.482, total_loss = 260.82, entropy_loss = -7.915, pg_loss = 177.43, baseline_loss = 91.298, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:47,126[0m][[34mroot[0m][[32mINFO[0m] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1607.9, step = 458240, mean_episode_return = 0.60043, mean_episode_step = 51.482, total_loss = 260.82, entropy_loss = -7.915, pg_loss = 177.43, baseline_loss = 91.298, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:52,139[0m][[34mroot[0m][[32mINFO[0m] - Step 460800 @ 510.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1612.9, step = 460800, mean_episode_return = 0.77636, mean_episode_step = 62.076, total_loss = -88.877, entropy_loss = -7.8876, pg_loss = -136.77, baseline_loss = 55.782, learner_queue_size = 32, _tick = 179, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:28:57,144[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1617.9, step = 463360, mean_episode_return = 0.56458, mean_episode_step = 55.528, total_loss = 347.7, entropy_loss = -7.8915, pg_loss = 269.65, baseline_loss = 85.942, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:02,150[0m][[34mroot[0m][[32mINFO[0m] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1622.9, step = 463360, mean_episode_return = 0.56458, mean_episode_step = 55.528, total_loss = 347.7, entropy_loss = -7.8915, pg_loss = 269.65, baseline_loss = 85.942, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:07,163[0m][[34mroot[0m][[32mINFO[0m] - Step 465920 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1627.9, step = 465920, mean_episode_return = 0.57981, mean_episode_step = 48.78, total_loss = 183.73, entropy_loss = -7.886, pg_loss = 116.24, baseline_loss = 75.377, learner_queue_size = 32, _tick = 181, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:12,168[0m][[34mroot[0m][[32mINFO[0m] - Step 468480 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1632.9, step = 468480, mean_episode_return = 0.52546, mean_episode_step = 53.677, total_loss = -327.59, entropy_loss = -7.8866, pg_loss = -386.93, baseline_loss = 67.228, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:17,173[0m][[34mroot[0m][[32mINFO[0m] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1637.9, step = 468480, mean_episode_return = 0.52546, mean_episode_step = 53.677, total_loss = -327.59, entropy_loss = -7.8866, pg_loss = -386.93, baseline_loss = 67.228, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:22,179[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1642.9, step = 471040, mean_episode_return = 0.56388, mean_episode_step = 53.522, total_loss = -86.602, entropy_loss = -7.8924, pg_loss = -152.18, baseline_loss = 73.476, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:27,184[0m][[34mroot[0m][[32mINFO[0m] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1647.9, step = 471040, mean_episode_return = 0.56388, mean_episode_step = 53.522, total_loss = -86.602, entropy_loss = -7.8924, pg_loss = -152.18, baseline_loss = 73.476, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:32,189[0m][[34mroot[0m][[32mINFO[0m] - Step 473600 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1652.9, step = 473600, mean_episode_return = 0.5088, mean_episode_step = 56.355, total_loss = -320.21, entropy_loss = -7.8825, pg_loss = -383.51, baseline_loss = 71.183, learner_queue_size = 32, _tick = 184, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:37,194[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1657.9, step = 476160, mean_episode_return = 0.58026, mean_episode_step = 44.521, total_loss = -207.49, entropy_loss = -7.8851, pg_loss = -282.94, baseline_loss = 83.335, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:42,201[0m][[34mroot[0m][[32mINFO[0m] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1662.9, step = 476160, mean_episode_return = 0.58026, mean_episode_step = 44.521, total_loss = -207.49, entropy_loss = -7.8851, pg_loss = -282.94, baseline_loss = 83.335, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:47,206[0m][[34mroot[0m][[32mINFO[0m] - Step 478720 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1667.9, step = 478720, mean_episode_return = 0.52348, mean_episode_step = 55.359, total_loss = -81.563, entropy_loss = -7.8888, pg_loss = -153.27, baseline_loss = 79.592, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:52,211[0m][[34mroot[0m][[32mINFO[0m] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1673.0, step = 478720, mean_episode_return = 0.52348, mean_episode_step = 55.359, total_loss = -81.563, entropy_loss = -7.8888, pg_loss = -153.27, baseline_loss = 79.592, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:29:57,216[0m][[34mroot[0m][[32mINFO[0m] - Step 481280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1678.0, step = 481280, mean_episode_return = 0.56926, mean_episode_step = 65.916, total_loss = -53.616, entropy_loss = -7.8646, pg_loss = -114.23, baseline_loss = 68.483, learner_queue_size = 32, _tick = 187, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:02,221[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1683.0, step = 483840, mean_episode_return = 0.68374, mean_episode_step = 55.261, total_loss = 105.56, entropy_loss = -7.9003, pg_loss = 20.497, baseline_loss = 92.964, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:07,226[0m][[34mroot[0m][[32mINFO[0m] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1688.0, step = 483840, mean_episode_return = 0.68374, mean_episode_step = 55.261, total_loss = 105.56, entropy_loss = -7.9003, pg_loss = 20.497, baseline_loss = 92.964, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:12,231[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1693.0, step = 486400, mean_episode_return = 0.62259, mean_episode_step = 59.261, total_loss = -146.08, entropy_loss = -7.8753, pg_loss = -203.07, baseline_loss = 64.866, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:17,237[0m][[34mroot[0m][[32mINFO[0m] - Step 486400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1698.0, step = 486400, mean_episode_return = 0.62259, mean_episode_step = 59.261, total_loss = -146.08, entropy_loss = -7.8753, pg_loss = -203.07, baseline_loss = 64.866, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:22,242[0m][[34mroot[0m][[32mINFO[0m] - Step 488960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1703.0, step = 488960, mean_episode_return = 0.55051, mean_episode_step = 40.624, total_loss = -108.22, entropy_loss = -7.91, pg_loss = -187.87, baseline_loss = 87.56, learner_queue_size = 32, _tick = 190, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:27,247[0m][[34mroot[0m][[32mINFO[0m] - Step 491520 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1708.0, step = 491520, mean_episode_return = 0.91934, mean_episode_step = 56.79, total_loss = 431.89, entropy_loss = -7.8582, pg_loss = 372.97, baseline_loss = 66.772, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:32,252[0m][[34mroot[0m][[32mINFO[0m] - Step 491520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1713.0, step = 491520, mean_episode_return = 0.91934, mean_episode_step = 56.79, total_loss = 431.89, entropy_loss = -7.8582, pg_loss = 372.97, baseline_loss = 66.772, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:37,257[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1718.0, step = 494080, mean_episode_return = 0.75769, mean_episode_step = 49.139, total_loss = 237.32, entropy_loss = -7.8714, pg_loss = 169.72, baseline_loss = 75.469, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:42,262[0m][[34mroot[0m][[32mINFO[0m] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1723.0, step = 494080, mean_episode_return = 0.75769, mean_episode_step = 49.139, total_loss = 237.32, entropy_loss = -7.8714, pg_loss = 169.72, baseline_loss = 75.469, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:47,267[0m][[34mroot[0m][[32mINFO[0m] - Step 496640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1728.0, step = 496640, mean_episode_return = 0.59004, mean_episode_step = 46.679, total_loss = 65.252, entropy_loss = -7.872, pg_loss = 0.60249, baseline_loss = 72.522, learner_queue_size = 32, _tick = 193, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:52,273[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1733.0, step = 499200, mean_episode_return = 0.63089, mean_episode_step = 47.883, total_loss = -282.38, entropy_loss = -7.8669, pg_loss = -340.49, baseline_loss = 65.978, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:30:57,279[0m][[34mroot[0m][[32mINFO[0m] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1738.0, step = 499200, mean_episode_return = 0.63089, mean_episode_step = 47.883, total_loss = -282.38, entropy_loss = -7.8669, pg_loss = -340.49, baseline_loss = 65.978, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:31:02,284[0m][[34mroot[0m][[32mINFO[0m] - Step 501760 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1743.0, step = 501760, mean_episode_return = 0.51464, mean_episode_step = 54.47, total_loss = -429.44, entropy_loss = -7.86, pg_loss = -487.99, baseline_loss = 66.413, learner_queue_size = 32, _tick = 195, _time = 1.7371e+09)[0m
[[36m2025-01-17 18:31:02,284[0m][[34mroot[0m][[32mINFO[0m] - Learning finished after 501760 steps.[0m
[[36m2025-01-17 18:31:02,286[0m][[34mroot[0m][[32mINFO[0m] - Saving checkpoint to /opt/minihack/checkpoint.tar[0m
[[36m2025-01-17 19:55:34,806[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,778[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,782[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,802[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,788[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,839[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,780[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,783[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,802[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,779[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,806[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,772[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,795[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,772[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,782[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,797[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,778[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,775[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,828[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,774[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,807[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,828[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,778[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,781[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,842[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,778[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,812[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,795[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,772[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,790[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,782[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,817[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,813[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,787[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,775[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,779[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,773[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,794[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,783[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,823[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,811[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,800[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,783[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,778[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,825[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,776[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,773[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,837[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,769[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,818[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,815[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,796[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,810[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,780[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,793[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,809[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,870[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,821[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,775[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,826[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,775[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,837[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,809[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,787[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,777[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,814[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,768[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,814[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,835[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,812[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,859[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,848[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,827[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,814[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,839[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,835[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,874[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,861[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,820[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,832[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,832[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,845[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,870[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,838[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,836[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,869[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,845[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,863[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,869[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,897[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,889[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,779[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,890[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,836[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,925[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,830[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,844[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,887[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,850[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,891[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,915[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,842[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,859[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,847[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,885[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,844[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,864[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,846[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,817[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,835[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,844[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,851[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,831[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,859[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,864[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,860[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,862[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,891[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,884[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,866[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,866[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,810[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,847[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,858[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,951[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,867[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,854[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,937[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,891[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,913[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,852[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,866[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
<MiniHackCombatSkill instance>
[[36m2025-01-17 19:55:34,766[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,946[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,965[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,860[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,895[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,854[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,915[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,895[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,962[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:34,910[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:35,178[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
[[36m2025-01-17 19:55:35,293[0m][[34mnle.env.base[0m][[32mINFO[0m] - Not saving any NLE data.[0m
