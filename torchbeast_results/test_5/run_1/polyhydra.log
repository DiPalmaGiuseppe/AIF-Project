[2025-01-17 18:01:58,911][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-17 18:01:58,977][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 18:01:58,978][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 18:01:58,984][root][INFO] - Logging results to /opt/minihack
[2025-01-17 18:01:59,048][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 18:01:59,049][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 18:01:59,050][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 18:01:59,050][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 18:01:59,050][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 18:01:59,052][root][INFO] - Not using CUDA.
[2025-01-17 18:01:59,060][root][INFO] - Using model baseline
[2025-01-17 18:01:59,061][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,094][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,165][root][INFO] - Number of model parameters: 4264078
[2025-01-17 18:01:59,166][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,192][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,264][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,266][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,267][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,267][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,261][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,263][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,272][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,264][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,273][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,273][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,267][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,278][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,270][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,284][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,290][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,291][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,292][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,291][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,296][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,307][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,310][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,310][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,312][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,318][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,326][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,290][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,330][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,336][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,280][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,339][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,337][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,344][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,345][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,346][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,351][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:01:59,341][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:04,261][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 0. Other stats: (train_seconds = 5.0)
[2025-01-17 18:02:09,266][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 30. Learner queue size: 26. Other stats: (train_seconds = 10.0)
[2025-01-17 18:02:14,271][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 114. Learner queue size: 28. Other stats: (train_seconds = 15.0)
[2025-01-17 18:02:19,279][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 76. Learner queue size: 28. Other stats: (train_seconds = 20.0)
[2025-01-17 18:02:24,295][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 138. Learner queue size: 30. Other stats: (train_seconds = 25.0)
[2025-01-17 18:02:29,300][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 91. Learner queue size: 32. Other stats: (train_seconds = 30.0)
[2025-01-17 18:02:34,302][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 96. Learner queue size: 32. Other stats: (train_seconds = 35.0)
[2025-01-17 18:02:39,307][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 117. Learner queue size: 32. Other stats: (train_seconds = 40.1)
[2025-01-17 18:02:41,817][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-17 18:02:44,313][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-17 18:02:44,398][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 122. Learner queue size: 5. Other stats: (train_seconds = 45.1, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 18:02:49,403][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 55. Learner queue size: 7. Other stats: (train_seconds = 50.1, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 18:02:54,409][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 53. Learner queue size: 8. Other stats: (train_seconds = 55.2, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 18:02:59,414][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 147. Learner queue size: 10. Other stats: (train_seconds = 60.2, step = 2560, mean_episode_return = -0.036421, mean_episode_step = 32.183, total_loss = -1250.6, entropy_loss = -11.371, pg_loss = -1555.9, baseline_loss = 316.71, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 18:03:04,420][root][INFO] - Step 5120 @ 511.4 SPS. Inference batcher size: 76. Learner queue size: 32. Other stats: (train_seconds = 65.2, step = 5120, mean_episode_return = 0.067211, mean_episode_step = 33.455, total_loss = 1759.5, entropy_loss = -11.368, pg_loss = 1393.4, baseline_loss = 377.51, learner_queue_size = 10, _tick = 1, _time = 1.7371e+09)
[2025-01-17 18:03:09,426][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (train_seconds = 70.2, step = 5120, mean_episode_return = 0.067211, mean_episode_step = 33.455, total_loss = 1759.5, entropy_loss = -11.368, pg_loss = 1393.4, baseline_loss = 377.51, learner_queue_size = 10, _tick = 1, _time = 1.7371e+09)
[2025-01-17 18:03:14,431][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 75.2, step = 5120, mean_episode_return = 0.067211, mean_episode_step = 33.455, total_loss = 1759.5, entropy_loss = -11.368, pg_loss = 1393.4, baseline_loss = 377.51, learner_queue_size = 10, _tick = 1, _time = 1.7371e+09)
[2025-01-17 18:03:19,436][root][INFO] - Step 7680 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 80.2, step = 7680, mean_episode_return = -0.06844, mean_episode_step = 54.49, total_loss = 1098.2, entropy_loss = -11.362, pg_loss = 830.52, baseline_loss = 279.05, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 18:03:24,769][root][INFO] - Step 7680 @ 0.0 SPS. Inference batcher size: 49. Learner queue size: 32. Other stats: (train_seconds = 85.2, step = 7680, mean_episode_return = -0.06844, mean_episode_step = 54.49, total_loss = 1098.2, entropy_loss = -11.362, pg_loss = 830.52, baseline_loss = 279.05, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 18:03:29,774][root][INFO] - Step 10240 @ 480.0 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 90.5, step = 10240, mean_episode_return = -0.069286, mean_episode_step = 60.793, total_loss = -781.47, entropy_loss = -11.366, pg_loss = -946.52, baseline_loss = 176.42, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 18:03:34,779][root][INFO] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 95.5, step = 10240, mean_episode_return = -0.069286, mean_episode_step = 60.793, total_loss = -781.47, entropy_loss = -11.366, pg_loss = -946.52, baseline_loss = 176.42, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 18:03:39,784][root][INFO] - Step 12800 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 100.5, step = 12800, mean_episode_return = -0.04281, mean_episode_step = 43.145, total_loss = -230.64, entropy_loss = -11.356, pg_loss = -352.3, baseline_loss = 133.01, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)
[2025-01-17 18:03:44,795][root][INFO] - Step 15360 @ 510.8 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 105.5, step = 15360, mean_episode_return = 0.0119, mean_episode_step = 32.635, total_loss = 1629.4, entropy_loss = -11.341, pg_loss = 1390.7, baseline_loss = 249.99, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 18:03:49,801][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 110.5, step = 15360, mean_episode_return = 0.0119, mean_episode_step = 32.635, total_loss = 1629.4, entropy_loss = -11.341, pg_loss = 1390.7, baseline_loss = 249.99, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 18:03:54,807][root][INFO] - Step 17920 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 115.6, step = 17920, mean_episode_return = -0.06, mean_episode_step = 45.371, total_loss = 219.97, entropy_loss = -11.37, pg_loss = 56.303, baseline_loss = 175.03, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 18:03:59,813][root][INFO] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 120.6, step = 17920, mean_episode_return = -0.06, mean_episode_step = 45.371, total_loss = 219.97, entropy_loss = -11.37, pg_loss = 56.303, baseline_loss = 175.03, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 18:04:04,818][root][INFO] - Step 20480 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 125.6, step = 20480, mean_episode_return = -0.052913, mean_episode_step = 49.192, total_loss = 18.312, entropy_loss = -11.365, pg_loss = -147.36, baseline_loss = 177.04, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 18:04:09,824][root][INFO] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 130.6, step = 20480, mean_episode_return = -0.052913, mean_episode_step = 49.192, total_loss = 18.312, entropy_loss = -11.365, pg_loss = -147.36, baseline_loss = 177.04, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 18:04:14,829][root][INFO] - Step 23040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 135.6, step = 23040, mean_episode_return = 0.005, mean_episode_step = 57.084, total_loss = -478.77, entropy_loss = -11.347, pg_loss = -471.66, baseline_loss = 4.2365, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 18:04:19,834][root][INFO] - Step 25600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 140.6, step = 25600, mean_episode_return = 0.041637, mean_episode_step = 64.602, total_loss = 1065.8, entropy_loss = -11.333, pg_loss = 919.92, baseline_loss = 157.2, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 18:04:24,839][root][INFO] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 145.6, step = 25600, mean_episode_return = 0.041637, mean_episode_step = 64.602, total_loss = 1065.8, entropy_loss = -11.333, pg_loss = 919.92, baseline_loss = 157.2, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 18:04:29,845][root][INFO] - Step 28160 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 150.6, step = 28160, mean_episode_return = -0.066037, mean_episode_step = 57.186, total_loss = 738.02, entropy_loss = -11.363, pg_loss = 558.06, baseline_loss = 191.33, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 18:04:34,850][root][INFO] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 155.6, step = 28160, mean_episode_return = -0.066037, mean_episode_step = 57.186, total_loss = 738.02, entropy_loss = -11.363, pg_loss = 558.06, baseline_loss = 191.33, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 18:04:39,855][root][INFO] - Step 30720 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 160.6, step = 30720, mean_episode_return = -0.080667, mean_episode_step = 55.76, total_loss = 1144.0, entropy_loss = -11.37, pg_loss = 825.19, baseline_loss = 330.19, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)
[2025-01-17 18:04:44,862][root][INFO] - Step 33280 @ 511.2 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 165.6, step = 33280, mean_episode_return = 0.043179, mean_episode_step = 56.377, total_loss = 1277.9, entropy_loss = -11.369, pg_loss = 883.3, baseline_loss = 405.92, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)
[2025-01-17 18:04:49,868][root][INFO] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 170.6, step = 33280, mean_episode_return = 0.043179, mean_episode_step = 56.377, total_loss = 1277.9, entropy_loss = -11.369, pg_loss = 883.3, baseline_loss = 405.92, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)
[2025-01-17 18:04:54,873][root][INFO] - Step 35840 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 175.6, step = 35840, mean_episode_return = 0.01481, mean_episode_step = 62.737, total_loss = 183.48, entropy_loss = -11.353, pg_loss = -28.097, baseline_loss = 222.93, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)
[2025-01-17 18:04:59,879][root][INFO] - Step 35840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 180.6, step = 35840, mean_episode_return = 0.01481, mean_episode_step = 62.737, total_loss = 183.48, entropy_loss = -11.353, pg_loss = -28.097, baseline_loss = 222.93, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)
[2025-01-17 18:05:04,884][root][INFO] - Step 38400 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 185.6, step = 38400, mean_episode_return = -0.016613, mean_episode_step = 57.034, total_loss = -502.79, entropy_loss = -11.36, pg_loss = -639.2, baseline_loss = 147.77, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)
[2025-01-17 18:05:09,889][root][INFO] - Step 40960 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 190.6, step = 40960, mean_episode_return = -0.049138, mean_episode_step = 73.154, total_loss = 1109.9, entropy_loss = -11.368, pg_loss = 747.3, baseline_loss = 374.0, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)
[2025-01-17 18:05:14,895][root][INFO] - Step 40960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 195.6, step = 40960, mean_episode_return = -0.049138, mean_episode_step = 73.154, total_loss = 1109.9, entropy_loss = -11.368, pg_loss = 747.3, baseline_loss = 374.0, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)
[2025-01-17 18:05:19,900][root][INFO] - Step 43520 @ 511.5 SPS. Inference batcher size: 29. Learner queue size: 32. Other stats: (train_seconds = 200.6, step = 43520, mean_episode_return = -0.044037, mean_episode_step = 57.02, total_loss = -194.53, entropy_loss = -11.366, pg_loss = -379.49, baseline_loss = 196.32, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)
[2025-01-17 18:05:24,905][root][INFO] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 205.6, step = 43520, mean_episode_return = -0.044037, mean_episode_step = 57.02, total_loss = -194.53, entropy_loss = -11.366, pg_loss = -379.49, baseline_loss = 196.32, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)
[2025-01-17 18:05:29,910][root][INFO] - Step 46080 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 210.7, step = 46080, mean_episode_return = -0.044407, mean_episode_step = 60.467, total_loss = -80.787, entropy_loss = -11.368, pg_loss = -277.12, baseline_loss = 207.71, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)
[2025-01-17 18:05:34,915][root][INFO] - Step 48640 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 215.7, step = 48640, mean_episode_return = 0.048044, mean_episode_step = 62.993, total_loss = 1934.2, entropy_loss = -11.368, pg_loss = 1460.1, baseline_loss = 485.44, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)
[2025-01-17 18:05:39,921][root][INFO] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 220.7, step = 48640, mean_episode_return = 0.048044, mean_episode_step = 62.993, total_loss = 1934.2, entropy_loss = -11.368, pg_loss = 1460.1, baseline_loss = 485.44, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)
[2025-01-17 18:05:44,926][root][INFO] - Step 51200 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 225.7, step = 51200, mean_episode_return = -0.03096, mean_episode_step = 57.375, total_loss = -1225.6, entropy_loss = -11.367, pg_loss = -1223.9, baseline_loss = 9.7212, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)
[2025-01-17 18:05:49,931][root][INFO] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 230.7, step = 51200, mean_episode_return = -0.03096, mean_episode_step = 57.375, total_loss = -1225.6, entropy_loss = -11.367, pg_loss = -1223.9, baseline_loss = 9.7212, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)
[2025-01-17 18:05:54,936][root][INFO] - Step 53760 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 235.7, step = 53760, mean_episode_return = 0.051478, mean_episode_step = 57.998, total_loss = -676.09, entropy_loss = -11.369, pg_loss = -724.45, baseline_loss = 59.725, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)
[2025-01-17 18:05:59,941][root][INFO] - Step 56320 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 240.7, step = 56320, mean_episode_return = 0.010667, mean_episode_step = 68.332, total_loss = 785.3, entropy_loss = -11.364, pg_loss = 505.47, baseline_loss = 291.2, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)
[2025-01-17 18:06:04,947][root][INFO] - Step 56320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 245.7, step = 56320, mean_episode_return = 0.010667, mean_episode_step = 68.332, total_loss = 785.3, entropy_loss = -11.364, pg_loss = 505.47, baseline_loss = 291.2, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)
[2025-01-17 18:06:09,952][root][INFO] - Step 58880 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 250.7, step = 58880, mean_episode_return = -0.0076071, mean_episode_step = 57.213, total_loss = 264.23, entropy_loss = -11.367, pg_loss = 62.439, baseline_loss = 213.15, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)
[2025-01-17 18:06:14,957][root][INFO] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 255.7, step = 58880, mean_episode_return = -0.0076071, mean_episode_step = 57.213, total_loss = 264.23, entropy_loss = -11.367, pg_loss = 62.439, baseline_loss = 213.15, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)
[2025-01-17 18:06:19,962][root][INFO] - Step 61440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 260.7, step = 61440, mean_episode_return = 0.12016, mean_episode_step = 70.821, total_loss = 250.4, entropy_loss = -11.359, pg_loss = 84.143, baseline_loss = 177.61, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)
[2025-01-17 18:06:24,967][root][INFO] - Step 64000 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 265.7, step = 64000, mean_episode_return = -0.0725, mean_episode_step = 69.196, total_loss = 846.86, entropy_loss = -11.364, pg_loss = 548.54, baseline_loss = 309.68, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)
[2025-01-17 18:06:29,972][root][INFO] - Step 64000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 270.7, step = 64000, mean_episode_return = -0.0725, mean_episode_step = 69.196, total_loss = 846.86, entropy_loss = -11.364, pg_loss = 548.54, baseline_loss = 309.68, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)
[2025-01-17 18:06:34,978][root][INFO] - Step 66560 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 275.7, step = 66560, mean_episode_return = 0.037548, mean_episode_step = 73.16, total_loss = -419.03, entropy_loss = -11.366, pg_loss = -575.47, baseline_loss = 167.8, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 18:06:39,989][root][INFO] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 280.7, step = 66560, mean_episode_return = 0.037548, mean_episode_step = 73.16, total_loss = -419.03, entropy_loss = -11.366, pg_loss = -575.47, baseline_loss = 167.8, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 18:06:44,994][root][INFO] - Step 69120 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 285.7, step = 69120, mean_episode_return = -0.063219, mean_episode_step = 61.133, total_loss = 933.21, entropy_loss = -11.369, pg_loss = 590.93, baseline_loss = 353.64, learner_queue_size = 32, _tick = 26, _time = 1.7371e+09)
[2025-01-17 18:06:49,999][root][INFO] - Step 71680 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 290.7, step = 71680, mean_episode_return = -0.003074, mean_episode_step = 54.397, total_loss = -638.34, entropy_loss = -11.364, pg_loss = -711.9, baseline_loss = 84.927, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)
[2025-01-17 18:06:55,004][root][INFO] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 295.7, step = 71680, mean_episode_return = -0.003074, mean_episode_step = 54.397, total_loss = -638.34, entropy_loss = -11.364, pg_loss = -711.9, baseline_loss = 84.927, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)
[2025-01-17 18:07:00,009][root][INFO] - Step 74240 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 300.8, step = 74240, mean_episode_return = -0.06532, mean_episode_step = 64.674, total_loss = 1859.3, entropy_loss = -11.366, pg_loss = 1355.3, baseline_loss = 515.41, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)
[2025-01-17 18:07:05,014][root][INFO] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 305.8, step = 74240, mean_episode_return = -0.06532, mean_episode_step = 64.674, total_loss = 1859.3, entropy_loss = -11.366, pg_loss = 1355.3, baseline_loss = 515.41, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)
[2025-01-17 18:07:10,020][root][INFO] - Step 76800 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 310.8, step = 76800, mean_episode_return = 0.0664, mean_episode_step = 66.662, total_loss = 132.59, entropy_loss = -11.367, pg_loss = -134.7, baseline_loss = 278.65, learner_queue_size = 32, _tick = 29, _time = 1.7371e+09)
[2025-01-17 18:07:15,027][root][INFO] - Step 79360 @ 511.2 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 315.8, step = 79360, mean_episode_return = -0.077788, mean_episode_step = 53.53, total_loss = 444.17, entropy_loss = -11.364, pg_loss = 177.89, baseline_loss = 277.64, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)
[2025-01-17 18:07:20,033][root][INFO] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 320.8, step = 79360, mean_episode_return = -0.077788, mean_episode_step = 53.53, total_loss = 444.17, entropy_loss = -11.364, pg_loss = 177.89, baseline_loss = 277.64, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)
[2025-01-17 18:07:25,038][root][INFO] - Step 81920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 325.8, step = 81920, mean_episode_return = 0.039125, mean_episode_step = 65.099, total_loss = -62.695, entropy_loss = -11.36, pg_loss = -250.53, baseline_loss = 199.19, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)
[2025-01-17 18:07:30,043][root][INFO] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 330.8, step = 81920, mean_episode_return = 0.039125, mean_episode_step = 65.099, total_loss = -62.695, entropy_loss = -11.36, pg_loss = -250.53, baseline_loss = 199.19, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)
[2025-01-17 18:07:35,048][root][INFO] - Step 84480 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 335.8, step = 84480, mean_episode_return = 0.14945, mean_episode_step = 69.829, total_loss = 1114.2, entropy_loss = -11.36, pg_loss = 789.18, baseline_loss = 336.36, learner_queue_size = 32, _tick = 32, _time = 1.7371e+09)
[2025-01-17 18:07:40,055][root][INFO] - Step 87040 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 340.8, step = 87040, mean_episode_return = 0.030926, mean_episode_step = 70.166, total_loss = 781.8, entropy_loss = -11.359, pg_loss = 424.9, baseline_loss = 368.26, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)
[2025-01-17 18:07:45,060][root][INFO] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 345.8, step = 87040, mean_episode_return = 0.030926, mean_episode_step = 70.166, total_loss = 781.8, entropy_loss = -11.359, pg_loss = 424.9, baseline_loss = 368.26, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)
[2025-01-17 18:07:50,065][root][INFO] - Step 89600 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 350.8, step = 89600, mean_episode_return = -0.052704, mean_episode_step = 64.535, total_loss = -1094.3, entropy_loss = -11.348, pg_loss = -1090.4, baseline_loss = 7.4686, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)
[2025-01-17 18:07:55,071][root][INFO] - Step 92160 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 355.8, step = 92160, mean_episode_return = 0.04071, mean_episode_step = 64.198, total_loss = -657.75, entropy_loss = -11.358, pg_loss = -729.35, baseline_loss = 82.956, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 18:08:00,076][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 360.8, step = 92160, mean_episode_return = 0.04071, mean_episode_step = 64.198, total_loss = -657.75, entropy_loss = -11.358, pg_loss = -729.35, baseline_loss = 82.956, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 18:08:05,081][root][INFO] - Step 94720 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 365.8, step = 94720, mean_episode_return = -0.043136, mean_episode_step = 68.748, total_loss = 3158.6, entropy_loss = -11.36, pg_loss = 2411.0, baseline_loss = 759.02, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 18:08:10,082][root][INFO] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 370.8, step = 94720, mean_episode_return = -0.043136, mean_episode_step = 68.748, total_loss = 3158.6, entropy_loss = -11.36, pg_loss = 2411.0, baseline_loss = 759.02, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 18:08:15,087][root][INFO] - Step 97280 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 375.8, step = 97280, mean_episode_return = 0.012147, mean_episode_step = 61.171, total_loss = 1390.5, entropy_loss = -11.36, pg_loss = 951.14, baseline_loss = 450.7, learner_queue_size = 32, _tick = 37, _time = 1.7371e+09)
[2025-01-17 18:08:20,093][root][INFO] - Step 99840 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 380.8, step = 99840, mean_episode_return = -0.018064, mean_episode_step = 66.664, total_loss = 67.577, entropy_loss = -11.352, pg_loss = -137.36, baseline_loss = 216.29, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)
[2025-01-17 18:08:25,098][root][INFO] - Step 99840 @ 0.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 385.8, step = 99840, mean_episode_return = -0.018064, mean_episode_step = 66.664, total_loss = 67.577, entropy_loss = -11.352, pg_loss = -137.36, baseline_loss = 216.29, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)
[2025-01-17 18:08:30,105][root][INFO] - Step 102400 @ 511.3 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 390.8, step = 102400, mean_episode_return = 0.055552, mean_episode_step = 62.088, total_loss = 755.39, entropy_loss = -11.354, pg_loss = 456.86, baseline_loss = 309.88, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)
[2025-01-17 18:08:35,110][root][INFO] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 395.9, step = 102400, mean_episode_return = 0.055552, mean_episode_step = 62.088, total_loss = 755.39, entropy_loss = -11.354, pg_loss = 456.86, baseline_loss = 309.88, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)
[2025-01-17 18:08:40,115][root][INFO] - Step 104960 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 400.9, step = 104960, mean_episode_return = -0.082407, mean_episode_step = 60.548, total_loss = -311.83, entropy_loss = -11.346, pg_loss = -440.12, baseline_loss = 139.64, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)
[2025-01-17 18:08:45,120][root][INFO] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 405.9, step = 104960, mean_episode_return = -0.082407, mean_episode_step = 60.548, total_loss = -311.83, entropy_loss = -11.346, pg_loss = -440.12, baseline_loss = 139.64, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)
[2025-01-17 18:08:50,125][root][INFO] - Step 107520 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 410.9, step = 107520, mean_episode_return = -0.02084, mean_episode_step = 69.917, total_loss = 340.96, entropy_loss = -11.352, pg_loss = 119.99, baseline_loss = 232.31, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)
[2025-01-17 18:08:55,131][root][INFO] - Step 107520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 415.9, step = 107520, mean_episode_return = -0.02084, mean_episode_step = 69.917, total_loss = 340.96, entropy_loss = -11.352, pg_loss = 119.99, baseline_loss = 232.31, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)
[2025-01-17 18:09:00,136][root][INFO] - Step 110080 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 420.9, step = 110080, mean_episode_return = 0.0564, mean_episode_step = 61.817, total_loss = 781.05, entropy_loss = -11.342, pg_loss = 475.17, baseline_loss = 317.22, learner_queue_size = 32, _tick = 42, _time = 1.7371e+09)
[2025-01-17 18:09:05,142][root][INFO] - Step 112640 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 425.9, step = 112640, mean_episode_return = -0.04231, mean_episode_step = 62.315, total_loss = -1161.6, entropy_loss = -11.324, pg_loss = -1159.5, baseline_loss = 9.2178, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)
[2025-01-17 18:09:10,147][root][INFO] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 430.9, step = 112640, mean_episode_return = -0.04231, mean_episode_step = 62.315, total_loss = -1161.6, entropy_loss = -11.324, pg_loss = -1159.5, baseline_loss = 9.2178, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)
[2025-01-17 18:09:15,152][root][INFO] - Step 115200 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 435.9, step = 115200, mean_episode_return = 0.027208, mean_episode_step = 64.82, total_loss = 170.52, entropy_loss = -11.337, pg_loss = -37.996, baseline_loss = 219.85, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)
[2025-01-17 18:09:20,157][root][INFO] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 440.9, step = 115200, mean_episode_return = 0.027208, mean_episode_step = 64.82, total_loss = 170.52, entropy_loss = -11.337, pg_loss = -37.996, baseline_loss = 219.85, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)
[2025-01-17 18:09:25,162][root][INFO] - Step 117760 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 445.9, step = 117760, mean_episode_return = -0.023975, mean_episode_step = 60.404, total_loss = 615.04, entropy_loss = -11.336, pg_loss = 329.39, baseline_loss = 296.98, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)
[2025-01-17 18:09:30,168][root][INFO] - Step 117760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 450.9, step = 117760, mean_episode_return = -0.023975, mean_episode_step = 60.404, total_loss = 615.04, entropy_loss = -11.336, pg_loss = 329.39, baseline_loss = 296.98, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)
[2025-01-17 18:09:35,173][root][INFO] - Step 120320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 455.9, step = 120320, mean_episode_return = 0.075423, mean_episode_step = 65.495, total_loss = 3983.0, entropy_loss = -11.326, pg_loss = 3099.3, baseline_loss = 894.97, learner_queue_size = 32, _tick = 46, _time = 1.7371e+09)
[2025-01-17 18:09:40,178][root][INFO] - Step 122880 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 460.9, step = 122880, mean_episode_return = 0.0094376, mean_episode_step = 59.306, total_loss = -520.01, entropy_loss = -11.31, pg_loss = -629.3, baseline_loss = 120.6, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)
[2025-01-17 18:09:45,184][root][INFO] - Step 122880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 465.9, step = 122880, mean_episode_return = 0.0094376, mean_episode_step = 59.306, total_loss = -520.01, entropy_loss = -11.31, pg_loss = -629.3, baseline_loss = 120.6, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)
[2025-01-17 18:09:50,189][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar
[2025-01-17 18:09:50,267][root][INFO] - Step 125440 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 470.9, step = 125440, mean_episode_return = 0.1102, mean_episode_step = 72.786, total_loss = 114.15, entropy_loss = -11.317, pg_loss = -90.068, baseline_loss = 215.54, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)
[2025-01-17 18:09:55,272][root][INFO] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 476.0, step = 125440, mean_episode_return = 0.1102, mean_episode_step = 72.786, total_loss = 114.15, entropy_loss = -11.317, pg_loss = -90.068, baseline_loss = 215.54, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)
[2025-01-17 18:10:00,277][root][INFO] - Step 128000 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 481.0, step = 128000, mean_episode_return = 0.065185, mean_episode_step = 60.648, total_loss = -179.41, entropy_loss = -11.278, pg_loss = -269.38, baseline_loss = 101.24, learner_queue_size = 32, _tick = 49, _time = 1.7371e+09)
[2025-01-17 18:10:05,282][root][INFO] - Step 130560 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 486.0, step = 130560, mean_episode_return = 0.029345, mean_episode_step = 57.268, total_loss = 336.44, entropy_loss = -11.267, pg_loss = 206.63, baseline_loss = 141.07, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)
[2025-01-17 18:10:10,288][root][INFO] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 491.0, step = 130560, mean_episode_return = 0.029345, mean_episode_step = 57.268, total_loss = 336.44, entropy_loss = -11.267, pg_loss = 206.63, baseline_loss = 141.07, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)
[2025-01-17 18:10:15,293][root][INFO] - Step 133120 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 496.0, step = 133120, mean_episode_return = -0.010556, mean_episode_step = 59.157, total_loss = -210.06, entropy_loss = -11.251, pg_loss = -287.06, baseline_loss = 88.255, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)
[2025-01-17 18:10:20,298][root][INFO] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 501.0, step = 133120, mean_episode_return = -0.010556, mean_episode_step = 59.157, total_loss = -210.06, entropy_loss = -11.251, pg_loss = -287.06, baseline_loss = 88.255, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)
[2025-01-17 18:10:25,298][root][INFO] - Step 135680 @ 511.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 506.0, step = 135680, mean_episode_return = 0.080834, mean_episode_step = 53.483, total_loss = -618.69, entropy_loss = -11.236, pg_loss = -609.81, baseline_loss = 2.361, learner_queue_size = 32, _tick = 52, _time = 1.7371e+09)
[2025-01-17 18:10:30,304][root][INFO] - Step 138240 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 511.0, step = 138240, mean_episode_return = 0.025242, mean_episode_step = 64.955, total_loss = -421.74, entropy_loss = -11.225, pg_loss = -412.12, baseline_loss = 1.6127, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)
[2025-01-17 18:10:35,309][root][INFO] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 516.1, step = 138240, mean_episode_return = 0.025242, mean_episode_step = 64.955, total_loss = -421.74, entropy_loss = -11.225, pg_loss = -412.12, baseline_loss = 1.6127, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)
[2025-01-17 18:10:40,314][root][INFO] - Step 140800 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 521.1, step = 140800, mean_episode_return = -0.010939, mean_episode_step = 63.856, total_loss = 1086.3, entropy_loss = -11.198, pg_loss = 906.56, baseline_loss = 190.93, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)
[2025-01-17 18:10:45,321][root][INFO] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 526.1, step = 140800, mean_episode_return = -0.010939, mean_episode_step = 63.856, total_loss = 1086.3, entropy_loss = -11.198, pg_loss = 906.56, baseline_loss = 190.93, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)
[2025-01-17 18:10:50,327][root][INFO] - Step 143360 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 531.1, step = 143360, mean_episode_return = -0.024613, mean_episode_step = 60.233, total_loss = 1355.3, entropy_loss = -11.219, pg_loss = 1069.1, baseline_loss = 297.33, learner_queue_size = 32, _tick = 55, _time = 1.7371e+09)
[2025-01-17 18:10:55,332][root][INFO] - Step 145920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 536.1, step = 145920, mean_episode_return = 0.05085, mean_episode_step = 48.075, total_loss = 1519.0, entropy_loss = -11.228, pg_loss = 1151.6, baseline_loss = 378.64, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)
[2025-01-17 18:11:00,338][root][INFO] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 541.1, step = 145920, mean_episode_return = 0.05085, mean_episode_step = 48.075, total_loss = 1519.0, entropy_loss = -11.228, pg_loss = 1151.6, baseline_loss = 378.64, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)
[2025-01-17 18:11:05,343][root][INFO] - Step 148480 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 546.1, step = 148480, mean_episode_return = 0.020742, mean_episode_step = 63.641, total_loss = 1434.5, entropy_loss = -11.208, pg_loss = 1096.8, baseline_loss = 348.87, learner_queue_size = 32, _tick = 57, _time = 1.7371e+09)
[2025-01-17 18:11:10,348][root][INFO] - Step 151040 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 551.1, step = 151040, mean_episode_return = 0.010475, mean_episode_step = 55.537, total_loss = 812.5, entropy_loss = -11.183, pg_loss = 540.27, baseline_loss = 283.42, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)
[2025-01-17 18:11:15,354][root][INFO] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 556.1, step = 151040, mean_episode_return = 0.010475, mean_episode_step = 55.537, total_loss = 812.5, entropy_loss = -11.183, pg_loss = 540.27, baseline_loss = 283.42, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)
[2025-01-17 18:11:20,359][root][INFO] - Step 153600 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 561.1, step = 153600, mean_episode_return = 0.22021, mean_episode_step = 57.641, total_loss = 515.23, entropy_loss = -11.152, pg_loss = 285.72, baseline_loss = 240.67, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)
[2025-01-17 18:11:25,366][root][INFO] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 566.1, step = 153600, mean_episode_return = 0.22021, mean_episode_step = 57.641, total_loss = 515.23, entropy_loss = -11.152, pg_loss = 285.72, baseline_loss = 240.67, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)
[2025-01-17 18:11:30,371][root][INFO] - Step 156160 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 571.1, step = 156160, mean_episode_return = 0.036267, mean_episode_step = 57.745, total_loss = -260.61, entropy_loss = -11.044, pg_loss = -347.45, baseline_loss = 97.88, learner_queue_size = 32, _tick = 60, _time = 1.7371e+09)
[2025-01-17 18:11:35,377][root][INFO] - Step 158720 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 576.1, step = 158720, mean_episode_return = 0.19148, mean_episode_step = 64.486, total_loss = 2039.5, entropy_loss = -11.058, pg_loss = 1661.3, baseline_loss = 389.3, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)
[2025-01-17 18:11:40,383][root][INFO] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 581.1, step = 158720, mean_episode_return = 0.19148, mean_episode_step = 64.486, total_loss = 2039.5, entropy_loss = -11.058, pg_loss = 1661.3, baseline_loss = 389.3, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)
[2025-01-17 18:11:45,388][root][INFO] - Step 161280 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 586.1, step = 161280, mean_episode_return = -0.042743, mean_episode_step = 52.986, total_loss = -400.8, entropy_loss = -11.003, pg_loss = -472.23, baseline_loss = 82.433, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)
[2025-01-17 18:11:50,394][root][INFO] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 591.1, step = 161280, mean_episode_return = -0.042743, mean_episode_step = 52.986, total_loss = -400.8, entropy_loss = -11.003, pg_loss = -472.23, baseline_loss = 82.433, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)
[2025-01-17 18:11:55,399][root][INFO] - Step 163840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 596.1, step = 163840, mean_episode_return = 0.093132, mean_episode_step = 52.506, total_loss = 112.7, entropy_loss = -11.037, pg_loss = -82.962, baseline_loss = 206.69, learner_queue_size = 32, _tick = 63, _time = 1.7371e+09)
[2025-01-17 18:12:00,404][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 18:12:00,450][root][INFO] - Step 166400 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 601.1, step = 166400, mean_episode_return = 0.12558, mean_episode_step = 59.141, total_loss = 1558.2, entropy_loss = -10.875, pg_loss = 1293.2, baseline_loss = 275.91, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)
[2025-01-17 18:12:05,456][root][INFO] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 606.2, step = 166400, mean_episode_return = 0.12558, mean_episode_step = 59.141, total_loss = 1558.2, entropy_loss = -10.875, pg_loss = 1293.2, baseline_loss = 275.91, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)
[2025-01-17 18:12:10,461][root][INFO] - Step 168960 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 611.2, step = 168960, mean_episode_return = 0.067973, mean_episode_step = 51.294, total_loss = 321.26, entropy_loss = -10.835, pg_loss = 172.96, baseline_loss = 159.13, learner_queue_size = 32, _tick = 65, _time = 1.7371e+09)
[2025-01-17 18:12:15,466][root][INFO] - Step 171520 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 616.2, step = 171520, mean_episode_return = -0.00031245, mean_episode_step = 61.387, total_loss = -186.94, entropy_loss = -10.677, pg_loss = -255.76, baseline_loss = 79.5, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)
[2025-01-17 18:12:20,472][root][INFO] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 621.2, step = 171520, mean_episode_return = -0.00031245, mean_episode_step = 61.387, total_loss = -186.94, entropy_loss = -10.677, pg_loss = -255.76, baseline_loss = 79.5, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)
[2025-01-17 18:12:25,478][root][INFO] - Step 174080 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 626.2, step = 174080, mean_episode_return = 0.12403, mean_episode_step = 60.633, total_loss = 1206.4, entropy_loss = -10.65, pg_loss = 961.38, baseline_loss = 255.72, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)
[2025-01-17 18:12:30,483][root][INFO] - Step 174080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 631.2, step = 174080, mean_episode_return = 0.12403, mean_episode_step = 60.633, total_loss = 1206.4, entropy_loss = -10.65, pg_loss = 961.38, baseline_loss = 255.72, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)
[2025-01-17 18:12:35,488][root][INFO] - Step 176640 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 636.2, step = 176640, mean_episode_return = 0.12303, mean_episode_step = 60.887, total_loss = 197.96, entropy_loss = -10.588, pg_loss = 91.395, baseline_loss = 117.15, learner_queue_size = 32, _tick = 68, _time = 1.7371e+09)
[2025-01-17 18:12:40,493][root][INFO] - Step 179200 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 641.2, step = 179200, mean_episode_return = 0.27272, mean_episode_step = 59.371, total_loss = 1279.5, entropy_loss = -10.654, pg_loss = 1036.4, baseline_loss = 253.72, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)
[2025-01-17 18:12:45,498][root][INFO] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 646.2, step = 179200, mean_episode_return = 0.27272, mean_episode_step = 59.371, total_loss = 1279.5, entropy_loss = -10.654, pg_loss = 1036.4, baseline_loss = 253.72, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)
[2025-01-17 18:12:50,504][root][INFO] - Step 181760 @ 511.4 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 651.2, step = 181760, mean_episode_return = -0.0024166, mean_episode_step = 56.783, total_loss = -344.67, entropy_loss = -10.573, pg_loss = -504.87, baseline_loss = 170.77, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)
[2025-01-17 18:12:55,510][root][INFO] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 656.3, step = 181760, mean_episode_return = -0.0024166, mean_episode_step = 56.783, total_loss = -344.67, entropy_loss = -10.573, pg_loss = -504.87, baseline_loss = 170.77, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)
[2025-01-17 18:13:00,515][root][INFO] - Step 184320 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 661.3, step = 184320, mean_episode_return = 0.075912, mean_episode_step = 55.075, total_loss = 759.15, entropy_loss = -10.513, pg_loss = 502.06, baseline_loss = 267.6, learner_queue_size = 32, _tick = 71, _time = 1.7371e+09)
[2025-01-17 18:13:05,520][root][INFO] - Step 186880 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 666.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)
[2025-01-17 18:13:10,527][root][INFO] - Step 186880 @ 0.0 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 671.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)
[2025-01-17 18:13:15,533][root][INFO] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 676.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)
[2025-01-17 18:13:20,536][root][INFO] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 681.3, step = 186880, mean_episode_return = 0.306, mean_episode_step = 61.813, total_loss = 882.03, entropy_loss = -10.433, pg_loss = 652.85, baseline_loss = 239.61, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)
[2025-01-17 18:13:25,542][root][INFO] - Step 189440 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 686.3, step = 189440, mean_episode_return = 0.14233, mean_episode_step = 64.236, total_loss = -30.257, entropy_loss = -10.309, pg_loss = -175.95, baseline_loss = 156.0, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)
[2025-01-17 18:13:30,548][root][INFO] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 691.3, step = 189440, mean_episode_return = 0.14233, mean_episode_step = 64.236, total_loss = -30.257, entropy_loss = -10.309, pg_loss = -175.95, baseline_loss = 156.0, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)
[2025-01-17 18:13:35,555][root][INFO] - Step 192000 @ 511.3 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 696.3, step = 192000, mean_episode_return = 0.14649, mean_episode_step = 61.934, total_loss = -372.83, entropy_loss = -10.182, pg_loss = -483.84, baseline_loss = 121.2, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)
[2025-01-17 18:13:40,560][root][INFO] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 701.3, step = 192000, mean_episode_return = 0.14649, mean_episode_step = 61.934, total_loss = -372.83, entropy_loss = -10.182, pg_loss = -483.84, baseline_loss = 121.2, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)
[2025-01-17 18:13:45,566][root][INFO] - Step 194560 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 706.3, step = 194560, mean_episode_return = 0.075, mean_episode_step = 54.571, total_loss = -453.12, entropy_loss = -10.162, pg_loss = -507.83, baseline_loss = 64.876, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)
[2025-01-17 18:13:50,571][root][INFO] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 711.3, step = 194560, mean_episode_return = 0.075, mean_episode_step = 54.571, total_loss = -453.12, entropy_loss = -10.162, pg_loss = -507.83, baseline_loss = 64.876, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)
[2025-01-17 18:13:55,576][root][INFO] - Step 197120 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 716.3, step = 197120, mean_episode_return = 0.077563, mean_episode_step = 43.183, total_loss = -627.1, entropy_loss = -10.165, pg_loss = -736.49, baseline_loss = 119.55, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)
[2025-01-17 18:14:00,581][root][INFO] - Step 197120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 721.3, step = 197120, mean_episode_return = 0.077563, mean_episode_step = 43.183, total_loss = -627.1, entropy_loss = -10.165, pg_loss = -736.49, baseline_loss = 119.55, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)
[2025-01-17 18:14:05,586][root][INFO] - Step 199680 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 726.3, step = 199680, mean_episode_return = 0.23849, mean_episode_step = 68.365, total_loss = 434.76, entropy_loss = -10.117, pg_loss = 258.71, baseline_loss = 186.17, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)
[2025-01-17 18:14:10,592][root][INFO] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 731.3, step = 199680, mean_episode_return = 0.23849, mean_episode_step = 68.365, total_loss = 434.76, entropy_loss = -10.117, pg_loss = 258.71, baseline_loss = 186.17, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)
[2025-01-17 18:14:15,598][root][INFO] - Step 202240 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 736.3, step = 202240, mean_episode_return = 0.1378, mean_episode_step = 62.961, total_loss = 33.169, entropy_loss = -10.199, pg_loss = -110.2, baseline_loss = 153.57, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)
[2025-01-17 18:14:20,604][root][INFO] - Step 202240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 741.3, step = 202240, mean_episode_return = 0.1378, mean_episode_step = 62.961, total_loss = 33.169, entropy_loss = -10.199, pg_loss = -110.2, baseline_loss = 153.57, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)
[2025-01-17 18:14:25,609][root][INFO] - Step 204800 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 746.4, step = 204800, mean_episode_return = 0.13494, mean_episode_step = 63.545, total_loss = 654.5, entropy_loss = -10.17, pg_loss = 503.27, baseline_loss = 161.4, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)
[2025-01-17 18:14:30,614][root][INFO] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 751.4, step = 204800, mean_episode_return = 0.13494, mean_episode_step = 63.545, total_loss = 654.5, entropy_loss = -10.17, pg_loss = 503.27, baseline_loss = 161.4, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)
[2025-01-17 18:14:35,619][root][INFO] - Step 207360 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 756.4, step = 207360, mean_episode_return = 0.14333, mean_episode_step = 48.68, total_loss = 42.056, entropy_loss = -10.094, pg_loss = -147.23, baseline_loss = 199.38, learner_queue_size = 32, _tick = 80, _time = 1.7371e+09)
[2025-01-17 18:14:40,625][root][INFO] - Step 209920 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 761.4, step = 209920, mean_episode_return = 0.18814, mean_episode_step = 44.525, total_loss = 738.83, entropy_loss = -10.02, pg_loss = 581.69, baseline_loss = 167.15, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)
[2025-01-17 18:14:45,630][root][INFO] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 766.4, step = 209920, mean_episode_return = 0.18814, mean_episode_step = 44.525, total_loss = 738.83, entropy_loss = -10.02, pg_loss = 581.69, baseline_loss = 167.15, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)
[2025-01-17 18:14:50,635][root][INFO] - Step 212480 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 771.4, step = 212480, mean_episode_return = 0.23, mean_episode_step = 64.675, total_loss = 489.43, entropy_loss = -9.9421, pg_loss = 360.58, baseline_loss = 138.8, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)
[2025-01-17 18:14:55,641][root][INFO] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 776.4, step = 212480, mean_episode_return = 0.23, mean_episode_step = 64.675, total_loss = 489.43, entropy_loss = -9.9421, pg_loss = 360.58, baseline_loss = 138.8, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)
[2025-01-17 18:15:00,647][root][INFO] - Step 215040 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 781.4, step = 215040, mean_episode_return = 0.38211, mean_episode_step = 64.161, total_loss = -97.698, entropy_loss = -9.9075, pg_loss = -223.08, baseline_loss = 135.29, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)
[2025-01-17 18:15:05,652][root][INFO] - Step 215040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 786.4, step = 215040, mean_episode_return = 0.38211, mean_episode_step = 64.161, total_loss = -97.698, entropy_loss = -9.9075, pg_loss = -223.08, baseline_loss = 135.29, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)
[2025-01-17 18:15:10,657][root][INFO] - Step 217600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 791.4, step = 217600, mean_episode_return = 0.15408, mean_episode_step = 48.889, total_loss = -349.13, entropy_loss = -9.8463, pg_loss = -499.94, baseline_loss = 160.66, learner_queue_size = 32, _tick = 84, _time = 1.7371e+09)
[2025-01-17 18:15:15,663][root][INFO] - Step 220160 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 796.4, step = 220160, mean_episode_return = 0.26249, mean_episode_step = 53.889, total_loss = 1356.2, entropy_loss = -9.8245, pg_loss = 1085.3, baseline_loss = 280.71, learner_queue_size = 32, _tick = 85, _time = 1.7371e+09)
[2025-01-17 18:15:20,668][root][INFO] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 801.4, step = 220160, mean_episode_return = 0.26249, mean_episode_step = 53.889, total_loss = 1356.2, entropy_loss = -9.8245, pg_loss = 1085.3, baseline_loss = 280.71, learner_queue_size = 32, _tick = 85, _time = 1.7371e+09)
[2025-01-17 18:15:25,674][root][INFO] - Step 222720 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 806.4, step = 222720, mean_episode_return = 0.1569, mean_episode_step = 53.521, total_loss = -943.53, entropy_loss = -9.7846, pg_loss = -1067.1, baseline_loss = 133.37, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)
[2025-01-17 18:15:30,679][root][INFO] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 811.4, step = 222720, mean_episode_return = 0.1569, mean_episode_step = 53.521, total_loss = -943.53, entropy_loss = -9.7846, pg_loss = -1067.1, baseline_loss = 133.37, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)
[2025-01-17 18:15:35,684][root][INFO] - Step 225280 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 816.4, step = 225280, mean_episode_return = 0.27845, mean_episode_step = 51.148, total_loss = -314.11, entropy_loss = -9.7898, pg_loss = -405.39, baseline_loss = 101.06, learner_queue_size = 32, _tick = 87, _time = 1.7371e+09)
[2025-01-17 18:15:40,691][root][INFO] - Step 227840 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 821.4, step = 227840, mean_episode_return = 0.40123, mean_episode_step = 58.596, total_loss = 1249.2, entropy_loss = -9.751, pg_loss = 1042.1, baseline_loss = 216.8, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)
[2025-01-17 18:15:45,696][root][INFO] - Step 227840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 826.4, step = 227840, mean_episode_return = 0.40123, mean_episode_step = 58.596, total_loss = 1249.2, entropy_loss = -9.751, pg_loss = 1042.1, baseline_loss = 216.8, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)
[2025-01-17 18:15:50,701][root][INFO] - Step 230400 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 831.4, step = 230400, mean_episode_return = 0.37115, mean_episode_step = 59.54, total_loss = 58.035, entropy_loss = -9.7323, pg_loss = -109.31, baseline_loss = 177.07, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)
[2025-01-17 18:15:55,707][root][INFO] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 836.5, step = 230400, mean_episode_return = 0.37115, mean_episode_step = 59.54, total_loss = 58.035, entropy_loss = -9.7323, pg_loss = -109.31, baseline_loss = 177.07, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)
[2025-01-17 18:16:00,712][root][INFO] - Step 232960 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 841.5, step = 232960, mean_episode_return = 0.22951, mean_episode_step = 51.53, total_loss = -62.962, entropy_loss = -9.7472, pg_loss = -180.86, baseline_loss = 127.64, learner_queue_size = 32, _tick = 90, _time = 1.7371e+09)
[2025-01-17 18:16:05,717][root][INFO] - Step 235520 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 846.5, step = 235520, mean_episode_return = 0.342, mean_episode_step = 50.352, total_loss = 919.37, entropy_loss = -9.7094, pg_loss = 762.81, baseline_loss = 166.27, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)
[2025-01-17 18:16:10,722][root][INFO] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 851.5, step = 235520, mean_episode_return = 0.342, mean_episode_step = 50.352, total_loss = 919.37, entropy_loss = -9.7094, pg_loss = 762.81, baseline_loss = 166.27, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)
[2025-01-17 18:16:15,727][root][INFO] - Step 238080 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 856.5, step = 238080, mean_episode_return = 0.29711, mean_episode_step = 50.217, total_loss = 721.16, entropy_loss = -9.6938, pg_loss = 576.54, baseline_loss = 154.32, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)
[2025-01-17 18:16:20,733][root][INFO] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 861.5, step = 238080, mean_episode_return = 0.29711, mean_episode_step = 50.217, total_loss = 721.16, entropy_loss = -9.6938, pg_loss = 576.54, baseline_loss = 154.32, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)
[2025-01-17 18:16:25,738][root][INFO] - Step 240640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 866.5, step = 240640, mean_episode_return = 0.17497, mean_episode_step = 45.375, total_loss = -372.65, entropy_loss = -9.6419, pg_loss = -499.94, baseline_loss = 136.93, learner_queue_size = 32, _tick = 93, _time = 1.7371e+09)
[2025-01-17 18:16:30,743][root][INFO] - Step 243200 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 871.5, step = 243200, mean_episode_return = 0.19326, mean_episode_step = 48.734, total_loss = -151.11, entropy_loss = -9.6095, pg_loss = -280.07, baseline_loss = 138.57, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)
[2025-01-17 18:16:35,749][root][INFO] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 876.5, step = 243200, mean_episode_return = 0.19326, mean_episode_step = 48.734, total_loss = -151.11, entropy_loss = -9.6095, pg_loss = -280.07, baseline_loss = 138.57, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)
[2025-01-17 18:16:40,755][root][INFO] - Step 245760 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 881.5, step = 245760, mean_episode_return = 0.489, mean_episode_step = 65.84, total_loss = 595.12, entropy_loss = -9.5248, pg_loss = 488.65, baseline_loss = 115.99, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)
[2025-01-17 18:16:45,760][root][INFO] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 886.5, step = 245760, mean_episode_return = 0.489, mean_episode_step = 65.84, total_loss = 595.12, entropy_loss = -9.5248, pg_loss = 488.65, baseline_loss = 115.99, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)
[2025-01-17 18:16:50,765][root][INFO] - Step 248320 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 891.5, step = 248320, mean_episode_return = 0.38829, mean_episode_step = 44.141, total_loss = 283.03, entropy_loss = -9.5252, pg_loss = 144.2, baseline_loss = 148.35, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)
[2025-01-17 18:16:55,771][root][INFO] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 896.5, step = 248320, mean_episode_return = 0.38829, mean_episode_step = 44.141, total_loss = 283.03, entropy_loss = -9.5252, pg_loss = 144.2, baseline_loss = 148.35, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)
[2025-01-17 18:17:00,777][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar
[2025-01-17 18:17:00,879][root][INFO] - Step 250880 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 901.5, step = 250880, mean_episode_return = 0.34937, mean_episode_step = 58.879, total_loss = 313.75, entropy_loss = -9.596, pg_loss = 168.97, baseline_loss = 154.39, learner_queue_size = 32, _tick = 97, _time = 1.7371e+09)
[2025-01-17 18:17:05,884][root][INFO] - Step 253440 @ 501.3 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 906.6, step = 253440, mean_episode_return = 0.20407, mean_episode_step = 57.029, total_loss = -287.37, entropy_loss = -9.518, pg_loss = -411.52, baseline_loss = 133.67, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)
[2025-01-17 18:17:10,890][root][INFO] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 911.6, step = 253440, mean_episode_return = 0.20407, mean_episode_step = 57.029, total_loss = -287.37, entropy_loss = -9.518, pg_loss = -411.52, baseline_loss = 133.67, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)
[2025-01-17 18:17:15,895][root][INFO] - Step 256000 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 916.6, step = 256000, mean_episode_return = 0.58354, mean_episode_step = 55.426, total_loss = 1004.2, entropy_loss = -9.5104, pg_loss = 830.36, baseline_loss = 183.35, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)
[2025-01-17 18:17:20,900][root][INFO] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 921.6, step = 256000, mean_episode_return = 0.58354, mean_episode_step = 55.426, total_loss = 1004.2, entropy_loss = -9.5104, pg_loss = 830.36, baseline_loss = 183.35, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)
[2025-01-17 18:17:25,905][root][INFO] - Step 258560 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 926.6, step = 258560, mean_episode_return = 0.36785, mean_episode_step = 55.766, total_loss = -338.07, entropy_loss = -9.4728, pg_loss = -427.86, baseline_loss = 99.265, learner_queue_size = 32, _tick = 100, _time = 1.7371e+09)
[2025-01-17 18:17:30,911][root][INFO] - Step 261120 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 931.7, step = 261120, mean_episode_return = 0.52406, mean_episode_step = 75.027, total_loss = -357.82, entropy_loss = -9.4846, pg_loss = -446.81, baseline_loss = 98.472, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)
[2025-01-17 18:17:35,916][root][INFO] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 936.7, step = 261120, mean_episode_return = 0.52406, mean_episode_step = 75.027, total_loss = -357.82, entropy_loss = -9.4846, pg_loss = -446.81, baseline_loss = 98.472, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)
[2025-01-17 18:17:40,922][root][INFO] - Step 263680 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 941.7, step = 263680, mean_episode_return = 0.34775, mean_episode_step = 59.682, total_loss = 46.045, entropy_loss = -9.4921, pg_loss = -62.561, baseline_loss = 118.1, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)
[2025-01-17 18:17:45,927][root][INFO] - Step 263680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 946.7, step = 263680, mean_episode_return = 0.34775, mean_episode_step = 59.682, total_loss = 46.045, entropy_loss = -9.4921, pg_loss = -62.561, baseline_loss = 118.1, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)
[2025-01-17 18:17:50,933][root][INFO] - Step 266240 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 951.7, step = 266240, mean_episode_return = 0.37708, mean_episode_step = 63.895, total_loss = 760.7, entropy_loss = -9.3368, pg_loss = 638.74, baseline_loss = 131.3, learner_queue_size = 32, _tick = 103, _time = 1.7371e+09)
[2025-01-17 18:17:55,939][root][INFO] - Step 268800 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 956.7, step = 268800, mean_episode_return = 0.31818, mean_episode_step = 52.932, total_loss = -42.562, entropy_loss = -9.3482, pg_loss = -167.75, baseline_loss = 134.53, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)
[2025-01-17 18:18:00,944][root][INFO] - Step 268800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 961.7, step = 268800, mean_episode_return = 0.31818, mean_episode_step = 52.932, total_loss = -42.562, entropy_loss = -9.3482, pg_loss = -167.75, baseline_loss = 134.53, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)
[2025-01-17 18:18:05,949][root][INFO] - Step 271360 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 966.7, step = 271360, mean_episode_return = 0.48183, mean_episode_step = 54.371, total_loss = 194.79, entropy_loss = -9.2629, pg_loss = 82.834, baseline_loss = 121.22, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)
[2025-01-17 18:18:10,954][root][INFO] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 971.7, step = 271360, mean_episode_return = 0.48183, mean_episode_step = 54.371, total_loss = 194.79, entropy_loss = -9.2629, pg_loss = 82.834, baseline_loss = 121.22, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)
[2025-01-17 18:18:15,959][root][INFO] - Step 273920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 976.7, step = 273920, mean_episode_return = 0.48223, mean_episode_step = 64.835, total_loss = -272.89, entropy_loss = -9.2682, pg_loss = -334.21, baseline_loss = 70.585, learner_queue_size = 32, _tick = 106, _time = 1.7371e+09)
[2025-01-17 18:18:20,964][root][INFO] - Step 276480 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 981.7, step = 276480, mean_episode_return = 0.43155, mean_episode_step = 55.625, total_loss = 145.93, entropy_loss = -9.2121, pg_loss = 56.78, baseline_loss = 98.363, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)
[2025-01-17 18:18:25,970][root][INFO] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 986.7, step = 276480, mean_episode_return = 0.43155, mean_episode_step = 55.625, total_loss = 145.93, entropy_loss = -9.2121, pg_loss = 56.78, baseline_loss = 98.363, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)
[2025-01-17 18:18:30,975][root][INFO] - Step 279040 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 991.7, step = 279040, mean_episode_return = 0.40798, mean_episode_step = 61.259, total_loss = 100.14, entropy_loss = -9.2027, pg_loss = 22.578, baseline_loss = 86.76, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)
[2025-01-17 18:18:35,980][root][INFO] - Step 279040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 996.7, step = 279040, mean_episode_return = 0.40798, mean_episode_step = 61.259, total_loss = 100.14, entropy_loss = -9.2027, pg_loss = 22.578, baseline_loss = 86.76, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)
[2025-01-17 18:18:40,985][root][INFO] - Step 281600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1001.7, step = 281600, mean_episode_return = 0.37289, mean_episode_step = 53.788, total_loss = -366.08, entropy_loss = -9.1371, pg_loss = -442.21, baseline_loss = 85.269, learner_queue_size = 32, _tick = 109, _time = 1.7371e+09)
[2025-01-17 18:18:45,990][root][INFO] - Step 284160 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1006.7, step = 284160, mean_episode_return = 0.42381, mean_episode_step = 46.941, total_loss = -83.03, entropy_loss = -9.084, pg_loss = -144.68, baseline_loss = 70.734, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)
[2025-01-17 18:18:50,995][root][INFO] - Step 284160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1011.7, step = 284160, mean_episode_return = 0.42381, mean_episode_step = 46.941, total_loss = -83.03, entropy_loss = -9.084, pg_loss = -144.68, baseline_loss = 70.734, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)
[2025-01-17 18:18:56,001][root][INFO] - Step 286720 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1016.7, step = 286720, mean_episode_return = 0.41821, mean_episode_step = 52.918, total_loss = 521.23, entropy_loss = -9.0628, pg_loss = 421.86, baseline_loss = 108.43, learner_queue_size = 32, _tick = 111, _time = 1.7371e+09)
[2025-01-17 18:19:01,006][root][INFO] - Step 289280 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1021.7, step = 289280, mean_episode_return = 0.76215, mean_episode_step = 55.206, total_loss = 555.42, entropy_loss = -9.0335, pg_loss = 472.88, baseline_loss = 91.57, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)
[2025-01-17 18:19:06,012][root][INFO] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1026.8, step = 289280, mean_episode_return = 0.76215, mean_episode_step = 55.206, total_loss = 555.42, entropy_loss = -9.0335, pg_loss = 472.88, baseline_loss = 91.57, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)
[2025-01-17 18:19:11,017][root][INFO] - Step 291840 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1031.8, step = 291840, mean_episode_return = 0.18928, mean_episode_step = 49.827, total_loss = -495.91, entropy_loss = -9.0087, pg_loss = -566.53, baseline_loss = 79.628, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)
[2025-01-17 18:19:16,023][root][INFO] - Step 291840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1036.8, step = 291840, mean_episode_return = 0.18928, mean_episode_step = 49.827, total_loss = -495.91, entropy_loss = -9.0087, pg_loss = -566.53, baseline_loss = 79.628, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)
[2025-01-17 18:19:21,028][root][INFO] - Step 294400 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1041.8, step = 294400, mean_episode_return = 0.44108, mean_episode_step = 46.076, total_loss = 925.82, entropy_loss = -9.011, pg_loss = 727.13, baseline_loss = 207.7, learner_queue_size = 32, _tick = 114, _time = 1.7371e+09)
[2025-01-17 18:19:26,034][root][INFO] - Step 296960 @ 511.4 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1046.8, step = 296960, mean_episode_return = 0.28483, mean_episode_step = 51.219, total_loss = -589.89, entropy_loss = -8.9899, pg_loss = -704.7, baseline_loss = 123.79, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)
[2025-01-17 18:19:31,040][root][INFO] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1051.8, step = 296960, mean_episode_return = 0.28483, mean_episode_step = 51.219, total_loss = -589.89, entropy_loss = -8.9899, pg_loss = -704.7, baseline_loss = 123.79, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)
[2025-01-17 18:19:36,045][root][INFO] - Step 299520 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1056.8, step = 299520, mean_episode_return = 0.42986, mean_episode_step = 60.256, total_loss = 374.06, entropy_loss = -8.9777, pg_loss = 233.57, baseline_loss = 149.46, learner_queue_size = 32, _tick = 116, _time = 1.7371e+09)
[2025-01-17 18:19:41,051][root][INFO] - Step 302080 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1061.8, step = 302080, mean_episode_return = 0.56551, mean_episode_step = 58.45, total_loss = 156.87, entropy_loss = -8.92, pg_loss = 56.38, baseline_loss = 109.41, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)
[2025-01-17 18:19:46,056][root][INFO] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1066.8, step = 302080, mean_episode_return = 0.56551, mean_episode_step = 58.45, total_loss = 156.87, entropy_loss = -8.92, pg_loss = 56.38, baseline_loss = 109.41, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)
[2025-01-17 18:19:51,062][root][INFO] - Step 304640 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1071.8, step = 304640, mean_episode_return = 0.75779, mean_episode_step = 70.6, total_loss = 35.129, entropy_loss = -8.8732, pg_loss = -47.894, baseline_loss = 91.896, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)
[2025-01-17 18:19:56,068][root][INFO] - Step 304640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1076.8, step = 304640, mean_episode_return = 0.75779, mean_episode_step = 70.6, total_loss = 35.129, entropy_loss = -8.8732, pg_loss = -47.894, baseline_loss = 91.896, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)
[2025-01-17 18:20:01,073][root][INFO] - Step 307200 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1081.8, step = 307200, mean_episode_return = 0.43789, mean_episode_step = 42.621, total_loss = -121.77, entropy_loss = -8.9038, pg_loss = -211.44, baseline_loss = 98.57, learner_queue_size = 32, _tick = 119, _time = 1.7371e+09)
[2025-01-17 18:20:06,079][root][INFO] - Step 309760 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1086.8, step = 309760, mean_episode_return = 0.42893, mean_episode_step = 35.196, total_loss = 157.47, entropy_loss = -8.9169, pg_loss = 57.978, baseline_loss = 108.41, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)
[2025-01-17 18:20:11,085][root][INFO] - Step 309760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1091.8, step = 309760, mean_episode_return = 0.42893, mean_episode_step = 35.196, total_loss = 157.47, entropy_loss = -8.9169, pg_loss = 57.978, baseline_loss = 108.41, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)
[2025-01-17 18:20:16,090][root][INFO] - Step 312320 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1096.8, step = 312320, mean_episode_return = 0.38813, mean_episode_step = 48.353, total_loss = -699.8, entropy_loss = -8.8185, pg_loss = -768.76, baseline_loss = 77.784, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)
[2025-01-17 18:20:21,095][root][INFO] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1101.8, step = 312320, mean_episode_return = 0.38813, mean_episode_step = 48.353, total_loss = -699.8, entropy_loss = -8.8185, pg_loss = -768.76, baseline_loss = 77.784, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)
[2025-01-17 18:20:26,100][root][INFO] - Step 314880 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1106.8, step = 314880, mean_episode_return = 0.44657, mean_episode_step = 41.751, total_loss = -135.16, entropy_loss = -8.8174, pg_loss = -200.24, baseline_loss = 73.894, learner_queue_size = 32, _tick = 122, _time = 1.7371e+09)
[2025-01-17 18:20:31,105][root][INFO] - Step 317440 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1111.8, step = 317440, mean_episode_return = 0.58264, mean_episode_step = 51.417, total_loss = 301.24, entropy_loss = -8.7711, pg_loss = 215.77, baseline_loss = 94.246, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)
[2025-01-17 18:20:36,111][root][INFO] - Step 317440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1116.9, step = 317440, mean_episode_return = 0.58264, mean_episode_step = 51.417, total_loss = 301.24, entropy_loss = -8.7711, pg_loss = 215.77, baseline_loss = 94.246, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)
[2025-01-17 18:20:41,116][root][INFO] - Step 320000 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1121.9, step = 320000, mean_episode_return = 0.52169, mean_episode_step = 54.019, total_loss = 21.964, entropy_loss = -8.8206, pg_loss = -33.675, baseline_loss = 64.46, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)
[2025-01-17 18:20:46,121][root][INFO] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1126.9, step = 320000, mean_episode_return = 0.52169, mean_episode_step = 54.019, total_loss = 21.964, entropy_loss = -8.8206, pg_loss = -33.675, baseline_loss = 64.46, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)
[2025-01-17 18:20:51,127][root][INFO] - Step 322560 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1131.9, step = 322560, mean_episode_return = 0.51252, mean_episode_step = 62.162, total_loss = -44.464, entropy_loss = -8.7859, pg_loss = -91.845, baseline_loss = 56.166, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)
[2025-01-17 18:20:56,133][root][INFO] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1136.9, step = 322560, mean_episode_return = 0.51252, mean_episode_step = 62.162, total_loss = -44.464, entropy_loss = -8.7859, pg_loss = -91.845, baseline_loss = 56.166, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)
[2025-01-17 18:21:01,139][root][INFO] - Step 325120 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1141.9, step = 325120, mean_episode_return = 0.23273, mean_episode_step = 48.079, total_loss = -248.76, entropy_loss = -8.6956, pg_loss = -281.65, baseline_loss = 41.588, learner_queue_size = 32, _tick = 126, _time = 1.7371e+09)
[2025-01-17 18:21:06,144][root][INFO] - Step 327680 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1146.9, step = 327680, mean_episode_return = 0.5123, mean_episode_step = 50.603, total_loss = 124.35, entropy_loss = -8.6392, pg_loss = 83.41, baseline_loss = 49.58, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)
[2025-01-17 18:21:11,150][root][INFO] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1151.9, step = 327680, mean_episode_return = 0.5123, mean_episode_step = 50.603, total_loss = 124.35, entropy_loss = -8.6392, pg_loss = 83.41, baseline_loss = 49.58, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)
[2025-01-17 18:21:16,155][root][INFO] - Step 330240 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1156.9, step = 330240, mean_episode_return = 0.85473, mean_episode_step = 61.518, total_loss = 389.36, entropy_loss = -8.6199, pg_loss = 314.5, baseline_loss = 83.48, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)
[2025-01-17 18:21:21,160][root][INFO] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1161.9, step = 330240, mean_episode_return = 0.85473, mean_episode_step = 61.518, total_loss = 389.36, entropy_loss = -8.6199, pg_loss = 314.5, baseline_loss = 83.48, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)
[2025-01-17 18:21:26,165][root][INFO] - Step 332800 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1166.9, step = 332800, mean_episode_return = 0.54911, mean_episode_step = 60.437, total_loss = -479.5, entropy_loss = -8.6202, pg_loss = -535.81, baseline_loss = 64.93, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)
[2025-01-17 18:21:31,171][root][INFO] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1171.9, step = 332800, mean_episode_return = 0.54911, mean_episode_step = 60.437, total_loss = -479.5, entropy_loss = -8.6202, pg_loss = -535.81, baseline_loss = 64.93, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)
[2025-01-17 18:21:36,176][root][INFO] - Step 335360 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1176.9, step = 335360, mean_episode_return = 0.35628, mean_episode_step = 50.716, total_loss = -332.39, entropy_loss = -8.6146, pg_loss = -381.44, baseline_loss = 57.665, learner_queue_size = 32, _tick = 130, _time = 1.7371e+09)
[2025-01-17 18:21:41,181][root][INFO] - Step 337920 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1181.9, step = 337920, mean_episode_return = 0.59502, mean_episode_step = 52.753, total_loss = 485.03, entropy_loss = -8.5614, pg_loss = 397.78, baseline_loss = 95.808, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)
[2025-01-17 18:21:46,186][root][INFO] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1186.9, step = 337920, mean_episode_return = 0.59502, mean_episode_step = 52.753, total_loss = 485.03, entropy_loss = -8.5614, pg_loss = 397.78, baseline_loss = 95.808, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)
[2025-01-17 18:21:51,191][root][INFO] - Step 340480 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1191.9, step = 340480, mean_episode_return = 0.56428, mean_episode_step = 69.907, total_loss = -327.12, entropy_loss = -8.5545, pg_loss = -391.32, baseline_loss = 72.748, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)
[2025-01-17 18:21:56,197][root][INFO] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1196.9, step = 340480, mean_episode_return = 0.56428, mean_episode_step = 69.907, total_loss = -327.12, entropy_loss = -8.5545, pg_loss = -391.32, baseline_loss = 72.748, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)
[2025-01-17 18:22:01,202][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 18:22:01,622][root][INFO] - Step 343040 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1201.9, step = 343040, mean_episode_return = 0.60411, mean_episode_step = 59.126, total_loss = 429.46, entropy_loss = -8.5485, pg_loss = 348.56, baseline_loss = 89.447, learner_queue_size = 32, _tick = 133, _time = 1.7371e+09)
[2025-01-17 18:22:06,627][root][INFO] - Step 345600 @ 471.9 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1207.4, step = 345600, mean_episode_return = 0.5426, mean_episode_step = 44.628, total_loss = 318.98, entropy_loss = -8.5659, pg_loss = 191.06, baseline_loss = 136.49, learner_queue_size = 32, _tick = 134, _time = 1.7371e+09)
[2025-01-17 18:22:11,633][root][INFO] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1212.4, step = 345600, mean_episode_return = 0.5426, mean_episode_step = 44.628, total_loss = 318.98, entropy_loss = -8.5659, pg_loss = 191.06, baseline_loss = 136.49, learner_queue_size = 32, _tick = 134, _time = 1.7371e+09)
[2025-01-17 18:22:16,638][root][INFO] - Step 348160 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1217.4, step = 348160, mean_episode_return = 0.49965, mean_episode_step = 57.497, total_loss = -425.88, entropy_loss = -8.5123, pg_loss = -504.67, baseline_loss = 87.31, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)
[2025-01-17 18:22:21,644][root][INFO] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1222.4, step = 348160, mean_episode_return = 0.49965, mean_episode_step = 57.497, total_loss = -425.88, entropy_loss = -8.5123, pg_loss = -504.67, baseline_loss = 87.31, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)
[2025-01-17 18:22:26,649][root][INFO] - Step 350720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1227.4, step = 350720, mean_episode_return = 0.38052, mean_episode_step = 52.53, total_loss = -92.328, entropy_loss = -8.5244, pg_loss = -168.69, baseline_loss = 84.889, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)
[2025-01-17 18:22:31,654][root][INFO] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1232.4, step = 350720, mean_episode_return = 0.38052, mean_episode_step = 52.53, total_loss = -92.328, entropy_loss = -8.5244, pg_loss = -168.69, baseline_loss = 84.889, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)
[2025-01-17 18:22:36,659][root][INFO] - Step 353280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1237.4, step = 353280, mean_episode_return = 0.60657, mean_episode_step = 56.152, total_loss = 279.09, entropy_loss = -8.5654, pg_loss = 182.24, baseline_loss = 105.41, learner_queue_size = 32, _tick = 137, _time = 1.7371e+09)
[2025-01-17 18:22:41,664][root][INFO] - Step 355840 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1242.4, step = 355840, mean_episode_return = 0.59932, mean_episode_step = 57.73, total_loss = 221.77, entropy_loss = -8.5, pg_loss = 113.72, baseline_loss = 116.55, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)
[2025-01-17 18:22:46,669][root][INFO] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1247.4, step = 355840, mean_episode_return = 0.59932, mean_episode_step = 57.73, total_loss = 221.77, entropy_loss = -8.5, pg_loss = 113.72, baseline_loss = 116.55, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)
[2025-01-17 18:22:51,674][root][INFO] - Step 358400 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1252.4, step = 358400, mean_episode_return = 0.6706, mean_episode_step = 58.675, total_loss = 62.076, entropy_loss = -8.6025, pg_loss = -42.405, baseline_loss = 113.08, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)
[2025-01-17 18:22:56,680][root][INFO] - Step 358400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1257.4, step = 358400, mean_episode_return = 0.6706, mean_episode_step = 58.675, total_loss = 62.076, entropy_loss = -8.6025, pg_loss = -42.405, baseline_loss = 113.08, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)
[2025-01-17 18:23:01,685][root][INFO] - Step 360960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1262.4, step = 360960, mean_episode_return = 0.57908, mean_episode_step = 61.294, total_loss = -169.4, entropy_loss = -8.4854, pg_loss = -231.09, baseline_loss = 70.172, learner_queue_size = 32, _tick = 140, _time = 1.7371e+09)
[2025-01-17 18:23:06,690][root][INFO] - Step 363520 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1267.4, step = 363520, mean_episode_return = 0.4666, mean_episode_step = 54.418, total_loss = -145.92, entropy_loss = -8.4747, pg_loss = -240.39, baseline_loss = 102.94, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)
[2025-01-17 18:23:11,695][root][INFO] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1272.4, step = 363520, mean_episode_return = 0.4666, mean_episode_step = 54.418, total_loss = -145.92, entropy_loss = -8.4747, pg_loss = -240.39, baseline_loss = 102.94, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)
[2025-01-17 18:23:16,700][root][INFO] - Step 366080 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1277.4, step = 366080, mean_episode_return = 0.79907, mean_episode_step = 50.307, total_loss = 393.79, entropy_loss = -8.4316, pg_loss = 318.87, baseline_loss = 83.355, learner_queue_size = 32, _tick = 142, _time = 1.7371e+09)
[2025-01-17 18:23:21,705][root][INFO] - Step 368640 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1282.4, step = 368640, mean_episode_return = 0.7101, mean_episode_step = 63.855, total_loss = 76.382, entropy_loss = -8.4403, pg_loss = 11.673, baseline_loss = 73.149, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)
[2025-01-17 18:23:26,712][root][INFO] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1287.5, step = 368640, mean_episode_return = 0.7101, mean_episode_step = 63.855, total_loss = 76.382, entropy_loss = -8.4403, pg_loss = 11.673, baseline_loss = 73.149, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)
[2025-01-17 18:23:31,717][root][INFO] - Step 371200 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1292.5, step = 371200, mean_episode_return = 0.48907, mean_episode_step = 51.73, total_loss = -86.177, entropy_loss = -8.4199, pg_loss = -149.26, baseline_loss = 71.504, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)
[2025-01-17 18:23:36,722][root][INFO] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1297.5, step = 371200, mean_episode_return = 0.48907, mean_episode_step = 51.73, total_loss = -86.177, entropy_loss = -8.4199, pg_loss = -149.26, baseline_loss = 71.504, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)
[2025-01-17 18:23:41,727][root][INFO] - Step 373760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1302.5, step = 373760, mean_episode_return = 0.35034, mean_episode_step = 58.072, total_loss = -267.05, entropy_loss = -8.3605, pg_loss = -325.54, baseline_loss = 66.852, learner_queue_size = 32, _tick = 145, _time = 1.7371e+09)
[2025-01-17 18:23:46,733][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar
[2025-01-17 18:23:46,783][root][INFO] - Step 376320 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1307.5, step = 376320, mean_episode_return = 0.59679, mean_episode_step = 48.446, total_loss = -84.187, entropy_loss = -8.3433, pg_loss = -144.02, baseline_loss = 68.174, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)
[2025-01-17 18:23:51,790][root][INFO] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1312.5, step = 376320, mean_episode_return = 0.59679, mean_episode_step = 48.446, total_loss = -84.187, entropy_loss = -8.3433, pg_loss = -144.02, baseline_loss = 68.174, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)
[2025-01-17 18:23:56,795][root][INFO] - Step 378880 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1317.5, step = 378880, mean_episode_return = 0.37484, mean_episode_step = 58.068, total_loss = -290.12, entropy_loss = -8.2442, pg_loss = -321.51, baseline_loss = 39.632, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)
[2025-01-17 18:24:01,800][root][INFO] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1322.5, step = 378880, mean_episode_return = 0.37484, mean_episode_step = 58.068, total_loss = -290.12, entropy_loss = -8.2442, pg_loss = -321.51, baseline_loss = 39.632, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)
[2025-01-17 18:24:06,805][root][INFO] - Step 381440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1327.5, step = 381440, mean_episode_return = 0.8393, mean_episode_step = 47.686, total_loss = 654.72, entropy_loss = -8.237, pg_loss = 593.42, baseline_loss = 69.54, learner_queue_size = 32, _tick = 148, _time = 1.7371e+09)
[2025-01-17 18:24:11,810][root][INFO] - Step 384000 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1332.6, step = 384000, mean_episode_return = 0.44164, mean_episode_step = 56.89, total_loss = -429.21, entropy_loss = -8.2382, pg_loss = -471.81, baseline_loss = 50.836, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)
[2025-01-17 18:24:16,815][root][INFO] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1337.6, step = 384000, mean_episode_return = 0.44164, mean_episode_step = 56.89, total_loss = -429.21, entropy_loss = -8.2382, pg_loss = -471.81, baseline_loss = 50.836, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)
[2025-01-17 18:24:21,820][root][INFO] - Step 386560 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1342.6, step = 386560, mean_episode_return = 0.55546, mean_episode_step = 47.366, total_loss = 174.65, entropy_loss = -8.25, pg_loss = 104.58, baseline_loss = 78.324, learner_queue_size = 32, _tick = 150, _time = 1.7371e+09)
[2025-01-17 18:24:26,825][root][INFO] - Step 389120 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1347.6, step = 389120, mean_episode_return = 0.93674, mean_episode_step = 64.859, total_loss = 313.2, entropy_loss = -8.1678, pg_loss = 252.19, baseline_loss = 69.171, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)
[2025-01-17 18:24:31,831][root][INFO] - Step 389120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1352.6, step = 389120, mean_episode_return = 0.93674, mean_episode_step = 64.859, total_loss = 313.2, entropy_loss = -8.1678, pg_loss = 252.19, baseline_loss = 69.171, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)
[2025-01-17 18:24:36,837][root][INFO] - Step 391680 @ 511.3 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1357.6, step = 391680, mean_episode_return = 0.52058, mean_episode_step = 52.767, total_loss = 317.22, entropy_loss = -8.1407, pg_loss = 248.35, baseline_loss = 77.005, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)
[2025-01-17 18:24:41,844][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1362.6, step = 391680, mean_episode_return = 0.52058, mean_episode_step = 52.767, total_loss = 317.22, entropy_loss = -8.1407, pg_loss = 248.35, baseline_loss = 77.005, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)
[2025-01-17 18:24:46,849][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1367.6, step = 391680, mean_episode_return = 0.52058, mean_episode_step = 52.767, total_loss = 317.22, entropy_loss = -8.1407, pg_loss = 248.35, baseline_loss = 77.005, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)
[2025-01-17 18:24:51,867][root][INFO] - Step 394240 @ 510.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1372.6, step = 394240, mean_episode_return = 0.57406, mean_episode_step = 59.602, total_loss = -93.814, entropy_loss = -8.1663, pg_loss = -157.71, baseline_loss = 72.059, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)
[2025-01-17 18:24:56,872][root][INFO] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1377.6, step = 394240, mean_episode_return = 0.57406, mean_episode_step = 59.602, total_loss = -93.814, entropy_loss = -8.1663, pg_loss = -157.71, baseline_loss = 72.059, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)
[2025-01-17 18:25:01,877][root][INFO] - Step 396800 @ 511.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1382.6, step = 396800, mean_episode_return = 0.5865, mean_episode_step = 54.799, total_loss = 79.683, entropy_loss = -8.0938, pg_loss = 19.505, baseline_loss = 68.272, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)
[2025-01-17 18:25:06,883][root][INFO] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1387.6, step = 396800, mean_episode_return = 0.5865, mean_episode_step = 54.799, total_loss = 79.683, entropy_loss = -8.0938, pg_loss = 19.505, baseline_loss = 68.272, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)
[2025-01-17 18:25:11,888][root][INFO] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1392.6, step = 396800, mean_episode_return = 0.5865, mean_episode_step = 54.799, total_loss = 79.683, entropy_loss = -8.0938, pg_loss = 19.505, baseline_loss = 68.272, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)
[2025-01-17 18:25:16,893][root][INFO] - Step 399360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1397.6, step = 399360, mean_episode_return = 0.56054, mean_episode_step = 57.18, total_loss = 6.8394, entropy_loss = -8.0966, pg_loss = -78.711, baseline_loss = 93.647, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)
[2025-01-17 18:25:21,898][root][INFO] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1402.6, step = 399360, mean_episode_return = 0.56054, mean_episode_step = 57.18, total_loss = 6.8394, entropy_loss = -8.0966, pg_loss = -78.711, baseline_loss = 93.647, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)
[2025-01-17 18:25:26,903][root][INFO] - Step 401920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1407.6, step = 401920, mean_episode_return = 0.60432, mean_episode_step = 39.154, total_loss = -167.15, entropy_loss = -8.0524, pg_loss = -234.56, baseline_loss = 75.461, learner_queue_size = 32, _tick = 156, _time = 1.7371e+09)
[2025-01-17 18:25:31,910][root][INFO] - Step 404480 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1412.7, step = 404480, mean_episode_return = 0.56068, mean_episode_step = 66.292, total_loss = -269.58, entropy_loss = -8.0069, pg_loss = -319.16, baseline_loss = 57.592, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)
[2025-01-17 18:25:36,919][root][INFO] - Step 404480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1417.7, step = 404480, mean_episode_return = 0.56068, mean_episode_step = 66.292, total_loss = -269.58, entropy_loss = -8.0069, pg_loss = -319.16, baseline_loss = 57.592, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)
[2025-01-17 18:25:41,925][root][INFO] - Step 407040 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1422.7, step = 407040, mean_episode_return = 0.74511, mean_episode_step = 51.795, total_loss = 618.56, entropy_loss = -7.9997, pg_loss = 553.4, baseline_loss = 73.165, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)
[2025-01-17 18:25:46,930][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1427.7, step = 407040, mean_episode_return = 0.74511, mean_episode_step = 51.795, total_loss = 618.56, entropy_loss = -7.9997, pg_loss = 553.4, baseline_loss = 73.165, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)
[2025-01-17 18:25:51,935][root][INFO] - Step 409600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1432.7, step = 409600, mean_episode_return = 0.2856, mean_episode_step = 57.842, total_loss = -68.726, entropy_loss = -7.9909, pg_loss = -125.11, baseline_loss = 64.376, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)
[2025-01-17 18:25:56,940][root][INFO] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1437.7, step = 409600, mean_episode_return = 0.2856, mean_episode_step = 57.842, total_loss = -68.726, entropy_loss = -7.9909, pg_loss = -125.11, baseline_loss = 64.376, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)
[2025-01-17 18:26:01,945][root][INFO] - Step 412160 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1442.7, step = 412160, mean_episode_return = 0.5116, mean_episode_step = 50.58, total_loss = -164.16, entropy_loss = -8.0023, pg_loss = -229.9, baseline_loss = 73.745, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)
[2025-01-17 18:26:06,950][root][INFO] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1447.7, step = 412160, mean_episode_return = 0.5116, mean_episode_step = 50.58, total_loss = -164.16, entropy_loss = -8.0023, pg_loss = -229.9, baseline_loss = 73.745, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)
[2025-01-17 18:26:11,955][root][INFO] - Step 414720 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1452.7, step = 414720, mean_episode_return = 0.62592, mean_episode_step = 43.254, total_loss = 160.41, entropy_loss = -8.026, pg_loss = 91.374, baseline_loss = 77.064, learner_queue_size = 32, _tick = 161, _time = 1.7371e+09)
[2025-01-17 18:26:16,961][root][INFO] - Step 414720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1457.7, step = 414720, mean_episode_return = 0.62592, mean_episode_step = 43.254, total_loss = 160.41, entropy_loss = -8.026, pg_loss = 91.374, baseline_loss = 77.064, learner_queue_size = 32, _tick = 161, _time = 1.7371e+09)
[2025-01-17 18:26:21,966][root][INFO] - Step 417280 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1462.7, step = 417280, mean_episode_return = 0.67697, mean_episode_step = 57.044, total_loss = 574.12, entropy_loss = -7.9703, pg_loss = 492.81, baseline_loss = 89.288, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)
[2025-01-17 18:26:26,971][root][INFO] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1467.7, step = 417280, mean_episode_return = 0.67697, mean_episode_step = 57.044, total_loss = 574.12, entropy_loss = -7.9703, pg_loss = 492.81, baseline_loss = 89.288, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)
[2025-01-17 18:26:31,976][root][INFO] - Step 419840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1472.7, step = 419840, mean_episode_return = 0.57927, mean_episode_step = 48.788, total_loss = -369.05, entropy_loss = -7.9862, pg_loss = -428.77, baseline_loss = 67.705, learner_queue_size = 32, _tick = 163, _time = 1.7371e+09)
[2025-01-17 18:26:36,981][root][INFO] - Step 422400 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1477.7, step = 422400, mean_episode_return = 0.59017, mean_episode_step = 51.814, total_loss = 473.33, entropy_loss = -7.9865, pg_loss = 401.01, baseline_loss = 80.308, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)
[2025-01-17 18:26:41,987][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1482.7, step = 422400, mean_episode_return = 0.59017, mean_episode_step = 51.814, total_loss = 473.33, entropy_loss = -7.9865, pg_loss = 401.01, baseline_loss = 80.308, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)
[2025-01-17 18:26:46,992][root][INFO] - Step 424960 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1487.7, step = 424960, mean_episode_return = 0.46507, mean_episode_step = 52.909, total_loss = -469.04, entropy_loss = -7.9782, pg_loss = -525.01, baseline_loss = 63.948, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)
[2025-01-17 18:26:51,997][root][INFO] - Step 424960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1492.7, step = 424960, mean_episode_return = 0.46507, mean_episode_step = 52.909, total_loss = -469.04, entropy_loss = -7.9782, pg_loss = -525.01, baseline_loss = 63.948, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)
[2025-01-17 18:26:57,003][root][INFO] - Step 427520 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1497.7, step = 427520, mean_episode_return = 0.4131, mean_episode_step = 64.487, total_loss = -300.73, entropy_loss = -7.9846, pg_loss = -354.56, baseline_loss = 61.818, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)
[2025-01-17 18:27:02,008][root][INFO] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1502.8, step = 427520, mean_episode_return = 0.4131, mean_episode_step = 64.487, total_loss = -300.73, entropy_loss = -7.9846, pg_loss = -354.56, baseline_loss = 61.818, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)
[2025-01-17 18:27:07,013][root][INFO] - Step 430080 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1507.8, step = 430080, mean_episode_return = 0.72156, mean_episode_step = 52.158, total_loss = 306.09, entropy_loss = -7.9943, pg_loss = 219.48, baseline_loss = 94.601, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)
[2025-01-17 18:27:12,019][root][INFO] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1512.8, step = 430080, mean_episode_return = 0.72156, mean_episode_step = 52.158, total_loss = 306.09, entropy_loss = -7.9943, pg_loss = 219.48, baseline_loss = 94.601, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)
[2025-01-17 18:27:17,024][root][INFO] - Step 432640 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1517.8, step = 432640, mean_episode_return = 0.70506, mean_episode_step = 64.732, total_loss = 133.98, entropy_loss = -7.9832, pg_loss = 73.307, baseline_loss = 68.657, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)
[2025-01-17 18:27:22,030][root][INFO] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1522.8, step = 432640, mean_episode_return = 0.70506, mean_episode_step = 64.732, total_loss = 133.98, entropy_loss = -7.9832, pg_loss = 73.307, baseline_loss = 68.657, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)
[2025-01-17 18:27:27,035][root][INFO] - Step 435200 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1527.8, step = 435200, mean_episode_return = 0.67484, mean_episode_step = 45.946, total_loss = 32.055, entropy_loss = -8.0051, pg_loss = -39.034, baseline_loss = 79.094, learner_queue_size = 32, _tick = 169, _time = 1.7371e+09)
[2025-01-17 18:27:32,041][root][INFO] - Step 437760 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1532.8, step = 437760, mean_episode_return = 0.81102, mean_episode_step = 68.212, total_loss = -283.35, entropy_loss = -8.0123, pg_loss = -335.62, baseline_loss = 60.276, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)
[2025-01-17 18:27:37,047][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1537.8, step = 437760, mean_episode_return = 0.81102, mean_episode_step = 68.212, total_loss = -283.35, entropy_loss = -8.0123, pg_loss = -335.62, baseline_loss = 60.276, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)
[2025-01-17 18:27:42,054][root][INFO] - Step 440320 @ 511.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1542.8, step = 440320, mean_episode_return = 0.83983, mean_episode_step = 42.512, total_loss = 373.42, entropy_loss = -8.0334, pg_loss = 298.35, baseline_loss = 83.105, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)
[2025-01-17 18:27:47,060][root][INFO] - Step 440320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1547.8, step = 440320, mean_episode_return = 0.83983, mean_episode_step = 42.512, total_loss = 373.42, entropy_loss = -8.0334, pg_loss = 298.35, baseline_loss = 83.105, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)
[2025-01-17 18:27:52,065][root][INFO] - Step 442880 @ 511.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1552.8, step = 442880, mean_episode_return = 0.69635, mean_episode_step = 54.734, total_loss = -79.986, entropy_loss = -8.0083, pg_loss = -136.92, baseline_loss = 64.946, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)
[2025-01-17 18:27:57,071][root][INFO] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1557.8, step = 442880, mean_episode_return = 0.69635, mean_episode_step = 54.734, total_loss = -79.986, entropy_loss = -8.0083, pg_loss = -136.92, baseline_loss = 64.946, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)
[2025-01-17 18:28:02,076][root][INFO] - Step 445440 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1562.8, step = 445440, mean_episode_return = 0.59409, mean_episode_step = 55.553, total_loss = 64.529, entropy_loss = -7.9944, pg_loss = 3.6, baseline_loss = 68.924, learner_queue_size = 32, _tick = 173, _time = 1.7371e+09)
[2025-01-17 18:28:07,082][root][INFO] - Step 448000 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1567.8, step = 448000, mean_episode_return = 0.78624, mean_episode_step = 52.949, total_loss = 224.37, entropy_loss = -7.9772, pg_loss = 147.1, baseline_loss = 85.248, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)
[2025-01-17 18:28:12,088][root][INFO] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1572.8, step = 448000, mean_episode_return = 0.78624, mean_episode_step = 52.949, total_loss = 224.37, entropy_loss = -7.9772, pg_loss = 147.1, baseline_loss = 85.248, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)
[2025-01-17 18:28:17,093][root][INFO] - Step 450560 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1577.8, step = 450560, mean_episode_return = 0.81183, mean_episode_step = 59.116, total_loss = -273.49, entropy_loss = -7.9414, pg_loss = -336.88, baseline_loss = 71.331, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)
[2025-01-17 18:28:22,098][root][INFO] - Step 450560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1582.8, step = 450560, mean_episode_return = 0.81183, mean_episode_step = 59.116, total_loss = -273.49, entropy_loss = -7.9414, pg_loss = -336.88, baseline_loss = 71.331, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)
[2025-01-17 18:28:27,104][root][INFO] - Step 453120 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1587.8, step = 453120, mean_episode_return = 0.71696, mean_episode_step = 61.475, total_loss = -143.77, entropy_loss = -7.9314, pg_loss = -196.93, baseline_loss = 61.097, learner_queue_size = 32, _tick = 176, _time = 1.7371e+09)
[2025-01-17 18:28:32,110][root][INFO] - Step 455680 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1592.9, step = 455680, mean_episode_return = 0.58804, mean_episode_step = 51.134, total_loss = -106.18, entropy_loss = -7.9522, pg_loss = -183.46, baseline_loss = 85.236, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)
[2025-01-17 18:28:37,115][root][INFO] - Step 455680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1597.9, step = 455680, mean_episode_return = 0.58804, mean_episode_step = 51.134, total_loss = -106.18, entropy_loss = -7.9522, pg_loss = -183.46, baseline_loss = 85.236, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)
[2025-01-17 18:28:42,120][root][INFO] - Step 458240 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1602.9, step = 458240, mean_episode_return = 0.60043, mean_episode_step = 51.482, total_loss = 260.82, entropy_loss = -7.915, pg_loss = 177.43, baseline_loss = 91.298, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)
[2025-01-17 18:28:47,126][root][INFO] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1607.9, step = 458240, mean_episode_return = 0.60043, mean_episode_step = 51.482, total_loss = 260.82, entropy_loss = -7.915, pg_loss = 177.43, baseline_loss = 91.298, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)
[2025-01-17 18:28:52,139][root][INFO] - Step 460800 @ 510.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1612.9, step = 460800, mean_episode_return = 0.77636, mean_episode_step = 62.076, total_loss = -88.877, entropy_loss = -7.8876, pg_loss = -136.77, baseline_loss = 55.782, learner_queue_size = 32, _tick = 179, _time = 1.7371e+09)
[2025-01-17 18:28:57,144][root][INFO] - Step 463360 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1617.9, step = 463360, mean_episode_return = 0.56458, mean_episode_step = 55.528, total_loss = 347.7, entropy_loss = -7.8915, pg_loss = 269.65, baseline_loss = 85.942, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)
[2025-01-17 18:29:02,150][root][INFO] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1622.9, step = 463360, mean_episode_return = 0.56458, mean_episode_step = 55.528, total_loss = 347.7, entropy_loss = -7.8915, pg_loss = 269.65, baseline_loss = 85.942, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)
[2025-01-17 18:29:07,163][root][INFO] - Step 465920 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1627.9, step = 465920, mean_episode_return = 0.57981, mean_episode_step = 48.78, total_loss = 183.73, entropy_loss = -7.886, pg_loss = 116.24, baseline_loss = 75.377, learner_queue_size = 32, _tick = 181, _time = 1.7371e+09)
[2025-01-17 18:29:12,168][root][INFO] - Step 468480 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1632.9, step = 468480, mean_episode_return = 0.52546, mean_episode_step = 53.677, total_loss = -327.59, entropy_loss = -7.8866, pg_loss = -386.93, baseline_loss = 67.228, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)
[2025-01-17 18:29:17,173][root][INFO] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1637.9, step = 468480, mean_episode_return = 0.52546, mean_episode_step = 53.677, total_loss = -327.59, entropy_loss = -7.8866, pg_loss = -386.93, baseline_loss = 67.228, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)
[2025-01-17 18:29:22,179][root][INFO] - Step 471040 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1642.9, step = 471040, mean_episode_return = 0.56388, mean_episode_step = 53.522, total_loss = -86.602, entropy_loss = -7.8924, pg_loss = -152.18, baseline_loss = 73.476, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)
[2025-01-17 18:29:27,184][root][INFO] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1647.9, step = 471040, mean_episode_return = 0.56388, mean_episode_step = 53.522, total_loss = -86.602, entropy_loss = -7.8924, pg_loss = -152.18, baseline_loss = 73.476, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)
[2025-01-17 18:29:32,189][root][INFO] - Step 473600 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1652.9, step = 473600, mean_episode_return = 0.5088, mean_episode_step = 56.355, total_loss = -320.21, entropy_loss = -7.8825, pg_loss = -383.51, baseline_loss = 71.183, learner_queue_size = 32, _tick = 184, _time = 1.7371e+09)
[2025-01-17 18:29:37,194][root][INFO] - Step 476160 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1657.9, step = 476160, mean_episode_return = 0.58026, mean_episode_step = 44.521, total_loss = -207.49, entropy_loss = -7.8851, pg_loss = -282.94, baseline_loss = 83.335, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)
[2025-01-17 18:29:42,201][root][INFO] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1662.9, step = 476160, mean_episode_return = 0.58026, mean_episode_step = 44.521, total_loss = -207.49, entropy_loss = -7.8851, pg_loss = -282.94, baseline_loss = 83.335, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)
[2025-01-17 18:29:47,206][root][INFO] - Step 478720 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1667.9, step = 478720, mean_episode_return = 0.52348, mean_episode_step = 55.359, total_loss = -81.563, entropy_loss = -7.8888, pg_loss = -153.27, baseline_loss = 79.592, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)
[2025-01-17 18:29:52,211][root][INFO] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1673.0, step = 478720, mean_episode_return = 0.52348, mean_episode_step = 55.359, total_loss = -81.563, entropy_loss = -7.8888, pg_loss = -153.27, baseline_loss = 79.592, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)
[2025-01-17 18:29:57,216][root][INFO] - Step 481280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1678.0, step = 481280, mean_episode_return = 0.56926, mean_episode_step = 65.916, total_loss = -53.616, entropy_loss = -7.8646, pg_loss = -114.23, baseline_loss = 68.483, learner_queue_size = 32, _tick = 187, _time = 1.7371e+09)
[2025-01-17 18:30:02,221][root][INFO] - Step 483840 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1683.0, step = 483840, mean_episode_return = 0.68374, mean_episode_step = 55.261, total_loss = 105.56, entropy_loss = -7.9003, pg_loss = 20.497, baseline_loss = 92.964, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)
[2025-01-17 18:30:07,226][root][INFO] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1688.0, step = 483840, mean_episode_return = 0.68374, mean_episode_step = 55.261, total_loss = 105.56, entropy_loss = -7.9003, pg_loss = 20.497, baseline_loss = 92.964, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)
[2025-01-17 18:30:12,231][root][INFO] - Step 486400 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1693.0, step = 486400, mean_episode_return = 0.62259, mean_episode_step = 59.261, total_loss = -146.08, entropy_loss = -7.8753, pg_loss = -203.07, baseline_loss = 64.866, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)
[2025-01-17 18:30:17,237][root][INFO] - Step 486400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1698.0, step = 486400, mean_episode_return = 0.62259, mean_episode_step = 59.261, total_loss = -146.08, entropy_loss = -7.8753, pg_loss = -203.07, baseline_loss = 64.866, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)
[2025-01-17 18:30:22,242][root][INFO] - Step 488960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1703.0, step = 488960, mean_episode_return = 0.55051, mean_episode_step = 40.624, total_loss = -108.22, entropy_loss = -7.91, pg_loss = -187.87, baseline_loss = 87.56, learner_queue_size = 32, _tick = 190, _time = 1.7371e+09)
[2025-01-17 18:30:27,247][root][INFO] - Step 491520 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1708.0, step = 491520, mean_episode_return = 0.91934, mean_episode_step = 56.79, total_loss = 431.89, entropy_loss = -7.8582, pg_loss = 372.97, baseline_loss = 66.772, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)
[2025-01-17 18:30:32,252][root][INFO] - Step 491520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1713.0, step = 491520, mean_episode_return = 0.91934, mean_episode_step = 56.79, total_loss = 431.89, entropy_loss = -7.8582, pg_loss = 372.97, baseline_loss = 66.772, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)
[2025-01-17 18:30:37,257][root][INFO] - Step 494080 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1718.0, step = 494080, mean_episode_return = 0.75769, mean_episode_step = 49.139, total_loss = 237.32, entropy_loss = -7.8714, pg_loss = 169.72, baseline_loss = 75.469, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)
[2025-01-17 18:30:42,262][root][INFO] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1723.0, step = 494080, mean_episode_return = 0.75769, mean_episode_step = 49.139, total_loss = 237.32, entropy_loss = -7.8714, pg_loss = 169.72, baseline_loss = 75.469, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)
[2025-01-17 18:30:47,267][root][INFO] - Step 496640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1728.0, step = 496640, mean_episode_return = 0.59004, mean_episode_step = 46.679, total_loss = 65.252, entropy_loss = -7.872, pg_loss = 0.60249, baseline_loss = 72.522, learner_queue_size = 32, _tick = 193, _time = 1.7371e+09)
[2025-01-17 18:30:52,273][root][INFO] - Step 499200 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1733.0, step = 499200, mean_episode_return = 0.63089, mean_episode_step = 47.883, total_loss = -282.38, entropy_loss = -7.8669, pg_loss = -340.49, baseline_loss = 65.978, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)
[2025-01-17 18:30:57,279][root][INFO] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1738.0, step = 499200, mean_episode_return = 0.63089, mean_episode_step = 47.883, total_loss = -282.38, entropy_loss = -7.8669, pg_loss = -340.49, baseline_loss = 65.978, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)
[2025-01-17 18:31:02,284][root][INFO] - Step 501760 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1743.0, step = 501760, mean_episode_return = 0.51464, mean_episode_step = 54.47, total_loss = -429.44, entropy_loss = -7.86, pg_loss = -487.99, baseline_loss = 66.413, learner_queue_size = 32, _tick = 195, _time = 1.7371e+09)
[2025-01-17 18:31:02,284][root][INFO] - Learning finished after 501760 steps.
[2025-01-17 18:31:02,286][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 19:55:34,776][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,782][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,802][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,778][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,779][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,806][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,788][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,839][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,802][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,780][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,783][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,778][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,781][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,776][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,772][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,783][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,806][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,775][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,772][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,776][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,782][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,790][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,828][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,813][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,823][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,817][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,800][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,818][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,807][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,795][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,778][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,794][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,812][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,778][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,828][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,795][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,783][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,772][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,778][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,776][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,826][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,787][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,842][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,837][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,774][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,797][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,811][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,779][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,809][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,775][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,773][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,825][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,810][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,787][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,815][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,835][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,782][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,773][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,821][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,780][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,809][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,859][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,793][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,814][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,775][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,814][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,827][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,874][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,775][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,848][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,837][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,839][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,814][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,796][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,861][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,835][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,870][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,820][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,870][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,832][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,832][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,838][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,845][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,812][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,836][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,869][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,845][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,869][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,863][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,889][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,897][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,779][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,925][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,913][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,836][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,887][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,850][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,844][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,891][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,847][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,915][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,859][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,844][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,846][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,830][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,842][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,817][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,835][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,864][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,844][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,859][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,851][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,831][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,860][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,891][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,866][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,810][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,847][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,864][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,867][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,951][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,866][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,937][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,862][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,854][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,913][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,913][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,891][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,884][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,766][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,858][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,965][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,866][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,852][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,854][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,895][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,860][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,915][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,946][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,962][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,895][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:34,910][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:35,293][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 19:55:35,178][nle.env.base][INFO] - Not saving any NLE data.
