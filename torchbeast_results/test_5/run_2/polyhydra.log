[2025-01-20 13:26:00,748][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-20 13:26:00,798][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-20 13:26:00,799][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-20 13:26:00,803][root][INFO] - Logging results to /opt/minihack
[2025-01-20 13:26:00,849][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-20 13:26:00,849][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-20 13:26:00,850][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-20 13:26:00,850][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-20 13:26:00,850][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-20 13:26:00,851][root][INFO] - Not using CUDA.
[2025-01-20 13:26:00,864][root][INFO] - Using model baseline
[2025-01-20 13:26:00,864][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,931][root][INFO] - Number of model parameters: 4264078
[2025-01-20 13:26:00,931][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,987][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,987][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,987][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,988][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,990][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,991][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,992][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,992][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,993][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,993][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,994][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,996][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,996][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,995][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,997][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,997][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,997][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:00,997][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,000][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,000][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,000][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,004][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,006][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,009][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,010][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,013][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,021][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,023][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,023][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,025][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,026][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,030][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,021][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,045][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,028][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,055][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,058][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,051][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,061][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,077][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,080][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,081][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:01,102][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 13:26:05,987][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 157. Learner queue size: 22. Other stats: (train_seconds = 5.0)
[2025-01-20 13:26:10,992][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 48. Learner queue size: 26. Other stats: (train_seconds = 10.0)
[2025-01-20 13:26:15,998][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 84. Learner queue size: 27. Other stats: (train_seconds = 15.0)
[2025-01-20 13:26:21,003][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 82. Learner queue size: 4. Other stats: (train_seconds = 20.0)
[2025-01-20 13:26:26,009][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 31. Learner queue size: 32. Other stats: (train_seconds = 25.0)
[2025-01-20 13:26:31,009][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 30.0)
[2025-01-20 13:26:34,758][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-20 13:26:36,015][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-20 13:26:36,060][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 35.0, step = 2560, mean_episode_return = -0.074611, mean_episode_step = 61.939, total_loss = -1654.4, entropy_loss = -11.371, pg_loss = -1826.6, baseline_loss = 183.61, learner_queue_size = 32, _tick = 0, _time = 1.7374e+09)
[2025-01-20 13:26:41,065][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 40.1, step = 2560, mean_episode_return = -0.074611, mean_episode_step = 61.939, total_loss = -1654.4, entropy_loss = -11.371, pg_loss = -1826.6, baseline_loss = 183.61, learner_queue_size = 32, _tick = 0, _time = 1.7374e+09)
[2025-01-20 13:26:46,070][root][INFO] - Step 5120 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 45.1, step = 5120, mean_episode_return = -0.04537, mean_episode_step = 32.9, total_loss = 1952.1, entropy_loss = -11.324, pg_loss = 1745.8, baseline_loss = 217.6, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)
[2025-01-20 13:26:51,077][root][INFO] - Step 7680 @ 511.3 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 50.1, step = 7680, mean_episode_return = 0.00655, mean_episode_step = 32.71, total_loss = 2111.8, entropy_loss = -11.367, pg_loss = 1745.9, baseline_loss = 377.24, learner_queue_size = 32, _tick = 2, _time = 1.7374e+09)
[2025-01-20 13:26:56,082][root][INFO] - Step 7680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 55.1, step = 7680, mean_episode_return = 0.00655, mean_episode_step = 32.71, total_loss = 2111.8, entropy_loss = -11.367, pg_loss = 1745.9, baseline_loss = 377.24, learner_queue_size = 32, _tick = 2, _time = 1.7374e+09)
[2025-01-20 13:27:01,087][root][INFO] - Step 10240 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 60.1, step = 10240, mean_episode_return = -0.043909, mean_episode_step = 43.711, total_loss = -677.76, entropy_loss = -11.341, pg_loss = -802.82, baseline_loss = 136.4, learner_queue_size = 32, _tick = 3, _time = 1.7374e+09)
[2025-01-20 13:27:06,092][root][INFO] - Step 12800 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 65.1, step = 12800, mean_episode_return = 0.050579, mean_episode_step = 47.298, total_loss = 661.84, entropy_loss = -11.355, pg_loss = 529.24, baseline_loss = 143.96, learner_queue_size = 32, _tick = 4, _time = 1.7374e+09)
[2025-01-20 13:27:11,097][root][INFO] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 70.1, step = 12800, mean_episode_return = 0.050579, mean_episode_step = 47.298, total_loss = 661.84, entropy_loss = -11.355, pg_loss = 529.24, baseline_loss = 143.96, learner_queue_size = 32, _tick = 4, _time = 1.7374e+09)
[2025-01-20 13:27:16,103][root][INFO] - Step 15360 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 75.1, step = 15360, mean_episode_return = -0.055364, mean_episode_step = 51.772, total_loss = -868.46, entropy_loss = -11.296, pg_loss = -915.15, baseline_loss = 57.981, learner_queue_size = 32, _tick = 5, _time = 1.7374e+09)
[2025-01-20 13:27:21,108][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 80.1, step = 15360, mean_episode_return = -0.055364, mean_episode_step = 51.772, total_loss = -868.46, entropy_loss = -11.296, pg_loss = -915.15, baseline_loss = 57.981, learner_queue_size = 32, _tick = 5, _time = 1.7374e+09)
[2025-01-20 13:27:26,113][root][INFO] - Step 17920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 85.1, step = 17920, mean_episode_return = -0.018464, mean_episode_step = 40.409, total_loss = 635.3, entropy_loss = -11.336, pg_loss = 500.43, baseline_loss = 146.21, learner_queue_size = 32, _tick = 6, _time = 1.7374e+09)
[2025-01-20 13:27:31,118][root][INFO] - Step 20480 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 90.1, step = 20480, mean_episode_return = 0.00175, mean_episode_step = 51.017, total_loss = 128.49, entropy_loss = -11.342, pg_loss = -36.692, baseline_loss = 176.53, learner_queue_size = 32, _tick = 7, _time = 1.7374e+09)
[2025-01-20 13:27:36,123][root][INFO] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 95.1, step = 20480, mean_episode_return = 0.00175, mean_episode_step = 51.017, total_loss = 128.49, entropy_loss = -11.342, pg_loss = -36.692, baseline_loss = 176.53, learner_queue_size = 32, _tick = 7, _time = 1.7374e+09)
[2025-01-20 13:27:41,128][root][INFO] - Step 23040 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 100.1, step = 23040, mean_episode_return = -0.029821, mean_episode_step = 51.245, total_loss = -501.42, entropy_loss = -11.294, pg_loss = -526.99, baseline_loss = 36.863, learner_queue_size = 32, _tick = 8, _time = 1.7374e+09)
[2025-01-20 13:27:46,133][root][INFO] - Step 25600 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 105.2, step = 25600, mean_episode_return = 0.011966, mean_episode_step = 45.723, total_loss = 155.99, entropy_loss = -11.294, pg_loss = 107.93, baseline_loss = 59.356, learner_queue_size = 32, _tick = 9, _time = 1.7374e+09)
[2025-01-20 13:27:51,139][root][INFO] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 110.2, step = 25600, mean_episode_return = 0.011966, mean_episode_step = 45.723, total_loss = 155.99, entropy_loss = -11.294, pg_loss = 107.93, baseline_loss = 59.356, learner_queue_size = 32, _tick = 9, _time = 1.7374e+09)
[2025-01-20 13:27:56,144][root][INFO] - Step 28160 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 115.2, step = 28160, mean_episode_return = -0.0086499, mean_episode_step = 46.608, total_loss = 158.6, entropy_loss = -11.328, pg_loss = 68.942, baseline_loss = 100.98, learner_queue_size = 32, _tick = 10, _time = 1.7374e+09)
[2025-01-20 13:28:01,151][root][INFO] - Step 30720 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 120.2, step = 30720, mean_episode_return = -0.025467, mean_episode_step = 47.103, total_loss = -291.26, entropy_loss = -11.364, pg_loss = -360.63, baseline_loss = 80.729, learner_queue_size = 32, _tick = 11, _time = 1.7374e+09)
[2025-01-20 13:28:06,156][root][INFO] - Step 30720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 125.2, step = 30720, mean_episode_return = -0.025467, mean_episode_step = 47.103, total_loss = -291.26, entropy_loss = -11.364, pg_loss = -360.63, baseline_loss = 80.729, learner_queue_size = 32, _tick = 11, _time = 1.7374e+09)
[2025-01-20 13:28:11,162][root][INFO] - Step 33280 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 130.2, step = 33280, mean_episode_return = -0.038929, mean_episode_step = 59.758, total_loss = 799.12, entropy_loss = -11.323, pg_loss = 605.74, baseline_loss = 204.7, learner_queue_size = 32, _tick = 12, _time = 1.7374e+09)
[2025-01-20 13:28:16,167][root][INFO] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 135.2, step = 33280, mean_episode_return = -0.038929, mean_episode_step = 59.758, total_loss = 799.12, entropy_loss = -11.323, pg_loss = 605.74, baseline_loss = 204.7, learner_queue_size = 32, _tick = 12, _time = 1.7374e+09)
[2025-01-20 13:28:21,172][root][INFO] - Step 35840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 140.2, step = 35840, mean_episode_return = 0.024722, mean_episode_step = 47.877, total_loss = -325.32, entropy_loss = -11.248, pg_loss = -405.14, baseline_loss = 91.065, learner_queue_size = 32, _tick = 13, _time = 1.7374e+09)
[2025-01-20 13:28:26,180][root][INFO] - Step 38400 @ 511.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 145.2, step = 38400, mean_episode_return = -0.056174, mean_episode_step = 60.585, total_loss = 293.2, entropy_loss = -11.226, pg_loss = 209.64, baseline_loss = 94.786, learner_queue_size = 32, _tick = 14, _time = 1.7374e+09)
[2025-01-20 13:28:31,185][root][INFO] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 150.2, step = 38400, mean_episode_return = -0.056174, mean_episode_step = 60.585, total_loss = 293.2, entropy_loss = -11.226, pg_loss = 209.64, baseline_loss = 94.786, learner_queue_size = 32, _tick = 14, _time = 1.7374e+09)
[2025-01-20 13:28:36,190][root][INFO] - Step 40960 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 155.2, step = 40960, mean_episode_return = 0.050621, mean_episode_step = 64.484, total_loss = -443.53, entropy_loss = -11.226, pg_loss = -461.34, baseline_loss = 29.032, learner_queue_size = 32, _tick = 15, _time = 1.7374e+09)
[2025-01-20 13:28:41,195][root][INFO] - Step 43520 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 160.2, step = 43520, mean_episode_return = 0.045459, mean_episode_step = 69.222, total_loss = -84.037, entropy_loss = -11.207, pg_loss = -111.33, baseline_loss = 38.498, learner_queue_size = 32, _tick = 16, _time = 1.7374e+09)
[2025-01-20 13:28:46,200][root][INFO] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 165.2, step = 43520, mean_episode_return = 0.045459, mean_episode_step = 69.222, total_loss = -84.037, entropy_loss = -11.207, pg_loss = -111.33, baseline_loss = 38.498, learner_queue_size = 32, _tick = 16, _time = 1.7374e+09)
[2025-01-20 13:28:51,205][root][INFO] - Step 46080 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 170.2, step = 46080, mean_episode_return = 0.033667, mean_episode_step = 54.438, total_loss = 68.458, entropy_loss = -11.147, pg_loss = 53.458, baseline_loss = 26.146, learner_queue_size = 32, _tick = 17, _time = 1.7374e+09)
[2025-01-20 13:28:56,247][root][INFO] - Step 46080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 175.2, step = 46080, mean_episode_return = 0.033667, mean_episode_step = 54.438, total_loss = 68.458, entropy_loss = -11.147, pg_loss = 53.458, baseline_loss = 26.146, learner_queue_size = 32, _tick = 17, _time = 1.7374e+09)
[2025-01-20 13:29:01,272][root][INFO] - Step 48640 @ 506.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 180.3, step = 48640, mean_episode_return = -0.06831, mean_episode_step = 63.531, total_loss = -294.0, entropy_loss = -11.123, pg_loss = -283.79, baseline_loss = 0.91582, learner_queue_size = 32, _tick = 18, _time = 1.7374e+09)
[2025-01-20 13:29:06,502][root][INFO] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 185.3, step = 48640, mean_episode_return = -0.06831, mean_episode_step = 63.531, total_loss = -294.0, entropy_loss = -11.123, pg_loss = -283.79, baseline_loss = 0.91582, learner_queue_size = 32, _tick = 18, _time = 1.7374e+09)
[2025-01-20 13:29:11,535][root][INFO] - Step 51200 @ 486.7 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 190.6, step = 51200, mean_episode_return = 0.046, mean_episode_step = 64.071, total_loss = 1178.3, entropy_loss = -11.069, pg_loss = 1007.8, baseline_loss = 181.58, learner_queue_size = 32, _tick = 19, _time = 1.7374e+09)
[2025-01-20 13:29:16,542][root][INFO] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 195.6, step = 51200, mean_episode_return = 0.046, mean_episode_step = 64.071, total_loss = 1178.3, entropy_loss = -11.069, pg_loss = 1007.8, baseline_loss = 181.58, learner_queue_size = 32, _tick = 19, _time = 1.7374e+09)
[2025-01-20 13:29:21,548][root][INFO] - Step 53760 @ 511.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 200.6, step = 53760, mean_episode_return = 0.069714, mean_episode_step = 58.576, total_loss = 500.52, entropy_loss = -11.087, pg_loss = 408.71, baseline_loss = 102.89, learner_queue_size = 32, _tick = 20, _time = 1.7374e+09)
[2025-01-20 13:29:26,554][root][INFO] - Step 56320 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 205.6, step = 56320, mean_episode_return = 0.080586, mean_episode_step = 59.766, total_loss = 914.3, entropy_loss = -11.071, pg_loss = 701.09, baseline_loss = 224.28, learner_queue_size = 32, _tick = 21, _time = 1.7374e+09)
[2025-01-20 13:29:31,561][root][INFO] - Step 56320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 210.6, step = 56320, mean_episode_return = 0.080586, mean_episode_step = 59.766, total_loss = 914.3, entropy_loss = -11.071, pg_loss = 701.09, baseline_loss = 224.28, learner_queue_size = 32, _tick = 21, _time = 1.7374e+09)
[2025-01-20 13:29:36,567][root][INFO] - Step 58880 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 215.6, step = 58880, mean_episode_return = 0.035813, mean_episode_step = 66.946, total_loss = 98.178, entropy_loss = -11.043, pg_loss = -62.5, baseline_loss = 171.72, learner_queue_size = 32, _tick = 22, _time = 1.7374e+09)
[2025-01-20 13:29:41,572][root][INFO] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 220.6, step = 58880, mean_episode_return = 0.035813, mean_episode_step = 66.946, total_loss = 98.178, entropy_loss = -11.043, pg_loss = -62.5, baseline_loss = 171.72, learner_queue_size = 32, _tick = 22, _time = 1.7374e+09)
[2025-01-20 13:29:46,573][root][INFO] - Step 61440 @ 511.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 225.6, step = 61440, mean_episode_return = -0.012833, mean_episode_step = 53.167, total_loss = -51.001, entropy_loss = -10.786, pg_loss = -127.62, baseline_loss = 87.405, learner_queue_size = 32, _tick = 23, _time = 1.7374e+09)
[2025-01-20 13:29:51,578][root][INFO] - Step 64000 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 230.6, step = 64000, mean_episode_return = 0.041886, mean_episode_step = 60.298, total_loss = 239.21, entropy_loss = -10.717, pg_loss = 160.05, baseline_loss = 89.875, learner_queue_size = 32, _tick = 24, _time = 1.7374e+09)
[2025-01-20 13:29:56,583][root][INFO] - Step 64000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 235.6, step = 64000, mean_episode_return = 0.041886, mean_episode_step = 60.298, total_loss = 239.21, entropy_loss = -10.717, pg_loss = 160.05, baseline_loss = 89.875, learner_queue_size = 32, _tick = 24, _time = 1.7374e+09)
[2025-01-20 13:30:01,589][root][INFO] - Step 66560 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 240.6, step = 66560, mean_episode_return = 0.068657, mean_episode_step = 58.257, total_loss = 225.75, entropy_loss = -10.809, pg_loss = 136.69, baseline_loss = 99.859, learner_queue_size = 32, _tick = 25, _time = 1.7374e+09)
[2025-01-20 13:30:06,596][root][INFO] - Step 69120 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 245.6, step = 69120, mean_episode_return = -0.0053235, mean_episode_step = 52.054, total_loss = 423.98, entropy_loss = -10.771, pg_loss = 277.72, baseline_loss = 157.02, learner_queue_size = 32, _tick = 26, _time = 1.7374e+09)
[2025-01-20 13:30:11,601][root][INFO] - Step 69120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 250.6, step = 69120, mean_episode_return = -0.0053235, mean_episode_step = 52.054, total_loss = 423.98, entropy_loss = -10.771, pg_loss = 277.72, baseline_loss = 157.02, learner_queue_size = 32, _tick = 26, _time = 1.7374e+09)
[2025-01-20 13:30:16,606][root][INFO] - Step 71680 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 255.6, step = 71680, mean_episode_return = 0.0014584, mean_episode_step = 61.439, total_loss = -378.35, entropy_loss = -10.669, pg_loss = -468.34, baseline_loss = 100.66, learner_queue_size = 32, _tick = 27, _time = 1.7374e+09)
[2025-01-20 13:30:21,611][root][INFO] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 260.6, step = 71680, mean_episode_return = 0.0014584, mean_episode_step = 61.439, total_loss = -378.35, entropy_loss = -10.669, pg_loss = -468.34, baseline_loss = 100.66, learner_queue_size = 32, _tick = 27, _time = 1.7374e+09)
[2025-01-20 13:30:26,616][root][INFO] - Step 74240 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 265.6, step = 74240, mean_episode_return = -0.0032903, mean_episode_step = 57.421, total_loss = -436.32, entropy_loss = -10.658, pg_loss = -483.58, baseline_loss = 57.916, learner_queue_size = 32, _tick = 28, _time = 1.7374e+09)
[2025-01-20 13:30:31,623][root][INFO] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 270.6, step = 74240, mean_episode_return = -0.0032903, mean_episode_step = 57.421, total_loss = -436.32, entropy_loss = -10.658, pg_loss = -483.58, baseline_loss = 57.916, learner_queue_size = 32, _tick = 28, _time = 1.7374e+09)
[2025-01-20 13:30:36,630][root][INFO] - Step 76800 @ 511.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 275.6, step = 76800, mean_episode_return = 0.081513, mean_episode_step = 48.103, total_loss = 839.11, entropy_loss = -10.679, pg_loss = 662.33, baseline_loss = 187.46, learner_queue_size = 32, _tick = 29, _time = 1.7374e+09)
[2025-01-20 13:30:41,640][root][INFO] - Step 76800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 280.7, step = 76800, mean_episode_return = 0.081513, mean_episode_step = 48.103, total_loss = 839.11, entropy_loss = -10.679, pg_loss = 662.33, baseline_loss = 187.46, learner_queue_size = 32, _tick = 29, _time = 1.7374e+09)
[2025-01-20 13:30:46,646][root][INFO] - Step 79360 @ 510.9 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 285.7, step = 79360, mean_episode_return = 0.086229, mean_episode_step = 57.243, total_loss = 34.786, entropy_loss = -10.606, pg_loss = -120.47, baseline_loss = 165.86, learner_queue_size = 32, _tick = 30, _time = 1.7374e+09)
[2025-01-20 13:30:51,652][root][INFO] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 290.7, step = 79360, mean_episode_return = 0.086229, mean_episode_step = 57.243, total_loss = 34.786, entropy_loss = -10.606, pg_loss = -120.47, baseline_loss = 165.86, learner_queue_size = 32, _tick = 30, _time = 1.7374e+09)
[2025-01-20 13:30:56,727][root][INFO] - Step 81920 @ 504.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 295.7, step = 81920, mean_episode_return = 0.095135, mean_episode_step = 65.198, total_loss = 414.99, entropy_loss = -10.576, pg_loss = 270.34, baseline_loss = 155.22, learner_queue_size = 32, _tick = 31, _time = 1.7374e+09)
[2025-01-20 13:31:01,729][root][INFO] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 300.7, step = 81920, mean_episode_return = 0.095135, mean_episode_step = 65.198, total_loss = 414.99, entropy_loss = -10.576, pg_loss = 270.34, baseline_loss = 155.22, learner_queue_size = 32, _tick = 31, _time = 1.7374e+09)
[2025-01-20 13:31:06,756][root][INFO] - Step 84480 @ 509.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 305.8, step = 84480, mean_episode_return = 0.12557, mean_episode_step = 53.197, total_loss = 230.19, entropy_loss = -10.42, pg_loss = 90.777, baseline_loss = 149.84, learner_queue_size = 32, _tick = 32, _time = 1.7374e+09)
[2025-01-20 13:31:11,768][root][INFO] - Step 84480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 310.8, step = 84480, mean_episode_return = 0.12557, mean_episode_step = 53.197, total_loss = 230.19, entropy_loss = -10.42, pg_loss = 90.777, baseline_loss = 149.84, learner_queue_size = 32, _tick = 32, _time = 1.7374e+09)
[2025-01-20 13:31:16,774][root][INFO] - Step 87040 @ 510.9 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 315.8, step = 87040, mean_episode_return = 0.078824, mean_episode_step = 59.105, total_loss = -252.59, entropy_loss = -10.201, pg_loss = -316.88, baseline_loss = 74.486, learner_queue_size = 32, _tick = 33, _time = 1.7374e+09)
[2025-01-20 13:31:22,198][root][INFO] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 320.8, step = 87040, mean_episode_return = 0.078824, mean_episode_step = 59.105, total_loss = -252.59, entropy_loss = -10.201, pg_loss = -316.88, baseline_loss = 74.486, learner_queue_size = 32, _tick = 33, _time = 1.7374e+09)
[2025-01-20 13:31:27,214][root][INFO] - Step 89600 @ 474.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 326.2, step = 89600, mean_episode_return = 0.20737, mean_episode_step = 62.949, total_loss = 582.12, entropy_loss = -10.092, pg_loss = 475.29, baseline_loss = 116.92, learner_queue_size = 32, _tick = 34, _time = 1.7374e+09)
[2025-01-20 13:31:32,220][root][INFO] - Step 89600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 331.2, step = 89600, mean_episode_return = 0.20737, mean_episode_step = 62.949, total_loss = 582.12, entropy_loss = -10.092, pg_loss = 475.29, baseline_loss = 116.92, learner_queue_size = 32, _tick = 34, _time = 1.7374e+09)
[2025-01-20 13:31:37,231][root][INFO] - Step 92160 @ 510.9 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 336.2, step = 92160, mean_episode_return = 0.047929, mean_episode_step = 61.199, total_loss = 308.18, entropy_loss = -10.063, pg_loss = 198.44, baseline_loss = 119.79, learner_queue_size = 32, _tick = 35, _time = 1.7374e+09)
[2025-01-20 13:31:42,246][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 341.3, step = 92160, mean_episode_return = 0.047929, mean_episode_step = 61.199, total_loss = 308.18, entropy_loss = -10.063, pg_loss = 198.44, baseline_loss = 119.79, learner_queue_size = 32, _tick = 35, _time = 1.7374e+09)
[2025-01-20 13:31:47,254][root][INFO] - Step 94720 @ 510.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 346.3, step = 94720, mean_episode_return = 0.15215, mean_episode_step = 49.516, total_loss = -475.27, entropy_loss = -9.9657, pg_loss = -597.81, baseline_loss = 132.51, learner_queue_size = 32, _tick = 36, _time = 1.7374e+09)
[2025-01-20 13:31:52,265][root][INFO] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 351.3, step = 94720, mean_episode_return = 0.15215, mean_episode_step = 49.516, total_loss = -475.27, entropy_loss = -9.9657, pg_loss = -597.81, baseline_loss = 132.51, learner_queue_size = 32, _tick = 36, _time = 1.7374e+09)
[2025-01-20 13:31:57,271][root][INFO] - Step 97280 @ 511.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 356.3, step = 97280, mean_episode_return = 0.10389, mean_episode_step = 56.699, total_loss = -628.31, entropy_loss = -9.8989, pg_loss = -708.48, baseline_loss = 90.076, learner_queue_size = 32, _tick = 37, _time = 1.7374e+09)
[2025-01-20 13:32:02,515][root][INFO] - Step 97280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 361.3, step = 97280, mean_episode_return = 0.10389, mean_episode_step = 56.699, total_loss = -628.31, entropy_loss = -9.8989, pg_loss = -708.48, baseline_loss = 90.076, learner_queue_size = 32, _tick = 37, _time = 1.7374e+09)
[2025-01-20 13:36:38,639][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 13:36:38,726][root][INFO] - Step 99840 @ 9.3 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 637.7, step = 99840, mean_episode_return = 0.17864, mean_episode_step = 49.198, total_loss = 37.962, entropy_loss = -9.8899, pg_loss = -79.786, baseline_loss = 127.64, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)
[2025-01-20 13:36:43,733][root][INFO] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 642.7, step = 99840, mean_episode_return = 0.17864, mean_episode_step = 49.198, total_loss = 37.962, entropy_loss = -9.8899, pg_loss = -79.786, baseline_loss = 127.64, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)
[2025-01-20 13:36:48,738][root][INFO] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 647.8, step = 99840, mean_episode_return = 0.17864, mean_episode_step = 49.198, total_loss = 37.962, entropy_loss = -9.8899, pg_loss = -79.786, baseline_loss = 127.64, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)
[2025-01-20 13:36:53,743][root][INFO] - Step 102400 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 652.8, step = 102400, mean_episode_return = 0.13336, mean_episode_step = 61.427, total_loss = 156.1, entropy_loss = -9.9573, pg_loss = 48.815, baseline_loss = 117.25, learner_queue_size = 32, _tick = 39, _time = 1.7374e+09)
[2025-01-20 13:36:58,749][root][INFO] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 657.8, step = 102400, mean_episode_return = 0.13336, mean_episode_step = 61.427, total_loss = 156.1, entropy_loss = -9.9573, pg_loss = 48.815, baseline_loss = 117.25, learner_queue_size = 32, _tick = 39, _time = 1.7374e+09)
[2025-01-20 13:37:03,754][root][INFO] - Step 104960 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 662.8, step = 104960, mean_episode_return = 0.025444, mean_episode_step = 47.822, total_loss = 471.6, entropy_loss = -9.886, pg_loss = 322.45, baseline_loss = 159.03, learner_queue_size = 32, _tick = 40, _time = 1.7374e+09)
[2025-01-20 13:37:08,759][root][INFO] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 667.8, step = 104960, mean_episode_return = 0.025444, mean_episode_step = 47.822, total_loss = 471.6, entropy_loss = -9.886, pg_loss = 322.45, baseline_loss = 159.03, learner_queue_size = 32, _tick = 40, _time = 1.7374e+09)
[2025-01-20 13:37:13,764][root][INFO] - Step 107520 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 672.8, step = 107520, mean_episode_return = 0.14113, mean_episode_step = 68.577, total_loss = 463.13, entropy_loss = -9.8479, pg_loss = 339.38, baseline_loss = 133.6, learner_queue_size = 32, _tick = 41, _time = 1.7374e+09)
[2025-01-20 13:37:18,776][root][INFO] - Step 107520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 677.8, step = 107520, mean_episode_return = 0.14113, mean_episode_step = 68.577, total_loss = 463.13, entropy_loss = -9.8479, pg_loss = 339.38, baseline_loss = 133.6, learner_queue_size = 32, _tick = 41, _time = 1.7374e+09)
[2025-01-20 13:37:23,781][root][INFO] - Step 110080 @ 510.9 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 682.8, step = 110080, mean_episode_return = 0.11893, mean_episode_step = 59.995, total_loss = -661.99, entropy_loss = -9.7962, pg_loss = -736.41, baseline_loss = 84.213, learner_queue_size = 32, _tick = 42, _time = 1.7374e+09)
[2025-01-20 13:37:28,787][root][INFO] - Step 112640 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 687.8, step = 112640, mean_episode_return = 0.30945, mean_episode_step = 67.456, total_loss = 852.73, entropy_loss = -9.7465, pg_loss = 677.53, baseline_loss = 184.95, learner_queue_size = 32, _tick = 43, _time = 1.7374e+09)
[2025-01-20 13:37:33,793][root][INFO] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 692.8, step = 112640, mean_episode_return = 0.30945, mean_episode_step = 67.456, total_loss = 852.73, entropy_loss = -9.7465, pg_loss = 677.53, baseline_loss = 184.95, learner_queue_size = 32, _tick = 43, _time = 1.7374e+09)
[2025-01-20 13:37:38,798][root][INFO] - Step 115200 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 697.8, step = 115200, mean_episode_return = 0.083322, mean_episode_step = 65.934, total_loss = 552.12, entropy_loss = -9.7607, pg_loss = 382.54, baseline_loss = 179.35, learner_queue_size = 32, _tick = 44, _time = 1.7374e+09)
[2025-01-20 13:37:43,803][root][INFO] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 702.8, step = 115200, mean_episode_return = 0.083322, mean_episode_step = 65.934, total_loss = 552.12, entropy_loss = -9.7607, pg_loss = 382.54, baseline_loss = 179.35, learner_queue_size = 32, _tick = 44, _time = 1.7374e+09)
[2025-01-20 13:37:48,812][root][INFO] - Step 117760 @ 511.3 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 707.8, step = 117760, mean_episode_return = 0.31852, mean_episode_step = 61.859, total_loss = -449.78, entropy_loss = -9.6115, pg_loss = -554.86, baseline_loss = 114.69, learner_queue_size = 32, _tick = 45, _time = 1.7374e+09)
[2025-01-20 13:37:53,826][root][INFO] - Step 117760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 712.8, step = 117760, mean_episode_return = 0.31852, mean_episode_step = 61.859, total_loss = -449.78, entropy_loss = -9.6115, pg_loss = -554.86, baseline_loss = 114.69, learner_queue_size = 32, _tick = 45, _time = 1.7374e+09)
[2025-01-20 13:37:58,833][root][INFO] - Step 120320 @ 510.6 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 717.9, step = 120320, mean_episode_return = 0.34388, mean_episode_step = 65.141, total_loss = -291.42, entropy_loss = -9.5885, pg_loss = -396.71, baseline_loss = 114.88, learner_queue_size = 32, _tick = 46, _time = 1.7374e+09)
[2025-01-20 13:38:03,839][root][INFO] - Step 120320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 722.9, step = 120320, mean_episode_return = 0.34388, mean_episode_step = 65.141, total_loss = -291.42, entropy_loss = -9.5885, pg_loss = -396.71, baseline_loss = 114.88, learner_queue_size = 32, _tick = 46, _time = 1.7374e+09)
[2025-01-20 13:38:08,895][root][INFO] - Step 122880 @ 506.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 727.9, step = 122880, mean_episode_return = 0.25047, mean_episode_step = 72.795, total_loss = 181.94, entropy_loss = -9.562, pg_loss = 56.89, baseline_loss = 134.61, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)
[2025-01-20 13:38:13,901][root][INFO] - Step 122880 @ 0.0 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 732.9, step = 122880, mean_episode_return = 0.25047, mean_episode_step = 72.795, total_loss = 181.94, entropy_loss = -9.562, pg_loss = 56.89, baseline_loss = 134.61, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)
[2025-01-20 13:38:18,907][root][INFO] - Step 122880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 737.9, step = 122880, mean_episode_return = 0.25047, mean_episode_step = 72.795, total_loss = 181.94, entropy_loss = -9.562, pg_loss = 56.89, baseline_loss = 134.61, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)
[2025-01-20 13:38:23,913][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar
[2025-01-20 13:38:23,979][root][INFO] - Step 125440 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 742.9, step = 125440, mean_episode_return = 0.26097, mean_episode_step = 66.057, total_loss = -206.15, entropy_loss = -9.6868, pg_loss = -295.65, baseline_loss = 99.194, learner_queue_size = 32, _tick = 48, _time = 1.7374e+09)
[2025-01-20 13:38:29,062][root][INFO] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 748.0, step = 125440, mean_episode_return = 0.26097, mean_episode_step = 66.057, total_loss = -206.15, entropy_loss = -9.6868, pg_loss = -295.65, baseline_loss = 99.194, learner_queue_size = 32, _tick = 48, _time = 1.7374e+09)
[2025-01-20 13:38:34,068][root][INFO] - Step 128000 @ 507.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 753.1, step = 128000, mean_episode_return = 0.19343, mean_episode_step = 69.884, total_loss = -67.106, entropy_loss = -9.6169, pg_loss = -139.33, baseline_loss = 81.84, learner_queue_size = 32, _tick = 49, _time = 1.7374e+09)
[2025-01-20 13:38:39,788][root][INFO] - Step 128000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 758.2, step = 128000, mean_episode_return = 0.19343, mean_episode_step = 69.884, total_loss = -67.106, entropy_loss = -9.6169, pg_loss = -139.33, baseline_loss = 81.84, learner_queue_size = 32, _tick = 49, _time = 1.7374e+09)
[2025-01-20 13:38:44,796][root][INFO] - Step 130560 @ 454.8 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 763.8, step = 130560, mean_episode_return = 0.26349, mean_episode_step = 57.274, total_loss = -69.234, entropy_loss = -9.7824, pg_loss = -144.7, baseline_loss = 85.251, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)
[2025-01-20 13:38:49,992][root][INFO] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 768.8, step = 130560, mean_episode_return = 0.26349, mean_episode_step = 57.274, total_loss = -69.234, entropy_loss = -9.7824, pg_loss = -144.7, baseline_loss = 85.251, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)
[2025-01-20 13:38:55,008][root][INFO] - Step 133120 @ 492.9 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 774.0, step = 133120, mean_episode_return = 0.26975, mean_episode_step = 77.827, total_loss = 576.01, entropy_loss = -9.6796, pg_loss = 503.99, baseline_loss = 81.701, learner_queue_size = 32, _tick = 51, _time = 1.7374e+09)
[2025-01-20 13:39:00,012][root][INFO] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 779.0, step = 133120, mean_episode_return = 0.26975, mean_episode_step = 77.827, total_loss = 576.01, entropy_loss = -9.6796, pg_loss = 503.99, baseline_loss = 81.701, learner_queue_size = 32, _tick = 51, _time = 1.7374e+09)
[2025-01-20 13:39:05,020][root][INFO] - Step 135680 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 784.0, step = 135680, mean_episode_return = 0.10803, mean_episode_step = 68.199, total_loss = 55.312, entropy_loss = -9.669, pg_loss = -21.931, baseline_loss = 86.912, learner_queue_size = 32, _tick = 52, _time = 1.7374e+09)
[2025-01-20 13:39:10,026][root][INFO] - Step 135680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 789.0, step = 135680, mean_episode_return = 0.10803, mean_episode_step = 68.199, total_loss = 55.312, entropy_loss = -9.669, pg_loss = -21.931, baseline_loss = 86.912, learner_queue_size = 32, _tick = 52, _time = 1.7374e+09)
[2025-01-20 13:39:15,191][root][INFO] - Step 138240 @ 495.6 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 794.2, step = 138240, mean_episode_return = 0.19218, mean_episode_step = 54.97, total_loss = 88.952, entropy_loss = -9.5464, pg_loss = 6.727, baseline_loss = 91.772, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)
[2025-01-20 13:39:20,197][root][INFO] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 799.2, step = 138240, mean_episode_return = 0.19218, mean_episode_step = 54.97, total_loss = 88.952, entropy_loss = -9.5464, pg_loss = 6.727, baseline_loss = 91.772, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)
[2025-01-20 13:39:25,202][root][INFO] - Step 140800 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 804.2, step = 140800, mean_episode_return = 0.37641, mean_episode_step = 77.363, total_loss = 146.31, entropy_loss = -9.4783, pg_loss = 91.623, baseline_loss = 64.165, learner_queue_size = 32, _tick = 54, _time = 1.7374e+09)
[2025-01-20 13:39:30,211][root][INFO] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 809.2, step = 140800, mean_episode_return = 0.37641, mean_episode_step = 77.363, total_loss = 146.31, entropy_loss = -9.4783, pg_loss = 91.623, baseline_loss = 64.165, learner_queue_size = 32, _tick = 54, _time = 1.7374e+09)
[2025-01-20 13:39:35,217][root][INFO] - Step 143360 @ 511.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 814.2, step = 143360, mean_episode_return = 0.29174, mean_episode_step = 73.624, total_loss = 452.77, entropy_loss = -9.488, pg_loss = 345.93, baseline_loss = 116.33, learner_queue_size = 32, _tick = 55, _time = 1.7374e+09)
[2025-01-20 13:39:40,223][root][INFO] - Step 145920 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 819.2, step = 145920, mean_episode_return = 0.1916, mean_episode_step = 54.55, total_loss = -248.73, entropy_loss = -9.4454, pg_loss = -340.43, baseline_loss = 101.14, learner_queue_size = 32, _tick = 56, _time = 1.7374e+09)
[2025-01-20 13:39:45,228][root][INFO] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 824.2, step = 145920, mean_episode_return = 0.1916, mean_episode_step = 54.55, total_loss = -248.73, entropy_loss = -9.4454, pg_loss = -340.43, baseline_loss = 101.14, learner_queue_size = 32, _tick = 56, _time = 1.7374e+09)
[2025-01-20 13:39:50,233][root][INFO] - Step 148480 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 829.3, step = 148480, mean_episode_return = 0.30756, mean_episode_step = 60.959, total_loss = -527.1, entropy_loss = -9.3421, pg_loss = -582.58, baseline_loss = 64.825, learner_queue_size = 32, _tick = 57, _time = 1.7374e+09)
[2025-01-20 13:39:55,239][root][INFO] - Step 148480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 834.3, step = 148480, mean_episode_return = 0.30756, mean_episode_step = 60.959, total_loss = -527.1, entropy_loss = -9.3421, pg_loss = -582.58, baseline_loss = 64.825, learner_queue_size = 32, _tick = 57, _time = 1.7374e+09)
[2025-01-20 13:40:00,246][root][INFO] - Step 151040 @ 511.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 839.3, step = 151040, mean_episode_return = 0.47189, mean_episode_step = 71.387, total_loss = 450.0, entropy_loss = -9.3147, pg_loss = 367.24, baseline_loss = 92.075, learner_queue_size = 32, _tick = 58, _time = 1.7374e+09)
[2025-01-20 13:40:05,252][root][INFO] - Step 153600 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 844.3, step = 153600, mean_episode_return = 0.27707, mean_episode_step = 65.806, total_loss = 326.27, entropy_loss = -9.3322, pg_loss = 179.78, baseline_loss = 155.82, learner_queue_size = 32, _tick = 59, _time = 1.7374e+09)
[2025-01-20 13:40:10,258][root][INFO] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 849.3, step = 153600, mean_episode_return = 0.27707, mean_episode_step = 65.806, total_loss = 326.27, entropy_loss = -9.3322, pg_loss = 179.78, baseline_loss = 155.82, learner_queue_size = 32, _tick = 59, _time = 1.7374e+09)
[2025-01-20 13:40:15,263][root][INFO] - Step 156160 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 854.3, step = 156160, mean_episode_return = 0.33816, mean_episode_step = 70.497, total_loss = -662.3, entropy_loss = -9.3772, pg_loss = -741.54, baseline_loss = 88.619, learner_queue_size = 32, _tick = 60, _time = 1.7374e+09)
[2025-01-20 13:40:20,268][root][INFO] - Step 156160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 859.3, step = 156160, mean_episode_return = 0.33816, mean_episode_step = 70.497, total_loss = -662.3, entropy_loss = -9.3772, pg_loss = -741.54, baseline_loss = 88.619, learner_queue_size = 32, _tick = 60, _time = 1.7374e+09)
[2025-01-20 13:40:25,279][root][INFO] - Step 158720 @ 510.9 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 864.3, step = 158720, mean_episode_return = 0.43015, mean_episode_step = 78.323, total_loss = -71.908, entropy_loss = -9.3849, pg_loss = -153.06, baseline_loss = 90.538, learner_queue_size = 32, _tick = 61, _time = 1.7374e+09)
[2025-01-20 13:40:30,287][root][INFO] - Step 161280 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 869.3, step = 161280, mean_episode_return = 0.46753, mean_episode_step = 80.433, total_loss = 954.63, entropy_loss = -9.3994, pg_loss = 825.04, baseline_loss = 138.98, learner_queue_size = 32, _tick = 62, _time = 1.7374e+09)
[2025-01-20 13:40:35,292][root][INFO] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 874.3, step = 161280, mean_episode_return = 0.46753, mean_episode_step = 80.433, total_loss = 954.63, entropy_loss = -9.3994, pg_loss = 825.04, baseline_loss = 138.98, learner_queue_size = 32, _tick = 62, _time = 1.7374e+09)
[2025-01-20 13:40:40,298][root][INFO] - Step 163840 @ 511.4 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 879.3, step = 163840, mean_episode_return = 0.13297, mean_episode_step = 50.97, total_loss = -698.52, entropy_loss = -9.4224, pg_loss = -777.13, baseline_loss = 88.029, learner_queue_size = 32, _tick = 63, _time = 1.7374e+09)
[2025-01-20 13:40:45,304][root][INFO] - Step 163840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 884.3, step = 163840, mean_episode_return = 0.13297, mean_episode_step = 50.97, total_loss = -698.52, entropy_loss = -9.4224, pg_loss = -777.13, baseline_loss = 88.029, learner_queue_size = 32, _tick = 63, _time = 1.7374e+09)
[2025-01-20 13:40:50,309][root][INFO] - Step 166400 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 889.3, step = 166400, mean_episode_return = 0.32175, mean_episode_step = 56.46, total_loss = -351.65, entropy_loss = -9.4045, pg_loss = -447.98, baseline_loss = 105.74, learner_queue_size = 32, _tick = 64, _time = 1.7374e+09)
[2025-01-20 13:40:55,314][root][INFO] - Step 168960 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 894.3, step = 168960, mean_episode_return = 0.71677, mean_episode_step = 77.262, total_loss = 241.3, entropy_loss = -9.4023, pg_loss = 106.67, baseline_loss = 144.03, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)
[2025-01-20 13:41:00,321][root][INFO] - Step 168960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 899.3, step = 168960, mean_episode_return = 0.71677, mean_episode_step = 77.262, total_loss = 241.3, entropy_loss = -9.4023, pg_loss = 106.67, baseline_loss = 144.03, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)
[2025-01-20 13:41:05,326][root][INFO] - Step 171520 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 904.3, step = 171520, mean_episode_return = 0.37837, mean_episode_step = 61.995, total_loss = -479.33, entropy_loss = -9.3705, pg_loss = -598.33, baseline_loss = 128.37, learner_queue_size = 32, _tick = 66, _time = 1.7374e+09)
[2025-01-20 13:41:10,332][root][INFO] - Step 174080 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 909.4, step = 174080, mean_episode_return = 0.2577, mean_episode_step = 67.041, total_loss = -153.29, entropy_loss = -9.3633, pg_loss = -255.99, baseline_loss = 112.06, learner_queue_size = 32, _tick = 67, _time = 1.7374e+09)
[2025-01-20 13:41:15,338][root][INFO] - Step 174080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 914.4, step = 174080, mean_episode_return = 0.2577, mean_episode_step = 67.041, total_loss = -153.29, entropy_loss = -9.3633, pg_loss = -255.99, baseline_loss = 112.06, learner_queue_size = 32, _tick = 67, _time = 1.7374e+09)
[2025-01-20 13:41:20,349][root][INFO] - Step 176640 @ 510.8 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 919.4, step = 176640, mean_episode_return = 0.32374, mean_episode_step = 58.63, total_loss = 565.86, entropy_loss = -9.3313, pg_loss = 467.8, baseline_loss = 107.39, learner_queue_size = 32, _tick = 68, _time = 1.7374e+09)
[2025-01-20 13:41:25,356][root][INFO] - Step 176640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 924.4, step = 176640, mean_episode_return = 0.32374, mean_episode_step = 58.63, total_loss = 565.86, entropy_loss = -9.3313, pg_loss = 467.8, baseline_loss = 107.39, learner_queue_size = 32, _tick = 68, _time = 1.7374e+09)
[2025-01-20 13:41:30,362][root][INFO] - Step 179200 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 929.4, step = 179200, mean_episode_return = 0.3325, mean_episode_step = 83.45, total_loss = 550.89, entropy_loss = -9.2872, pg_loss = 458.28, baseline_loss = 101.89, learner_queue_size = 32, _tick = 69, _time = 1.7374e+09)
[2025-01-20 13:41:35,367][root][INFO] - Step 181760 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 934.4, step = 181760, mean_episode_return = 0.35041, mean_episode_step = 70.445, total_loss = 920.82, entropy_loss = -9.3214, pg_loss = 764.4, baseline_loss = 165.74, learner_queue_size = 32, _tick = 70, _time = 1.7374e+09)
[2025-01-20 13:41:40,374][root][INFO] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 939.4, step = 181760, mean_episode_return = 0.35041, mean_episode_step = 70.445, total_loss = 920.82, entropy_loss = -9.3214, pg_loss = 764.4, baseline_loss = 165.74, learner_queue_size = 32, _tick = 70, _time = 1.7374e+09)
[2025-01-20 13:41:45,379][root][INFO] - Step 184320 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 944.4, step = 184320, mean_episode_return = 0.3797, mean_episode_step = 61.086, total_loss = -532.12, entropy_loss = -9.3454, pg_loss = -661.76, baseline_loss = 138.98, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)
[2025-01-20 13:41:50,385][root][INFO] - Step 184320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 949.4, step = 184320, mean_episode_return = 0.3797, mean_episode_step = 61.086, total_loss = -532.12, entropy_loss = -9.3454, pg_loss = -661.76, baseline_loss = 138.98, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)
[2025-01-20 13:41:55,390][root][INFO] - Step 186880 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 954.4, step = 186880, mean_episode_return = 0.41284, mean_episode_step = 80.055, total_loss = 388.08, entropy_loss = -9.3489, pg_loss = 259.84, baseline_loss = 137.59, learner_queue_size = 32, _tick = 72, _time = 1.7374e+09)
[2025-01-20 13:42:00,396][root][INFO] - Step 189440 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 959.4, step = 189440, mean_episode_return = 0.52486, mean_episode_step = 72.894, total_loss = -776.9, entropy_loss = -9.3045, pg_loss = -888.01, baseline_loss = 120.42, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)
[2025-01-20 13:42:05,401][root][INFO] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 964.4, step = 189440, mean_episode_return = 0.52486, mean_episode_step = 72.894, total_loss = -776.9, entropy_loss = -9.3045, pg_loss = -888.01, baseline_loss = 120.42, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)
[2025-01-20 13:42:10,409][root][INFO] - Step 192000 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 969.4, step = 192000, mean_episode_return = 0.35012, mean_episode_step = 63.962, total_loss = -470.5, entropy_loss = -9.3025, pg_loss = -592.58, baseline_loss = 131.39, learner_queue_size = 32, _tick = 74, _time = 1.7374e+09)
[2025-01-20 13:42:15,417][root][INFO] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 974.4, step = 192000, mean_episode_return = 0.35012, mean_episode_step = 63.962, total_loss = -470.5, entropy_loss = -9.3025, pg_loss = -592.58, baseline_loss = 131.39, learner_queue_size = 32, _tick = 74, _time = 1.7374e+09)
[2025-01-20 13:42:20,422][root][INFO] - Step 194560 @ 511.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 979.4, step = 194560, mean_episode_return = 0.30527, mean_episode_step = 74.963, total_loss = -238.07, entropy_loss = -9.291, pg_loss = -309.31, baseline_loss = 80.53, learner_queue_size = 32, _tick = 75, _time = 1.7374e+09)
[2025-01-20 13:42:25,429][root][INFO] - Step 197120 @ 511.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 984.4, step = 197120, mean_episode_return = 0.49703, mean_episode_step = 67.132, total_loss = 255.33, entropy_loss = -9.3314, pg_loss = 148.27, baseline_loss = 116.39, learner_queue_size = 32, _tick = 76, _time = 1.7374e+09)
[2025-01-20 13:42:30,434][root][INFO] - Step 197120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 989.5, step = 197120, mean_episode_return = 0.49703, mean_episode_step = 67.132, total_loss = 255.33, entropy_loss = -9.3314, pg_loss = 148.27, baseline_loss = 116.39, learner_queue_size = 32, _tick = 76, _time = 1.7374e+09)
[2025-01-20 13:42:35,440][root][INFO] - Step 199680 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 994.5, step = 199680, mean_episode_return = 0.23854, mean_episode_step = 59.353, total_loss = -213.53, entropy_loss = -9.2667, pg_loss = -341.24, baseline_loss = 136.97, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)
[2025-01-20 13:42:40,445][root][INFO] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 999.5, step = 199680, mean_episode_return = 0.23854, mean_episode_step = 59.353, total_loss = -213.53, entropy_loss = -9.2667, pg_loss = -341.24, baseline_loss = 136.97, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)
[2025-01-20 13:42:45,450][root][INFO] - Step 202240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1004.5, step = 202240, mean_episode_return = 0.44135, mean_episode_step = 67.753, total_loss = 492.54, entropy_loss = -9.2547, pg_loss = 352.55, baseline_loss = 149.24, learner_queue_size = 32, _tick = 78, _time = 1.7374e+09)
[2025-01-20 13:42:50,456][root][INFO] - Step 204800 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1009.5, step = 204800, mean_episode_return = 0.37252, mean_episode_step = 71.918, total_loss = -92.138, entropy_loss = -9.2288, pg_loss = -181.44, baseline_loss = 98.533, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)
[2025-01-20 13:42:55,506][root][INFO] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1014.5, step = 204800, mean_episode_return = 0.37252, mean_episode_step = 71.918, total_loss = -92.138, entropy_loss = -9.2288, pg_loss = -181.44, baseline_loss = 98.533, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)
[2025-01-20 13:43:00,528][root][INFO] - Step 207360 @ 506.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1019.5, step = 207360, mean_episode_return = 0.19676, mean_episode_step = 64.668, total_loss = 569.45, entropy_loss = -9.2012, pg_loss = 467.91, baseline_loss = 110.74, learner_queue_size = 32, _tick = 80, _time = 1.7374e+09)
[2025-01-20 13:43:05,534][root][INFO] - Step 209920 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1024.6, step = 209920, mean_episode_return = 0.48153, mean_episode_step = 69.308, total_loss = 220.49, entropy_loss = -9.2419, pg_loss = 83.788, baseline_loss = 145.95, learner_queue_size = 32, _tick = 81, _time = 1.7374e+09)
[2025-01-20 13:43:10,539][root][INFO] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1029.6, step = 209920, mean_episode_return = 0.48153, mean_episode_step = 69.308, total_loss = 220.49, entropy_loss = -9.2419, pg_loss = 83.788, baseline_loss = 145.95, learner_queue_size = 32, _tick = 81, _time = 1.7374e+09)
[2025-01-20 13:43:15,546][root][INFO] - Step 212480 @ 511.3 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1034.6, step = 212480, mean_episode_return = 0.33444, mean_episode_step = 83.604, total_loss = 70.541, entropy_loss = -9.2351, pg_loss = -29.871, baseline_loss = 109.65, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)
[2025-01-20 13:43:20,551][root][INFO] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1039.6, step = 212480, mean_episode_return = 0.33444, mean_episode_step = 83.604, total_loss = 70.541, entropy_loss = -9.2351, pg_loss = -29.871, baseline_loss = 109.65, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)
[2025-01-20 13:43:25,559][root][INFO] - Step 215040 @ 511.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1044.6, step = 215040, mean_episode_return = 0.3761, mean_episode_step = 64.025, total_loss = -496.56, entropy_loss = -9.1713, pg_loss = -570.44, baseline_loss = 83.05, learner_queue_size = 32, _tick = 83, _time = 1.7374e+09)
[2025-01-20 13:43:30,565][root][INFO] - Step 217600 @ 511.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1049.6, step = 217600, mean_episode_return = 0.29704, mean_episode_step = 69.502, total_loss = 231.6, entropy_loss = -9.1384, pg_loss = 152.7, baseline_loss = 88.037, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)
[2025-01-20 13:43:35,570][root][INFO] - Step 217600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1054.6, step = 217600, mean_episode_return = 0.29704, mean_episode_step = 69.502, total_loss = 231.6, entropy_loss = -9.1384, pg_loss = 152.7, baseline_loss = 88.037, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)
[2025-01-20 13:43:40,575][root][INFO] - Step 220160 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1059.6, step = 220160, mean_episode_return = 0.6606, mean_episode_step = 70.332, total_loss = 47.521, entropy_loss = -9.0972, pg_loss = -25.27, baseline_loss = 81.888, learner_queue_size = 32, _tick = 85, _time = 1.7374e+09)
[2025-01-20 13:43:45,581][root][INFO] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1064.6, step = 220160, mean_episode_return = 0.6606, mean_episode_step = 70.332, total_loss = 47.521, entropy_loss = -9.0972, pg_loss = -25.27, baseline_loss = 81.888, learner_queue_size = 32, _tick = 85, _time = 1.7374e+09)
[2025-01-20 13:43:50,586][root][INFO] - Step 222720 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1069.6, step = 222720, mean_episode_return = 0.56927, mean_episode_step = 76.261, total_loss = 22.533, entropy_loss = -9.0078, pg_loss = -42.787, baseline_loss = 74.327, learner_queue_size = 32, _tick = 86, _time = 1.7374e+09)
[2025-01-20 13:43:55,591][root][INFO] - Step 225280 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1074.6, step = 225280, mean_episode_return = 0.46595, mean_episode_step = 64.502, total_loss = 62.076, entropy_loss = -8.9257, pg_loss = -1.8318, baseline_loss = 72.834, learner_queue_size = 32, _tick = 87, _time = 1.7374e+09)
[2025-01-20 13:44:00,596][root][INFO] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1079.6, step = 225280, mean_episode_return = 0.46595, mean_episode_step = 64.502, total_loss = 62.076, entropy_loss = -8.9257, pg_loss = -1.8318, baseline_loss = 72.834, learner_queue_size = 32, _tick = 87, _time = 1.7374e+09)
[2025-01-20 13:44:05,611][root][INFO] - Step 227840 @ 510.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1084.6, step = 227840, mean_episode_return = 0.45181, mean_episode_step = 71.345, total_loss = 17.459, entropy_loss = -8.8327, pg_loss = -30.313, baseline_loss = 56.605, learner_queue_size = 32, _tick = 88, _time = 1.7374e+09)
[2025-01-20 13:44:10,616][root][INFO] - Step 230400 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1089.6, step = 230400, mean_episode_return = 0.44357, mean_episode_step = 70.747, total_loss = 106.18, entropy_loss = -8.7389, pg_loss = 67.925, baseline_loss = 46.994, learner_queue_size = 32, _tick = 89, _time = 1.7374e+09)
[2025-01-20 13:44:15,622][root][INFO] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1094.6, step = 230400, mean_episode_return = 0.44357, mean_episode_step = 70.747, total_loss = 106.18, entropy_loss = -8.7389, pg_loss = 67.925, baseline_loss = 46.994, learner_queue_size = 32, _tick = 89, _time = 1.7374e+09)
[2025-01-20 13:44:20,630][root][INFO] - Step 232960 @ 511.2 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1099.6, step = 232960, mean_episode_return = 0.39715, mean_episode_step = 67.499, total_loss = 171.69, entropy_loss = -8.8302, pg_loss = 122.04, baseline_loss = 58.484, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)
[2025-01-20 13:44:25,635][root][INFO] - Step 232960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1104.7, step = 232960, mean_episode_return = 0.39715, mean_episode_step = 67.499, total_loss = 171.69, entropy_loss = -8.8302, pg_loss = 122.04, baseline_loss = 58.484, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)
[2025-01-20 13:44:30,640][root][INFO] - Step 235520 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1109.7, step = 235520, mean_episode_return = 0.21607, mean_episode_step = 67.754, total_loss = -364.19, entropy_loss = -8.7857, pg_loss = -399.62, baseline_loss = 44.223, learner_queue_size = 32, _tick = 91, _time = 1.7374e+09)
[2025-01-20 13:44:35,646][root][INFO] - Step 238080 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1114.7, step = 238080, mean_episode_return = 0.47397, mean_episode_step = 76.268, total_loss = -173.13, entropy_loss = -8.768, pg_loss = -219.85, baseline_loss = 55.493, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)
[2025-01-20 13:44:40,652][root][INFO] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1119.7, step = 238080, mean_episode_return = 0.47397, mean_episode_step = 76.268, total_loss = -173.13, entropy_loss = -8.768, pg_loss = -219.85, baseline_loss = 55.493, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)
[2025-01-20 13:44:45,657][root][INFO] - Step 240640 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1124.7, step = 240640, mean_episode_return = 0.46526, mean_episode_step = 70.086, total_loss = 563.16, entropy_loss = -8.7021, pg_loss = 483.98, baseline_loss = 87.892, learner_queue_size = 32, _tick = 93, _time = 1.7374e+09)
[2025-01-20 13:44:50,662][root][INFO] - Step 240640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1129.7, step = 240640, mean_episode_return = 0.46526, mean_episode_step = 70.086, total_loss = 563.16, entropy_loss = -8.7021, pg_loss = 483.98, baseline_loss = 87.892, learner_queue_size = 32, _tick = 93, _time = 1.7374e+09)
[2025-01-20 13:44:55,667][root][INFO] - Step 243200 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1134.7, step = 243200, mean_episode_return = 0.44859, mean_episode_step = 79.267, total_loss = 109.9, entropy_loss = -8.7315, pg_loss = 34.904, baseline_loss = 83.725, learner_queue_size = 32, _tick = 94, _time = 1.7374e+09)
[2025-01-20 13:45:00,672][root][INFO] - Step 245760 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1139.7, step = 245760, mean_episode_return = 0.60571, mean_episode_step = 77.949, total_loss = -517.48, entropy_loss = -8.68, pg_loss = -570.89, baseline_loss = 62.092, learner_queue_size = 32, _tick = 95, _time = 1.7374e+09)
[2025-01-20 13:45:05,677][root][INFO] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1144.7, step = 245760, mean_episode_return = 0.60571, mean_episode_step = 77.949, total_loss = -517.48, entropy_loss = -8.68, pg_loss = -570.89, baseline_loss = 62.092, learner_queue_size = 32, _tick = 95, _time = 1.7374e+09)
[2025-01-20 13:45:10,682][root][INFO] - Step 248320 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1149.7, step = 248320, mean_episode_return = 0.49057, mean_episode_step = 65.929, total_loss = -266.94, entropy_loss = -8.6215, pg_loss = -304.75, baseline_loss = 46.435, learner_queue_size = 32, _tick = 96, _time = 1.7374e+09)
[2025-01-20 13:45:15,687][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar
[2025-01-20 13:45:15,735][root][INFO] - Step 250880 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1154.7, step = 250880, mean_episode_return = 0.52583, mean_episode_step = 80.764, total_loss = 351.92, entropy_loss = -8.5839, pg_loss = 297.33, baseline_loss = 63.18, learner_queue_size = 32, _tick = 97, _time = 1.7374e+09)
[2025-01-20 13:45:20,740][root][INFO] - Step 250880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1159.8, step = 250880, mean_episode_return = 0.52583, mean_episode_step = 80.764, total_loss = 351.92, entropy_loss = -8.5839, pg_loss = 297.33, baseline_loss = 63.18, learner_queue_size = 32, _tick = 97, _time = 1.7374e+09)
[2025-01-20 13:45:25,745][root][INFO] - Step 253440 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1164.8, step = 253440, mean_episode_return = 0.3488, mean_episode_step = 78.266, total_loss = 613.36, entropy_loss = -8.5925, pg_loss = 553.0, baseline_loss = 68.955, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)
[2025-01-20 13:45:30,751][root][INFO] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1169.8, step = 253440, mean_episode_return = 0.3488, mean_episode_step = 78.266, total_loss = 613.36, entropy_loss = -8.5925, pg_loss = 553.0, baseline_loss = 68.955, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)
[2025-01-20 13:45:35,756][root][INFO] - Step 256000 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1174.8, step = 256000, mean_episode_return = 0.4804, mean_episode_step = 65.241, total_loss = -176.1, entropy_loss = -8.6467, pg_loss = -256.25, baseline_loss = 88.791, learner_queue_size = 32, _tick = 99, _time = 1.7374e+09)
[2025-01-20 13:45:40,762][root][INFO] - Step 258560 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1179.8, step = 258560, mean_episode_return = 0.48296, mean_episode_step = 79.5, total_loss = -277.38, entropy_loss = -8.5719, pg_loss = -336.61, baseline_loss = 67.8, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)
[2025-01-20 13:45:45,767][root][INFO] - Step 258560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1184.8, step = 258560, mean_episode_return = 0.48296, mean_episode_step = 79.5, total_loss = -277.38, entropy_loss = -8.5719, pg_loss = -336.61, baseline_loss = 67.8, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)
[2025-01-20 13:45:50,772][root][INFO] - Step 261120 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1189.8, step = 261120, mean_episode_return = 0.49012, mean_episode_step = 79.231, total_loss = 185.83, entropy_loss = -8.5585, pg_loss = 111.72, baseline_loss = 82.669, learner_queue_size = 32, _tick = 101, _time = 1.7374e+09)
[2025-01-20 13:45:55,778][root][INFO] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1194.8, step = 261120, mean_episode_return = 0.49012, mean_episode_step = 79.231, total_loss = 185.83, entropy_loss = -8.5585, pg_loss = 111.72, baseline_loss = 82.669, learner_queue_size = 32, _tick = 101, _time = 1.7374e+09)
[2025-01-20 13:46:00,784][root][INFO] - Step 263680 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1199.8, step = 263680, mean_episode_return = 0.5535, mean_episode_step = 71.811, total_loss = -273.04, entropy_loss = -8.5856, pg_loss = -348.56, baseline_loss = 84.104, learner_queue_size = 32, _tick = 102, _time = 1.7374e+09)
[2025-01-20 13:46:05,789][root][INFO] - Step 266240 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1204.8, step = 266240, mean_episode_return = 0.60393, mean_episode_step = 69.906, total_loss = -68.312, entropy_loss = -8.5672, pg_loss = -131.77, baseline_loss = 72.029, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)
[2025-01-20 13:46:10,795][root][INFO] - Step 266240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1209.8, step = 266240, mean_episode_return = 0.60393, mean_episode_step = 69.906, total_loss = -68.312, entropy_loss = -8.5672, pg_loss = -131.77, baseline_loss = 72.029, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)
[2025-01-20 13:46:15,801][root][INFO] - Step 268800 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1214.8, step = 268800, mean_episode_return = 0.51018, mean_episode_step = 82.574, total_loss = -269.15, entropy_loss = -8.418, pg_loss = -315.32, baseline_loss = 54.591, learner_queue_size = 32, _tick = 104, _time = 1.7374e+09)
[2025-01-20 13:46:20,810][root][INFO] - Step 268800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1219.8, step = 268800, mean_episode_return = 0.51018, mean_episode_step = 82.574, total_loss = -269.15, entropy_loss = -8.418, pg_loss = -315.32, baseline_loss = 54.591, learner_queue_size = 32, _tick = 104, _time = 1.7374e+09)
[2025-01-20 13:46:25,816][root][INFO] - Step 271360 @ 511.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1224.8, step = 271360, mean_episode_return = 0.43465, mean_episode_step = 66.442, total_loss = -58.139, entropy_loss = -8.402, pg_loss = -90.673, baseline_loss = 40.935, learner_queue_size = 32, _tick = 105, _time = 1.7374e+09)
[2025-01-20 13:46:30,821][root][INFO] - Step 273920 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1229.8, step = 273920, mean_episode_return = 0.37929, mean_episode_step = 67.436, total_loss = 290.08, entropy_loss = -8.3676, pg_loss = 257.17, baseline_loss = 41.283, learner_queue_size = 32, _tick = 106, _time = 1.7374e+09)
[2025-01-20 13:46:35,827][root][INFO] - Step 273920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1234.8, step = 273920, mean_episode_return = 0.37929, mean_episode_step = 67.436, total_loss = 290.08, entropy_loss = -8.3676, pg_loss = 257.17, baseline_loss = 41.283, learner_queue_size = 32, _tick = 106, _time = 1.7374e+09)
[2025-01-20 13:46:40,832][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 13:46:40,933][root][INFO] - Step 276480 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1239.9, step = 276480, mean_episode_return = 0.45974, mean_episode_step = 74.785, total_loss = 572.05, entropy_loss = -8.3929, pg_loss = 503.99, baseline_loss = 76.453, learner_queue_size = 32, _tick = 107, _time = 1.7374e+09)
[2025-01-20 13:46:45,939][root][INFO] - Step 279040 @ 501.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1245.0, step = 279040, mean_episode_return = 0.68015, mean_episode_step = 79.994, total_loss = 474.17, entropy_loss = -8.3963, pg_loss = 403.42, baseline_loss = 79.145, learner_queue_size = 32, _tick = 108, _time = 1.7374e+09)
[2025-01-20 13:46:50,944][root][INFO] - Step 279040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1250.0, step = 279040, mean_episode_return = 0.68015, mean_episode_step = 79.994, total_loss = 474.17, entropy_loss = -8.3963, pg_loss = 403.42, baseline_loss = 79.145, learner_queue_size = 32, _tick = 108, _time = 1.7374e+09)
[2025-01-20 13:46:55,950][root][INFO] - Step 281600 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1255.0, step = 281600, mean_episode_return = 0.55553, mean_episode_step = 74.011, total_loss = -13.565, entropy_loss = -8.4414, pg_loss = -93.241, baseline_loss = 88.117, learner_queue_size = 32, _tick = 109, _time = 1.7374e+09)
[2025-01-20 13:47:00,959][root][INFO] - Step 281600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1260.0, step = 281600, mean_episode_return = 0.55553, mean_episode_step = 74.011, total_loss = -13.565, entropy_loss = -8.4414, pg_loss = -93.241, baseline_loss = 88.117, learner_queue_size = 32, _tick = 109, _time = 1.7374e+09)
[2025-01-20 13:47:05,964][root][INFO] - Step 284160 @ 511.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1265.0, step = 284160, mean_episode_return = 0.1429, mean_episode_step = 75.779, total_loss = 118.18, entropy_loss = -8.4574, pg_loss = 63.34, baseline_loss = 63.302, learner_queue_size = 32, _tick = 110, _time = 1.7374e+09)
[2025-01-20 13:47:10,969][root][INFO] - Step 286720 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1270.0, step = 286720, mean_episode_return = 0.43446, mean_episode_step = 68.287, total_loss = -360.98, entropy_loss = -8.5467, pg_loss = -420.49, baseline_loss = 68.061, learner_queue_size = 32, _tick = 111, _time = 1.7374e+09)
[2025-01-20 13:47:15,976][root][INFO] - Step 286720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1275.0, step = 286720, mean_episode_return = 0.43446, mean_episode_step = 68.287, total_loss = -360.98, entropy_loss = -8.5467, pg_loss = -420.49, baseline_loss = 68.061, learner_queue_size = 32, _tick = 111, _time = 1.7374e+09)
[2025-01-20 13:47:20,981][root][INFO] - Step 289280 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1280.0, step = 289280, mean_episode_return = 0.57776, mean_episode_step = 66.127, total_loss = 113.14, entropy_loss = -8.5124, pg_loss = 39.786, baseline_loss = 81.867, learner_queue_size = 32, _tick = 112, _time = 1.7374e+09)
[2025-01-20 13:47:25,986][root][INFO] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1285.0, step = 289280, mean_episode_return = 0.57776, mean_episode_step = 66.127, total_loss = 113.14, entropy_loss = -8.5124, pg_loss = 39.786, baseline_loss = 81.867, learner_queue_size = 32, _tick = 112, _time = 1.7374e+09)
[2025-01-20 13:47:30,991][root][INFO] - Step 291840 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1290.0, step = 291840, mean_episode_return = 0.26077, mean_episode_step = 72.938, total_loss = 182.26, entropy_loss = -8.4536, pg_loss = 110.04, baseline_loss = 80.666, learner_queue_size = 32, _tick = 113, _time = 1.7374e+09)
[2025-01-20 13:47:35,996][root][INFO] - Step 294400 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1295.0, step = 294400, mean_episode_return = 0.58568, mean_episode_step = 77.358, total_loss = 394.83, entropy_loss = -8.474, pg_loss = 287.59, baseline_loss = 115.71, learner_queue_size = 32, _tick = 114, _time = 1.7374e+09)
[2025-01-20 13:47:41,001][root][INFO] - Step 294400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1300.0, step = 294400, mean_episode_return = 0.58568, mean_episode_step = 77.358, total_loss = 394.83, entropy_loss = -8.474, pg_loss = 287.59, baseline_loss = 115.71, learner_queue_size = 32, _tick = 114, _time = 1.7374e+09)
[2025-01-20 13:47:46,007][root][INFO] - Step 296960 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1305.0, step = 296960, mean_episode_return = 0.5925, mean_episode_step = 92.689, total_loss = -327.1, entropy_loss = -8.4254, pg_loss = -388.01, baseline_loss = 69.337, learner_queue_size = 32, _tick = 115, _time = 1.7374e+09)
[2025-01-20 13:47:51,012][root][INFO] - Step 299520 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1310.0, step = 299520, mean_episode_return = 0.56735, mean_episode_step = 67.867, total_loss = -279.91, entropy_loss = -8.4473, pg_loss = -364.68, baseline_loss = 93.217, learner_queue_size = 32, _tick = 116, _time = 1.7374e+09)
[2025-01-20 13:47:56,025][root][INFO] - Step 299520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1315.0, step = 299520, mean_episode_return = 0.56735, mean_episode_step = 67.867, total_loss = -279.91, entropy_loss = -8.4473, pg_loss = -364.68, baseline_loss = 93.217, learner_queue_size = 32, _tick = 116, _time = 1.7374e+09)
[2025-01-20 13:48:01,031][root][INFO] - Step 302080 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1320.0, step = 302080, mean_episode_return = 0.81044, mean_episode_step = 85.347, total_loss = 191.99, entropy_loss = -8.4072, pg_loss = 127.63, baseline_loss = 72.761, learner_queue_size = 32, _tick = 117, _time = 1.7374e+09)
[2025-01-20 13:48:06,037][root][INFO] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1325.1, step = 302080, mean_episode_return = 0.81044, mean_episode_step = 85.347, total_loss = 191.99, entropy_loss = -8.4072, pg_loss = 127.63, baseline_loss = 72.761, learner_queue_size = 32, _tick = 117, _time = 1.7374e+09)
[2025-01-20 13:48:11,042][root][INFO] - Step 304640 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1330.1, step = 304640, mean_episode_return = 0.80342, mean_episode_step = 84.848, total_loss = 45.935, entropy_loss = -8.4521, pg_loss = -33.574, baseline_loss = 87.961, learner_queue_size = 32, _tick = 118, _time = 1.7374e+09)
[2025-01-20 13:48:16,048][root][INFO] - Step 307200 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1335.1, step = 307200, mean_episode_return = 0.45128, mean_episode_step = 65.363, total_loss = -169.61, entropy_loss = -8.5076, pg_loss = -214.08, baseline_loss = 52.972, learner_queue_size = 32, _tick = 119, _time = 1.7374e+09)
[2025-01-20 13:48:21,055][root][INFO] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1340.1, step = 307200, mean_episode_return = 0.45128, mean_episode_step = 65.363, total_loss = -169.61, entropy_loss = -8.5076, pg_loss = -214.08, baseline_loss = 52.972, learner_queue_size = 32, _tick = 119, _time = 1.7374e+09)
[2025-01-20 13:48:26,061][root][INFO] - Step 309760 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1345.1, step = 309760, mean_episode_return = 0.5774, mean_episode_step = 84.59, total_loss = 180.22, entropy_loss = -8.4602, pg_loss = 143.59, baseline_loss = 45.086, learner_queue_size = 32, _tick = 120, _time = 1.7374e+09)
[2025-01-20 13:48:31,066][root][INFO] - Step 309760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1350.1, step = 309760, mean_episode_return = 0.5774, mean_episode_step = 84.59, total_loss = 180.22, entropy_loss = -8.4602, pg_loss = 143.59, baseline_loss = 45.086, learner_queue_size = 32, _tick = 120, _time = 1.7374e+09)
[2025-01-20 13:48:36,071][root][INFO] - Step 312320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1355.1, step = 312320, mean_episode_return = 0.565, mean_episode_step = 74.398, total_loss = 413.82, entropy_loss = -8.4211, pg_loss = 333.55, baseline_loss = 88.686, learner_queue_size = 32, _tick = 121, _time = 1.7374e+09)
[2025-01-20 13:48:41,076][root][INFO] - Step 314880 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1360.1, step = 314880, mean_episode_return = 0.48057, mean_episode_step = 72.002, total_loss = -172.09, entropy_loss = -8.4439, pg_loss = -242.53, baseline_loss = 78.88, learner_queue_size = 32, _tick = 122, _time = 1.7374e+09)
[2025-01-20 13:48:46,082][root][INFO] - Step 314880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1365.1, step = 314880, mean_episode_return = 0.48057, mean_episode_step = 72.002, total_loss = -172.09, entropy_loss = -8.4439, pg_loss = -242.53, baseline_loss = 78.88, learner_queue_size = 32, _tick = 122, _time = 1.7374e+09)
[2025-01-20 13:48:51,087][root][INFO] - Step 317440 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1370.1, step = 317440, mean_episode_return = 0.44381, mean_episode_step = 73.096, total_loss = -138.05, entropy_loss = -8.4636, pg_loss = -207.1, baseline_loss = 77.512, learner_queue_size = 32, _tick = 123, _time = 1.7374e+09)
[2025-01-20 13:48:56,092][root][INFO] - Step 320000 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1375.1, step = 320000, mean_episode_return = 0.44818, mean_episode_step = 68.323, total_loss = -115.5, entropy_loss = -8.4384, pg_loss = -155.49, baseline_loss = 48.436, learner_queue_size = 32, _tick = 124, _time = 1.7374e+09)
[2025-01-20 13:49:01,104][root][INFO] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1380.1, step = 320000, mean_episode_return = 0.44818, mean_episode_step = 68.323, total_loss = -115.5, entropy_loss = -8.4384, pg_loss = -155.49, baseline_loss = 48.436, learner_queue_size = 32, _tick = 124, _time = 1.7374e+09)
[2025-01-20 13:49:06,109][root][INFO] - Step 322560 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1385.1, step = 322560, mean_episode_return = 0.59142, mean_episode_step = 78.328, total_loss = 0.71503, entropy_loss = -8.3976, pg_loss = -23.384, baseline_loss = 32.497, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)
[2025-01-20 13:49:11,115][root][INFO] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1390.1, step = 322560, mean_episode_return = 0.59142, mean_episode_step = 78.328, total_loss = 0.71503, entropy_loss = -8.3976, pg_loss = -23.384, baseline_loss = 32.497, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)
[2025-01-20 13:49:16,120][root][INFO] - Step 325120 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1395.1, step = 325120, mean_episode_return = 0.521, mean_episode_step = 73.327, total_loss = 8.827, entropy_loss = -8.3565, pg_loss = -32.149, baseline_loss = 49.332, learner_queue_size = 32, _tick = 126, _time = 1.7374e+09)
[2025-01-20 13:49:21,127][root][INFO] - Step 327680 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1400.1, step = 327680, mean_episode_return = 0.51239, mean_episode_step = 71.269, total_loss = 677.08, entropy_loss = -8.2816, pg_loss = 619.49, baseline_loss = 65.871, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)
[2025-01-20 13:49:26,133][root][INFO] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1405.2, step = 327680, mean_episode_return = 0.51239, mean_episode_step = 71.269, total_loss = 677.08, entropy_loss = -8.2816, pg_loss = 619.49, baseline_loss = 65.871, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)
[2025-01-20 13:49:31,139][root][INFO] - Step 330240 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1410.2, step = 330240, mean_episode_return = 0.48573, mean_episode_step = 83.265, total_loss = 112.44, entropy_loss = -8.2426, pg_loss = 78.802, baseline_loss = 41.881, learner_queue_size = 32, _tick = 128, _time = 1.7374e+09)
[2025-01-20 13:49:36,146][root][INFO] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1415.2, step = 330240, mean_episode_return = 0.48573, mean_episode_step = 83.265, total_loss = 112.44, entropy_loss = -8.2426, pg_loss = 78.802, baseline_loss = 41.881, learner_queue_size = 32, _tick = 128, _time = 1.7374e+09)
[2025-01-20 13:49:41,153][root][INFO] - Step 332800 @ 511.1 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1420.2, step = 332800, mean_episode_return = 0.50122, mean_episode_step = 87.508, total_loss = 35.705, entropy_loss = -8.2498, pg_loss = -21.854, baseline_loss = 65.81, learner_queue_size = 32, _tick = 129, _time = 1.7374e+09)
[2025-01-20 13:49:46,159][root][INFO] - Step 335360 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1425.2, step = 335360, mean_episode_return = 0.71263, mean_episode_step = 82.604, total_loss = 86.186, entropy_loss = -8.2731, pg_loss = 39.523, baseline_loss = 54.936, learner_queue_size = 32, _tick = 130, _time = 1.7374e+09)
[2025-01-20 13:49:51,165][root][INFO] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1430.2, step = 335360, mean_episode_return = 0.71263, mean_episode_step = 82.604, total_loss = 86.186, entropy_loss = -8.2731, pg_loss = 39.523, baseline_loss = 54.936, learner_queue_size = 32, _tick = 130, _time = 1.7374e+09)
[2025-01-20 13:49:56,171][root][INFO] - Step 337920 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1435.2, step = 337920, mean_episode_return = 0.59216, mean_episode_step = 92.034, total_loss = 23.332, entropy_loss = -8.2719, pg_loss = -34.729, baseline_loss = 66.333, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)
[2025-01-20 13:50:01,177][root][INFO] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1440.2, step = 337920, mean_episode_return = 0.59216, mean_episode_step = 92.034, total_loss = 23.332, entropy_loss = -8.2719, pg_loss = -34.729, baseline_loss = 66.333, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)
[2025-01-20 13:50:06,182][root][INFO] - Step 340480 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1445.2, step = 340480, mean_episode_return = 0.42472, mean_episode_step = 82.964, total_loss = -98.963, entropy_loss = -8.2957, pg_loss = -144.76, baseline_loss = 54.088, learner_queue_size = 32, _tick = 132, _time = 1.7374e+09)
[2025-01-20 13:50:11,188][root][INFO] - Step 343040 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1450.2, step = 343040, mean_episode_return = 0.67326, mean_episode_step = 80.159, total_loss = 419.79, entropy_loss = -8.2932, pg_loss = 369.8, baseline_loss = 58.283, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)
[2025-01-20 13:50:16,193][root][INFO] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1455.2, step = 343040, mean_episode_return = 0.67326, mean_episode_step = 80.159, total_loss = 419.79, entropy_loss = -8.2932, pg_loss = 369.8, baseline_loss = 58.283, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)
[2025-01-20 13:50:21,198][root][INFO] - Step 345600 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1460.2, step = 345600, mean_episode_return = 0.61421, mean_episode_step = 77.8, total_loss = -219.8, entropy_loss = -8.2748, pg_loss = -259.93, baseline_loss = 48.407, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)
[2025-01-20 13:50:26,204][root][INFO] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1465.2, step = 345600, mean_episode_return = 0.61421, mean_episode_step = 77.8, total_loss = -219.8, entropy_loss = -8.2748, pg_loss = -259.93, baseline_loss = 48.407, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)
[2025-01-20 13:50:31,210][root][INFO] - Step 348160 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1470.2, step = 348160, mean_episode_return = 0.61111, mean_episode_step = 75.47, total_loss = 342.34, entropy_loss = -8.3083, pg_loss = 279.97, baseline_loss = 70.679, learner_queue_size = 32, _tick = 135, _time = 1.7374e+09)
[2025-01-20 13:50:36,216][root][INFO] - Step 350720 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1475.2, step = 350720, mean_episode_return = 0.59861, mean_episode_step = 83.28, total_loss = -99.342, entropy_loss = -8.28, pg_loss = -147.83, baseline_loss = 56.768, learner_queue_size = 32, _tick = 136, _time = 1.7374e+09)
[2025-01-20 13:50:41,222][root][INFO] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1480.2, step = 350720, mean_episode_return = 0.59861, mean_episode_step = 83.28, total_loss = -99.342, entropy_loss = -8.28, pg_loss = -147.83, baseline_loss = 56.768, learner_queue_size = 32, _tick = 136, _time = 1.7374e+09)
[2025-01-20 13:50:46,233][root][INFO] - Step 353280 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1485.2, step = 353280, mean_episode_return = 0.64245, mean_episode_step = 72.258, total_loss = 68.85, entropy_loss = -8.2853, pg_loss = 21.677, baseline_loss = 55.459, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)
[2025-01-20 13:50:51,238][root][INFO] - Step 353280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1490.3, step = 353280, mean_episode_return = 0.64245, mean_episode_step = 72.258, total_loss = 68.85, entropy_loss = -8.2853, pg_loss = 21.677, baseline_loss = 55.459, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)
[2025-01-20 13:50:56,243][root][INFO] - Step 355840 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1495.3, step = 355840, mean_episode_return = 0.63114, mean_episode_step = 74.782, total_loss = -93.458, entropy_loss = -8.3583, pg_loss = -123.46, baseline_loss = 38.361, learner_queue_size = 32, _tick = 138, _time = 1.7374e+09)
[2025-01-20 13:51:01,248][root][INFO] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1500.3, step = 355840, mean_episode_return = 0.63114, mean_episode_step = 74.782, total_loss = -93.458, entropy_loss = -8.3583, pg_loss = -123.46, baseline_loss = 38.361, learner_queue_size = 32, _tick = 138, _time = 1.7374e+09)
[2025-01-20 13:51:06,253][root][INFO] - Step 358400 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1505.3, step = 358400, mean_episode_return = 0.99469, mean_episode_step = 80.111, total_loss = 611.16, entropy_loss = -8.346, pg_loss = 574.01, baseline_loss = 45.495, learner_queue_size = 32, _tick = 139, _time = 1.7374e+09)
[2025-01-20 13:51:11,261][root][INFO] - Step 360960 @ 511.2 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1510.3, step = 360960, mean_episode_return = 0.48849, mean_episode_step = 70.432, total_loss = 284.07, entropy_loss = -8.307, pg_loss = 221.08, baseline_loss = 71.3, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)
[2025-01-20 13:51:16,271][root][INFO] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1515.3, step = 360960, mean_episode_return = 0.48849, mean_episode_step = 70.432, total_loss = 284.07, entropy_loss = -8.307, pg_loss = 221.08, baseline_loss = 71.3, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)
[2025-01-20 13:51:21,277][root][INFO] - Step 363520 @ 511.1 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1520.3, step = 363520, mean_episode_return = 0.96195, mean_episode_step = 89.107, total_loss = 0.44161, entropy_loss = -8.2265, pg_loss = -39.511, baseline_loss = 48.179, learner_queue_size = 32, _tick = 141, _time = 1.7374e+09)
[2025-01-20 13:51:26,287][root][INFO] - Step 366080 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1525.3, step = 366080, mean_episode_return = 0.64477, mean_episode_step = 78.722, total_loss = 217.12, entropy_loss = -8.1959, pg_loss = 145.98, baseline_loss = 79.338, learner_queue_size = 32, _tick = 142, _time = 1.7374e+09)
[2025-01-20 13:51:31,295][root][INFO] - Step 366080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1530.3, step = 366080, mean_episode_return = 0.64477, mean_episode_step = 78.722, total_loss = 217.12, entropy_loss = -8.1959, pg_loss = 145.98, baseline_loss = 79.338, learner_queue_size = 32, _tick = 142, _time = 1.7374e+09)
[2025-01-20 13:51:36,300][root][INFO] - Step 368640 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1535.3, step = 368640, mean_episode_return = 0.39744, mean_episode_step = 78.601, total_loss = -182.89, entropy_loss = -8.1683, pg_loss = -236.06, baseline_loss = 61.337, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)
[2025-01-20 13:51:41,306][root][INFO] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1540.3, step = 368640, mean_episode_return = 0.39744, mean_episode_step = 78.601, total_loss = -182.89, entropy_loss = -8.1683, pg_loss = -236.06, baseline_loss = 61.337, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)
[2025-01-20 13:51:46,312][root][INFO] - Step 371200 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1545.3, step = 371200, mean_episode_return = 0.79995, mean_episode_step = 80.451, total_loss = -32.067, entropy_loss = -8.176, pg_loss = -73.239, baseline_loss = 49.348, learner_queue_size = 32, _tick = 144, _time = 1.7374e+09)
[2025-01-20 13:51:51,319][root][INFO] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1550.3, step = 371200, mean_episode_return = 0.79995, mean_episode_step = 80.451, total_loss = -32.067, entropy_loss = -8.176, pg_loss = -73.239, baseline_loss = 49.348, learner_queue_size = 32, _tick = 144, _time = 1.7374e+09)
[2025-01-20 13:51:56,325][root][INFO] - Step 373760 @ 511.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1555.3, step = 373760, mean_episode_return = 0.55907, mean_episode_step = 87.539, total_loss = -219.6, entropy_loss = -8.1382, pg_loss = -266.91, baseline_loss = 55.442, learner_queue_size = 32, _tick = 145, _time = 1.7374e+09)
[2025-01-20 13:52:01,330][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar
[2025-01-20 13:52:01,368][root][INFO] - Step 376320 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1560.3, step = 376320, mean_episode_return = 0.63217, mean_episode_step = 79.627, total_loss = 77.554, entropy_loss = -8.1815, pg_loss = 38.246, baseline_loss = 47.49, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)
[2025-01-20 13:52:06,380][root][INFO] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1565.4, step = 376320, mean_episode_return = 0.63217, mean_episode_step = 79.627, total_loss = 77.554, entropy_loss = -8.1815, pg_loss = 38.246, baseline_loss = 47.49, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)
[2025-01-20 13:52:11,387][root][INFO] - Step 378880 @ 510.8 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1570.4, step = 378880, mean_episode_return = 0.50164, mean_episode_step = 85.52, total_loss = -297.32, entropy_loss = -8.1469, pg_loss = -346.21, baseline_loss = 57.032, learner_queue_size = 32, _tick = 147, _time = 1.7374e+09)
[2025-01-20 13:52:16,394][root][INFO] - Step 381440 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1575.4, step = 381440, mean_episode_return = 0.53125, mean_episode_step = 82.38, total_loss = 67.694, entropy_loss = -8.1694, pg_loss = 34.316, baseline_loss = 41.547, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)
[2025-01-20 13:52:21,401][root][INFO] - Step 381440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1580.4, step = 381440, mean_episode_return = 0.53125, mean_episode_step = 82.38, total_loss = 67.694, entropy_loss = -8.1694, pg_loss = 34.316, baseline_loss = 41.547, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)
[2025-01-20 13:52:26,406][root][INFO] - Step 384000 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1585.4, step = 384000, mean_episode_return = 0.69097, mean_episode_step = 75.802, total_loss = 19.111, entropy_loss = -8.1476, pg_loss = -33.46, baseline_loss = 60.719, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)
[2025-01-20 13:52:31,417][root][INFO] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1590.4, step = 384000, mean_episode_return = 0.69097, mean_episode_step = 75.802, total_loss = 19.111, entropy_loss = -8.1476, pg_loss = -33.46, baseline_loss = 60.719, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)
[2025-01-20 13:52:36,423][root][INFO] - Step 386560 @ 510.8 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1595.4, step = 386560, mean_episode_return = 0.78507, mean_episode_step = 89.562, total_loss = 62.542, entropy_loss = -8.1613, pg_loss = 23.106, baseline_loss = 47.597, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)
[2025-01-20 13:52:41,435][root][INFO] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1600.4, step = 386560, mean_episode_return = 0.78507, mean_episode_step = 89.562, total_loss = 62.542, entropy_loss = -8.1613, pg_loss = 23.106, baseline_loss = 47.597, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)
[2025-01-20 13:52:46,441][root][INFO] - Step 389120 @ 510.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1605.5, step = 389120, mean_episode_return = 0.71288, mean_episode_step = 78.67, total_loss = -127.7, entropy_loss = -8.1109, pg_loss = -184.66, baseline_loss = 65.077, learner_queue_size = 32, _tick = 151, _time = 1.7374e+09)
[2025-01-20 13:52:51,446][root][INFO] - Step 391680 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1610.5, step = 391680, mean_episode_return = 0.60864, mean_episode_step = 70.483, total_loss = -214.26, entropy_loss = -8.1361, pg_loss = -256.89, baseline_loss = 50.769, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)
[2025-01-20 13:52:56,453][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1615.5, step = 391680, mean_episode_return = 0.60864, mean_episode_step = 70.483, total_loss = -214.26, entropy_loss = -8.1361, pg_loss = -256.89, baseline_loss = 50.769, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)
[2025-01-20 13:53:01,458][root][INFO] - Step 394240 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1620.5, step = 394240, mean_episode_return = 0.56918, mean_episode_step = 63.004, total_loss = 196.43, entropy_loss = -8.1237, pg_loss = 146.56, baseline_loss = 57.995, learner_queue_size = 32, _tick = 153, _time = 1.7374e+09)
[2025-01-20 13:53:06,460][root][INFO] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1625.5, step = 394240, mean_episode_return = 0.56918, mean_episode_step = 63.004, total_loss = 196.43, entropy_loss = -8.1237, pg_loss = 146.56, baseline_loss = 57.995, learner_queue_size = 32, _tick = 153, _time = 1.7374e+09)
[2025-01-20 13:53:11,465][root][INFO] - Step 396800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1630.5, step = 396800, mean_episode_return = 0.61359, mean_episode_step = 74.807, total_loss = 68.988, entropy_loss = -8.1087, pg_loss = 8.1343, baseline_loss = 68.963, learner_queue_size = 32, _tick = 154, _time = 1.7374e+09)
[2025-01-20 13:53:16,471][root][INFO] - Step 399360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1635.5, step = 399360, mean_episode_return = 0.64673, mean_episode_step = 75.142, total_loss = 437.95, entropy_loss = -8.0792, pg_loss = 365.14, baseline_loss = 80.882, learner_queue_size = 32, _tick = 155, _time = 1.7374e+09)
[2025-01-20 13:53:21,479][root][INFO] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1640.5, step = 399360, mean_episode_return = 0.64673, mean_episode_step = 75.142, total_loss = 437.95, entropy_loss = -8.0792, pg_loss = 365.14, baseline_loss = 80.882, learner_queue_size = 32, _tick = 155, _time = 1.7374e+09)
[2025-01-20 13:53:26,485][root][INFO] - Step 401920 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1645.5, step = 401920, mean_episode_return = 0.5769, mean_episode_step = 80.961, total_loss = -332.72, entropy_loss = -8.0771, pg_loss = -373.96, baseline_loss = 49.32, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)
[2025-01-20 13:53:31,495][root][INFO] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1650.5, step = 401920, mean_episode_return = 0.5769, mean_episode_step = 80.961, total_loss = -332.72, entropy_loss = -8.0771, pg_loss = -373.96, baseline_loss = 49.32, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)
[2025-01-20 13:53:36,501][root][INFO] - Step 404480 @ 510.9 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1655.5, step = 404480, mean_episode_return = 0.49356, mean_episode_step = 79.397, total_loss = -519.71, entropy_loss = -8.0983, pg_loss = -559.79, baseline_loss = 48.177, learner_queue_size = 32, _tick = 157, _time = 1.7374e+09)
[2025-01-20 13:53:41,517][root][INFO] - Step 407040 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1660.5, step = 407040, mean_episode_return = 0.83189, mean_episode_step = 96.517, total_loss = 16.101, entropy_loss = -8.1091, pg_loss = -26.902, baseline_loss = 51.112, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)
[2025-01-20 13:53:46,522][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1665.5, step = 407040, mean_episode_return = 0.83189, mean_episode_step = 96.517, total_loss = 16.101, entropy_loss = -8.1091, pg_loss = -26.902, baseline_loss = 51.112, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)
[2025-01-20 13:53:51,528][root][INFO] - Step 409600 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1670.5, step = 409600, mean_episode_return = 0.40284, mean_episode_step = 76.164, total_loss = -512.12, entropy_loss = -8.0563, pg_loss = -561.48, baseline_loss = 57.409, learner_queue_size = 32, _tick = 159, _time = 1.7374e+09)
[2025-01-20 13:53:56,533][root][INFO] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1675.6, step = 409600, mean_episode_return = 0.40284, mean_episode_step = 76.164, total_loss = -512.12, entropy_loss = -8.0563, pg_loss = -561.48, baseline_loss = 57.409, learner_queue_size = 32, _tick = 159, _time = 1.7374e+09)
[2025-01-20 13:54:01,538][root][INFO] - Step 412160 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1680.6, step = 412160, mean_episode_return = 0.50709, mean_episode_step = 76.657, total_loss = 13.509, entropy_loss = -8.0627, pg_loss = -37.015, baseline_loss = 58.587, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)
[2025-01-20 13:54:06,543][root][INFO] - Step 414720 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1685.6, step = 414720, mean_episode_return = 0.54673, mean_episode_step = 66.192, total_loss = 505.31, entropy_loss = -8.1168, pg_loss = 440.97, baseline_loss = 72.451, learner_queue_size = 32, _tick = 161, _time = 1.7374e+09)
[2025-01-20 13:54:11,549][root][INFO] - Step 414720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1690.6, step = 414720, mean_episode_return = 0.54673, mean_episode_step = 66.192, total_loss = 505.31, entropy_loss = -8.1168, pg_loss = 440.97, baseline_loss = 72.451, learner_queue_size = 32, _tick = 161, _time = 1.7374e+09)
[2025-01-20 13:54:16,555][root][INFO] - Step 417280 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1695.6, step = 417280, mean_episode_return = 0.47079, mean_episode_step = 86.316, total_loss = 127.72, entropy_loss = -8.0931, pg_loss = 76.319, baseline_loss = 59.492, learner_queue_size = 32, _tick = 162, _time = 1.7374e+09)
[2025-01-20 13:54:21,560][root][INFO] - Step 419840 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1700.6, step = 419840, mean_episode_return = 0.56548, mean_episode_step = 78.163, total_loss = 172.14, entropy_loss = -8.0751, pg_loss = 112.24, baseline_loss = 67.976, learner_queue_size = 32, _tick = 163, _time = 1.7374e+09)
[2025-01-20 13:54:26,567][root][INFO] - Step 419840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1705.6, step = 419840, mean_episode_return = 0.56548, mean_episode_step = 78.163, total_loss = 172.14, entropy_loss = -8.0751, pg_loss = 112.24, baseline_loss = 67.976, learner_queue_size = 32, _tick = 163, _time = 1.7374e+09)
[2025-01-20 13:54:31,605][root][INFO] - Step 422400 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1710.6, step = 422400, mean_episode_return = 0.61675, mean_episode_step = 80.855, total_loss = 221.93, entropy_loss = -8.0458, pg_loss = 137.33, baseline_loss = 92.637, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)
[2025-01-20 13:54:36,611][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1715.6, step = 422400, mean_episode_return = 0.61675, mean_episode_step = 80.855, total_loss = 221.93, entropy_loss = -8.0458, pg_loss = 137.33, baseline_loss = 92.637, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)
[2025-01-20 13:54:41,617][root][INFO] - Step 424960 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1720.6, step = 424960, mean_episode_return = 0.6359, mean_episode_step = 86.042, total_loss = 411.04, entropy_loss = -8.0446, pg_loss = 327.29, baseline_loss = 91.793, learner_queue_size = 32, _tick = 165, _time = 1.7374e+09)
[2025-01-20 13:54:46,623][root][INFO] - Step 427520 @ 511.4 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 1725.6, step = 427520, mean_episode_return = 0.66273, mean_episode_step = 79.552, total_loss = -5.3892, entropy_loss = -8.0568, pg_loss = -89.199, baseline_loss = 91.866, learner_queue_size = 32, _tick = 166, _time = 1.7374e+09)
[2025-01-20 13:54:51,629][root][INFO] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1730.6, step = 427520, mean_episode_return = 0.66273, mean_episode_step = 79.552, total_loss = -5.3892, entropy_loss = -8.0568, pg_loss = -89.199, baseline_loss = 91.866, learner_queue_size = 32, _tick = 166, _time = 1.7374e+09)
[2025-01-20 13:54:56,636][root][INFO] - Step 430080 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1735.7, step = 430080, mean_episode_return = 0.76136, mean_episode_step = 74.853, total_loss = 9.3056, entropy_loss = -8.0185, pg_loss = -44.696, baseline_loss = 62.02, learner_queue_size = 32, _tick = 167, _time = 1.7374e+09)
[2025-01-20 13:55:01,638][root][INFO] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1740.7, step = 430080, mean_episode_return = 0.76136, mean_episode_step = 74.853, total_loss = 9.3056, entropy_loss = -8.0185, pg_loss = -44.696, baseline_loss = 62.02, learner_queue_size = 32, _tick = 167, _time = 1.7374e+09)
[2025-01-20 13:55:06,643][root][INFO] - Step 432640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1745.7, step = 432640, mean_episode_return = 0.83154, mean_episode_step = 78.556, total_loss = 178.62, entropy_loss = -8.0481, pg_loss = 120.34, baseline_loss = 66.33, learner_queue_size = 32, _tick = 168, _time = 1.7374e+09)
[2025-01-20 13:55:11,650][root][INFO] - Step 435200 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1750.7, step = 435200, mean_episode_return = 0.39317, mean_episode_step = 72.168, total_loss = -257.11, entropy_loss = -8.0362, pg_loss = -314.55, baseline_loss = 65.484, learner_queue_size = 32, _tick = 169, _time = 1.7374e+09)
[2025-01-20 13:55:16,657][root][INFO] - Step 435200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1755.7, step = 435200, mean_episode_return = 0.39317, mean_episode_step = 72.168, total_loss = -257.11, entropy_loss = -8.0362, pg_loss = -314.55, baseline_loss = 65.484, learner_queue_size = 32, _tick = 169, _time = 1.7374e+09)
[2025-01-20 13:55:21,663][root][INFO] - Step 437760 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1760.7, step = 437760, mean_episode_return = 0.52618, mean_episode_step = 68.354, total_loss = -324.4, entropy_loss = -8.0507, pg_loss = -385.35, baseline_loss = 69.002, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)
[2025-01-20 13:55:26,673][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1765.7, step = 437760, mean_episode_return = 0.52618, mean_episode_step = 68.354, total_loss = -324.4, entropy_loss = -8.0507, pg_loss = -385.35, baseline_loss = 69.002, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)
[2025-01-20 13:55:31,679][root][INFO] - Step 440320 @ 510.9 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1770.7, step = 440320, mean_episode_return = 0.56914, mean_episode_step = 67.992, total_loss = -63.547, entropy_loss = -8.0671, pg_loss = -117.15, baseline_loss = 61.671, learner_queue_size = 32, _tick = 171, _time = 1.7374e+09)
[2025-01-20 13:55:36,685][root][INFO] - Step 442880 @ 511.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1775.7, step = 442880, mean_episode_return = 0.54666, mean_episode_step = 67.818, total_loss = 9.5484, entropy_loss = -8.0822, pg_loss = -39.744, baseline_loss = 57.374, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)
[2025-01-20 13:55:41,691][root][INFO] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1780.7, step = 442880, mean_episode_return = 0.54666, mean_episode_step = 67.818, total_loss = 9.5484, entropy_loss = -8.0822, pg_loss = -39.744, baseline_loss = 57.374, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)
[2025-01-20 13:55:46,696][root][INFO] - Step 445440 @ 511.5 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1785.7, step = 445440, mean_episode_return = 0.86833, mean_episode_step = 87.421, total_loss = 34.339, entropy_loss = -8.0935, pg_loss = -3.4805, baseline_loss = 45.913, learner_queue_size = 32, _tick = 173, _time = 1.7374e+09)
[2025-01-20 13:55:51,701][root][INFO] - Step 445440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1790.7, step = 445440, mean_episode_return = 0.86833, mean_episode_step = 87.421, total_loss = 34.339, entropy_loss = -8.0935, pg_loss = -3.4805, baseline_loss = 45.913, learner_queue_size = 32, _tick = 173, _time = 1.7374e+09)
[2025-01-20 13:55:56,710][root][INFO] - Step 448000 @ 511.1 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1795.7, step = 448000, mean_episode_return = 0.64667, mean_episode_step = 69.62, total_loss = 14.319, entropy_loss = -8.0855, pg_loss = -47.227, baseline_loss = 69.631, learner_queue_size = 32, _tick = 174, _time = 1.7374e+09)
[2025-01-20 13:56:01,716][root][INFO] - Step 450560 @ 511.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1800.7, step = 450560, mean_episode_return = 0.54581, mean_episode_step = 74.432, total_loss = 118.24, entropy_loss = -8.0742, pg_loss = 71.722, baseline_loss = 54.594, learner_queue_size = 32, _tick = 175, _time = 1.7374e+09)
[2025-01-20 13:56:06,721][root][INFO] - Step 450560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1805.7, step = 450560, mean_episode_return = 0.54581, mean_episode_step = 74.432, total_loss = 118.24, entropy_loss = -8.0742, pg_loss = 71.722, baseline_loss = 54.594, learner_queue_size = 32, _tick = 175, _time = 1.7374e+09)
[2025-01-20 13:56:11,726][root][INFO] - Step 453120 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1810.7, step = 453120, mean_episode_return = 0.39393, mean_episode_step = 68.576, total_loss = -100.87, entropy_loss = -8.0522, pg_loss = -164.08, baseline_loss = 71.259, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)
[2025-01-20 13:56:16,737][root][INFO] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1815.8, step = 453120, mean_episode_return = 0.39393, mean_episode_step = 68.576, total_loss = -100.87, entropy_loss = -8.0522, pg_loss = -164.08, baseline_loss = 71.259, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)
[2025-01-20 13:56:21,746][root][INFO] - Step 455680 @ 510.6 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1820.8, step = 455680, mean_episode_return = 0.54564, mean_episode_step = 79.52, total_loss = 197.64, entropy_loss = -8.0285, pg_loss = 141.77, baseline_loss = 63.894, learner_queue_size = 32, _tick = 177, _time = 1.7374e+09)
[2025-01-20 13:56:26,751][root][INFO] - Step 455680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1825.8, step = 455680, mean_episode_return = 0.54564, mean_episode_step = 79.52, total_loss = 197.64, entropy_loss = -8.0285, pg_loss = 141.77, baseline_loss = 63.894, learner_queue_size = 32, _tick = 177, _time = 1.7374e+09)
[2025-01-20 13:56:31,757][root][INFO] - Step 458240 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1830.8, step = 458240, mean_episode_return = 0.86173, mean_episode_step = 82.689, total_loss = 74.276, entropy_loss = -8.0419, pg_loss = 18.905, baseline_loss = 63.414, learner_queue_size = 32, _tick = 178, _time = 1.7374e+09)
[2025-01-20 13:56:36,762][root][INFO] - Step 460800 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1835.8, step = 460800, mean_episode_return = 0.60723, mean_episode_step = 77.487, total_loss = -9.379, entropy_loss = -8.0323, pg_loss = -70.224, baseline_loss = 68.878, learner_queue_size = 32, _tick = 179, _time = 1.7374e+09)
[2025-01-20 13:56:41,768][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 13:56:42,324][root][INFO] - Step 460800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1840.8, step = 460800, mean_episode_return = 0.60723, mean_episode_step = 77.487, total_loss = -9.379, entropy_loss = -8.0323, pg_loss = -70.224, baseline_loss = 68.878, learner_queue_size = 32, _tick = 179, _time = 1.7374e+09)
[2025-01-20 13:56:47,354][root][INFO] - Step 463360 @ 458.3 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1846.4, step = 463360, mean_episode_return = 0.50043, mean_episode_step = 83.806, total_loss = -135.31, entropy_loss = -8.0382, pg_loss = -202.85, baseline_loss = 75.575, learner_queue_size = 32, _tick = 180, _time = 1.7374e+09)
[2025-01-20 13:56:52,365][root][INFO] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1851.4, step = 463360, mean_episode_return = 0.50043, mean_episode_step = 83.806, total_loss = -135.31, entropy_loss = -8.0382, pg_loss = -202.85, baseline_loss = 75.575, learner_queue_size = 32, _tick = 180, _time = 1.7374e+09)
[2025-01-20 13:56:57,371][root][INFO] - Step 465920 @ 511.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1856.4, step = 465920, mean_episode_return = 0.69888, mean_episode_step = 94.346, total_loss = -91.091, entropy_loss = -8.0394, pg_loss = -131.12, baseline_loss = 48.066, learner_queue_size = 32, _tick = 181, _time = 1.7374e+09)
[2025-01-20 13:57:02,376][root][INFO] - Step 468480 @ 511.5 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1861.4, step = 468480, mean_episode_return = 0.43177, mean_episode_step = 73.908, total_loss = -207.94, entropy_loss = -8.0453, pg_loss = -268.32, baseline_loss = 68.429, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)
[2025-01-20 13:57:07,401][root][INFO] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1866.4, step = 468480, mean_episode_return = 0.43177, mean_episode_step = 73.908, total_loss = -207.94, entropy_loss = -8.0453, pg_loss = -268.32, baseline_loss = 68.429, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)
[2025-01-20 13:57:12,406][root][INFO] - Step 471040 @ 509.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1871.4, step = 471040, mean_episode_return = 0.74167, mean_episode_step = 87.019, total_loss = 149.59, entropy_loss = -8.0469, pg_loss = 90.275, baseline_loss = 67.367, learner_queue_size = 32, _tick = 183, _time = 1.7374e+09)
[2025-01-20 13:57:17,417][root][INFO] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1876.4, step = 471040, mean_episode_return = 0.74167, mean_episode_step = 87.019, total_loss = 149.59, entropy_loss = -8.0469, pg_loss = 90.275, baseline_loss = 67.367, learner_queue_size = 32, _tick = 183, _time = 1.7374e+09)
[2025-01-20 13:57:22,424][root][INFO] - Step 473600 @ 510.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1881.4, step = 473600, mean_episode_return = 0.39531, mean_episode_step = 70.029, total_loss = -378.63, entropy_loss = -8.033, pg_loss = -432.7, baseline_loss = 62.103, learner_queue_size = 32, _tick = 184, _time = 1.7374e+09)
[2025-01-20 13:57:27,430][root][INFO] - Step 476160 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1886.4, step = 476160, mean_episode_return = 0.62022, mean_episode_step = 72.682, total_loss = 298.21, entropy_loss = -8.0148, pg_loss = 243.65, baseline_loss = 62.574, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)
[2025-01-20 13:57:32,436][root][INFO] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1891.5, step = 476160, mean_episode_return = 0.62022, mean_episode_step = 72.682, total_loss = 298.21, entropy_loss = -8.0148, pg_loss = 243.65, baseline_loss = 62.574, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)
[2025-01-20 13:57:37,441][root][INFO] - Step 478720 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1896.5, step = 478720, mean_episode_return = 0.53348, mean_episode_step = 84.444, total_loss = -398.25, entropy_loss = -8.016, pg_loss = -430.1, baseline_loss = 39.873, learner_queue_size = 32, _tick = 186, _time = 1.7374e+09)
[2025-01-20 13:57:42,642][root][INFO] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1901.5, step = 478720, mean_episode_return = 0.53348, mean_episode_step = 84.444, total_loss = -398.25, entropy_loss = -8.016, pg_loss = -430.1, baseline_loss = 39.873, learner_queue_size = 32, _tick = 186, _time = 1.7374e+09)
[2025-01-20 13:57:47,649][root][INFO] - Step 481280 @ 497.0 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1906.7, step = 481280, mean_episode_return = 0.65962, mean_episode_step = 66.781, total_loss = 227.25, entropy_loss = -8.0239, pg_loss = 156.07, baseline_loss = 79.206, learner_queue_size = 32, _tick = 187, _time = 1.7374e+09)
[2025-01-20 13:57:52,659][root][INFO] - Step 481280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1911.7, step = 481280, mean_episode_return = 0.65962, mean_episode_step = 66.781, total_loss = 227.25, entropy_loss = -8.0239, pg_loss = 156.07, baseline_loss = 79.206, learner_queue_size = 32, _tick = 187, _time = 1.7374e+09)
[2025-01-20 13:57:57,665][root][INFO] - Step 483840 @ 510.9 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1916.7, step = 483840, mean_episode_return = 0.74494, mean_episode_step = 73.257, total_loss = 46.537, entropy_loss = -8.0247, pg_loss = -11.18, baseline_loss = 65.741, learner_queue_size = 32, _tick = 188, _time = 1.7374e+09)
[2025-01-20 13:58:02,671][root][INFO] - Step 486400 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1921.7, step = 486400, mean_episode_return = 0.61602, mean_episode_step = 74.597, total_loss = 183.79, entropy_loss = -8.0257, pg_loss = 99.741, baseline_loss = 92.075, learner_queue_size = 32, _tick = 189, _time = 1.7374e+09)
[2025-01-20 13:58:07,678][root][INFO] - Step 486400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1926.7, step = 486400, mean_episode_return = 0.61602, mean_episode_step = 74.597, total_loss = 183.79, entropy_loss = -8.0257, pg_loss = 99.741, baseline_loss = 92.075, learner_queue_size = 32, _tick = 189, _time = 1.7374e+09)
[2025-01-20 13:58:12,683][root][INFO] - Step 488960 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1931.7, step = 488960, mean_episode_return = 0.4179, mean_episode_step = 82.068, total_loss = 488.86, entropy_loss = -8.0038, pg_loss = 397.3, baseline_loss = 99.567, learner_queue_size = 32, _tick = 190, _time = 1.7374e+09)
[2025-01-20 13:58:17,692][root][INFO] - Step 488960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1936.7, step = 488960, mean_episode_return = 0.4179, mean_episode_step = 82.068, total_loss = 488.86, entropy_loss = -8.0038, pg_loss = 397.3, baseline_loss = 99.567, learner_queue_size = 32, _tick = 190, _time = 1.7374e+09)
[2025-01-20 13:58:22,698][root][INFO] - Step 491520 @ 511.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1941.7, step = 491520, mean_episode_return = 0.35767, mean_episode_step = 69.679, total_loss = -56.541, entropy_loss = -7.9905, pg_loss = -111.8, baseline_loss = 63.25, learner_queue_size = 32, _tick = 191, _time = 1.7374e+09)
[2025-01-20 13:58:27,706][root][INFO] - Step 494080 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1946.7, step = 494080, mean_episode_return = 0.61837, mean_episode_step = 95.493, total_loss = 180.02, entropy_loss = -7.9806, pg_loss = 129.21, baseline_loss = 58.786, learner_queue_size = 32, _tick = 192, _time = 1.7374e+09)
[2025-01-20 13:58:32,711][root][INFO] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1951.7, step = 494080, mean_episode_return = 0.61837, mean_episode_step = 95.493, total_loss = 180.02, entropy_loss = -7.9806, pg_loss = 129.21, baseline_loss = 58.786, learner_queue_size = 32, _tick = 192, _time = 1.7374e+09)
[2025-01-20 13:58:37,718][root][INFO] - Step 496640 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1956.7, step = 496640, mean_episode_return = 0.81343, mean_episode_step = 84.339, total_loss = 165.99, entropy_loss = -7.9954, pg_loss = 123.16, baseline_loss = 50.829, learner_queue_size = 32, _tick = 193, _time = 1.7374e+09)
[2025-01-20 13:58:42,760][root][INFO] - Step 496640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1961.7, step = 496640, mean_episode_return = 0.81343, mean_episode_step = 84.339, total_loss = 165.99, entropy_loss = -7.9954, pg_loss = 123.16, baseline_loss = 50.829, learner_queue_size = 32, _tick = 193, _time = 1.7374e+09)
[2025-01-20 13:58:47,783][root][INFO] - Step 499200 @ 506.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1966.8, step = 499200, mean_episode_return = 0.43703, mean_episode_step = 68.439, total_loss = 482.06, entropy_loss = -7.9993, pg_loss = 371.49, baseline_loss = 118.58, learner_queue_size = 32, _tick = 194, _time = 1.7374e+09)
[2025-01-20 13:58:52,795][root][INFO] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1971.8, step = 499200, mean_episode_return = 0.43703, mean_episode_step = 68.439, total_loss = 482.06, entropy_loss = -7.9993, pg_loss = 371.49, baseline_loss = 118.58, learner_queue_size = 32, _tick = 194, _time = 1.7374e+09)
[2025-01-20 13:58:57,801][root][INFO] - Step 501760 @ 510.8 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1976.8, step = 501760, mean_episode_return = 0.69325, mean_episode_step = 95.66, total_loss = -346.7, entropy_loss = -8.0279, pg_loss = -379.31, baseline_loss = 40.637, learner_queue_size = 32, _tick = 195, _time = 1.7374e+09)
[2025-01-20 13:58:57,801][root][INFO] - Learning finished after 501760 steps.
[2025-01-20 13:58:57,801][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 14:07:52,610][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,610][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,612][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,614][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,614][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,615][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,616][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,616][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,616][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,617][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,617][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,621][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,622][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,623][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,623][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,623][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,625][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,625][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,626][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,627][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,627][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,628][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,629][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,630][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,629][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,631][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,632][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,633][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,633][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,634][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,635][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,636][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,636][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,639][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,639][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,639][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,639][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,643][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,643][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,637][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,621][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,648][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,649][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,649][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,649][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,628][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,651][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,653][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,656][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,657][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,659][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,660][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,660][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,663][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,663][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,663][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,663][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,666][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,667][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,669][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,669][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,672][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,673][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,673][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,673][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,674][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,677][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,678][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,679][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,680][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,681][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,682][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,678][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,678][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,682][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,683][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,683][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,677][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,685][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,688][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,689][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,690][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,688][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,670][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,693][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,695][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,696][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,696][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,697][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,697][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,699][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,703][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,703][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,704][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,704][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,705][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,707][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,709][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,709][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,709][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,709][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,712][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,712][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,714][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,715][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,715][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,719][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,719][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,719][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,719][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,720][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,720][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,708][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,708][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,703][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,709][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,723][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,725][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,717][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,729][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,729][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,731][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,732][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,733][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,736][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,736][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,736][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,739][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,740][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,742][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,743][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,744][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,744][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,745][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,746][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,748][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,748][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,748][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,749][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,749][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,688][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,751][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,751][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,751][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,752][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,748][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,754][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,755][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,755][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,728][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,693][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,695][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,758][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,759][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,759][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,692][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,760][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,760][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,724][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,762][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,758][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,702][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,762][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,763][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,727][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,725][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,764][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,765][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,765][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,766][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,766][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,767][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,767][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,761][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,769][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,770][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,771][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,773][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,775][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,728][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,779][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,782][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,784][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,768][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 14:07:52,757][nle.env.base][INFO] - Not saving any NLE data.
