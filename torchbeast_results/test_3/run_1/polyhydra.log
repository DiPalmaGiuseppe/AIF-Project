[2025-01-17 15:42:13,241][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 15:42:13,292][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Custom-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-17 15:42:13,306][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 15:42:13,307][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 15:42:13,312][root][INFO] - Logging results to /opt/minihack
[2025-01-17 15:42:13,368][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 15:42:13,368][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 15:42:13,369][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 15:42:13,369][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 15:42:13,369][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 15:42:13,369][root][INFO] - Not using CUDA.
[2025-01-17 15:42:13,378][root][INFO] - Using model baseline
[2025-01-17 15:51:45,680][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 15:51:45,738][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Custom-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-17 15:52:08,358][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 15:52:08,409][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Custom-Skill-v1
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-17 15:52:08,424][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 15:52:08,425][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 15:52:08,429][root][INFO] - Logging results to /opt/minihack
[2025-01-17 15:52:08,476][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 15:52:08,477][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 15:52:08,477][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 15:52:08,477][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 15:52:08,477][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 15:52:08,477][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 15:52:08,477][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 15:52:08,477][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 15:52:08,478][root][INFO] - Not using CUDA.
[2025-01-17 15:52:08,487][root][INFO] - Using model baseline
[2025-01-17 16:01:18,996][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:01:19,053][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-17 16:01:19,069][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:01:19,069][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:01:19,075][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:01:19,126][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:01:19,126][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:01:19,126][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:01:19,126][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:01:19,126][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:01:19,126][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:01:19,126][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:01:19,126][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:01:19,127][root][INFO] - Not using CUDA.
[2025-01-17 16:01:19,136][root][INFO] - Using model baseline
[2025-01-17 16:13:08,250][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:13:08,299][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-17 16:13:08,315][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:13:08,315][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:13:08,320][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:13:08,368][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:13:08,368][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:13:08,368][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:13:08,368][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:13:08,368][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:13:08,368][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:13:08,368][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:13:08,368][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:13:08,369][root][INFO] - Not using CUDA.
[2025-01-17 16:13:08,378][root][INFO] - Using model baseline
[2025-01-17 16:14:27,277][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:14:27,292][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:14:27,309][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:14:27,309][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:14:27,314][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:14:27,328][git.cmd][DEBUG] - Popen(['git', 'cat-file', '--batch-check'], cwd=/opt/minihack, stdin=<valid stream>, shell=False, universal_newlines=False)
[2025-01-17 16:14:27,344][git.cmd][DEBUG] - Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/opt/minihack, stdin=None, shell=False, universal_newlines=False)
[2025-01-17 16:14:27,354][git.cmd][DEBUG] - Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/opt/minihack, stdin=None, shell=False, universal_newlines=False)
[2025-01-17 16:14:27,365][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:14:27,365][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:14:27,366][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:14:27,366][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:14:27,366][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:14:27,366][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:14:27,366][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:14:27,366][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:14:27,366][root][INFO] - Not using CUDA.
[2025-01-17 16:14:27,376][root][INFO] - Using model baseline
[2025-01-17 16:16:23,439][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:16:23,489][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: rnd
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:16:23,504][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:16:23,505][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:16:23,510][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:16:23,559][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:16:23,559][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:16:23,559][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:16:23,559][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:16:23,559][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:16:23,559][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:16:23,559][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:16:23,560][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:16:23,560][root][INFO] - Not using CUDA.
[2025-01-17 16:16:23,569][root][INFO] - Using model rnd
[2025-01-17 16:17:59,272][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:17:59,322][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:17:59,338][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:17:59,339][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:17:59,343][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:17:59,396][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:17:59,396][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:17:59,396][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:17:59,396][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:17:59,396][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:17:59,396][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:17:59,396][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:17:59,397][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:17:59,397][root][INFO] - Not using CUDA.
[2025-01-17 16:17:59,410][root][INFO] - Using model baseline
[2025-01-17 16:19:35,356][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:19:35,418][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:19:35,437][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:19:35,437][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:19:35,442][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:19:35,490][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:19:35,490][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:19:35,490][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:19:35,490][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:19:35,490][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:19:35,491][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:19:35,491][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:19:35,491][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:19:35,491][root][INFO] - Not using CUDA.
[2025-01-17 16:19:35,504][root][INFO] - Using model baseline
[2025-01-17 16:21:20,757][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:21:20,819][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:21:20,837][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:21:20,837][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:21:20,843][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:21:20,889][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:21:20,889][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:21:20,890][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:21:20,890][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:21:20,890][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:21:20,890][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:21:20,890][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:21:20,890][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:21:20,890][root][INFO] - Not using CUDA.
[2025-01-17 16:21:20,900][root][INFO] - Using model baseline
[2025-01-17 16:22:52,897][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:22:52,948][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:22:52,963][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:22:52,964][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:22:52,968][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:22:53,015][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:22:53,015][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:22:53,015][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:22:53,015][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:22:53,015][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:22:53,015][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:22:53,015][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:22:53,015][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:22:53,016][root][INFO] - Not using CUDA.
[2025-01-17 16:22:53,025][root][INFO] - Using model baseline
[2025-01-17 16:22:53,025][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,049][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,103][root][INFO] - Number of model parameters: 4264078
[2025-01-17 16:22:53,104][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,130][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,192][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,194][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,195][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,195][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,208][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,197][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,209][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,209][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,212][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,208][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,204][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,201][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,206][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,216][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,218][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,217][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,221][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,229][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,220][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,202][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,230][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,203][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,256][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,203][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,204][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,253][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,259][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,197][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:53,283][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,193][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,197][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,197][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,197][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,198][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,201][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,201][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,203][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,208][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,210][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,213][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,222][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,223][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,218][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,224][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,224][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,226][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,223][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,227][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,199][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,228][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,230][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,230][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,223][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,233][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,231][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,221][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,234][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,217][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,239][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,240][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,230][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,240][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,217][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,241][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,229][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,240][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,245][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,242][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,249][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,247][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,241][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,258][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,230][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,234][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,237][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,237][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,308][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,315][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,326][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,326][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,329][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,333][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,333][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,325][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,341][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,342][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,311][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,344][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,340][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,345][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,346][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,347][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,319][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,349][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,349][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,314][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,311][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,305][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,339][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,351][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,353][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,317][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,356][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,359][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,319][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,349][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,347][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,361][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,363][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,365][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,353][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,368][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,371][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,375][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,378][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,386][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:54,393][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,522][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,523][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,528][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,548][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,562][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,570][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,583][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,585][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,588][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,591][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,605][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,629][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,644][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,644][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,653][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,664][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,673][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,673][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,676][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,676][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,684][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,685][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,690][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,702][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,720][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,740][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,742][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,745][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,753][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,781][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,785][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,787][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,787][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,789][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,791][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,792][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,795][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,803][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,813][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,817][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,840][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,841][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,843][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,851][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,853][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,855][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,870][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,859][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,873][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,874][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,900][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,911][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,927][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,959][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,963][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,979][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,983][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,992][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,994][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:55,998][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,013][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,013][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,020][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,022][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,039][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,040][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,039][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,049][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,049][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,056][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,067][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,072][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,075][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,078][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,083][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,084][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,088][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,090][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,106][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,116][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,120][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,121][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,121][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,123][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,123][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,133][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:56,139][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:22:58,193][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 19. Other stats: (train_seconds = 5.0)
[2025-01-17 16:23:04,133][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 42. Learner queue size: 31. Other stats: (train_seconds = 10.9)
[2025-01-17 16:23:09,140][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 45. Learner queue size: 32. Other stats: (train_seconds = 16.0)
[2025-01-17 16:23:14,143][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 84. Learner queue size: 32. Other stats: (train_seconds = 21.0)
[2025-01-17 16:23:19,147][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 154. Learner queue size: 32. Other stats: (train_seconds = 26.0)
[2025-01-17 16:23:24,151][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 67. Learner queue size: 32. Other stats: (train_seconds = 31.0)
[2025-01-17 16:23:29,156][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 97. Learner queue size: 32. Other stats: (train_seconds = 36.0)
[2025-01-17 16:23:34,161][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 77. Learner queue size: 32. Other stats: (train_seconds = 41.0)
[2025-01-17 16:23:39,166][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 78. Learner queue size: 32. Other stats: (train_seconds = 46.0)
[2025-01-17 16:23:44,171][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 109. Learner queue size: 32. Other stats: (train_seconds = 51.0)
[2025-01-17 16:23:48,079][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-17 16:23:49,176][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-17 16:23:49,274][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 183. Learner queue size: 17. Other stats: (train_seconds = 56.0, step = 2560, mean_episode_return = -0.0188, mean_episode_step = 35.478, total_loss = 1585.3, entropy_loss = -11.371, pg_loss = 655.04, baseline_loss = 941.62, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 16:23:49,281][root][INFO] - Learning finished after 2560 steps.
[2025-01-17 16:23:49,282][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 16:57:18,823][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:57:18,889][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 1000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:57:18,908][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:57:18,909][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:57:18,915][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:57:18,979][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:57:18,979][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:57:18,979][palaas/out][WARNING] - Path to meta file already exists. Not overriding meta.
[2025-01-17 16:57:18,980][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:57:18,980][palaas/out][WARNING] - Path to message file already exists. New data will be appended.
[2025-01-17 16:57:18,980][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:57:18,980][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:57:18,980][palaas/out][WARNING] - Path to log file already exists. New data will be appended.
[2025-01-17 16:57:18,981][root][INFO] - Not using CUDA.
[2025-01-17 16:57:18,994][root][INFO] - Using model baseline
[2025-01-17 16:57:18,995][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:57:19,052][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:57:19,114][root][INFO] - Number of model parameters: 4264078
[2025-01-17 16:57:19,114][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:57:19,135][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:57:19,184][root][INFO] - Loading checkpoint: /opt/minihack/checkpoint.tar
[2025-01-17 16:58:09,650][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:58:09,698][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 1000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:58:09,714][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:58:09,715][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:58:09,719][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:58:09,768][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:58:09,768][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:58:09,769][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:58:09,769][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:58:09,769][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:58:09,769][root][INFO] - Not using CUDA.
[2025-01-17 16:58:09,778][root][INFO] - Using model baseline
[2025-01-17 16:58:09,779][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,010][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,171][root][INFO] - Number of model parameters: 4264078
[2025-01-17 16:58:10,171][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,204][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,275][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,279][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,279][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,280][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,280][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,283][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,283][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,284][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,285][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,286][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,286][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,286][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,287][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,287][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,289][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,290][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,288][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,291][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,292][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,293][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,293][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,289][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,285][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,296][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,298][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,298][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,298][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,298][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,299][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,300][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,298][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,300][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,301][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,303][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,303][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,304][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,304][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,306][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,288][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,307][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,297][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,292][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,310][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,310][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,302][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,297][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,315][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,318][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,293][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,320][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,316][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,309][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,324][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,318][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,326][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,326][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,330][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,316][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,323][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,314][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,312][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,335][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,323][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,342][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,346][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,340][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,347][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,346][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,350][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,352][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,352][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,356][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,344][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,360][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,366][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,362][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,369][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,369][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,374][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,375][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,381][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,381][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,393][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,393][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:10,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,279][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,283][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,284][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,285][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,285][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,286][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,289][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,291][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,293][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,298][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,292][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,312][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,312][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,314][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,319][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,321][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,325][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,328][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,330][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,330][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,335][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,336][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,341][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,341][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,345][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,345][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,349][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,350][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,350][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,351][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,352][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,353][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,354][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,355][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,333][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,335][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,358][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,336][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,340][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,362][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,362][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,364][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,365][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,367][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,367][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,369][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,373][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,373][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,378][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,378][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,360][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,385][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,385][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,384][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,384][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,386][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,348][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,389][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,391][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,376][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,391][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,392][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,399][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,400][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,392][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,406][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,406][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,398][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,407][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,413][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,410][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,401][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,396][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,400][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,409][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,428][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,405][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,438][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,466][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,479][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,449][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,459][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,454][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,460][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,459][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,466][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,460][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,509][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,509][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,462][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,507][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,486][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,490][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,494][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,493][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,513][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,471][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,504][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,502][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,512][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,517][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,504][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,505][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,501][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,519][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:11,516][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,674][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,698][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,815][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,837][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,851][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,898][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,901][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,903][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,939][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,955][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:12,982][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,055][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,060][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,062][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,132][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,176][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,182][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,187][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,213][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,241][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,261][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,263][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:13,296][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:58:15,274][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 1. Learner queue size: 18. Other stats: (train_seconds = 5.0)
[2025-01-17 16:58:20,279][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 19. Learner queue size: 3. Other stats: (train_seconds = 10.0)
[2025-01-17 16:58:28,210][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 45. Learner queue size: 3. Other stats: (train_seconds = 17.9)
[2025-01-17 16:58:33,213][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 110. Learner queue size: 3. Other stats: (train_seconds = 22.9)
[2025-01-17 16:58:38,219][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 110. Learner queue size: 3. Other stats: (train_seconds = 28.0)
[2025-01-17 16:58:43,225][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 100. Learner queue size: 4. Other stats: (train_seconds = 33.0)
[2025-01-17 16:58:48,231][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 54. Learner queue size: 4. Other stats: (train_seconds = 38.0)
[2025-01-17 16:58:53,234][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 54. Learner queue size: 4. Other stats: (train_seconds = 43.0)
[2025-01-17 16:58:58,239][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 85. Learner queue size: 4. Other stats: (train_seconds = 48.0)
[2025-01-17 16:59:03,244][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 158. Learner queue size: 4. Other stats: (train_seconds = 53.0)
[2025-01-17 16:59:08,196][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-17 16:59:08,249][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-17 16:59:08,285][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 86. Learner queue size: 6. Other stats: (train_seconds = 58.0, step = 2560, mean_episode_return = 0.04688, mean_episode_step = 57.487, total_loss = 1926.2, entropy_loss = -11.371, pg_loss = 1387.5, baseline_loss = 550.06, learner_queue_size = 6, _tick = 0, _time = 1.7371e+09)
[2025-01-17 16:59:08,285][root][INFO] - Learning finished after 2560 steps.
[2025-01-17 16:59:08,285][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 16:59:43,557][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 16:59:43,610][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 16:59:43,627][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 16:59:43,628][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 16:59:43,633][root][INFO] - Logging results to /opt/minihack
[2025-01-17 16:59:43,686][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 16:59:43,686][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 16:59:43,687][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 16:59:43,687][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 16:59:43,687][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 16:59:43,688][root][INFO] - Not using CUDA.
[2025-01-17 16:59:43,698][root][INFO] - Using model baseline
[2025-01-17 16:59:43,698][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:59:43,731][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:59:43,795][root][INFO] - Number of model parameters: 4264078
[2025-01-17 16:59:43,795][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:59:43,815][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 16:59:43,868][root][INFO] - Loading checkpoint: /opt/minihack/checkpoint.tar
[2025-01-17 17:00:33,878][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 17:00:33,928][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 100000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 17:00:33,943][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 17:00:33,944][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 17:00:33,949][root][INFO] - Logging results to /opt/minihack
[2025-01-17 17:00:33,996][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 17:00:33,996][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 17:00:33,997][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 17:00:33,997][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 17:00:33,997][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 17:00:33,997][root][INFO] - Not using CUDA.
[2025-01-17 17:00:34,006][root][INFO] - Using model baseline
[2025-01-17 17:00:34,007][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,043][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,106][root][INFO] - Number of model parameters: 4264078
[2025-01-17 17:00:34,108][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,137][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,202][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,204][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,204][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,207][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,208][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,210][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,212][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,212][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,208][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,213][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,213][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,215][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,216][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,216][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,217][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,218][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,220][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,220][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,221][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,222][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,222][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,223][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,224][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,226][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,228][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,226][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,228][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,224][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,227][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,232][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,221][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,236][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,220][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,242][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,244][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,246][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,247][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,253][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,253][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,254][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,254][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,255][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,255][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:34,253][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,208][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,210][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,211][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,219][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,223][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,224][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,225][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,228][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,228][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,229][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,230][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,220][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,216][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,232][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,234][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,236][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,236][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,239][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,240][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,243][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,247][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,241][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,232][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,252][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,252][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,253][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,256][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,259][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,263][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,270][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,266][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,264][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,268][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,289][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,326][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,333][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,337][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,341][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,348][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,353][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,354][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,357][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,359][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,363][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,363][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,365][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,366][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,369][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,352][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,859][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,370][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,375][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,377][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,374][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,383][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,377][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,384][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,878][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,376][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,881][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,377][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,385][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,883][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,886][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,386][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,387][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,380][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,894][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,390][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,391][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,380][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,880][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,897][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,332][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,892][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,392][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,375][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,330][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,909][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,372][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,914][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,398][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,914][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,399][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,378][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,382][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,402][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,928][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,402][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,402][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,402][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,403][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,404][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,404][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,407][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,407][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,409][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,407][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,408][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,410][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,412][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,412][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,961][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,413][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,396][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,399][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,414][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,414][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,417][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,418][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,419][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,420][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,421][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,421][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,422][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,425][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,423][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,426][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,425][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,428][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,991][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,429][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,432][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,432][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,433][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,433][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:36,999][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,432][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,420][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,435][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,434][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,428][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,437][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,416][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,437][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,012][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,438][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,439][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,440][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,442][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,015][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,440][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,440][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:35,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,066][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,069][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,077][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,077][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,080][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,081][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,103][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,107][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,109][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,111][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:37,144][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:39,203][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 16. Other stats: (train_seconds = 5.0)
[2025-01-17 17:00:41,419][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,442][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,444][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,446][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,447][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,421][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,451][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,422][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,453][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,452][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,455][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,458][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,420][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,422][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,465][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,465][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,427][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,475][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,476][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,459][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,422][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,435][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,433][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,433][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:41,471][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:00:46,446][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 6. Learner queue size: 10. Other stats: (train_seconds = 12.2)
[2025-01-17 17:00:51,451][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 22. Learner queue size: 10. Other stats: (train_seconds = 17.3)
[2025-01-17 17:00:56,455][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 121. Learner queue size: 11. Other stats: (train_seconds = 22.3)
[2025-01-17 17:01:01,459][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 95. Learner queue size: 11. Other stats: (train_seconds = 27.3)
[2025-01-17 17:01:09,059][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 51. Learner queue size: 13. Other stats: (train_seconds = 34.9)
[2025-01-17 17:01:14,064][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 90. Learner queue size: 13. Other stats: (train_seconds = 39.9)
[2025-01-17 17:01:19,071][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 60. Learner queue size: 15. Other stats: (train_seconds = 44.9)
[2025-01-17 17:01:24,074][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 60. Learner queue size: 15. Other stats: (train_seconds = 49.9)
[2025-01-17 17:01:29,075][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 137. Learner queue size: 16. Other stats: (train_seconds = 54.9)
[2025-01-17 17:01:33,252][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-17 17:01:34,080][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-17 17:01:34,111][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 105. Learner queue size: 18. Other stats: (train_seconds = 59.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:01:39,117][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 106. Learner queue size: 22. Other stats: (train_seconds = 64.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:01:44,122][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 103. Learner queue size: 26. Other stats: (train_seconds = 69.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:01:49,128][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 88. Learner queue size: 4. Other stats: (train_seconds = 74.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:01:54,134][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (train_seconds = 79.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:01:59,139][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 84.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:02:04,145][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 89.9, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:02:09,150][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 95.0, step = 2560, mean_episode_return = 0.045667, mean_episode_step = 54.86, total_loss = -558.86, entropy_loss = -11.371, pg_loss = -775.71, baseline_loss = 228.22, learner_queue_size = 16, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:02:14,156][root][INFO] - Step 5120 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 100.0, step = 5120, mean_episode_return = -0.06695, mean_episode_step = 56.942, total_loss = 2031.7, entropy_loss = -11.337, pg_loss = 1808.6, baseline_loss = 234.42, learner_queue_size = 32, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:02:19,164][root][INFO] - Step 7680 @ 511.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 105.0, step = 7680, mean_episode_return = 0.0661, mean_episode_step = 32.752, total_loss = 227.08, entropy_loss = -11.371, pg_loss = 111.4, baseline_loss = 127.05, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 17:02:24,170][root][INFO] - Step 7680 @ 0.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 110.0, step = 7680, mean_episode_return = 0.0661, mean_episode_step = 32.752, total_loss = 227.08, entropy_loss = -11.371, pg_loss = 111.4, baseline_loss = 127.05, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 17:02:29,176][root][INFO] - Step 10240 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 115.0, step = 10240, mean_episode_return = -0.0418, mean_episode_step = 34.393, total_loss = -302.74, entropy_loss = -11.303, pg_loss = -326.72, baseline_loss = 35.281, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:02:34,183][root][INFO] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 120.0, step = 10240, mean_episode_return = -0.0418, mean_episode_step = 34.393, total_loss = -302.74, entropy_loss = -11.303, pg_loss = -326.72, baseline_loss = 35.281, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:02:39,190][root][INFO] - Step 12800 @ 511.3 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 125.0, step = 12800, mean_episode_return = -0.0614, mean_episode_step = 46.299, total_loss = 280.79, entropy_loss = -11.365, pg_loss = 158.65, baseline_loss = 133.5, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)
[2025-01-17 17:02:44,196][root][INFO] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 130.0, step = 12800, mean_episode_return = -0.0614, mean_episode_step = 46.299, total_loss = 280.79, entropy_loss = -11.365, pg_loss = 158.65, baseline_loss = 133.5, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)
[2025-01-17 17:02:49,201][root][INFO] - Step 15360 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 135.0, step = 15360, mean_episode_return = -0.044, mean_episode_step = 48.55, total_loss = 159.49, entropy_loss = -11.332, pg_loss = 53.442, baseline_loss = 117.38, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 17:02:54,207][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 140.0, step = 15360, mean_episode_return = -0.044, mean_episode_step = 48.55, total_loss = 159.49, entropy_loss = -11.332, pg_loss = 53.442, baseline_loss = 117.38, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 17:02:59,212][root][INFO] - Step 17920 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 145.0, step = 17920, mean_episode_return = -0.01852, mean_episode_step = 48.546, total_loss = -228.52, entropy_loss = -11.162, pg_loss = -248.2, baseline_loss = 30.843, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 17:03:04,218][root][INFO] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 150.0, step = 17920, mean_episode_return = -0.01852, mean_episode_step = 48.546, total_loss = -228.52, entropy_loss = -11.162, pg_loss = -248.2, baseline_loss = 30.843, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 17:03:09,224][root][INFO] - Step 20480 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 155.0, step = 20480, mean_episode_return = -0.01964, mean_episode_step = 47.31, total_loss = 502.07, entropy_loss = -11.148, pg_loss = 426.12, baseline_loss = 87.097, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 17:03:14,229][root][INFO] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 160.0, step = 20480, mean_episode_return = -0.01964, mean_episode_step = 47.31, total_loss = 502.07, entropy_loss = -11.148, pg_loss = 426.12, baseline_loss = 87.097, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 17:03:19,236][root][INFO] - Step 23040 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 165.0, step = 23040, mean_episode_return = 0.021391, mean_episode_step = 61.975, total_loss = 866.37, entropy_loss = -11.22, pg_loss = 746.24, baseline_loss = 131.35, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 17:03:24,245][root][INFO] - Step 23040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 170.0, step = 23040, mean_episode_return = 0.021391, mean_episode_step = 61.975, total_loss = 866.37, entropy_loss = -11.22, pg_loss = 746.24, baseline_loss = 131.35, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 17:03:29,251][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar
[2025-01-17 17:03:29,316][root][INFO] - Step 25600 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 175.1, step = 25600, mean_episode_return = 0.046963, mean_episode_step = 50.179, total_loss = -200.05, entropy_loss = -11.221, pg_loss = -283.7, baseline_loss = 94.874, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 17:03:34,321][root][INFO] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 180.1, step = 25600, mean_episode_return = 0.046963, mean_episode_step = 50.179, total_loss = -200.05, entropy_loss = -11.221, pg_loss = -283.7, baseline_loss = 94.874, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 17:03:39,326][root][INFO] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 185.1, step = 25600, mean_episode_return = 0.046963, mean_episode_step = 50.179, total_loss = -200.05, entropy_loss = -11.221, pg_loss = -283.7, baseline_loss = 94.874, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 17:03:44,331][root][INFO] - Step 28160 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 190.1, step = 28160, mean_episode_return = 0.03044, mean_episode_step = 55.664, total_loss = 376.94, entropy_loss = -11.238, pg_loss = 291.21, baseline_loss = 96.966, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 17:03:49,336][root][INFO] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 195.1, step = 28160, mean_episode_return = 0.03044, mean_episode_step = 55.664, total_loss = 376.94, entropy_loss = -11.238, pg_loss = 291.21, baseline_loss = 96.966, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 17:03:54,341][root][INFO] - Step 30720 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 200.1, step = 30720, mean_episode_return = 0.1405, mean_episode_step = 59.274, total_loss = 266.45, entropy_loss = -11.111, pg_loss = 155.57, baseline_loss = 121.99, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)
[2025-01-17 17:03:59,346][root][INFO] - Step 33280 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 205.1, step = 33280, mean_episode_return = 0.040379, mean_episode_step = 51.952, total_loss = 177.54, entropy_loss = -11.061, pg_loss = 72.796, baseline_loss = 115.8, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)
[2025-01-17 17:04:04,353][root][INFO] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 210.2, step = 33280, mean_episode_return = 0.040379, mean_episode_step = 51.952, total_loss = 177.54, entropy_loss = -11.061, pg_loss = 72.796, baseline_loss = 115.8, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)
[2025-01-17 17:04:09,358][root][INFO] - Step 35840 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 215.2, step = 35840, mean_episode_return = 0.22277, mean_episode_step = 63.731, total_loss = 497.24, entropy_loss = -10.998, pg_loss = 393.38, baseline_loss = 114.86, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)
[2025-01-17 17:04:14,365][root][INFO] - Step 35840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 220.2, step = 35840, mean_episode_return = 0.22277, mean_episode_step = 63.731, total_loss = 497.24, entropy_loss = -10.998, pg_loss = 393.38, baseline_loss = 114.86, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)
[2025-01-17 17:04:19,371][root][INFO] - Step 38400 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 225.2, step = 38400, mean_episode_return = -0.033893, mean_episode_step = 54.779, total_loss = -383.93, entropy_loss = -10.924, pg_loss = -425.25, baseline_loss = 52.247, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)
[2025-01-17 17:04:24,376][root][INFO] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 230.2, step = 38400, mean_episode_return = -0.033893, mean_episode_step = 54.779, total_loss = -383.93, entropy_loss = -10.924, pg_loss = -425.25, baseline_loss = 52.247, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)
[2025-01-17 17:04:29,383][root][INFO] - Step 40960 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 235.2, step = 40960, mean_episode_return = -0.0032121, mean_episode_step = 61.075, total_loss = -430.19, entropy_loss = -10.916, pg_loss = -481.95, baseline_loss = 62.673, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)
[2025-01-17 17:04:34,388][root][INFO] - Step 40960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 240.2, step = 40960, mean_episode_return = -0.0032121, mean_episode_step = 61.075, total_loss = -430.19, entropy_loss = -10.916, pg_loss = -481.95, baseline_loss = 62.673, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)
[2025-01-17 17:04:39,393][root][INFO] - Step 43520 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 245.2, step = 43520, mean_episode_return = 0.074, mean_episode_step = 56.318, total_loss = -514.89, entropy_loss = -10.89, pg_loss = -541.92, baseline_loss = 37.922, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)
[2025-01-17 17:04:44,399][root][INFO] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 250.2, step = 43520, mean_episode_return = 0.074, mean_episode_step = 56.318, total_loss = -514.89, entropy_loss = -10.89, pg_loss = -541.92, baseline_loss = 37.922, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)
[2025-01-17 17:04:49,404][root][INFO] - Step 46080 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 255.2, step = 46080, mean_episode_return = 0.11196, mean_episode_step = 74.246, total_loss = 690.65, entropy_loss = -10.856, pg_loss = 579.14, baseline_loss = 122.36, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)
[2025-01-17 17:04:54,409][root][INFO] - Step 46080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 260.2, step = 46080, mean_episode_return = 0.11196, mean_episode_step = 74.246, total_loss = 690.65, entropy_loss = -10.856, pg_loss = 579.14, baseline_loss = 122.36, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)
[2025-01-17 17:04:59,414][root][INFO] - Step 48640 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 265.2, step = 48640, mean_episode_return = 0.10261, mean_episode_step = 61.443, total_loss = 306.1, entropy_loss = -10.857, pg_loss = 178.33, baseline_loss = 138.63, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)
[2025-01-17 17:05:04,421][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar
[2025-01-17 17:05:04,493][root][INFO] - Step 51200 @ 511.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 270.2, step = 51200, mean_episode_return = 0.066259, mean_episode_step = 66.419, total_loss = 31.545, entropy_loss = -10.775, pg_loss = -95.965, baseline_loss = 138.29, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)
[2025-01-17 17:05:09,499][root][INFO] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 275.3, step = 51200, mean_episode_return = 0.066259, mean_episode_step = 66.419, total_loss = 31.545, entropy_loss = -10.775, pg_loss = -95.965, baseline_loss = 138.29, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)
[2025-01-17 17:05:14,504][root][INFO] - Step 53760 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 280.3, step = 53760, mean_episode_return = 0.0716, mean_episode_step = 66.199, total_loss = 255.2, entropy_loss = -10.647, pg_loss = 163.7, baseline_loss = 102.15, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)
[2025-01-17 17:05:19,510][root][INFO] - Step 53760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 285.3, step = 53760, mean_episode_return = 0.0716, mean_episode_step = 66.199, total_loss = 255.2, entropy_loss = -10.647, pg_loss = 163.7, baseline_loss = 102.15, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)
[2025-01-17 17:05:24,515][root][INFO] - Step 56320 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 290.3, step = 56320, mean_episode_return = 0.18145, mean_episode_step = 62.137, total_loss = -439.71, entropy_loss = -10.526, pg_loss = -516.85, baseline_loss = 87.668, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)
[2025-01-17 17:05:29,521][root][INFO] - Step 56320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 295.3, step = 56320, mean_episode_return = 0.18145, mean_episode_step = 62.137, total_loss = -439.71, entropy_loss = -10.526, pg_loss = -516.85, baseline_loss = 87.668, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)
[2025-01-17 17:05:34,527][root][INFO] - Step 58880 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 300.3, step = 58880, mean_episode_return = 0.0027037, mean_episode_step = 61.033, total_loss = -198.46, entropy_loss = -10.472, pg_loss = -234.11, baseline_loss = 46.127, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)
[2025-01-17 17:05:39,533][root][INFO] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 305.3, step = 58880, mean_episode_return = 0.0027037, mean_episode_step = 61.033, total_loss = -198.46, entropy_loss = -10.472, pg_loss = -234.11, baseline_loss = 46.127, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)
[2025-01-17 17:05:44,538][root][INFO] - Step 61440 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 310.3, step = 61440, mean_episode_return = 0.15593, mean_episode_step = 68.228, total_loss = 254.72, entropy_loss = -10.439, pg_loss = 173.9, baseline_loss = 91.255, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)
[2025-01-17 17:05:49,543][root][INFO] - Step 61440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 315.3, step = 61440, mean_episode_return = 0.15593, mean_episode_step = 68.228, total_loss = 254.72, entropy_loss = -10.439, pg_loss = 173.9, baseline_loss = 91.255, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)
[2025-01-17 17:05:54,551][root][INFO] - Step 64000 @ 511.2 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 320.4, step = 64000, mean_episode_return = 0.089862, mean_episode_step = 59.502, total_loss = -131.04, entropy_loss = -10.327, pg_loss = -203.46, baseline_loss = 82.742, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)
[2025-01-17 17:05:59,556][root][INFO] - Step 64000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 325.4, step = 64000, mean_episode_return = 0.089862, mean_episode_step = 59.502, total_loss = -131.04, entropy_loss = -10.327, pg_loss = -203.46, baseline_loss = 82.742, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)
[2025-01-17 17:06:04,561][root][INFO] - Step 66560 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 330.4, step = 66560, mean_episode_return = 0.17542, mean_episode_step = 61.697, total_loss = -238.37, entropy_loss = -10.269, pg_loss = -277.83, baseline_loss = 49.737, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 17:06:09,566][root][INFO] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 335.4, step = 66560, mean_episode_return = 0.17542, mean_episode_step = 61.697, total_loss = -238.37, entropy_loss = -10.269, pg_loss = -277.83, baseline_loss = 49.737, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 17:06:14,571][root][INFO] - Step 69120 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 340.4, step = 69120, mean_episode_return = 0.17303, mean_episode_step = 58.74, total_loss = -314.78, entropy_loss = -10.187, pg_loss = -344.71, baseline_loss = 40.117, learner_queue_size = 32, _tick = 26, _time = 1.7371e+09)
[2025-01-17 17:06:19,577][root][INFO] - Step 71680 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 345.4, step = 71680, mean_episode_return = 0.14514, mean_episode_step = 59.198, total_loss = 667.58, entropy_loss = -10.114, pg_loss = 570.71, baseline_loss = 106.98, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)
[2025-01-17 17:06:24,583][root][INFO] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 350.4, step = 71680, mean_episode_return = 0.14514, mean_episode_step = 59.198, total_loss = 667.58, entropy_loss = -10.114, pg_loss = 570.71, baseline_loss = 106.98, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)
[2025-01-17 17:06:29,588][root][INFO] - Step 74240 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 355.4, step = 74240, mean_episode_return = 0.20647, mean_episode_step = 58.632, total_loss = 341.65, entropy_loss = -10.149, pg_loss = 243.67, baseline_loss = 108.13, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)
[2025-01-17 17:06:34,594][root][INFO] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 360.4, step = 74240, mean_episode_return = 0.20647, mean_episode_step = 58.632, total_loss = 341.65, entropy_loss = -10.149, pg_loss = 243.67, baseline_loss = 108.13, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)
[2025-01-17 17:06:39,599][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar
[2025-01-17 17:06:39,647][root][INFO] - Step 76800 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 365.4, step = 76800, mean_episode_return = 0.25029, mean_episode_step = 62.878, total_loss = 26.61, entropy_loss = -10.156, pg_loss = -76.775, baseline_loss = 113.54, learner_queue_size = 32, _tick = 29, _time = 1.7371e+09)
[2025-01-17 17:06:44,652][root][INFO] - Step 79360 @ 506.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 370.5, step = 79360, mean_episode_return = 0.24749, mean_episode_step = 54.809, total_loss = 213.91, entropy_loss = -10.07, pg_loss = 113.43, baseline_loss = 110.55, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)
[2025-01-17 17:06:49,657][root][INFO] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 375.5, step = 79360, mean_episode_return = 0.24749, mean_episode_step = 54.809, total_loss = 213.91, entropy_loss = -10.07, pg_loss = 113.43, baseline_loss = 110.55, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)
[2025-01-17 17:06:54,662][root][INFO] - Step 81920 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 380.5, step = 81920, mean_episode_return = 0.29188, mean_episode_step = 63.768, total_loss = 260.61, entropy_loss = -9.9633, pg_loss = 159.27, baseline_loss = 111.3, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)
[2025-01-17 17:06:59,667][root][INFO] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 385.5, step = 81920, mean_episode_return = 0.29188, mean_episode_step = 63.768, total_loss = 260.61, entropy_loss = -9.9633, pg_loss = 159.27, baseline_loss = 111.3, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)
[2025-01-17 17:07:04,672][root][INFO] - Step 84480 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 390.5, step = 84480, mean_episode_return = 0.41404, mean_episode_step = 70.058, total_loss = 168.28, entropy_loss = -9.9919, pg_loss = 54.35, baseline_loss = 123.92, learner_queue_size = 32, _tick = 32, _time = 1.7371e+09)
[2025-01-17 17:07:09,678][root][INFO] - Step 87040 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 395.5, step = 87040, mean_episode_return = 0.26745, mean_episode_step = 55.181, total_loss = -330.1, entropy_loss = -9.9395, pg_loss = -410.52, baseline_loss = 90.362, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)
[2025-01-17 17:07:14,684][root][INFO] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 400.5, step = 87040, mean_episode_return = 0.26745, mean_episode_step = 55.181, total_loss = -330.1, entropy_loss = -9.9395, pg_loss = -410.52, baseline_loss = 90.362, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)
[2025-01-17 17:07:19,689][root][INFO] - Step 89600 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 405.5, step = 89600, mean_episode_return = 0.37503, mean_episode_step = 59.621, total_loss = -54.04, entropy_loss = -9.9435, pg_loss = -172.36, baseline_loss = 128.27, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)
[2025-01-17 17:07:24,695][root][INFO] - Step 89600 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 410.5, step = 89600, mean_episode_return = 0.37503, mean_episode_step = 59.621, total_loss = -54.04, entropy_loss = -9.9435, pg_loss = -172.36, baseline_loss = 128.27, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)
[2025-01-17 17:07:29,700][root][INFO] - Step 92160 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 415.5, step = 92160, mean_episode_return = 0.28186, mean_episode_step = 56.509, total_loss = 247.88, entropy_loss = -9.9058, pg_loss = 130.61, baseline_loss = 127.18, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 17:07:34,708][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 420.5, step = 92160, mean_episode_return = 0.28186, mean_episode_step = 56.509, total_loss = 247.88, entropy_loss = -9.9058, pg_loss = 130.61, baseline_loss = 127.18, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 17:07:39,714][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 425.5, step = 92160, mean_episode_return = 0.28186, mean_episode_step = 56.509, total_loss = 247.88, entropy_loss = -9.9058, pg_loss = 130.61, baseline_loss = 127.18, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 17:07:44,719][root][INFO] - Step 94720 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 430.5, step = 94720, mean_episode_return = 0.19544, mean_episode_step = 64.804, total_loss = 273.0, entropy_loss = -9.8908, pg_loss = 136.69, baseline_loss = 146.21, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 17:07:49,724][root][INFO] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 435.5, step = 94720, mean_episode_return = 0.19544, mean_episode_step = 64.804, total_loss = 273.0, entropy_loss = -9.8908, pg_loss = 136.69, baseline_loss = 146.21, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 17:07:54,731][root][INFO] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 440.5, step = 94720, mean_episode_return = 0.19544, mean_episode_step = 64.804, total_loss = 273.0, entropy_loss = -9.8908, pg_loss = 136.69, baseline_loss = 146.21, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 17:07:59,740][root][INFO] - Step 97280 @ 511.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 445.5, step = 97280, mean_episode_return = 0.28214, mean_episode_step = 54.35, total_loss = 221.42, entropy_loss = -9.872, pg_loss = 98.401, baseline_loss = 132.89, learner_queue_size = 32, _tick = 37, _time = 1.7371e+09)
[2025-01-17 17:08:04,745][root][INFO] - Step 97280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 450.5, step = 97280, mean_episode_return = 0.28214, mean_episode_step = 54.35, total_loss = 221.42, entropy_loss = -9.872, pg_loss = 98.401, baseline_loss = 132.89, learner_queue_size = 32, _tick = 37, _time = 1.7371e+09)
[2025-01-17 17:08:09,750][root][INFO] - Step 99840 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 455.6, step = 99840, mean_episode_return = 0.12481, mean_episode_step = 58.496, total_loss = -318.38, entropy_loss = -9.872, pg_loss = -535.06, baseline_loss = 226.56, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)
[2025-01-17 17:08:14,755][root][INFO] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 460.6, step = 99840, mean_episode_return = 0.12481, mean_episode_step = 58.496, total_loss = -318.38, entropy_loss = -9.872, pg_loss = -535.06, baseline_loss = 226.56, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)
[2025-01-17 17:08:19,760][root][INFO] - Step 102400 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 465.6, step = 102400, mean_episode_return = 0.13914, mean_episode_step = 57.989, total_loss = 311.53, entropy_loss = -9.8548, pg_loss = 145.1, baseline_loss = 176.29, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)
[2025-01-17 17:08:19,761][root][INFO] - Learning finished after 102400 steps.
[2025-01-17 17:08:19,761][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 17:14:22,850][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 17:14:22,904][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 1000000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 17:14:22,921][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 17:14:22,922][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 17:14:22,926][root][INFO] - Logging results to /opt/minihack
[2025-01-17 17:14:22,987][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 17:14:22,988][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 17:14:22,988][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 17:14:22,989][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 17:14:22,989][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 17:14:22,990][root][INFO] - Not using CUDA.
[2025-01-17 17:14:23,006][root][INFO] - Using model baseline
[2025-01-17 17:14:23,007][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,062][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,133][root][INFO] - Number of model parameters: 4264078
[2025-01-17 17:14:23,134][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,152][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,257][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,259][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,261][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,264][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,266][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,267][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,270][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,270][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,270][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,271][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,272][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,264][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,273][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,275][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,275][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,267][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,278][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,278][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,271][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,281][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,258][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,262][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,284][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,285][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,284][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,287][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,275][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,268][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,287][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,291][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,265][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,301][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,301][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,303][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,299][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,264][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,311][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,323][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,334][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,340][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,337][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,329][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,348][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,339][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,344][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,352][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:23,369][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,871][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,888][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,903][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,940][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,922][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,934][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,871][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,918][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,903][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,896][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,941][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,957][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,967][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,988][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,919][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,943][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,934][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,982][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,966][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,903][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,943][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,920][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,946][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,940][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,980][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,977][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,982][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,995][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,943][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,970][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,962][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,905][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,929][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,999][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,992][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,949][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,983][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,881][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,927][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,898][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,944][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,898][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,953][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,961][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,968][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,962][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,967][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,936][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,960][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,951][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,984][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,923][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,001][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,996][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,950][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,964][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,938][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,918][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,926][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,980][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,944][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,042][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,984][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,966][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,975][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,043][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,978][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,935][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,029][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,983][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,953][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,006][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,981][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,984][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,032][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,026][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,030][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,035][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,937][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,940][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,015][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,936][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,955][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,026][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,968][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,998][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,960][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,919][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,060][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,000][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,956][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,031][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,991][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,046][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,032][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,085][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,904][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,024][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,999][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,036][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,061][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,982][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,939][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,949][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,069][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,034][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,994][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,965][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,993][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,061][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,997][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,042][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,000][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,958][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,987][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,049][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,972][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,981][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,054][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,047][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,005][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,973][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,004][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,047][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,975][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,951][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,038][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,046][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,999][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,043][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,993][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,047][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,981][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,025][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,038][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,992][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,032][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,990][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,962][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,969][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,063][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,033][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,060][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,059][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,056][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,053][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,042][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,080][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,073][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,059][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,997][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,051][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,044][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,034][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,042][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,006][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,051][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,026][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,043][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,058][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,036][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,126][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,024][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,068][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,071][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,070][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,026][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:25,993][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,053][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,065][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,080][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,038][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,096][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,047][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,090][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,056][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,033][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,054][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,052][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,044][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,102][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,038][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,057][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:26,106][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:28,277][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 33. Learner queue size: 13. Other stats: (train_seconds = 5.0)
[2025-01-17 17:14:26,056][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:14:33,281][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 10.0)
[2025-01-17 17:14:39,368][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (train_seconds = 16.1)
[2025-01-17 17:14:44,410][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 108. Learner queue size: 32. Other stats: (train_seconds = 21.1)
[2025-01-17 17:14:49,479][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 41. Learner queue size: 32. Other stats: (train_seconds = 26.1)
[2025-01-17 17:14:54,483][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 74. Learner queue size: 32. Other stats: (train_seconds = 31.2)
[2025-01-17 17:14:59,499][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 90. Learner queue size: 32. Other stats: (train_seconds = 36.2)
[2025-01-17 17:14:59,934][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-17 17:15:04,507][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-17 17:15:04,623][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 39. Learner queue size: 23. Other stats: (train_seconds = 41.2, step = 2560, mean_episode_return = -0.0595, mean_episode_step = 46.18, total_loss = 1168.6, entropy_loss = -11.372, pg_loss = 711.05, baseline_loss = 468.93, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:15:09,625][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 96. Learner queue size: 27. Other stats: (train_seconds = 46.4, step = 2560, mean_episode_return = -0.0595, mean_episode_step = 46.18, total_loss = 1168.6, entropy_loss = -11.372, pg_loss = 711.05, baseline_loss = 468.93, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:15:14,630][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 146. Learner queue size: 29. Other stats: (train_seconds = 51.4, step = 2560, mean_episode_return = -0.0595, mean_episode_step = 46.18, total_loss = 1168.6, entropy_loss = -11.372, pg_loss = 711.05, baseline_loss = 468.93, learner_queue_size = 32, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:15:19,636][root][INFO] - Step 5120 @ 511.4 SPS. Inference batcher size: 149. Learner queue size: 11. Other stats: (train_seconds = 56.4, step = 5120, mean_episode_return = -0.047778, mean_episode_step = 33.963, total_loss = -913.27, entropy_loss = -11.365, pg_loss = -1078.9, baseline_loss = 177.02, learner_queue_size = 29, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:15:24,639][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 94. Learner queue size: 32. Other stats: (train_seconds = 61.4, step = 5120, mean_episode_return = -0.047778, mean_episode_step = 33.963, total_loss = -913.27, entropy_loss = -11.365, pg_loss = -1078.9, baseline_loss = 177.02, learner_queue_size = 29, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:15:29,645][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 159. Learner queue size: 32. Other stats: (train_seconds = 66.4, step = 5120, mean_episode_return = -0.047778, mean_episode_step = 33.963, total_loss = -913.27, entropy_loss = -11.365, pg_loss = -1078.9, baseline_loss = 177.02, learner_queue_size = 29, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:15:34,650][root][INFO] - Step 7680 @ 511.5 SPS. Inference batcher size: 34. Learner queue size: 32. Other stats: (train_seconds = 71.4, step = 7680, mean_episode_return = 0.028091, mean_episode_step = 45.786, total_loss = 692.51, entropy_loss = -11.366, pg_loss = 489.8, baseline_loss = 214.08, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 17:15:39,655][root][INFO] - Step 7680 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 76.4, step = 7680, mean_episode_return = 0.028091, mean_episode_step = 45.786, total_loss = 692.51, entropy_loss = -11.366, pg_loss = 489.8, baseline_loss = 214.08, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 17:15:44,661][root][INFO] - Step 10240 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 81.4, step = 10240, mean_episode_return = -0.0068823, mean_episode_step = 43.903, total_loss = 2139.4, entropy_loss = -11.362, pg_loss = 1911.2, baseline_loss = 239.54, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:15:49,666][root][INFO] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 86.4, step = 10240, mean_episode_return = -0.0068823, mean_episode_step = 43.903, total_loss = 2139.4, entropy_loss = -11.362, pg_loss = 1911.2, baseline_loss = 239.54, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:15:54,671][root][INFO] - Step 12800 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 91.4, step = 12800, mean_episode_return = -0.013478, mean_episode_step = 45.312, total_loss = 211.68, entropy_loss = -11.368, pg_loss = -58.031, baseline_loss = 281.08, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)
[2025-01-17 17:15:59,676][root][INFO] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 96.4, step = 12800, mean_episode_return = -0.013478, mean_episode_step = 45.312, total_loss = 211.68, entropy_loss = -11.368, pg_loss = -58.031, baseline_loss = 281.08, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)
[2025-01-17 17:16:04,681][root][INFO] - Step 15360 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 101.4, step = 15360, mean_episode_return = 0.072056, mean_episode_step = 32.725, total_loss = 1033.0, entropy_loss = -11.369, pg_loss = 747.12, baseline_loss = 297.22, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 17:16:09,687][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 106.4, step = 15360, mean_episode_return = 0.072056, mean_episode_step = 32.725, total_loss = 1033.0, entropy_loss = -11.369, pg_loss = 747.12, baseline_loss = 297.22, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 17:16:14,694][root][INFO] - Step 17920 @ 511.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 111.4, step = 17920, mean_episode_return = -0.0099583, mean_episode_step = 45.158, total_loss = -877.58, entropy_loss = -11.315, pg_loss = -941.86, baseline_loss = 75.593, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 17:16:19,700][root][INFO] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 116.4, step = 17920, mean_episode_return = -0.0099583, mean_episode_step = 45.158, total_loss = -877.58, entropy_loss = -11.315, pg_loss = -941.86, baseline_loss = 75.593, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 17:16:24,705][root][INFO] - Step 20480 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 121.4, step = 20480, mean_episode_return = 0.07012, mean_episode_step = 47.752, total_loss = 397.12, entropy_loss = -11.359, pg_loss = 172.04, baseline_loss = 236.44, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 17:16:29,711][root][INFO] - Step 23040 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 126.4, step = 23040, mean_episode_return = -0.026823, mean_episode_step = 70.926, total_loss = -1136.8, entropy_loss = -11.352, pg_loss = -1142.4, baseline_loss = 16.885, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 17:16:34,717][root][INFO] - Step 23040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 131.4, step = 23040, mean_episode_return = -0.026823, mean_episode_step = 70.926, total_loss = -1136.8, entropy_loss = -11.352, pg_loss = -1142.4, baseline_loss = 16.885, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 17:16:39,722][root][INFO] - Step 25600 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 136.5, step = 25600, mean_episode_return = -0.038297, mean_episode_step = 53.795, total_loss = -342.63, entropy_loss = -11.364, pg_loss = -419.31, baseline_loss = 88.048, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 17:16:44,728][root][INFO] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 141.5, step = 25600, mean_episode_return = -0.038297, mean_episode_step = 53.795, total_loss = -342.63, entropy_loss = -11.364, pg_loss = -419.31, baseline_loss = 88.048, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 17:16:49,733][root][INFO] - Step 28160 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 146.5, step = 28160, mean_episode_return = 0.083474, mean_episode_step = 62.003, total_loss = 1222.4, entropy_loss = -11.338, pg_loss = 1018.7, baseline_loss = 215.01, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 17:16:54,738][root][INFO] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 151.5, step = 28160, mean_episode_return = 0.083474, mean_episode_step = 62.003, total_loss = 1222.4, entropy_loss = -11.338, pg_loss = 1018.7, baseline_loss = 215.01, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 17:16:59,743][root][INFO] - Step 30720 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 156.5, step = 30720, mean_episode_return = 0.031616, mean_episode_step = 58.493, total_loss = -932.46, entropy_loss = -11.361, pg_loss = -926.19, baseline_loss = 5.0891, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)
[2025-01-17 17:17:04,749][root][INFO] - Step 30720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 161.5, step = 30720, mean_episode_return = 0.031616, mean_episode_step = 58.493, total_loss = -932.46, entropy_loss = -11.361, pg_loss = -926.19, baseline_loss = 5.0891, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)
[2025-01-17 17:17:06,165][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 17:17:06,826][root][ERROR] - Exception in actorpool thread!
[2025-01-17 17:17:27,058][root][INFO] - loading existing configuration, we're continuing a previous run
[2025-01-17 17:17:27,109][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32
hydra:
  verbose: true

[2025-01-17 17:17:27,125][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-17 17:17:27,126][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-17 17:17:27,130][root][INFO] - Logging results to /opt/minihack
[2025-01-17 17:17:27,183][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-17 17:17:27,184][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-17 17:17:27,184][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-17 17:17:27,185][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-17 17:17:27,185][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-17 17:17:27,186][root][INFO] - Not using CUDA.
[2025-01-17 17:17:27,197][root][INFO] - Using model baseline
[2025-01-17 17:17:27,197][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,232][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,346][root][INFO] - Number of model parameters: 4264078
[2025-01-17 17:17:27,347][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,377][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,440][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,440][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,440][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,443][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,442][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,443][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,443][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,444][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,447][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,444][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,450][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,450][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,451][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,449][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,446][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,453][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,454][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,458][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,458][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,459][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,461][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,462][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,464][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,465][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,456][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,449][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,478][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,473][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,482][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,488][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,490][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,491][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,495][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,499][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,506][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,506][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,516][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,517][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,519][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,516][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,517][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:27,521][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,449][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,452][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,455][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,456][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,456][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,458][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,456][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,460][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,460][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,463][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,464][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,467][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,468][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,466][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,468][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,468][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,473][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,454][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,476][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,477][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,479][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,479][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,480][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,480][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,482][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,484][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,486][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,488][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,489][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,454][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,459][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,493][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,495][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,496][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,497][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,497][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,483][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,498][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,498][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,503][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,508][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,508][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,510][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,512][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,500][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,513][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,513][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,514][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,515][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,466][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,516][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,517][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,503][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,519][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,519][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,504][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,514][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,509][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,524][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,491][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,522][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,526][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,516][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,522][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,523][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,529][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,531][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,485][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,529][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,472][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,524][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,540][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,527][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,480][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,470][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,486][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,486][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,477][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,547][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,550][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,545][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,494][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,558][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,570][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,567][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,552][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,563][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,565][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,593][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,595][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,599][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,603][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,610][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,617][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,620][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,623][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,627][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,631][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:28,587][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:29,938][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,121][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,123][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,123][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,122][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,128][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,129][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,129][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,123][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,130][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,131][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,125][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,132][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,133][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,134][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,137][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,139][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,133][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,143][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,145][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,147][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,146][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,150][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,150][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,154][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,154][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,162][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,165][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,165][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,162][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,173][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,179][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,179][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,183][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,174][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,190][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,189][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,185][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,198][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,202][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,212][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,214][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,229][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,250][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,247][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,261][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,261][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,261][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,267][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,271][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,278][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,280][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,288][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,297][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,304][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,307][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,316][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,316][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,320][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,327][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,334][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,345][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,350][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,357][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,360][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,367][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:30,390][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:31,922][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:31,978][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,056][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,090][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,187][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,202][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,253][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,269][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,282][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,301][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,373][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,416][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,440][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 50. Learner queue size: 0. Other stats: (train_seconds = 5.0)
[2025-01-17 17:17:32,512][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,515][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,575][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,586][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,604][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,614][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,653][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,676][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,689][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,771][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,792][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,818][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:32,982][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:33,000][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:33,018][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:33,018][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:33,096][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:33,125][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 17:17:37,446][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 19. Learner queue size: 22. Other stats: (train_seconds = 10.0)
[2025-01-17 17:17:42,451][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 72. Learner queue size: 22. Other stats: (train_seconds = 15.0)
[2025-01-17 17:17:47,460][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 24. Learner queue size: 24. Other stats: (train_seconds = 20.0)
[2025-01-17 17:17:49,909][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-17 17:17:52,465][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-17 17:17:52,510][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 60. Learner queue size: 27. Other stats: (train_seconds = 25.0, step = 2560, mean_episode_return = -0.0305, mean_episode_step = 35.103, total_loss = -1704.3, entropy_loss = -11.371, pg_loss = -1912.4, baseline_loss = 219.49, learner_queue_size = 24, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:17:57,516][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 92. Learner queue size: 31. Other stats: (train_seconds = 30.1, step = 2560, mean_episode_return = -0.0305, mean_episode_step = 35.103, total_loss = -1704.3, entropy_loss = -11.371, pg_loss = -1912.4, baseline_loss = 219.49, learner_queue_size = 24, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:18:02,521][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 66. Learner queue size: 6. Other stats: (train_seconds = 35.1, step = 2560, mean_episode_return = -0.0305, mean_episode_step = 35.103, total_loss = -1704.3, entropy_loss = -11.371, pg_loss = -1912.4, baseline_loss = 219.49, learner_queue_size = 24, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:18:07,526][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 122. Learner queue size: 10. Other stats: (train_seconds = 40.1, step = 2560, mean_episode_return = -0.0305, mean_episode_step = 35.103, total_loss = -1704.3, entropy_loss = -11.371, pg_loss = -1912.4, baseline_loss = 219.49, learner_queue_size = 24, _tick = 0, _time = 1.7371e+09)
[2025-01-17 17:18:12,531][root][INFO] - Step 5120 @ 511.5 SPS. Inference batcher size: 66. Learner queue size: 32. Other stats: (train_seconds = 45.1, step = 5120, mean_episode_return = 0.14118, mean_episode_step = 33.508, total_loss = 2291.9, entropy_loss = -11.357, pg_loss = 1955.4, baseline_loss = 347.78, learner_queue_size = 24, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:18:17,537][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (train_seconds = 50.1, step = 5120, mean_episode_return = 0.14118, mean_episode_step = 33.508, total_loss = 2291.9, entropy_loss = -11.357, pg_loss = 1955.4, baseline_loss = 347.78, learner_queue_size = 24, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:18:22,542][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 55.1, step = 5120, mean_episode_return = 0.14118, mean_episode_step = 33.508, total_loss = 2291.9, entropy_loss = -11.357, pg_loss = 1955.4, baseline_loss = 347.78, learner_queue_size = 24, _tick = 1, _time = 1.7371e+09)
[2025-01-17 17:18:27,547][root][INFO] - Step 7680 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 60.1, step = 7680, mean_episode_return = -0.024, mean_episode_step = 46.068, total_loss = -18.449, entropy_loss = -11.368, pg_loss = -115.36, baseline_loss = 108.28, learner_queue_size = 32, _tick = 2, _time = 1.7371e+09)
[2025-01-17 17:18:32,552][root][INFO] - Step 10240 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 65.1, step = 10240, mean_episode_return = -0.034423, mean_episode_step = 54.599, total_loss = 1237.0, entropy_loss = -11.346, pg_loss = 1074.9, baseline_loss = 173.52, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:18:37,557][root][INFO] - Step 10240 @ 0.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 70.1, step = 10240, mean_episode_return = -0.034423, mean_episode_step = 54.599, total_loss = 1237.0, entropy_loss = -11.346, pg_loss = 1074.9, baseline_loss = 173.52, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:18:42,563][root][INFO] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 75.1, step = 10240, mean_episode_return = -0.034423, mean_episode_step = 54.599, total_loss = 1237.0, entropy_loss = -11.346, pg_loss = 1074.9, baseline_loss = 173.52, learner_queue_size = 32, _tick = 3, _time = 1.7371e+09)
[2025-01-17 17:18:47,568][root][INFO] - Step 12800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 80.1, step = 12800, mean_episode_return = 0.040409, mean_episode_step = 39.696, total_loss = 348.13, entropy_loss = -11.345, pg_loss = 207.44, baseline_loss = 152.03, learner_queue_size = 32, _tick = 4, _time = 1.7371e+09)
[2025-01-17 17:18:52,573][root][INFO] - Step 15360 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 85.1, step = 15360, mean_episode_return = 0.09945, mean_episode_step = 40.331, total_loss = -103.61, entropy_loss = -11.28, pg_loss = -210.17, baseline_loss = 117.84, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 17:18:57,578][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 90.1, step = 15360, mean_episode_return = 0.09945, mean_episode_step = 40.331, total_loss = -103.61, entropy_loss = -11.28, pg_loss = -210.17, baseline_loss = 117.84, learner_queue_size = 32, _tick = 5, _time = 1.7371e+09)
[2025-01-17 17:19:02,583][root][INFO] - Step 17920 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 95.1, step = 17920, mean_episode_return = -0.059895, mean_episode_step = 54.916, total_loss = -156.03, entropy_loss = -11.255, pg_loss = -161.3, baseline_loss = 16.523, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 17:19:07,588][root][INFO] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 100.2, step = 17920, mean_episode_return = -0.059895, mean_episode_step = 54.916, total_loss = -156.03, entropy_loss = -11.255, pg_loss = -161.3, baseline_loss = 16.523, learner_queue_size = 32, _tick = 6, _time = 1.7371e+09)
[2025-01-17 17:19:12,593][root][INFO] - Step 20480 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 105.2, step = 20480, mean_episode_return = -0.031063, mean_episode_step = 47.772, total_loss = 1079.4, entropy_loss = -11.201, pg_loss = 978.58, baseline_loss = 112.03, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 17:19:17,598][root][INFO] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 110.2, step = 20480, mean_episode_return = -0.031063, mean_episode_step = 47.772, total_loss = 1079.4, entropy_loss = -11.201, pg_loss = 978.58, baseline_loss = 112.03, learner_queue_size = 32, _tick = 7, _time = 1.7371e+09)
[2025-01-17 17:19:22,604][root][INFO] - Step 23040 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 115.2, step = 23040, mean_episode_return = 0.06787, mean_episode_step = 51.304, total_loss = 765.3, entropy_loss = -11.218, pg_loss = 644.0, baseline_loss = 132.52, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 17:19:27,609][root][INFO] - Step 23040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 120.2, step = 23040, mean_episode_return = 0.06787, mean_episode_step = 51.304, total_loss = 765.3, entropy_loss = -11.218, pg_loss = 644.0, baseline_loss = 132.52, learner_queue_size = 32, _tick = 8, _time = 1.7371e+09)
[2025-01-17 17:19:32,614][root][INFO] - Step 25600 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 125.2, step = 25600, mean_episode_return = -0.0295, mean_episode_step = 53.13, total_loss = -101.86, entropy_loss = -11.191, pg_loss = -168.99, baseline_loss = 78.323, learner_queue_size = 32, _tick = 9, _time = 1.7371e+09)
[2025-01-17 17:19:37,621][root][INFO] - Step 28160 @ 511.2 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 130.2, step = 28160, mean_episode_return = -0.0010666, mean_episode_step = 62.543, total_loss = 306.65, entropy_loss = -11.157, pg_loss = 260.37, baseline_loss = 57.439, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 17:19:42,627][root][INFO] - Step 28160 @ 0.0 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 135.2, step = 28160, mean_episode_return = -0.0010666, mean_episode_step = 62.543, total_loss = 306.65, entropy_loss = -11.157, pg_loss = 260.37, baseline_loss = 57.439, learner_queue_size = 32, _tick = 10, _time = 1.7371e+09)
[2025-01-17 17:19:47,632][root][INFO] - Step 30720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 140.2, step = 30720, mean_episode_return = 0.037929, mean_episode_step = 57.206, total_loss = 304.85, entropy_loss = -11.093, pg_loss = 212.95, baseline_loss = 102.99, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)
[2025-01-17 17:19:52,637][root][INFO] - Step 30720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 145.2, step = 30720, mean_episode_return = 0.037929, mean_episode_step = 57.206, total_loss = 304.85, entropy_loss = -11.093, pg_loss = 212.95, baseline_loss = 102.99, learner_queue_size = 32, _tick = 11, _time = 1.7371e+09)
[2025-01-17 17:19:57,709][root][INFO] - Step 33280 @ 504.7 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 150.3, step = 33280, mean_episode_return = -0.080656, mean_episode_step = 56.603, total_loss = -828.26, entropy_loss = -11.033, pg_loss = -831.58, baseline_loss = 14.352, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)
[2025-01-17 17:20:02,714][root][INFO] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 155.3, step = 33280, mean_episode_return = -0.080656, mean_episode_step = 56.603, total_loss = -828.26, entropy_loss = -11.033, pg_loss = -831.58, baseline_loss = 14.352, learner_queue_size = 32, _tick = 12, _time = 1.7371e+09)
[2025-01-17 17:20:07,719][root][INFO] - Step 35840 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 160.3, step = 35840, mean_episode_return = -0.058633, mean_episode_step = 45.804, total_loss = -355.5, entropy_loss = -11.04, pg_loss = -359.18, baseline_loss = 14.715, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)
[2025-01-17 17:20:12,724][root][INFO] - Step 35840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 165.3, step = 35840, mean_episode_return = -0.058633, mean_episode_step = 45.804, total_loss = -355.5, entropy_loss = -11.04, pg_loss = -359.18, baseline_loss = 14.715, learner_queue_size = 32, _tick = 13, _time = 1.7371e+09)
[2025-01-17 17:20:17,729][root][INFO] - Step 38400 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 170.3, step = 38400, mean_episode_return = 0.038561, mean_episode_step = 45.425, total_loss = 767.94, entropy_loss = -11.029, pg_loss = 644.31, baseline_loss = 134.66, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)
[2025-01-17 17:20:22,735][root][INFO] - Step 38400 @ 0.0 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 175.3, step = 38400, mean_episode_return = 0.038561, mean_episode_step = 45.425, total_loss = 767.94, entropy_loss = -11.029, pg_loss = 644.31, baseline_loss = 134.66, learner_queue_size = 32, _tick = 14, _time = 1.7371e+09)
[2025-01-17 17:20:27,741][root][INFO] - Step 40960 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 180.3, step = 40960, mean_episode_return = 0.060167, mean_episode_step = 47.856, total_loss = 318.69, entropy_loss = -10.991, pg_loss = 99.835, baseline_loss = 229.84, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)
[2025-01-17 17:20:32,746][root][INFO] - Step 40960 @ 0.0 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 185.3, step = 40960, mean_episode_return = 0.060167, mean_episode_step = 47.856, total_loss = 318.69, entropy_loss = -10.991, pg_loss = 99.835, baseline_loss = 229.84, learner_queue_size = 32, _tick = 15, _time = 1.7371e+09)
[2025-01-17 17:20:37,752][root][INFO] - Step 43520 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 190.3, step = 43520, mean_episode_return = 0.041075, mean_episode_step = 51.149, total_loss = 5.5776, entropy_loss = -10.932, pg_loss = -88.497, baseline_loss = 105.01, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)
[2025-01-17 17:20:42,758][root][INFO] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 195.3, step = 43520, mean_episode_return = 0.041075, mean_episode_step = 51.149, total_loss = 5.5776, entropy_loss = -10.932, pg_loss = -88.497, baseline_loss = 105.01, learner_queue_size = 32, _tick = 16, _time = 1.7371e+09)
[2025-01-17 17:20:47,763][root][INFO] - Step 46080 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 200.3, step = 46080, mean_episode_return = 0.038462, mean_episode_step = 45.833, total_loss = 522.74, entropy_loss = -10.742, pg_loss = 417.11, baseline_loss = 116.37, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)
[2025-01-17 17:20:52,768][root][INFO] - Step 46080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 205.3, step = 46080, mean_episode_return = 0.038462, mean_episode_step = 45.833, total_loss = 522.74, entropy_loss = -10.742, pg_loss = 417.11, baseline_loss = 116.37, learner_queue_size = 32, _tick = 17, _time = 1.7371e+09)
[2025-01-17 17:20:57,781][root][INFO] - Step 48640 @ 510.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 210.3, step = 48640, mean_episode_return = 0.12325, mean_episode_step = 54.589, total_loss = 255.82, entropy_loss = -10.737, pg_loss = 160.71, baseline_loss = 105.85, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)
[2025-01-17 17:21:02,786][root][INFO] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 215.4, step = 48640, mean_episode_return = 0.12325, mean_episode_step = 54.589, total_loss = 255.82, entropy_loss = -10.737, pg_loss = 160.71, baseline_loss = 105.85, learner_queue_size = 32, _tick = 18, _time = 1.7371e+09)
[2025-01-17 17:21:07,791][root][INFO] - Step 51200 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 220.4, step = 51200, mean_episode_return = -0.027714, mean_episode_step = 50.748, total_loss = -592.1, entropy_loss = -10.753, pg_loss = -641.24, baseline_loss = 59.899, learner_queue_size = 32, _tick = 19, _time = 1.7371e+09)
[2025-01-17 17:21:12,796][root][INFO] - Step 53760 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 225.4, step = 53760, mean_episode_return = 0.040686, mean_episode_step = 42.492, total_loss = -141.73, entropy_loss = -10.787, pg_loss = -241.48, baseline_loss = 110.54, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)
[2025-01-17 17:21:17,801][root][INFO] - Step 53760 @ 0.0 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 230.4, step = 53760, mean_episode_return = 0.040686, mean_episode_step = 42.492, total_loss = -141.73, entropy_loss = -10.787, pg_loss = -241.48, baseline_loss = 110.54, learner_queue_size = 32, _tick = 20, _time = 1.7371e+09)
[2025-01-17 17:21:22,806][root][INFO] - Step 56320 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 235.4, step = 56320, mean_episode_return = 0.083976, mean_episode_step = 52.025, total_loss = 862.87, entropy_loss = -10.746, pg_loss = 670.13, baseline_loss = 203.48, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)
[2025-01-17 17:21:27,811][root][INFO] - Step 56320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 240.4, step = 56320, mean_episode_return = 0.083976, mean_episode_step = 52.025, total_loss = 862.87, entropy_loss = -10.746, pg_loss = 670.13, baseline_loss = 203.48, learner_queue_size = 32, _tick = 21, _time = 1.7371e+09)
[2025-01-17 17:21:32,816][root][INFO] - Step 58880 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 245.4, step = 58880, mean_episode_return = 0.064767, mean_episode_step = 56.439, total_loss = 518.62, entropy_loss = -10.705, pg_loss = 335.93, baseline_loss = 193.39, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)
[2025-01-17 17:21:37,822][root][INFO] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 250.4, step = 58880, mean_episode_return = 0.064767, mean_episode_step = 56.439, total_loss = 518.62, entropy_loss = -10.705, pg_loss = 335.93, baseline_loss = 193.39, learner_queue_size = 32, _tick = 22, _time = 1.7371e+09)
[2025-01-17 17:21:42,827][root][INFO] - Step 61440 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 255.4, step = 61440, mean_episode_return = -0.01078, mean_episode_step = 49.352, total_loss = 156.26, entropy_loss = -10.638, pg_loss = -8.6348, baseline_loss = 175.53, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)
[2025-01-17 17:21:47,834][root][INFO] - Step 61440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 260.4, step = 61440, mean_episode_return = -0.01078, mean_episode_step = 49.352, total_loss = 156.26, entropy_loss = -10.638, pg_loss = -8.6348, baseline_loss = 175.53, learner_queue_size = 32, _tick = 23, _time = 1.7371e+09)
[2025-01-17 17:21:52,841][root][INFO] - Step 64000 @ 511.3 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 265.4, step = 64000, mean_episode_return = 0.074263, mean_episode_step = 54.362, total_loss = -620.77, entropy_loss = -10.552, pg_loss = -660.81, baseline_loss = 50.596, learner_queue_size = 32, _tick = 24, _time = 1.7371e+09)
[2025-01-17 17:21:57,846][root][INFO] - Step 66560 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 270.4, step = 66560, mean_episode_return = 0.15907, mean_episode_step = 56.537, total_loss = 1094.3, entropy_loss = -10.566, pg_loss = 946.9, baseline_loss = 157.96, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 17:22:02,852][root][INFO] - Step 66560 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 275.4, step = 66560, mean_episode_return = 0.15907, mean_episode_step = 56.537, total_loss = 1094.3, entropy_loss = -10.566, pg_loss = 946.9, baseline_loss = 157.96, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 17:22:07,858][root][INFO] - Step 66560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 280.4, step = 66560, mean_episode_return = 0.15907, mean_episode_step = 56.537, total_loss = 1094.3, entropy_loss = -10.566, pg_loss = 946.9, baseline_loss = 157.96, learner_queue_size = 32, _tick = 25, _time = 1.7371e+09)
[2025-01-17 17:22:12,863][root][INFO] - Step 69120 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 285.4, step = 69120, mean_episode_return = -0.0252, mean_episode_step = 57.685, total_loss = -198.64, entropy_loss = -10.575, pg_loss = -298.87, baseline_loss = 110.8, learner_queue_size = 32, _tick = 26, _time = 1.7371e+09)
[2025-01-17 17:22:17,870][root][INFO] - Step 71680 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 290.4, step = 71680, mean_episode_return = 0.31686, mean_episode_step = 59.88, total_loss = 770.07, entropy_loss = -10.546, pg_loss = 617.23, baseline_loss = 163.38, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)
[2025-01-17 17:22:22,876][root][INFO] - Step 71680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 295.4, step = 71680, mean_episode_return = 0.31686, mean_episode_step = 59.88, total_loss = 770.07, entropy_loss = -10.546, pg_loss = 617.23, baseline_loss = 163.38, learner_queue_size = 32, _tick = 27, _time = 1.7371e+09)
[2025-01-17 17:22:27,882][root][INFO] - Step 74240 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 300.4, step = 74240, mean_episode_return = 0.0984, mean_episode_step = 53.318, total_loss = -395.14, entropy_loss = -10.538, pg_loss = -474.79, baseline_loss = 90.197, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)
[2025-01-17 17:22:32,887][root][INFO] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 305.5, step = 74240, mean_episode_return = 0.0984, mean_episode_step = 53.318, total_loss = -395.14, entropy_loss = -10.538, pg_loss = -474.79, baseline_loss = 90.197, learner_queue_size = 32, _tick = 28, _time = 1.7371e+09)
[2025-01-17 17:22:37,892][root][INFO] - Step 76800 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 310.5, step = 76800, mean_episode_return = 0.1836, mean_episode_step = 58.911, total_loss = -398.5, entropy_loss = -10.537, pg_loss = -447.87, baseline_loss = 59.906, learner_queue_size = 32, _tick = 29, _time = 1.7371e+09)
[2025-01-17 17:22:42,898][root][INFO] - Step 76800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 315.5, step = 76800, mean_episode_return = 0.1836, mean_episode_step = 58.911, total_loss = -398.5, entropy_loss = -10.537, pg_loss = -447.87, baseline_loss = 59.906, learner_queue_size = 32, _tick = 29, _time = 1.7371e+09)
[2025-01-17 17:22:47,903][root][INFO] - Step 79360 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 320.5, step = 79360, mean_episode_return = 0.22393, mean_episode_step = 58.869, total_loss = -272.5, entropy_loss = -10.498, pg_loss = -359.77, baseline_loss = 97.767, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)
[2025-01-17 17:22:52,908][root][INFO] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 325.5, step = 79360, mean_episode_return = 0.22393, mean_episode_step = 58.869, total_loss = -272.5, entropy_loss = -10.498, pg_loss = -359.77, baseline_loss = 97.767, learner_queue_size = 32, _tick = 30, _time = 1.7371e+09)
[2025-01-17 17:22:57,913][root][INFO] - Step 81920 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 330.5, step = 81920, mean_episode_return = 0.032267, mean_episode_step = 51.884, total_loss = 121.56, entropy_loss = -10.462, pg_loss = 58.299, baseline_loss = 73.727, learner_queue_size = 32, _tick = 31, _time = 1.7371e+09)
[2025-01-17 17:23:02,919][root][INFO] - Step 84480 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 335.5, step = 84480, mean_episode_return = 0.13486, mean_episode_step = 45.495, total_loss = 1148.7, entropy_loss = -10.366, pg_loss = 988.93, baseline_loss = 170.13, learner_queue_size = 32, _tick = 32, _time = 1.7371e+09)
[2025-01-17 17:23:07,925][root][INFO] - Step 84480 @ 0.0 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 340.5, step = 84480, mean_episode_return = 0.13486, mean_episode_step = 45.495, total_loss = 1148.7, entropy_loss = -10.366, pg_loss = 988.93, baseline_loss = 170.13, learner_queue_size = 32, _tick = 32, _time = 1.7371e+09)
[2025-01-17 17:23:12,930][root][INFO] - Step 87040 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 345.5, step = 87040, mean_episode_return = 0.085319, mean_episode_step = 45.543, total_loss = 104.36, entropy_loss = -10.364, pg_loss = 15.737, baseline_loss = 98.986, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)
[2025-01-17 17:23:17,935][root][INFO] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 350.5, step = 87040, mean_episode_return = 0.085319, mean_episode_step = 45.543, total_loss = 104.36, entropy_loss = -10.364, pg_loss = 15.737, baseline_loss = 98.986, learner_queue_size = 32, _tick = 33, _time = 1.7371e+09)
[2025-01-17 17:23:22,940][root][INFO] - Step 89600 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 355.5, step = 89600, mean_episode_return = 0.16658, mean_episode_step = 47.68, total_loss = -14.144, entropy_loss = -10.334, pg_loss = -75.741, baseline_loss = 71.932, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)
[2025-01-17 17:23:27,947][root][INFO] - Step 89600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 360.5, step = 89600, mean_episode_return = 0.16658, mean_episode_step = 47.68, total_loss = -14.144, entropy_loss = -10.334, pg_loss = -75.741, baseline_loss = 71.932, learner_queue_size = 32, _tick = 34, _time = 1.7371e+09)
[2025-01-17 17:23:32,953][root][INFO] - Step 92160 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 365.5, step = 92160, mean_episode_return = 0.18319, mean_episode_step = 54.629, total_loss = 348.58, entropy_loss = -10.332, pg_loss = 257.64, baseline_loss = 101.27, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 17:23:37,958][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 370.5, step = 92160, mean_episode_return = 0.18319, mean_episode_step = 54.629, total_loss = 348.58, entropy_loss = -10.332, pg_loss = 257.64, baseline_loss = 101.27, learner_queue_size = 32, _tick = 35, _time = 1.7371e+09)
[2025-01-17 17:23:42,963][root][INFO] - Step 94720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 375.5, step = 94720, mean_episode_return = 0.016029, mean_episode_step = 55.426, total_loss = -139.09, entropy_loss = -10.268, pg_loss = -201.26, baseline_loss = 72.44, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 17:23:47,968][root][INFO] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 380.5, step = 94720, mean_episode_return = 0.016029, mean_episode_step = 55.426, total_loss = -139.09, entropy_loss = -10.268, pg_loss = -201.26, baseline_loss = 72.44, learner_queue_size = 32, _tick = 36, _time = 1.7371e+09)
[2025-01-17 17:23:52,974][root][INFO] - Step 97280 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 385.5, step = 97280, mean_episode_return = 0.17467, mean_episode_step = 59.368, total_loss = -86.181, entropy_loss = -10.22, pg_loss = -144.17, baseline_loss = 68.206, learner_queue_size = 32, _tick = 37, _time = 1.7371e+09)
[2025-01-17 17:23:57,981][root][INFO] - Step 99840 @ 511.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 390.5, step = 99840, mean_episode_return = 0.27102, mean_episode_step = 56.739, total_loss = 299.04, entropy_loss = -10.173, pg_loss = 235.26, baseline_loss = 73.946, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)
[2025-01-17 17:24:02,987][root][INFO] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 395.6, step = 99840, mean_episode_return = 0.27102, mean_episode_step = 56.739, total_loss = 299.04, entropy_loss = -10.173, pg_loss = 235.26, baseline_loss = 73.946, learner_queue_size = 32, _tick = 38, _time = 1.7371e+09)
[2025-01-17 17:24:07,992][root][INFO] - Step 102400 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 400.6, step = 102400, mean_episode_return = 0.15215, mean_episode_step = 55.204, total_loss = -187.71, entropy_loss = -10.163, pg_loss = -245.31, baseline_loss = 67.767, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)
[2025-01-17 17:24:12,997][root][INFO] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 405.6, step = 102400, mean_episode_return = 0.15215, mean_episode_step = 55.204, total_loss = -187.71, entropy_loss = -10.163, pg_loss = -245.31, baseline_loss = 67.767, learner_queue_size = 32, _tick = 39, _time = 1.7371e+09)
[2025-01-17 17:24:18,003][root][INFO] - Step 104960 @ 511.3 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 410.6, step = 104960, mean_episode_return = 0.16923, mean_episode_step = 55.674, total_loss = 108.29, entropy_loss = -10.122, pg_loss = 53.098, baseline_loss = 65.315, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)
[2025-01-17 17:24:23,010][root][INFO] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 415.6, step = 104960, mean_episode_return = 0.16923, mean_episode_step = 55.674, total_loss = 108.29, entropy_loss = -10.122, pg_loss = 53.098, baseline_loss = 65.315, learner_queue_size = 32, _tick = 40, _time = 1.7371e+09)
[2025-01-17 17:24:28,016][root][INFO] - Step 107520 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 420.6, step = 107520, mean_episode_return = 0.34903, mean_episode_step = 59.427, total_loss = 429.32, entropy_loss = -9.999, pg_loss = 352.46, baseline_loss = 86.852, learner_queue_size = 32, _tick = 41, _time = 1.7371e+09)
[2025-01-17 17:24:33,025][root][INFO] - Step 110080 @ 511.0 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 425.6, step = 110080, mean_episode_return = 0.21179, mean_episode_step = 38.528, total_loss = 73.326, entropy_loss = -9.9749, pg_loss = -4.2123, baseline_loss = 87.513, learner_queue_size = 32, _tick = 42, _time = 1.7371e+09)
[2025-01-17 17:24:38,031][root][INFO] - Step 110080 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 430.6, step = 110080, mean_episode_return = 0.21179, mean_episode_step = 38.528, total_loss = 73.326, entropy_loss = -9.9749, pg_loss = -4.2123, baseline_loss = 87.513, learner_queue_size = 32, _tick = 42, _time = 1.7371e+09)
[2025-01-17 17:24:43,037][root][INFO] - Step 112640 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 435.6, step = 112640, mean_episode_return = 0.21245, mean_episode_step = 46.04, total_loss = 334.32, entropy_loss = -9.9333, pg_loss = 257.93, baseline_loss = 86.323, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)
[2025-01-17 17:24:48,042][root][INFO] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 440.6, step = 112640, mean_episode_return = 0.21245, mean_episode_step = 46.04, total_loss = 334.32, entropy_loss = -9.9333, pg_loss = 257.93, baseline_loss = 86.323, learner_queue_size = 32, _tick = 43, _time = 1.7371e+09)
[2025-01-17 17:24:53,047][root][INFO] - Step 115200 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 445.6, step = 115200, mean_episode_return = 0.23724, mean_episode_step = 54.309, total_loss = 455.3, entropy_loss = -9.8663, pg_loss = 364.24, baseline_loss = 100.93, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)
[2025-01-17 17:24:58,055][root][INFO] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 450.6, step = 115200, mean_episode_return = 0.23724, mean_episode_step = 54.309, total_loss = 455.3, entropy_loss = -9.8663, pg_loss = 364.24, baseline_loss = 100.93, learner_queue_size = 32, _tick = 44, _time = 1.7371e+09)
[2025-01-17 17:25:03,060][root][INFO] - Step 117760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 455.6, step = 117760, mean_episode_return = 0.12221, mean_episode_step = 58.001, total_loss = -197.57, entropy_loss = -9.8222, pg_loss = -267.0, baseline_loss = 79.246, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)
[2025-01-17 17:25:08,065][root][INFO] - Step 117760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 460.6, step = 117760, mean_episode_return = 0.12221, mean_episode_step = 58.001, total_loss = -197.57, entropy_loss = -9.8222, pg_loss = -267.0, baseline_loss = 79.246, learner_queue_size = 32, _tick = 45, _time = 1.7371e+09)
[2025-01-17 17:25:13,070][root][INFO] - Step 120320 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 465.6, step = 120320, mean_episode_return = 0.2707, mean_episode_step = 58.439, total_loss = 225.1, entropy_loss = -9.7769, pg_loss = 166.01, baseline_loss = 68.861, learner_queue_size = 32, _tick = 46, _time = 1.7371e+09)
[2025-01-17 17:25:18,076][root][INFO] - Step 122880 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 470.6, step = 122880, mean_episode_return = 0.31895, mean_episode_step = 59.005, total_loss = -126.68, entropy_loss = -9.7674, pg_loss = -181.82, baseline_loss = 64.913, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)
[2025-01-17 17:25:23,082][root][INFO] - Step 122880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 475.6, step = 122880, mean_episode_return = 0.31895, mean_episode_step = 59.005, total_loss = -126.68, entropy_loss = -9.7674, pg_loss = -181.82, baseline_loss = 64.913, learner_queue_size = 32, _tick = 47, _time = 1.7371e+09)
[2025-01-17 17:25:28,089][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar
[2025-01-17 17:25:28,182][root][INFO] - Step 125440 @ 511.4 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 480.7, step = 125440, mean_episode_return = 0.27128, mean_episode_step = 59.812, total_loss = -335.68, entropy_loss = -9.7056, pg_loss = -402.83, baseline_loss = 76.858, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)
[2025-01-17 17:25:33,188][root][INFO] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 485.8, step = 125440, mean_episode_return = 0.27128, mean_episode_step = 59.812, total_loss = -335.68, entropy_loss = -9.7056, pg_loss = -402.83, baseline_loss = 76.858, learner_queue_size = 32, _tick = 48, _time = 1.7371e+09)
[2025-01-17 17:25:38,193][root][INFO] - Step 128000 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 490.8, step = 128000, mean_episode_return = 0.48357, mean_episode_step = 59.039, total_loss = 643.97, entropy_loss = -9.6791, pg_loss = 558.59, baseline_loss = 95.053, learner_queue_size = 32, _tick = 49, _time = 1.7371e+09)
[2025-01-17 17:25:43,199][root][INFO] - Step 128000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 495.8, step = 128000, mean_episode_return = 0.48357, mean_episode_step = 59.039, total_loss = 643.97, entropy_loss = -9.6791, pg_loss = 558.59, baseline_loss = 95.053, learner_queue_size = 32, _tick = 49, _time = 1.7371e+09)
[2025-01-17 17:25:48,207][root][INFO] - Step 130560 @ 511.2 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 500.8, step = 130560, mean_episode_return = 0.22548, mean_episode_step = 41.803, total_loss = -471.74, entropy_loss = -9.6812, pg_loss = -542.55, baseline_loss = 80.488, learner_queue_size = 32, _tick = 50, _time = 1.7371e+09)
[2025-01-17 17:25:53,212][root][INFO] - Step 133120 @ 511.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 505.8, step = 133120, mean_episode_return = 0.50957, mean_episode_step = 57.242, total_loss = 853.41, entropy_loss = -9.6816, pg_loss = 714.34, baseline_loss = 148.75, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)
[2025-01-17 17:25:58,217][root][INFO] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 510.8, step = 133120, mean_episode_return = 0.50957, mean_episode_step = 57.242, total_loss = 853.41, entropy_loss = -9.6816, pg_loss = 714.34, baseline_loss = 148.75, learner_queue_size = 32, _tick = 51, _time = 1.7371e+09)
[2025-01-17 17:26:03,222][root][INFO] - Step 135680 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 515.8, step = 135680, mean_episode_return = 0.37959, mean_episode_step = 64.105, total_loss = 64.942, entropy_loss = -9.7027, pg_loss = -18.041, baseline_loss = 92.686, learner_queue_size = 32, _tick = 52, _time = 1.7371e+09)
[2025-01-17 17:26:08,228][root][INFO] - Step 135680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 520.8, step = 135680, mean_episode_return = 0.37959, mean_episode_step = 64.105, total_loss = 64.942, entropy_loss = -9.7027, pg_loss = -18.041, baseline_loss = 92.686, learner_queue_size = 32, _tick = 52, _time = 1.7371e+09)
[2025-01-17 17:26:13,233][root][INFO] - Step 138240 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 525.8, step = 138240, mean_episode_return = 0.31957, mean_episode_step = 45.188, total_loss = -729.21, entropy_loss = -9.7579, pg_loss = -814.56, baseline_loss = 95.109, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)
[2025-01-17 17:26:18,239][root][INFO] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 530.8, step = 138240, mean_episode_return = 0.31957, mean_episode_step = 45.188, total_loss = -729.21, entropy_loss = -9.7579, pg_loss = -814.56, baseline_loss = 95.109, learner_queue_size = 32, _tick = 53, _time = 1.7371e+09)
[2025-01-17 17:26:23,244][root][INFO] - Step 140800 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 535.8, step = 140800, mean_episode_return = 0.49144, mean_episode_step = 72.689, total_loss = 79.051, entropy_loss = -9.739, pg_loss = 26.286, baseline_loss = 62.505, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)
[2025-01-17 17:26:28,250][root][INFO] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 540.8, step = 140800, mean_episode_return = 0.49144, mean_episode_step = 72.689, total_loss = 79.051, entropy_loss = -9.739, pg_loss = 26.286, baseline_loss = 62.505, learner_queue_size = 32, _tick = 54, _time = 1.7371e+09)
[2025-01-17 17:26:33,255][root][INFO] - Step 143360 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 545.8, step = 143360, mean_episode_return = 0.43, mean_episode_step = 63.004, total_loss = 153.56, entropy_loss = -9.7112, pg_loss = 41.735, baseline_loss = 121.54, learner_queue_size = 32, _tick = 55, _time = 1.7371e+09)
[2025-01-17 17:26:38,260][root][INFO] - Step 143360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 550.8, step = 143360, mean_episode_return = 0.43, mean_episode_step = 63.004, total_loss = 153.56, entropy_loss = -9.7112, pg_loss = 41.735, baseline_loss = 121.54, learner_queue_size = 32, _tick = 55, _time = 1.7371e+09)
[2025-01-17 17:26:43,265][root][INFO] - Step 145920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 555.8, step = 145920, mean_episode_return = 0.38493, mean_episode_step = 57.699, total_loss = -296.05, entropy_loss = -9.6947, pg_loss = -397.04, baseline_loss = 110.68, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)
[2025-01-17 17:26:48,270][root][INFO] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 560.8, step = 145920, mean_episode_return = 0.38493, mean_episode_step = 57.699, total_loss = -296.05, entropy_loss = -9.6947, pg_loss = -397.04, baseline_loss = 110.68, learner_queue_size = 32, _tick = 56, _time = 1.7371e+09)
[2025-01-17 17:26:53,275][root][INFO] - Step 148480 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 565.8, step = 148480, mean_episode_return = 0.31787, mean_episode_step = 67.86, total_loss = -385.51, entropy_loss = -9.6613, pg_loss = -421.94, baseline_loss = 46.085, learner_queue_size = 32, _tick = 57, _time = 1.7371e+09)
[2025-01-17 17:26:58,280][root][INFO] - Step 151040 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 570.8, step = 151040, mean_episode_return = 0.47834, mean_episode_step = 52.897, total_loss = 365.52, entropy_loss = -9.6709, pg_loss = 277.66, baseline_loss = 97.526, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)
[2025-01-17 17:27:03,285][root][INFO] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 575.8, step = 151040, mean_episode_return = 0.47834, mean_episode_step = 52.897, total_loss = 365.52, entropy_loss = -9.6709, pg_loss = 277.66, baseline_loss = 97.526, learner_queue_size = 32, _tick = 58, _time = 1.7371e+09)
[2025-01-17 17:27:08,290][root][INFO] - Step 153600 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 580.9, step = 153600, mean_episode_return = 0.21864, mean_episode_step = 49.493, total_loss = -112.13, entropy_loss = -9.6698, pg_loss = -181.29, baseline_loss = 78.824, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)
[2025-01-17 17:27:13,295][root][INFO] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 585.9, step = 153600, mean_episode_return = 0.21864, mean_episode_step = 49.493, total_loss = -112.13, entropy_loss = -9.6698, pg_loss = -181.29, baseline_loss = 78.824, learner_queue_size = 32, _tick = 59, _time = 1.7371e+09)
[2025-01-17 17:27:18,301][root][INFO] - Step 156160 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 590.9, step = 156160, mean_episode_return = 0.37585, mean_episode_step = 52.685, total_loss = 188.42, entropy_loss = -9.684, pg_loss = 98.24, baseline_loss = 99.866, learner_queue_size = 32, _tick = 60, _time = 1.7371e+09)
[2025-01-17 17:27:23,308][root][INFO] - Step 158720 @ 511.3 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 595.9, step = 158720, mean_episode_return = 0.27981, mean_episode_step = 50.198, total_loss = -601.08, entropy_loss = -9.6647, pg_loss = -669.41, baseline_loss = 77.991, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)
[2025-01-17 17:27:28,314][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 17:27:28,361][root][INFO] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 600.9, step = 158720, mean_episode_return = 0.27981, mean_episode_step = 50.198, total_loss = -601.08, entropy_loss = -9.6647, pg_loss = -669.41, baseline_loss = 77.991, learner_queue_size = 32, _tick = 61, _time = 1.7371e+09)
[2025-01-17 17:27:33,366][root][INFO] - Step 161280 @ 506.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 605.9, step = 161280, mean_episode_return = 0.40367, mean_episode_step = 50.668, total_loss = 268.94, entropy_loss = -9.6398, pg_loss = 185.66, baseline_loss = 92.914, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)
[2025-01-17 17:27:38,372][root][INFO] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 610.9, step = 161280, mean_episode_return = 0.40367, mean_episode_step = 50.668, total_loss = 268.94, entropy_loss = -9.6398, pg_loss = 185.66, baseline_loss = 92.914, learner_queue_size = 32, _tick = 62, _time = 1.7371e+09)
[2025-01-17 17:27:43,383][root][INFO] - Step 163840 @ 510.9 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 615.9, step = 163840, mean_episode_return = 0.4991, mean_episode_step = 61.421, total_loss = 181.22, entropy_loss = -9.63, pg_loss = 119.04, baseline_loss = 71.818, learner_queue_size = 32, _tick = 63, _time = 1.7371e+09)
[2025-01-17 17:27:48,388][root][INFO] - Step 166400 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 621.0, step = 166400, mean_episode_return = 0.41306, mean_episode_step = 65.959, total_loss = 103.88, entropy_loss = -9.6264, pg_loss = -9.9289, baseline_loss = 123.44, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)
[2025-01-17 17:27:53,393][root][INFO] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 626.0, step = 166400, mean_episode_return = 0.41306, mean_episode_step = 65.959, total_loss = 103.88, entropy_loss = -9.6264, pg_loss = -9.9289, baseline_loss = 123.44, learner_queue_size = 32, _tick = 64, _time = 1.7371e+09)
[2025-01-17 17:27:58,398][root][INFO] - Step 168960 @ 511.5 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 631.0, step = 168960, mean_episode_return = 0.17611, mean_episode_step = 46.344, total_loss = -437.47, entropy_loss = -9.6558, pg_loss = -517.31, baseline_loss = 89.5, learner_queue_size = 32, _tick = 65, _time = 1.7371e+09)
[2025-01-17 17:28:03,403][root][INFO] - Step 171520 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 636.0, step = 171520, mean_episode_return = 0.22915, mean_episode_step = 62.134, total_loss = -8.2669, entropy_loss = -9.6603, pg_loss = -80.894, baseline_loss = 82.287, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)
[2025-01-17 17:28:08,409][root][INFO] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 641.0, step = 171520, mean_episode_return = 0.22915, mean_episode_step = 62.134, total_loss = -8.2669, entropy_loss = -9.6603, pg_loss = -80.894, baseline_loss = 82.287, learner_queue_size = 32, _tick = 66, _time = 1.7371e+09)
[2025-01-17 17:28:13,415][root][INFO] - Step 174080 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 646.0, step = 174080, mean_episode_return = 0.24943, mean_episode_step = 52.162, total_loss = -191.51, entropy_loss = -9.5902, pg_loss = -242.61, baseline_loss = 60.684, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)
[2025-01-17 17:28:18,422][root][INFO] - Step 174080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 651.0, step = 174080, mean_episode_return = 0.24943, mean_episode_step = 52.162, total_loss = -191.51, entropy_loss = -9.5902, pg_loss = -242.61, baseline_loss = 60.684, learner_queue_size = 32, _tick = 67, _time = 1.7371e+09)
[2025-01-17 17:28:23,435][root][INFO] - Step 176640 @ 510.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 656.0, step = 176640, mean_episode_return = 0.50812, mean_episode_step = 57.158, total_loss = 608.79, entropy_loss = -9.5362, pg_loss = 546.45, baseline_loss = 71.88, learner_queue_size = 32, _tick = 68, _time = 1.7371e+09)
[2025-01-17 17:28:28,441][root][INFO] - Step 176640 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 661.0, step = 176640, mean_episode_return = 0.50812, mean_episode_step = 57.158, total_loss = 608.79, entropy_loss = -9.5362, pg_loss = 546.45, baseline_loss = 71.88, learner_queue_size = 32, _tick = 68, _time = 1.7371e+09)
[2025-01-17 17:28:33,450][root][INFO] - Step 179200 @ 511.0 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 666.0, step = 179200, mean_episode_return = 0.44156, mean_episode_step = 78.077, total_loss = 96.049, entropy_loss = -9.5303, pg_loss = 52.878, baseline_loss = 52.701, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)
[2025-01-17 17:28:38,456][root][INFO] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 671.0, step = 179200, mean_episode_return = 0.44156, mean_episode_step = 78.077, total_loss = 96.049, entropy_loss = -9.5303, pg_loss = 52.878, baseline_loss = 52.701, learner_queue_size = 32, _tick = 69, _time = 1.7371e+09)
[2025-01-17 17:28:43,461][root][INFO] - Step 181760 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 676.0, step = 181760, mean_episode_return = 0.37191, mean_episode_step = 56.138, total_loss = 86.951, entropy_loss = -9.5773, pg_loss = 20.566, baseline_loss = 75.963, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)
[2025-01-17 17:28:48,466][root][INFO] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 681.0, step = 181760, mean_episode_return = 0.37191, mean_episode_step = 56.138, total_loss = 86.951, entropy_loss = -9.5773, pg_loss = 20.566, baseline_loss = 75.963, learner_queue_size = 32, _tick = 70, _time = 1.7371e+09)
[2025-01-17 17:28:53,471][root][INFO] - Step 184320 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 686.0, step = 184320, mean_episode_return = 0.41327, mean_episode_step = 52.994, total_loss = -118.36, entropy_loss = -9.5319, pg_loss = -189.94, baseline_loss = 81.12, learner_queue_size = 32, _tick = 71, _time = 1.7371e+09)
[2025-01-17 17:28:58,477][root][INFO] - Step 186880 @ 511.4 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 691.0, step = 186880, mean_episode_return = 0.5215, mean_episode_step = 61.109, total_loss = 138.58, entropy_loss = -9.5071, pg_loss = 66.732, baseline_loss = 81.36, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)
[2025-01-17 17:29:03,482][root][INFO] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 696.0, step = 186880, mean_episode_return = 0.5215, mean_episode_step = 61.109, total_loss = 138.58, entropy_loss = -9.5071, pg_loss = 66.732, baseline_loss = 81.36, learner_queue_size = 32, _tick = 72, _time = 1.7371e+09)
[2025-01-17 17:29:08,487][root][INFO] - Step 189440 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 701.1, step = 189440, mean_episode_return = 0.32511, mean_episode_step = 52.339, total_loss = 35.576, entropy_loss = -9.4599, pg_loss = -22.863, baseline_loss = 67.898, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)
[2025-01-17 17:29:13,493][root][INFO] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 706.1, step = 189440, mean_episode_return = 0.32511, mean_episode_step = 52.339, total_loss = 35.576, entropy_loss = -9.4599, pg_loss = -22.863, baseline_loss = 67.898, learner_queue_size = 32, _tick = 73, _time = 1.7371e+09)
[2025-01-17 17:29:18,499][root][INFO] - Step 192000 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 711.1, step = 192000, mean_episode_return = 0.39022, mean_episode_step = 53.433, total_loss = -412.01, entropy_loss = -9.464, pg_loss = -472.97, baseline_loss = 70.426, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)
[2025-01-17 17:29:23,505][root][INFO] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 716.1, step = 192000, mean_episode_return = 0.39022, mean_episode_step = 53.433, total_loss = -412.01, entropy_loss = -9.464, pg_loss = -472.97, baseline_loss = 70.426, learner_queue_size = 32, _tick = 74, _time = 1.7371e+09)
[2025-01-17 17:29:28,510][root][INFO] - Step 194560 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 721.1, step = 194560, mean_episode_return = 0.6426, mean_episode_step = 48.831, total_loss = 504.5, entropy_loss = -9.4579, pg_loss = 419.15, baseline_loss = 94.81, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)
[2025-01-17 17:29:33,517][root][INFO] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 726.1, step = 194560, mean_episode_return = 0.6426, mean_episode_step = 48.831, total_loss = 504.5, entropy_loss = -9.4579, pg_loss = 419.15, baseline_loss = 94.81, learner_queue_size = 32, _tick = 75, _time = 1.7371e+09)
[2025-01-17 17:29:38,524][root][INFO] - Step 197120 @ 511.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 731.1, step = 197120, mean_episode_return = 0.27568, mean_episode_step = 60.766, total_loss = -282.96, entropy_loss = -9.4368, pg_loss = -351.79, baseline_loss = 78.262, learner_queue_size = 32, _tick = 76, _time = 1.7371e+09)
[2025-01-17 17:29:43,529][root][INFO] - Step 199680 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 736.1, step = 199680, mean_episode_return = 0.50056, mean_episode_step = 56.35, total_loss = -282.46, entropy_loss = -9.4339, pg_loss = -328.18, baseline_loss = 55.151, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)
[2025-01-17 17:29:48,536][root][INFO] - Step 199680 @ 0.0 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 741.1, step = 199680, mean_episode_return = 0.50056, mean_episode_step = 56.35, total_loss = -282.46, entropy_loss = -9.4339, pg_loss = -328.18, baseline_loss = 55.151, learner_queue_size = 32, _tick = 77, _time = 1.7371e+09)
[2025-01-17 17:29:53,542][root][INFO] - Step 202240 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 746.1, step = 202240, mean_episode_return = 0.40691, mean_episode_step = 56.095, total_loss = 796.12, entropy_loss = -9.4168, pg_loss = 704.74, baseline_loss = 100.8, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)
[2025-01-17 17:29:58,548][root][INFO] - Step 202240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 751.1, step = 202240, mean_episode_return = 0.40691, mean_episode_step = 56.095, total_loss = 796.12, entropy_loss = -9.4168, pg_loss = 704.74, baseline_loss = 100.8, learner_queue_size = 32, _tick = 78, _time = 1.7371e+09)
[2025-01-17 17:30:03,553][root][INFO] - Step 204800 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 756.1, step = 204800, mean_episode_return = 0.50115, mean_episode_step = 51.183, total_loss = -166.28, entropy_loss = -9.4316, pg_loss = -231.82, baseline_loss = 74.967, learner_queue_size = 32, _tick = 79, _time = 1.7371e+09)
[2025-01-17 17:30:08,559][root][INFO] - Step 207360 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 761.1, step = 207360, mean_episode_return = 0.40414, mean_episode_step = 57.126, total_loss = -323.48, entropy_loss = -9.38, pg_loss = -374.33, baseline_loss = 60.238, learner_queue_size = 32, _tick = 80, _time = 1.7371e+09)
[2025-01-17 17:30:13,565][root][INFO] - Step 207360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 766.1, step = 207360, mean_episode_return = 0.40414, mean_episode_step = 57.126, total_loss = -323.48, entropy_loss = -9.38, pg_loss = -374.33, baseline_loss = 60.238, learner_queue_size = 32, _tick = 80, _time = 1.7371e+09)
[2025-01-17 17:30:18,578][root][INFO] - Step 209920 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 771.1, step = 209920, mean_episode_return = 0.47787, mean_episode_step = 52.811, total_loss = 102.2, entropy_loss = -9.3817, pg_loss = 24.798, baseline_loss = 86.781, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)
[2025-01-17 17:30:23,584][root][INFO] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 776.1, step = 209920, mean_episode_return = 0.47787, mean_episode_step = 52.811, total_loss = 102.2, entropy_loss = -9.3817, pg_loss = 24.798, baseline_loss = 86.781, learner_queue_size = 32, _tick = 81, _time = 1.7371e+09)
[2025-01-17 17:30:28,590][root][INFO] - Step 212480 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 781.2, step = 212480, mean_episode_return = 0.33009, mean_episode_step = 48.259, total_loss = 54.983, entropy_loss = -9.3422, pg_loss = 8.8093, baseline_loss = 55.516, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)
[2025-01-17 17:30:33,595][root][INFO] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 786.2, step = 212480, mean_episode_return = 0.33009, mean_episode_step = 48.259, total_loss = 54.983, entropy_loss = -9.3422, pg_loss = 8.8093, baseline_loss = 55.516, learner_queue_size = 32, _tick = 82, _time = 1.7371e+09)
[2025-01-17 17:30:38,601][root][INFO] - Step 215040 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 791.2, step = 215040, mean_episode_return = 0.26342, mean_episode_step = 57.687, total_loss = -362.41, entropy_loss = -9.3102, pg_loss = -406.73, baseline_loss = 53.633, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)
[2025-01-17 17:30:43,606][root][INFO] - Step 215040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 796.2, step = 215040, mean_episode_return = 0.26342, mean_episode_step = 57.687, total_loss = -362.41, entropy_loss = -9.3102, pg_loss = -406.73, baseline_loss = 53.633, learner_queue_size = 32, _tick = 83, _time = 1.7371e+09)
[2025-01-17 17:30:48,611][root][INFO] - Step 217600 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 801.2, step = 217600, mean_episode_return = 0.4699, mean_episode_step = 57.843, total_loss = 170.69, entropy_loss = -9.2912, pg_loss = 113.25, baseline_loss = 66.73, learner_queue_size = 32, _tick = 84, _time = 1.7371e+09)
[2025-01-17 17:30:53,616][root][INFO] - Step 217600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 806.2, step = 217600, mean_episode_return = 0.4699, mean_episode_step = 57.843, total_loss = 170.69, entropy_loss = -9.2912, pg_loss = 113.25, baseline_loss = 66.73, learner_queue_size = 32, _tick = 84, _time = 1.7371e+09)
[2025-01-17 17:30:58,621][root][INFO] - Step 220160 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 811.2, step = 220160, mean_episode_return = 0.52603, mean_episode_step = 68.973, total_loss = 353.29, entropy_loss = -9.3679, pg_loss = 300.11, baseline_loss = 62.551, learner_queue_size = 32, _tick = 85, _time = 1.7371e+09)
[2025-01-17 17:31:03,626][root][INFO] - Step 222720 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 816.2, step = 222720, mean_episode_return = 0.52077, mean_episode_step = 55.27, total_loss = -108.64, entropy_loss = -9.396, pg_loss = -162.61, baseline_loss = 63.359, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)
[2025-01-17 17:31:08,632][root][INFO] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 821.2, step = 222720, mean_episode_return = 0.52077, mean_episode_step = 55.27, total_loss = -108.64, entropy_loss = -9.396, pg_loss = -162.61, baseline_loss = 63.359, learner_queue_size = 32, _tick = 86, _time = 1.7371e+09)
[2025-01-17 17:31:13,638][root][INFO] - Step 225280 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 826.2, step = 225280, mean_episode_return = 0.49443, mean_episode_step = 60.152, total_loss = -371.75, entropy_loss = -9.3928, pg_loss = -419.14, baseline_loss = 56.781, learner_queue_size = 32, _tick = 87, _time = 1.7371e+09)
[2025-01-17 17:31:18,644][root][INFO] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 831.2, step = 225280, mean_episode_return = 0.49443, mean_episode_step = 60.152, total_loss = -371.75, entropy_loss = -9.3928, pg_loss = -419.14, baseline_loss = 56.781, learner_queue_size = 32, _tick = 87, _time = 1.7371e+09)
[2025-01-17 17:31:23,649][root][INFO] - Step 227840 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 836.2, step = 227840, mean_episode_return = 0.41132, mean_episode_step = 61.809, total_loss = 278.27, entropy_loss = -9.3787, pg_loss = 216.93, baseline_loss = 70.726, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)
[2025-01-17 17:31:28,655][root][INFO] - Step 227840 @ 0.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 841.2, step = 227840, mean_episode_return = 0.41132, mean_episode_step = 61.809, total_loss = 278.27, entropy_loss = -9.3787, pg_loss = 216.93, baseline_loss = 70.726, learner_queue_size = 32, _tick = 88, _time = 1.7371e+09)
[2025-01-17 17:31:33,660][root][INFO] - Step 230400 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 846.2, step = 230400, mean_episode_return = 0.3388, mean_episode_step = 54.529, total_loss = -704.95, entropy_loss = -9.4175, pg_loss = -761.41, baseline_loss = 65.878, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)
[2025-01-17 17:31:38,666][root][INFO] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 851.2, step = 230400, mean_episode_return = 0.3388, mean_episode_step = 54.529, total_loss = -704.95, entropy_loss = -9.4175, pg_loss = -761.41, baseline_loss = 65.878, learner_queue_size = 32, _tick = 89, _time = 1.7371e+09)
[2025-01-17 17:31:43,671][root][INFO] - Step 232960 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 856.2, step = 232960, mean_episode_return = 0.36944, mean_episode_step = 59.158, total_loss = 334.35, entropy_loss = -9.4013, pg_loss = 270.93, baseline_loss = 72.817, learner_queue_size = 32, _tick = 90, _time = 1.7371e+09)
[2025-01-17 17:31:48,676][root][INFO] - Step 232960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 861.2, step = 232960, mean_episode_return = 0.36944, mean_episode_step = 59.158, total_loss = 334.35, entropy_loss = -9.4013, pg_loss = 270.93, baseline_loss = 72.817, learner_queue_size = 32, _tick = 90, _time = 1.7371e+09)
[2025-01-17 17:31:53,681][root][INFO] - Step 235520 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 866.2, step = 235520, mean_episode_return = 0.59492, mean_episode_step = 57.57, total_loss = 510.36, entropy_loss = -9.4139, pg_loss = 433.55, baseline_loss = 86.227, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)
[2025-01-17 17:31:58,686][root][INFO] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 871.3, step = 235520, mean_episode_return = 0.59492, mean_episode_step = 57.57, total_loss = 510.36, entropy_loss = -9.4139, pg_loss = 433.55, baseline_loss = 86.227, learner_queue_size = 32, _tick = 91, _time = 1.7371e+09)
[2025-01-17 17:32:03,692][root][INFO] - Step 238080 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 876.3, step = 238080, mean_episode_return = 0.38731, mean_episode_step = 64.93, total_loss = -451.12, entropy_loss = -9.4153, pg_loss = -512.2, baseline_loss = 70.493, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)
[2025-01-17 17:32:08,697][root][INFO] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 881.3, step = 238080, mean_episode_return = 0.38731, mean_episode_step = 64.93, total_loss = -451.12, entropy_loss = -9.4153, pg_loss = -512.2, baseline_loss = 70.493, learner_queue_size = 32, _tick = 92, _time = 1.7371e+09)
[2025-01-17 17:32:13,702][root][INFO] - Step 240640 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 886.3, step = 240640, mean_episode_return = 0.27233, mean_episode_step = 45.259, total_loss = -618.47, entropy_loss = -9.4129, pg_loss = -709.25, baseline_loss = 100.2, learner_queue_size = 32, _tick = 93, _time = 1.7371e+09)
[2025-01-17 17:32:18,707][root][INFO] - Step 243200 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 891.3, step = 243200, mean_episode_return = 0.62153, mean_episode_step = 57.002, total_loss = 162.11, entropy_loss = -9.4046, pg_loss = 63.122, baseline_loss = 108.4, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)
[2025-01-17 17:32:23,713][root][INFO] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 896.3, step = 243200, mean_episode_return = 0.62153, mean_episode_step = 57.002, total_loss = 162.11, entropy_loss = -9.4046, pg_loss = 63.122, baseline_loss = 108.4, learner_queue_size = 32, _tick = 94, _time = 1.7371e+09)
[2025-01-17 17:32:28,718][root][INFO] - Step 245760 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 901.3, step = 245760, mean_episode_return = 0.644, mean_episode_step = 70.11, total_loss = -248.6, entropy_loss = -9.3499, pg_loss = -281.84, baseline_loss = 42.596, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)
[2025-01-17 17:32:33,723][root][INFO] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 906.3, step = 245760, mean_episode_return = 0.644, mean_episode_step = 70.11, total_loss = -248.6, entropy_loss = -9.3499, pg_loss = -281.84, baseline_loss = 42.596, learner_queue_size = 32, _tick = 95, _time = 1.7371e+09)
[2025-01-17 17:32:38,728][root][INFO] - Step 248320 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 911.3, step = 248320, mean_episode_return = 0.4493, mean_episode_step = 45.537, total_loss = 301.99, entropy_loss = -9.3416, pg_loss = 222.94, baseline_loss = 88.388, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)
[2025-01-17 17:32:43,736][root][INFO] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 916.3, step = 248320, mean_episode_return = 0.4493, mean_episode_step = 45.537, total_loss = 301.99, entropy_loss = -9.3416, pg_loss = 222.94, baseline_loss = 88.388, learner_queue_size = 32, _tick = 96, _time = 1.7371e+09)
[2025-01-17 17:32:48,742][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar
[2025-01-17 17:32:48,785][root][INFO] - Step 250880 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 921.3, step = 250880, mean_episode_return = 0.4302, mean_episode_step = 59.255, total_loss = 203.47, entropy_loss = -9.3572, pg_loss = 117.77, baseline_loss = 95.055, learner_queue_size = 32, _tick = 97, _time = 1.7371e+09)
[2025-01-17 17:32:53,790][root][INFO] - Step 250880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 926.4, step = 250880, mean_episode_return = 0.4302, mean_episode_step = 59.255, total_loss = 203.47, entropy_loss = -9.3572, pg_loss = 117.77, baseline_loss = 95.055, learner_queue_size = 32, _tick = 97, _time = 1.7371e+09)
[2025-01-17 17:32:58,795][root][INFO] - Step 253440 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 931.4, step = 253440, mean_episode_return = 0.37211, mean_episode_step = 48.926, total_loss = 240.62, entropy_loss = -9.3238, pg_loss = 163.23, baseline_loss = 86.72, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)
[2025-01-17 17:33:03,801][root][INFO] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 936.4, step = 253440, mean_episode_return = 0.37211, mean_episode_step = 48.926, total_loss = 240.62, entropy_loss = -9.3238, pg_loss = 163.23, baseline_loss = 86.72, learner_queue_size = 32, _tick = 98, _time = 1.7371e+09)
[2025-01-17 17:33:08,806][root][INFO] - Step 256000 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 941.4, step = 256000, mean_episode_return = 0.43205, mean_episode_step = 56.648, total_loss = -350.35, entropy_loss = -9.3179, pg_loss = -406.09, baseline_loss = 65.06, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)
[2025-01-17 17:33:13,812][root][INFO] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 946.4, step = 256000, mean_episode_return = 0.43205, mean_episode_step = 56.648, total_loss = -350.35, entropy_loss = -9.3179, pg_loss = -406.09, baseline_loss = 65.06, learner_queue_size = 32, _tick = 99, _time = 1.7371e+09)
[2025-01-17 17:33:18,819][root][INFO] - Step 258560 @ 511.3 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 951.4, step = 258560, mean_episode_return = 0.42741, mean_episode_step = 60.924, total_loss = -347.48, entropy_loss = -9.2998, pg_loss = -411.88, baseline_loss = 73.692, learner_queue_size = 32, _tick = 100, _time = 1.7371e+09)
[2025-01-17 17:33:23,825][root][INFO] - Step 258560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 956.4, step = 258560, mean_episode_return = 0.42741, mean_episode_step = 60.924, total_loss = -347.48, entropy_loss = -9.2998, pg_loss = -411.88, baseline_loss = 73.692, learner_queue_size = 32, _tick = 100, _time = 1.7371e+09)
[2025-01-17 17:33:28,830][root][INFO] - Step 261120 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 961.4, step = 261120, mean_episode_return = 0.50568, mean_episode_step = 49.823, total_loss = 80.329, entropy_loss = -9.2869, pg_loss = 13.981, baseline_loss = 75.635, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)
[2025-01-17 17:33:33,836][root][INFO] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 966.4, step = 261120, mean_episode_return = 0.50568, mean_episode_step = 49.823, total_loss = 80.329, entropy_loss = -9.2869, pg_loss = 13.981, baseline_loss = 75.635, learner_queue_size = 32, _tick = 101, _time = 1.7371e+09)
[2025-01-17 17:33:38,841][root][INFO] - Step 263680 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 971.4, step = 263680, mean_episode_return = 0.55872, mean_episode_step = 71.373, total_loss = -77.036, entropy_loss = -9.2746, pg_loss = -124.4, baseline_loss = 56.639, learner_queue_size = 32, _tick = 102, _time = 1.7371e+09)
[2025-01-17 17:33:43,847][root][INFO] - Step 266240 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 976.4, step = 266240, mean_episode_return = 0.72985, mean_episode_step = 69.134, total_loss = 533.87, entropy_loss = -9.2277, pg_loss = 485.54, baseline_loss = 57.563, learner_queue_size = 32, _tick = 103, _time = 1.7371e+09)
[2025-01-17 17:33:48,853][root][INFO] - Step 266240 @ 0.0 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 981.4, step = 266240, mean_episode_return = 0.72985, mean_episode_step = 69.134, total_loss = 533.87, entropy_loss = -9.2277, pg_loss = 485.54, baseline_loss = 57.563, learner_queue_size = 32, _tick = 103, _time = 1.7371e+09)
[2025-01-17 17:33:53,859][root][INFO] - Step 268800 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 986.4, step = 268800, mean_episode_return = 0.38868, mean_episode_step = 47.089, total_loss = 190.66, entropy_loss = -9.25, pg_loss = 124.91, baseline_loss = 75.002, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)
[2025-01-17 17:33:58,864][root][INFO] - Step 268800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 991.4, step = 268800, mean_episode_return = 0.38868, mean_episode_step = 47.089, total_loss = 190.66, entropy_loss = -9.25, pg_loss = 124.91, baseline_loss = 75.002, learner_queue_size = 32, _tick = 104, _time = 1.7371e+09)
[2025-01-17 17:34:03,869][root][INFO] - Step 271360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 996.4, step = 271360, mean_episode_return = 0.53458, mean_episode_step = 51.966, total_loss = -353.16, entropy_loss = -9.2371, pg_loss = -409.77, baseline_loss = 65.849, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)
[2025-01-17 17:34:08,875][root][INFO] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1001.4, step = 271360, mean_episode_return = 0.53458, mean_episode_step = 51.966, total_loss = -353.16, entropy_loss = -9.2371, pg_loss = -409.77, baseline_loss = 65.849, learner_queue_size = 32, _tick = 105, _time = 1.7371e+09)
[2025-01-17 17:34:13,881][root][INFO] - Step 273920 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1006.4, step = 273920, mean_episode_return = 0.57273, mean_episode_step = 63.74, total_loss = 175.1, entropy_loss = -9.2625, pg_loss = 113.41, baseline_loss = 70.951, learner_queue_size = 32, _tick = 106, _time = 1.7371e+09)
[2025-01-17 17:34:18,887][root][INFO] - Step 273920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1011.5, step = 273920, mean_episode_return = 0.57273, mean_episode_step = 63.74, total_loss = 175.1, entropy_loss = -9.2625, pg_loss = 113.41, baseline_loss = 70.951, learner_queue_size = 32, _tick = 106, _time = 1.7371e+09)
[2025-01-17 17:34:23,892][root][INFO] - Step 276480 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1016.5, step = 276480, mean_episode_return = 0.72676, mean_episode_step = 56.513, total_loss = 190.78, entropy_loss = -9.3075, pg_loss = 111.34, baseline_loss = 88.75, learner_queue_size = 32, _tick = 107, _time = 1.7371e+09)
[2025-01-17 17:34:28,898][root][INFO] - Step 279040 @ 511.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1021.5, step = 279040, mean_episode_return = 0.28064, mean_episode_step = 68.114, total_loss = -596.94, entropy_loss = -9.2959, pg_loss = -650.27, baseline_loss = 62.627, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)
[2025-01-17 17:34:33,903][root][INFO] - Step 279040 @ 0.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1026.5, step = 279040, mean_episode_return = 0.28064, mean_episode_step = 68.114, total_loss = -596.94, entropy_loss = -9.2959, pg_loss = -650.27, baseline_loss = 62.627, learner_queue_size = 32, _tick = 108, _time = 1.7371e+09)
[2025-01-17 17:34:38,909][root][INFO] - Step 281600 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1031.5, step = 281600, mean_episode_return = 0.53011, mean_episode_step = 57.806, total_loss = -472.99, entropy_loss = -9.2961, pg_loss = -527.77, baseline_loss = 64.075, learner_queue_size = 32, _tick = 109, _time = 1.7371e+09)
[2025-01-17 17:34:43,915][root][INFO] - Step 281600 @ 0.0 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1036.5, step = 281600, mean_episode_return = 0.53011, mean_episode_step = 57.806, total_loss = -472.99, entropy_loss = -9.2961, pg_loss = -527.77, baseline_loss = 64.075, learner_queue_size = 32, _tick = 109, _time = 1.7371e+09)
[2025-01-17 17:34:48,921][root][INFO] - Step 284160 @ 511.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1041.5, step = 284160, mean_episode_return = 0.64549, mean_episode_step = 66.351, total_loss = 184.45, entropy_loss = -9.2999, pg_loss = 113.77, baseline_loss = 79.976, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)
[2025-01-17 17:34:53,928][root][INFO] - Step 284160 @ 0.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1046.5, step = 284160, mean_episode_return = 0.64549, mean_episode_step = 66.351, total_loss = 184.45, entropy_loss = -9.2999, pg_loss = 113.77, baseline_loss = 79.976, learner_queue_size = 32, _tick = 110, _time = 1.7371e+09)
[2025-01-17 17:34:58,934][root][INFO] - Step 286720 @ 511.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1051.5, step = 286720, mean_episode_return = 0.46042, mean_episode_step = 56.184, total_loss = -348.45, entropy_loss = -9.3008, pg_loss = -416.79, baseline_loss = 77.641, learner_queue_size = 32, _tick = 111, _time = 1.7371e+09)
[2025-01-17 17:35:03,939][root][INFO] - Step 286720 @ 0.0 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1056.5, step = 286720, mean_episode_return = 0.46042, mean_episode_step = 56.184, total_loss = -348.45, entropy_loss = -9.3008, pg_loss = -416.79, baseline_loss = 77.641, learner_queue_size = 32, _tick = 111, _time = 1.7371e+09)
[2025-01-17 17:35:08,945][root][INFO] - Step 289280 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1061.5, step = 289280, mean_episode_return = 0.55752, mean_episode_step = 54.348, total_loss = 306.92, entropy_loss = -9.2712, pg_loss = 233.44, baseline_loss = 82.748, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)
[2025-01-17 17:35:13,950][root][INFO] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1066.5, step = 289280, mean_episode_return = 0.55752, mean_episode_step = 54.348, total_loss = 306.92, entropy_loss = -9.2712, pg_loss = 233.44, baseline_loss = 82.748, learner_queue_size = 32, _tick = 112, _time = 1.7371e+09)
[2025-01-17 17:35:18,958][root][INFO] - Step 291840 @ 511.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1071.5, step = 291840, mean_episode_return = 0.64453, mean_episode_step = 51.366, total_loss = -7.2236, entropy_loss = -9.2659, pg_loss = -66.006, baseline_loss = 68.048, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)
[2025-01-17 17:35:23,963][root][INFO] - Step 291840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1076.5, step = 291840, mean_episode_return = 0.64453, mean_episode_step = 51.366, total_loss = -7.2236, entropy_loss = -9.2659, pg_loss = -66.006, baseline_loss = 68.048, learner_queue_size = 32, _tick = 113, _time = 1.7371e+09)
[2025-01-17 17:35:28,969][root][INFO] - Step 294400 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1081.5, step = 294400, mean_episode_return = 0.50991, mean_episode_step = 59.557, total_loss = -319.43, entropy_loss = -9.289, pg_loss = -364.44, baseline_loss = 54.299, learner_queue_size = 32, _tick = 114, _time = 1.7371e+09)
[2025-01-17 17:35:33,976][root][INFO] - Step 294400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1086.5, step = 294400, mean_episode_return = 0.50991, mean_episode_step = 59.557, total_loss = -319.43, entropy_loss = -9.289, pg_loss = -364.44, baseline_loss = 54.299, learner_queue_size = 32, _tick = 114, _time = 1.7371e+09)
[2025-01-17 17:35:38,984][root][INFO] - Step 296960 @ 511.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1091.5, step = 296960, mean_episode_return = 0.2941, mean_episode_step = 46.907, total_loss = -146.36, entropy_loss = -9.2783, pg_loss = -205.52, baseline_loss = 68.432, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)
[2025-01-17 17:35:43,989][root][INFO] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1096.6, step = 296960, mean_episode_return = 0.2941, mean_episode_step = 46.907, total_loss = -146.36, entropy_loss = -9.2783, pg_loss = -205.52, baseline_loss = 68.432, learner_queue_size = 32, _tick = 115, _time = 1.7371e+09)
[2025-01-17 17:35:48,996][root][INFO] - Step 299520 @ 511.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1101.6, step = 299520, mean_episode_return = 0.34585, mean_episode_step = 45.895, total_loss = -595.87, entropy_loss = -9.2801, pg_loss = -656.71, baseline_loss = 70.114, learner_queue_size = 32, _tick = 116, _time = 1.7371e+09)
[2025-01-17 17:35:54,002][root][INFO] - Step 299520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1106.6, step = 299520, mean_episode_return = 0.34585, mean_episode_step = 45.895, total_loss = -595.87, entropy_loss = -9.2801, pg_loss = -656.71, baseline_loss = 70.114, learner_queue_size = 32, _tick = 116, _time = 1.7371e+09)
[2025-01-17 17:35:59,008][root][INFO] - Step 302080 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1111.6, step = 302080, mean_episode_return = 0.63377, mean_episode_step = 58.97, total_loss = 15.927, entropy_loss = -9.2693, pg_loss = -40.408, baseline_loss = 65.605, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)
[2025-01-17 17:36:04,014][root][INFO] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1116.6, step = 302080, mean_episode_return = 0.63377, mean_episode_step = 58.97, total_loss = 15.927, entropy_loss = -9.2693, pg_loss = -40.408, baseline_loss = 65.605, learner_queue_size = 32, _tick = 117, _time = 1.7371e+09)
[2025-01-17 17:36:09,019][root][INFO] - Step 304640 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1121.6, step = 304640, mean_episode_return = 0.415, mean_episode_step = 46.834, total_loss = -47.629, entropy_loss = -9.2278, pg_loss = -110.52, baseline_loss = 72.123, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)
[2025-01-17 17:36:14,024][root][INFO] - Step 304640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1126.6, step = 304640, mean_episode_return = 0.415, mean_episode_step = 46.834, total_loss = -47.629, entropy_loss = -9.2278, pg_loss = -110.52, baseline_loss = 72.123, learner_queue_size = 32, _tick = 118, _time = 1.7371e+09)
[2025-01-17 17:36:20,124][root][INFO] - Step 307200 @ 419.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1132.7, step = 307200, mean_episode_return = 0.47162, mean_episode_step = 52.223, total_loss = -263.72, entropy_loss = -9.1766, pg_loss = -305.94, baseline_loss = 51.396, learner_queue_size = 32, _tick = 119, _time = 1.7371e+09)
[2025-01-17 17:36:25,129][root][INFO] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1137.7, step = 307200, mean_episode_return = 0.47162, mean_episode_step = 52.223, total_loss = -263.72, entropy_loss = -9.1766, pg_loss = -305.94, baseline_loss = 51.396, learner_queue_size = 32, _tick = 119, _time = 1.7371e+09)
[2025-01-17 17:36:30,135][root][INFO] - Step 309760 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1142.7, step = 309760, mean_episode_return = 0.37033, mean_episode_step = 49.225, total_loss = 80.047, entropy_loss = -9.1264, pg_loss = 41.236, baseline_loss = 47.938, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)
[2025-01-17 17:36:35,140][root][INFO] - Step 309760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1147.7, step = 309760, mean_episode_return = 0.37033, mean_episode_step = 49.225, total_loss = 80.047, entropy_loss = -9.1264, pg_loss = 41.236, baseline_loss = 47.938, learner_queue_size = 32, _tick = 120, _time = 1.7371e+09)
[2025-01-17 17:36:40,145][root][INFO] - Step 312320 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1152.7, step = 312320, mean_episode_return = 0.55967, mean_episode_step = 61.683, total_loss = 196.68, entropy_loss = -9.113, pg_loss = 172.51, baseline_loss = 33.279, learner_queue_size = 32, _tick = 121, _time = 1.7371e+09)
[2025-01-17 17:36:45,150][root][INFO] - Step 314880 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1157.7, step = 314880, mean_episode_return = 0.71252, mean_episode_step = 56.017, total_loss = 759.87, entropy_loss = -9.174, pg_loss = 693.22, baseline_loss = 75.827, learner_queue_size = 32, _tick = 122, _time = 1.7371e+09)
[2025-01-17 17:36:50,155][root][INFO] - Step 314880 @ 0.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1162.7, step = 314880, mean_episode_return = 0.71252, mean_episode_step = 56.017, total_loss = 759.87, entropy_loss = -9.174, pg_loss = 693.22, baseline_loss = 75.827, learner_queue_size = 32, _tick = 122, _time = 1.7371e+09)
[2025-01-17 17:36:55,160][root][INFO] - Step 317440 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1167.7, step = 317440, mean_episode_return = 0.44617, mean_episode_step = 43.584, total_loss = -125.26, entropy_loss = -9.2104, pg_loss = -193.38, baseline_loss = 77.334, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)
[2025-01-17 17:37:00,167][root][INFO] - Step 317440 @ 0.0 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1172.7, step = 317440, mean_episode_return = 0.44617, mean_episode_step = 43.584, total_loss = -125.26, entropy_loss = -9.2104, pg_loss = -193.38, baseline_loss = 77.334, learner_queue_size = 32, _tick = 123, _time = 1.7371e+09)
[2025-01-17 17:37:05,173][root][INFO] - Step 320000 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1177.7, step = 320000, mean_episode_return = 0.27334, mean_episode_step = 52.027, total_loss = -764.97, entropy_loss = -9.1662, pg_loss = -796.64, baseline_loss = 40.833, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)
[2025-01-17 17:37:10,179][root][INFO] - Step 320000 @ 0.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1182.7, step = 320000, mean_episode_return = 0.27334, mean_episode_step = 52.027, total_loss = -764.97, entropy_loss = -9.1662, pg_loss = -796.64, baseline_loss = 40.833, learner_queue_size = 32, _tick = 124, _time = 1.7371e+09)
[2025-01-17 17:37:15,187][root][INFO] - Step 322560 @ 511.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1187.8, step = 322560, mean_episode_return = 0.64954, mean_episode_step = 53.353, total_loss = 597.2, entropy_loss = -9.1482, pg_loss = 539.07, baseline_loss = 67.271, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)
[2025-01-17 17:37:20,195][root][INFO] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1192.8, step = 322560, mean_episode_return = 0.64954, mean_episode_step = 53.353, total_loss = 597.2, entropy_loss = -9.1482, pg_loss = 539.07, baseline_loss = 67.271, learner_queue_size = 32, _tick = 125, _time = 1.7371e+09)
[2025-01-17 17:37:25,200][root][INFO] - Step 325120 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1197.8, step = 325120, mean_episode_return = 0.58529, mean_episode_step = 58.854, total_loss = 58.992, entropy_loss = -9.1702, pg_loss = 5.7119, baseline_loss = 62.45, learner_queue_size = 32, _tick = 126, _time = 1.7371e+09)
[2025-01-17 17:37:30,205][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 17:37:30,948][root][INFO] - Step 325120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1202.8, step = 325120, mean_episode_return = 0.58529, mean_episode_step = 58.854, total_loss = 58.992, entropy_loss = -9.1702, pg_loss = 5.7119, baseline_loss = 62.45, learner_queue_size = 32, _tick = 126, _time = 1.7371e+09)
[2025-01-17 17:37:35,955][root][INFO] - Step 327680 @ 445.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1208.5, step = 327680, mean_episode_return = 0.34703, mean_episode_step = 54.621, total_loss = 325.57, entropy_loss = -9.1536, pg_loss = 263.15, baseline_loss = 71.568, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)
[2025-01-17 17:37:40,961][root][INFO] - Step 327680 @ 0.0 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1213.5, step = 327680, mean_episode_return = 0.34703, mean_episode_step = 54.621, total_loss = 325.57, entropy_loss = -9.1536, pg_loss = 263.15, baseline_loss = 71.568, learner_queue_size = 32, _tick = 127, _time = 1.7371e+09)
[2025-01-17 17:37:45,968][root][INFO] - Step 330240 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1218.5, step = 330240, mean_episode_return = 0.45488, mean_episode_step = 57.009, total_loss = -698.97, entropy_loss = -9.1871, pg_loss = -751.79, baseline_loss = 62.006, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)
[2025-01-17 17:37:50,973][root][INFO] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1223.5, step = 330240, mean_episode_return = 0.45488, mean_episode_step = 57.009, total_loss = -698.97, entropy_loss = -9.1871, pg_loss = -751.79, baseline_loss = 62.006, learner_queue_size = 32, _tick = 128, _time = 1.7371e+09)
[2025-01-17 17:37:55,978][root][INFO] - Step 332800 @ 511.4 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1228.5, step = 332800, mean_episode_return = 0.56862, mean_episode_step = 55.208, total_loss = 535.17, entropy_loss = -9.1698, pg_loss = 472.92, baseline_loss = 71.412, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)
[2025-01-17 17:38:00,984][root][INFO] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1233.5, step = 332800, mean_episode_return = 0.56862, mean_episode_step = 55.208, total_loss = 535.17, entropy_loss = -9.1698, pg_loss = 472.92, baseline_loss = 71.412, learner_queue_size = 32, _tick = 129, _time = 1.7371e+09)
[2025-01-17 17:38:05,989][root][INFO] - Step 335360 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1238.6, step = 335360, mean_episode_return = 0.46871, mean_episode_step = 52.026, total_loss = -220.82, entropy_loss = -9.1902, pg_loss = -303.32, baseline_loss = 91.689, learner_queue_size = 32, _tick = 130, _time = 1.7371e+09)
[2025-01-17 17:38:10,994][root][INFO] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1243.6, step = 335360, mean_episode_return = 0.46871, mean_episode_step = 52.026, total_loss = -220.82, entropy_loss = -9.1902, pg_loss = -303.32, baseline_loss = 91.689, learner_queue_size = 32, _tick = 130, _time = 1.7371e+09)
[2025-01-17 17:38:15,999][root][INFO] - Step 337920 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1248.6, step = 337920, mean_episode_return = 0.52826, mean_episode_step = 50.954, total_loss = -501.66, entropy_loss = -9.1747, pg_loss = -560.51, baseline_loss = 68.018, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)
[2025-01-17 17:38:21,004][root][INFO] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1253.6, step = 337920, mean_episode_return = 0.52826, mean_episode_step = 50.954, total_loss = -501.66, entropy_loss = -9.1747, pg_loss = -560.51, baseline_loss = 68.018, learner_queue_size = 32, _tick = 131, _time = 1.7371e+09)
[2025-01-17 17:38:26,009][root][INFO] - Step 340480 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1258.6, step = 340480, mean_episode_return = 0.38853, mean_episode_step = 62.633, total_loss = -681.25, entropy_loss = -9.1573, pg_loss = -724.79, baseline_loss = 52.697, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)
[2025-01-17 17:38:31,014][root][INFO] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1263.6, step = 340480, mean_episode_return = 0.38853, mean_episode_step = 62.633, total_loss = -681.25, entropy_loss = -9.1573, pg_loss = -724.79, baseline_loss = 52.697, learner_queue_size = 32, _tick = 132, _time = 1.7371e+09)
[2025-01-17 17:38:36,019][root][INFO] - Step 343040 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1268.6, step = 343040, mean_episode_return = 0.4623, mean_episode_step = 47.739, total_loss = 328.06, entropy_loss = -9.1359, pg_loss = 251.6, baseline_loss = 85.591, learner_queue_size = 32, _tick = 133, _time = 1.7371e+09)
[2025-01-17 17:38:41,024][root][INFO] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1273.6, step = 343040, mean_episode_return = 0.4623, mean_episode_step = 47.739, total_loss = 328.06, entropy_loss = -9.1359, pg_loss = 251.6, baseline_loss = 85.591, learner_queue_size = 32, _tick = 133, _time = 1.7371e+09)
[2025-01-17 17:38:46,030][root][INFO] - Step 345600 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1278.6, step = 345600, mean_episode_return = 0.54003, mean_episode_step = 56.035, total_loss = 759.08, entropy_loss = -9.1593, pg_loss = 663.66, baseline_loss = 104.58, learner_queue_size = 32, _tick = 134, _time = 1.7371e+09)
[2025-01-17 17:38:51,035][root][INFO] - Step 348160 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1283.6, step = 348160, mean_episode_return = 0.62403, mean_episode_step = 57.628, total_loss = 213.0, entropy_loss = -9.168, pg_loss = 146.11, baseline_loss = 76.057, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)
[2025-01-17 17:38:56,041][root][INFO] - Step 348160 @ 0.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1288.6, step = 348160, mean_episode_return = 0.62403, mean_episode_step = 57.628, total_loss = 213.0, entropy_loss = -9.168, pg_loss = 146.11, baseline_loss = 76.057, learner_queue_size = 32, _tick = 135, _time = 1.7371e+09)
[2025-01-17 17:39:01,047][root][INFO] - Step 350720 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1293.6, step = 350720, mean_episode_return = 0.63833, mean_episode_step = 52.29, total_loss = 523.18, entropy_loss = -9.1787, pg_loss = 440.33, baseline_loss = 92.03, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)
[2025-01-17 17:39:06,052][root][INFO] - Step 350720 @ 0.0 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1298.6, step = 350720, mean_episode_return = 0.63833, mean_episode_step = 52.29, total_loss = 523.18, entropy_loss = -9.1787, pg_loss = 440.33, baseline_loss = 92.03, learner_queue_size = 32, _tick = 136, _time = 1.7371e+09)
[2025-01-17 17:39:11,057][root][INFO] - Step 353280 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1303.6, step = 353280, mean_episode_return = 0.42878, mean_episode_step = 65.103, total_loss = -347.13, entropy_loss = -9.1839, pg_loss = -401.67, baseline_loss = 63.716, learner_queue_size = 32, _tick = 137, _time = 1.7371e+09)
[2025-01-17 17:39:16,062][root][INFO] - Step 353280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1308.6, step = 353280, mean_episode_return = 0.42878, mean_episode_step = 65.103, total_loss = -347.13, entropy_loss = -9.1839, pg_loss = -401.67, baseline_loss = 63.716, learner_queue_size = 32, _tick = 137, _time = 1.7371e+09)
[2025-01-17 17:39:21,068][root][INFO] - Step 355840 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1313.6, step = 355840, mean_episode_return = 0.43678, mean_episode_step = 49.755, total_loss = -857.57, entropy_loss = -9.1781, pg_loss = -912.87, baseline_loss = 64.477, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)
[2025-01-17 17:39:26,073][root][INFO] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1318.6, step = 355840, mean_episode_return = 0.43678, mean_episode_step = 49.755, total_loss = -857.57, entropy_loss = -9.1781, pg_loss = -912.87, baseline_loss = 64.477, learner_queue_size = 32, _tick = 138, _time = 1.7371e+09)
[2025-01-17 17:39:31,079][root][INFO] - Step 358400 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1323.6, step = 358400, mean_episode_return = 0.65979, mean_episode_step = 56.638, total_loss = 677.33, entropy_loss = -9.158, pg_loss = 588.53, baseline_loss = 97.96, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)
[2025-01-17 17:39:36,085][root][INFO] - Step 358400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1328.6, step = 358400, mean_episode_return = 0.65979, mean_episode_step = 56.638, total_loss = 677.33, entropy_loss = -9.158, pg_loss = 588.53, baseline_loss = 97.96, learner_queue_size = 32, _tick = 139, _time = 1.7371e+09)
[2025-01-17 17:39:41,090][root][INFO] - Step 360960 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1333.7, step = 360960, mean_episode_return = 0.53336, mean_episode_step = 52.487, total_loss = -341.16, entropy_loss = -9.1749, pg_loss = -408.14, baseline_loss = 76.157, learner_queue_size = 32, _tick = 140, _time = 1.7371e+09)
[2025-01-17 17:39:46,095][root][INFO] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1338.7, step = 360960, mean_episode_return = 0.53336, mean_episode_step = 52.487, total_loss = -341.16, entropy_loss = -9.1749, pg_loss = -408.14, baseline_loss = 76.157, learner_queue_size = 32, _tick = 140, _time = 1.7371e+09)
[2025-01-17 17:39:51,100][root][INFO] - Step 363520 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1343.7, step = 363520, mean_episode_return = 0.46092, mean_episode_step = 53.809, total_loss = -612.36, entropy_loss = -9.1719, pg_loss = -677.51, baseline_loss = 74.325, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)
[2025-01-17 17:39:56,106][root][INFO] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1348.7, step = 363520, mean_episode_return = 0.46092, mean_episode_step = 53.809, total_loss = -612.36, entropy_loss = -9.1719, pg_loss = -677.51, baseline_loss = 74.325, learner_queue_size = 32, _tick = 141, _time = 1.7371e+09)
[2025-01-17 17:40:01,117][root][INFO] - Step 366080 @ 510.9 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1353.7, step = 366080, mean_episode_return = 0.41778, mean_episode_step = 59.233, total_loss = -425.7, entropy_loss = -9.1568, pg_loss = -471.32, baseline_loss = 54.769, learner_queue_size = 32, _tick = 142, _time = 1.7371e+09)
[2025-01-17 17:40:06,122][root][INFO] - Step 366080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1358.7, step = 366080, mean_episode_return = 0.41778, mean_episode_step = 59.233, total_loss = -425.7, entropy_loss = -9.1568, pg_loss = -471.32, baseline_loss = 54.769, learner_queue_size = 32, _tick = 142, _time = 1.7371e+09)
[2025-01-17 17:40:11,127][root][INFO] - Step 368640 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1363.7, step = 368640, mean_episode_return = 0.35207, mean_episode_step = 52.952, total_loss = 56.387, entropy_loss = -9.1326, pg_loss = -5.4541, baseline_loss = 70.974, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)
[2025-01-17 17:40:16,133][root][INFO] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1368.7, step = 368640, mean_episode_return = 0.35207, mean_episode_step = 52.952, total_loss = 56.387, entropy_loss = -9.1326, pg_loss = -5.4541, baseline_loss = 70.974, learner_queue_size = 32, _tick = 143, _time = 1.7371e+09)
[2025-01-17 17:40:21,138][root][INFO] - Step 371200 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1373.7, step = 371200, mean_episode_return = 0.50413, mean_episode_step = 40.021, total_loss = -120.05, entropy_loss = -9.1272, pg_loss = -181.82, baseline_loss = 70.898, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)
[2025-01-17 17:40:26,144][root][INFO] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1378.7, step = 371200, mean_episode_return = 0.50413, mean_episode_step = 40.021, total_loss = -120.05, entropy_loss = -9.1272, pg_loss = -181.82, baseline_loss = 70.898, learner_queue_size = 32, _tick = 144, _time = 1.7371e+09)
[2025-01-17 17:40:31,149][root][INFO] - Step 373760 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1383.7, step = 373760, mean_episode_return = 0.59432, mean_episode_step = 52.76, total_loss = 361.3, entropy_loss = -9.098, pg_loss = 301.01, baseline_loss = 69.387, learner_queue_size = 32, _tick = 145, _time = 1.7371e+09)
[2025-01-17 17:40:36,155][root][INFO] - Step 373760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1388.7, step = 373760, mean_episode_return = 0.59432, mean_episode_step = 52.76, total_loss = 361.3, entropy_loss = -9.098, pg_loss = 301.01, baseline_loss = 69.387, learner_queue_size = 32, _tick = 145, _time = 1.7371e+09)
[2025-01-17 17:40:41,161][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar
[2025-01-17 17:40:41,232][root][INFO] - Step 376320 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1393.7, step = 376320, mean_episode_return = 0.45143, mean_episode_step = 58.686, total_loss = 91.794, entropy_loss = -9.1097, pg_loss = 44.164, baseline_loss = 56.739, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)
[2025-01-17 17:40:46,237][root][INFO] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1398.8, step = 376320, mean_episode_return = 0.45143, mean_episode_step = 58.686, total_loss = 91.794, entropy_loss = -9.1097, pg_loss = 44.164, baseline_loss = 56.739, learner_queue_size = 32, _tick = 146, _time = 1.7371e+09)
[2025-01-17 17:40:51,243][root][INFO] - Step 378880 @ 511.4 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 1403.8, step = 378880, mean_episode_return = 0.4588, mean_episode_step = 57.054, total_loss = -83.179, entropy_loss = -9.0948, pg_loss = -125.96, baseline_loss = 51.874, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)
[2025-01-17 17:40:56,248][root][INFO] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1408.8, step = 378880, mean_episode_return = 0.4588, mean_episode_step = 57.054, total_loss = -83.179, entropy_loss = -9.0948, pg_loss = -125.96, baseline_loss = 51.874, learner_queue_size = 32, _tick = 147, _time = 1.7371e+09)
[2025-01-17 17:41:01,254][root][INFO] - Step 381440 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1413.8, step = 381440, mean_episode_return = 0.44748, mean_episode_step = 42.535, total_loss = 135.55, entropy_loss = -9.0924, pg_loss = 69.894, baseline_loss = 74.745, learner_queue_size = 32, _tick = 148, _time = 1.7371e+09)
[2025-01-17 17:41:06,262][root][INFO] - Step 384000 @ 511.1 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1418.8, step = 384000, mean_episode_return = 0.55698, mean_episode_step = 62.236, total_loss = -255.53, entropy_loss = -9.0824, pg_loss = -296.71, baseline_loss = 50.258, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)
[2025-01-17 17:41:11,268][root][INFO] - Step 384000 @ 0.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1423.8, step = 384000, mean_episode_return = 0.55698, mean_episode_step = 62.236, total_loss = -255.53, entropy_loss = -9.0824, pg_loss = -296.71, baseline_loss = 50.258, learner_queue_size = 32, _tick = 149, _time = 1.7371e+09)
[2025-01-17 17:41:16,275][root][INFO] - Step 386560 @ 511.3 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1428.8, step = 386560, mean_episode_return = 0.31245, mean_episode_step = 44.657, total_loss = -21.019, entropy_loss = -9.0643, pg_loss = -60.549, baseline_loss = 48.594, learner_queue_size = 32, _tick = 150, _time = 1.7371e+09)
[2025-01-17 17:41:21,281][root][INFO] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1433.8, step = 386560, mean_episode_return = 0.31245, mean_episode_step = 44.657, total_loss = -21.019, entropy_loss = -9.0643, pg_loss = -60.549, baseline_loss = 48.594, learner_queue_size = 32, _tick = 150, _time = 1.7371e+09)
[2025-01-17 17:41:26,286][root][INFO] - Step 389120 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1438.9, step = 389120, mean_episode_return = 0.54202, mean_episode_step = 51.475, total_loss = 286.32, entropy_loss = -9.0313, pg_loss = 227.25, baseline_loss = 68.097, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)
[2025-01-17 17:41:31,291][root][INFO] - Step 389120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1443.9, step = 389120, mean_episode_return = 0.54202, mean_episode_step = 51.475, total_loss = 286.32, entropy_loss = -9.0313, pg_loss = 227.25, baseline_loss = 68.097, learner_queue_size = 32, _tick = 151, _time = 1.7371e+09)
[2025-01-17 17:41:36,296][root][INFO] - Step 391680 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1448.9, step = 391680, mean_episode_return = 0.61781, mean_episode_step = 52.598, total_loss = 419.91, entropy_loss = -9.0294, pg_loss = 367.68, baseline_loss = 61.258, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)
[2025-01-17 17:41:41,301][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1453.9, step = 391680, mean_episode_return = 0.61781, mean_episode_step = 52.598, total_loss = 419.91, entropy_loss = -9.0294, pg_loss = 367.68, baseline_loss = 61.258, learner_queue_size = 32, _tick = 152, _time = 1.7371e+09)
[2025-01-17 17:41:46,307][root][INFO] - Step 394240 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1458.9, step = 394240, mean_episode_return = 0.37384, mean_episode_step = 49.166, total_loss = -135.12, entropy_loss = -9.0483, pg_loss = -186.25, baseline_loss = 60.172, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)
[2025-01-17 17:41:51,314][root][INFO] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1463.9, step = 394240, mean_episode_return = 0.37384, mean_episode_step = 49.166, total_loss = -135.12, entropy_loss = -9.0483, pg_loss = -186.25, baseline_loss = 60.172, learner_queue_size = 32, _tick = 153, _time = 1.7371e+09)
[2025-01-17 17:41:56,319][root][INFO] - Step 396800 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1468.9, step = 396800, mean_episode_return = 0.43086, mean_episode_step = 50.055, total_loss = -31.024, entropy_loss = -9.0216, pg_loss = -80.853, baseline_loss = 58.85, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)
[2025-01-17 17:42:01,327][root][INFO] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1473.9, step = 396800, mean_episode_return = 0.43086, mean_episode_step = 50.055, total_loss = -31.024, entropy_loss = -9.0216, pg_loss = -80.853, baseline_loss = 58.85, learner_queue_size = 32, _tick = 154, _time = 1.7371e+09)
[2025-01-17 17:42:06,332][root][INFO] - Step 399360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1478.9, step = 399360, mean_episode_return = 0.62571, mean_episode_step = 55.653, total_loss = 782.12, entropy_loss = -9.0274, pg_loss = 711.09, baseline_loss = 80.064, learner_queue_size = 32, _tick = 155, _time = 1.7371e+09)
[2025-01-17 17:42:11,337][root][INFO] - Step 401920 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1483.9, step = 401920, mean_episode_return = 0.3782, mean_episode_step = 48.68, total_loss = -71.051, entropy_loss = -9.0519, pg_loss = -132.79, baseline_loss = 70.786, learner_queue_size = 32, _tick = 156, _time = 1.7371e+09)
[2025-01-17 17:42:16,342][root][INFO] - Step 401920 @ 0.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1488.9, step = 401920, mean_episode_return = 0.3782, mean_episode_step = 48.68, total_loss = -71.051, entropy_loss = -9.0519, pg_loss = -132.79, baseline_loss = 70.786, learner_queue_size = 32, _tick = 156, _time = 1.7371e+09)
[2025-01-17 17:42:21,347][root][INFO] - Step 404480 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1493.9, step = 404480, mean_episode_return = 0.64163, mean_episode_step = 64.282, total_loss = 409.46, entropy_loss = -9.0079, pg_loss = 357.56, baseline_loss = 60.906, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)
[2025-01-17 17:42:26,352][root][INFO] - Step 404480 @ 0.0 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1498.9, step = 404480, mean_episode_return = 0.64163, mean_episode_step = 64.282, total_loss = 409.46, entropy_loss = -9.0079, pg_loss = 357.56, baseline_loss = 60.906, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)
[2025-01-17 17:42:31,358][root][INFO] - Step 404480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1503.9, step = 404480, mean_episode_return = 0.64163, mean_episode_step = 64.282, total_loss = 409.46, entropy_loss = -9.0079, pg_loss = 357.56, baseline_loss = 60.906, learner_queue_size = 32, _tick = 157, _time = 1.7371e+09)
[2025-01-17 17:42:36,365][root][INFO] - Step 407040 @ 511.3 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1508.9, step = 407040, mean_episode_return = 0.35489, mean_episode_step = 43.552, total_loss = -202.04, entropy_loss = -9.0282, pg_loss = -259.83, baseline_loss = 66.819, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)
[2025-01-17 17:42:41,371][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1513.9, step = 407040, mean_episode_return = 0.35489, mean_episode_step = 43.552, total_loss = -202.04, entropy_loss = -9.0282, pg_loss = -259.83, baseline_loss = 66.819, learner_queue_size = 32, _tick = 158, _time = 1.7371e+09)
[2025-01-17 17:42:46,380][root][INFO] - Step 409600 @ 511.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1518.9, step = 409600, mean_episode_return = 0.54228, mean_episode_step = 40.659, total_loss = 266.93, entropy_loss = -9.0076, pg_loss = 206.42, baseline_loss = 69.518, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)
[2025-01-17 17:42:51,385][root][INFO] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1523.9, step = 409600, mean_episode_return = 0.54228, mean_episode_step = 40.659, total_loss = 266.93, entropy_loss = -9.0076, pg_loss = 206.42, baseline_loss = 69.518, learner_queue_size = 32, _tick = 159, _time = 1.7371e+09)
[2025-01-17 17:42:56,390][root][INFO] - Step 412160 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1529.0, step = 412160, mean_episode_return = 0.56367, mean_episode_step = 55.776, total_loss = 275.51, entropy_loss = -9.0017, pg_loss = 214.43, baseline_loss = 70.079, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)
[2025-01-17 17:43:01,396][root][INFO] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1534.0, step = 412160, mean_episode_return = 0.56367, mean_episode_step = 55.776, total_loss = 275.51, entropy_loss = -9.0017, pg_loss = 214.43, baseline_loss = 70.079, learner_queue_size = 32, _tick = 160, _time = 1.7371e+09)
[2025-01-17 17:43:06,401][root][INFO] - Step 414720 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1539.0, step = 414720, mean_episode_return = 0.22856, mean_episode_step = 39.554, total_loss = -637.12, entropy_loss = -9.0232, pg_loss = -686.76, baseline_loss = 58.663, learner_queue_size = 32, _tick = 161, _time = 1.7371e+09)
[2025-01-17 17:43:11,407][root][INFO] - Step 417280 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1544.0, step = 417280, mean_episode_return = 0.72046, mean_episode_step = 53.781, total_loss = 687.22, entropy_loss = -9.0007, pg_loss = 614.97, baseline_loss = 81.254, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)
[2025-01-17 17:43:16,412][root][INFO] - Step 417280 @ 0.0 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1549.0, step = 417280, mean_episode_return = 0.72046, mean_episode_step = 53.781, total_loss = 687.22, entropy_loss = -9.0007, pg_loss = 614.97, baseline_loss = 81.254, learner_queue_size = 32, _tick = 162, _time = 1.7371e+09)
[2025-01-17 17:43:21,419][root][INFO] - Step 419840 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1554.0, step = 419840, mean_episode_return = 0.64974, mean_episode_step = 49.139, total_loss = -51.872, entropy_loss = -9.0145, pg_loss = -109.52, baseline_loss = 66.66, learner_queue_size = 32, _tick = 163, _time = 1.7371e+09)
[2025-01-17 17:43:26,428][root][INFO] - Step 419840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1559.0, step = 419840, mean_episode_return = 0.64974, mean_episode_step = 49.139, total_loss = -51.872, entropy_loss = -9.0145, pg_loss = -109.52, baseline_loss = 66.66, learner_queue_size = 32, _tick = 163, _time = 1.7371e+09)
[2025-01-17 17:43:31,433][root][INFO] - Step 422400 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1564.0, step = 422400, mean_episode_return = 0.58174, mean_episode_step = 56.118, total_loss = -68.019, entropy_loss = -8.9896, pg_loss = -123.1, baseline_loss = 64.068, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)
[2025-01-17 17:43:36,438][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1569.0, step = 422400, mean_episode_return = 0.58174, mean_episode_step = 56.118, total_loss = -68.019, entropy_loss = -8.9896, pg_loss = -123.1, baseline_loss = 64.068, learner_queue_size = 32, _tick = 164, _time = 1.7371e+09)
[2025-01-17 17:43:41,512][root][INFO] - Step 424960 @ 504.5 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1574.1, step = 424960, mean_episode_return = 0.67845, mean_episode_step = 59.531, total_loss = 297.68, entropy_loss = -8.9751, pg_loss = 252.11, baseline_loss = 54.546, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)
[2025-01-17 17:43:46,518][root][INFO] - Step 424960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1579.1, step = 424960, mean_episode_return = 0.67845, mean_episode_step = 59.531, total_loss = 297.68, entropy_loss = -8.9751, pg_loss = 252.11, baseline_loss = 54.546, learner_queue_size = 32, _tick = 165, _time = 1.7371e+09)
[2025-01-17 17:43:51,523][root][INFO] - Step 427520 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1584.1, step = 427520, mean_episode_return = 0.2634, mean_episode_step = 56.517, total_loss = -469.56, entropy_loss = -8.9839, pg_loss = -508.43, baseline_loss = 47.853, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)
[2025-01-17 17:43:56,528][root][INFO] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1589.1, step = 427520, mean_episode_return = 0.2634, mean_episode_step = 56.517, total_loss = -469.56, entropy_loss = -8.9839, pg_loss = -508.43, baseline_loss = 47.853, learner_queue_size = 32, _tick = 166, _time = 1.7371e+09)
[2025-01-17 17:44:01,534][root][INFO] - Step 430080 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1594.1, step = 430080, mean_episode_return = 0.48185, mean_episode_step = 59.674, total_loss = -43.868, entropy_loss = -8.9799, pg_loss = -99.183, baseline_loss = 64.295, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)
[2025-01-17 17:44:06,539][root][INFO] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1599.1, step = 430080, mean_episode_return = 0.48185, mean_episode_step = 59.674, total_loss = -43.868, entropy_loss = -8.9799, pg_loss = -99.183, baseline_loss = 64.295, learner_queue_size = 32, _tick = 167, _time = 1.7371e+09)
[2025-01-17 17:44:11,544][root][INFO] - Step 432640 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1604.1, step = 432640, mean_episode_return = 0.45873, mean_episode_step = 46.171, total_loss = 108.69, entropy_loss = -8.9714, pg_loss = 46.334, baseline_loss = 71.325, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)
[2025-01-17 17:44:16,550][root][INFO] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1609.1, step = 432640, mean_episode_return = 0.45873, mean_episode_step = 46.171, total_loss = 108.69, entropy_loss = -8.9714, pg_loss = 46.334, baseline_loss = 71.325, learner_queue_size = 32, _tick = 168, _time = 1.7371e+09)
[2025-01-17 17:44:21,556][root][INFO] - Step 435200 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1614.1, step = 435200, mean_episode_return = 0.50789, mean_episode_step = 51.468, total_loss = -106.63, entropy_loss = -8.9721, pg_loss = -158.15, baseline_loss = 60.498, learner_queue_size = 32, _tick = 169, _time = 1.7371e+09)
[2025-01-17 17:44:26,561][root][INFO] - Step 437760 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1619.1, step = 437760, mean_episode_return = 0.35276, mean_episode_step = 44.659, total_loss = -340.53, entropy_loss = -8.9486, pg_loss = -383.4, baseline_loss = 51.818, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)
[2025-01-17 17:44:31,566][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 1624.1, step = 437760, mean_episode_return = 0.35276, mean_episode_step = 44.659, total_loss = -340.53, entropy_loss = -8.9486, pg_loss = -383.4, baseline_loss = 51.818, learner_queue_size = 32, _tick = 170, _time = 1.7371e+09)
[2025-01-17 17:44:36,573][root][INFO] - Step 440320 @ 511.3 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1629.1, step = 440320, mean_episode_return = 0.57218, mean_episode_step = 54.799, total_loss = 200.71, entropy_loss = -8.94, pg_loss = 154.65, baseline_loss = 54.992, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)
[2025-01-17 17:44:41,581][root][INFO] - Step 440320 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1634.1, step = 440320, mean_episode_return = 0.57218, mean_episode_step = 54.799, total_loss = 200.71, entropy_loss = -8.94, pg_loss = 154.65, baseline_loss = 54.992, learner_queue_size = 32, _tick = 171, _time = 1.7371e+09)
[2025-01-17 17:44:46,586][root][INFO] - Step 442880 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1639.2, step = 442880, mean_episode_return = 0.52503, mean_episode_step = 57.145, total_loss = 260.71, entropy_loss = -8.9336, pg_loss = 209.05, baseline_loss = 60.591, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)
[2025-01-17 17:44:51,594][root][INFO] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1644.2, step = 442880, mean_episode_return = 0.52503, mean_episode_step = 57.145, total_loss = 260.71, entropy_loss = -8.9336, pg_loss = 209.05, baseline_loss = 60.591, learner_queue_size = 32, _tick = 172, _time = 1.7371e+09)
[2025-01-17 17:44:56,599][root][INFO] - Step 445440 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1649.2, step = 445440, mean_episode_return = 0.39902, mean_episode_step = 45.879, total_loss = -159.04, entropy_loss = -8.9453, pg_loss = -210.61, baseline_loss = 60.516, learner_queue_size = 32, _tick = 173, _time = 1.7371e+09)
[2025-01-17 17:45:01,604][root][INFO] - Step 445440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1654.2, step = 445440, mean_episode_return = 0.39902, mean_episode_step = 45.879, total_loss = -159.04, entropy_loss = -8.9453, pg_loss = -210.61, baseline_loss = 60.516, learner_queue_size = 32, _tick = 173, _time = 1.7371e+09)
[2025-01-17 17:45:06,609][root][INFO] - Step 448000 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1659.2, step = 448000, mean_episode_return = 0.4829, mean_episode_step = 47.666, total_loss = 332.86, entropy_loss = -8.9371, pg_loss = 270.11, baseline_loss = 71.683, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)
[2025-01-17 17:45:11,614][root][INFO] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1664.2, step = 448000, mean_episode_return = 0.4829, mean_episode_step = 47.666, total_loss = 332.86, entropy_loss = -8.9371, pg_loss = 270.11, baseline_loss = 71.683, learner_queue_size = 32, _tick = 174, _time = 1.7371e+09)
[2025-01-17 17:45:16,619][root][INFO] - Step 450560 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1669.2, step = 450560, mean_episode_return = 0.48191, mean_episode_step = 51.05, total_loss = 217.27, entropy_loss = -8.9529, pg_loss = 155.17, baseline_loss = 71.054, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)
[2025-01-17 17:45:21,624][root][INFO] - Step 450560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1674.2, step = 450560, mean_episode_return = 0.48191, mean_episode_step = 51.05, total_loss = 217.27, entropy_loss = -8.9529, pg_loss = 155.17, baseline_loss = 71.054, learner_queue_size = 32, _tick = 175, _time = 1.7371e+09)
[2025-01-17 17:45:26,629][root][INFO] - Step 453120 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1679.2, step = 453120, mean_episode_return = 0.72582, mean_episode_step = 63.307, total_loss = 897.43, entropy_loss = -8.9398, pg_loss = 806.13, baseline_loss = 100.24, learner_queue_size = 32, _tick = 176, _time = 1.7371e+09)
[2025-01-17 17:45:31,634][root][INFO] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1684.2, step = 453120, mean_episode_return = 0.72582, mean_episode_step = 63.307, total_loss = 897.43, entropy_loss = -8.9398, pg_loss = 806.13, baseline_loss = 100.24, learner_queue_size = 32, _tick = 176, _time = 1.7371e+09)
[2025-01-17 17:45:36,639][root][INFO] - Step 455680 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1689.2, step = 455680, mean_episode_return = 0.32915, mean_episode_step = 65.045, total_loss = -684.3, entropy_loss = -8.9468, pg_loss = -718.9, baseline_loss = 43.548, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)
[2025-01-17 17:45:41,645][root][INFO] - Step 455680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1694.2, step = 455680, mean_episode_return = 0.32915, mean_episode_step = 65.045, total_loss = -684.3, entropy_loss = -8.9468, pg_loss = -718.9, baseline_loss = 43.548, learner_queue_size = 32, _tick = 177, _time = 1.7371e+09)
[2025-01-17 17:45:46,650][root][INFO] - Step 458240 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1699.2, step = 458240, mean_episode_return = 0.4712, mean_episode_step = 59.34, total_loss = -11.074, entropy_loss = -8.9447, pg_loss = -60.158, baseline_loss = 58.029, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)
[2025-01-17 17:45:51,655][root][INFO] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1704.2, step = 458240, mean_episode_return = 0.4712, mean_episode_step = 59.34, total_loss = -11.074, entropy_loss = -8.9447, pg_loss = -60.158, baseline_loss = 58.029, learner_queue_size = 32, _tick = 178, _time = 1.7371e+09)
[2025-01-17 17:45:56,660][root][INFO] - Step 460800 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1709.2, step = 460800, mean_episode_return = 0.71333, mean_episode_step = 57.018, total_loss = 908.45, entropy_loss = -8.9444, pg_loss = 827.82, baseline_loss = 89.572, learner_queue_size = 32, _tick = 179, _time = 1.7371e+09)
[2025-01-17 17:46:01,665][root][INFO] - Step 460800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1714.2, step = 460800, mean_episode_return = 0.71333, mean_episode_step = 57.018, total_loss = 908.45, entropy_loss = -8.9444, pg_loss = 827.82, baseline_loss = 89.572, learner_queue_size = 32, _tick = 179, _time = 1.7371e+09)
[2025-01-17 17:46:06,670][root][INFO] - Step 463360 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 1719.2, step = 463360, mean_episode_return = 0.72788, mean_episode_step = 47.891, total_loss = 311.76, entropy_loss = -8.9455, pg_loss = 252.51, baseline_loss = 68.193, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)
[2025-01-17 17:46:11,675][root][INFO] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1724.2, step = 463360, mean_episode_return = 0.72788, mean_episode_step = 47.891, total_loss = 311.76, entropy_loss = -8.9455, pg_loss = 252.51, baseline_loss = 68.193, learner_queue_size = 32, _tick = 180, _time = 1.7371e+09)
[2025-01-17 17:46:16,680][root][INFO] - Step 465920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1729.2, step = 465920, mean_episode_return = 0.53972, mean_episode_step = 57.756, total_loss = 321.81, entropy_loss = -8.9544, pg_loss = 267.82, baseline_loss = 62.944, learner_queue_size = 32, _tick = 181, _time = 1.7371e+09)
[2025-01-17 17:46:21,686][root][INFO] - Step 468480 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1734.3, step = 468480, mean_episode_return = 0.34574, mean_episode_step = 43.266, total_loss = 156.6, entropy_loss = -8.9537, pg_loss = 90.251, baseline_loss = 75.302, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)
[2025-01-17 17:46:26,691][root][INFO] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1739.3, step = 468480, mean_episode_return = 0.34574, mean_episode_step = 43.266, total_loss = 156.6, entropy_loss = -8.9537, pg_loss = 90.251, baseline_loss = 75.302, learner_queue_size = 32, _tick = 182, _time = 1.7371e+09)
[2025-01-17 17:46:31,696][root][INFO] - Step 471040 @ 511.4 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1744.3, step = 471040, mean_episode_return = 0.53854, mean_episode_step = 48.019, total_loss = 249.78, entropy_loss = -8.9553, pg_loss = 185.44, baseline_loss = 73.3, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)
[2025-01-17 17:46:36,702][root][INFO] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1749.3, step = 471040, mean_episode_return = 0.53854, mean_episode_step = 48.019, total_loss = 249.78, entropy_loss = -8.9553, pg_loss = 185.44, baseline_loss = 73.3, learner_queue_size = 32, _tick = 183, _time = 1.7371e+09)
[2025-01-17 17:46:41,708][root][INFO] - Step 473600 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1754.3, step = 473600, mean_episode_return = 0.54205, mean_episode_step = 55.322, total_loss = 15.23, entropy_loss = -8.9577, pg_loss = -39.289, baseline_loss = 63.476, learner_queue_size = 32, _tick = 184, _time = 1.7371e+09)
[2025-01-17 17:46:46,714][root][INFO] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1759.3, step = 473600, mean_episode_return = 0.54205, mean_episode_step = 55.322, total_loss = 15.23, entropy_loss = -8.9577, pg_loss = -39.289, baseline_loss = 63.476, learner_queue_size = 32, _tick = 184, _time = 1.7371e+09)
[2025-01-17 17:46:51,719][root][INFO] - Step 476160 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1764.3, step = 476160, mean_episode_return = 0.61413, mean_episode_step = 55.19, total_loss = 179.24, entropy_loss = -8.9666, pg_loss = 103.14, baseline_loss = 85.066, learner_queue_size = 32, _tick = 185, _time = 1.7371e+09)
[2025-01-17 17:46:56,724][root][INFO] - Step 478720 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1769.3, step = 478720, mean_episode_return = 0.43794, mean_episode_step = 45.015, total_loss = 327.88, entropy_loss = -8.9728, pg_loss = 241.56, baseline_loss = 95.302, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)
[2025-01-17 17:47:01,729][root][INFO] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1774.3, step = 478720, mean_episode_return = 0.43794, mean_episode_step = 45.015, total_loss = 327.88, entropy_loss = -8.9728, pg_loss = 241.56, baseline_loss = 95.302, learner_queue_size = 32, _tick = 186, _time = 1.7371e+09)
[2025-01-17 17:47:06,734][root][INFO] - Step 481280 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1779.3, step = 481280, mean_episode_return = 0.64727, mean_episode_step = 56.715, total_loss = 154.43, entropy_loss = -8.9604, pg_loss = 105.23, baseline_loss = 58.156, learner_queue_size = 32, _tick = 187, _time = 1.7371e+09)
[2025-01-17 17:47:11,740][root][INFO] - Step 481280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1784.3, step = 481280, mean_episode_return = 0.64727, mean_episode_step = 56.715, total_loss = 154.43, entropy_loss = -8.9604, pg_loss = 105.23, baseline_loss = 58.156, learner_queue_size = 32, _tick = 187, _time = 1.7371e+09)
[2025-01-17 17:47:16,745][root][INFO] - Step 483840 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1789.3, step = 483840, mean_episode_return = 0.22519, mean_episode_step = 46.507, total_loss = -526.46, entropy_loss = -8.9695, pg_loss = -584.35, baseline_loss = 66.86, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)
[2025-01-17 17:47:21,750][root][INFO] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1794.3, step = 483840, mean_episode_return = 0.22519, mean_episode_step = 46.507, total_loss = -526.46, entropy_loss = -8.9695, pg_loss = -584.35, baseline_loss = 66.86, learner_queue_size = 32, _tick = 188, _time = 1.7371e+09)
[2025-01-17 17:47:26,755][root][INFO] - Step 486400 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1799.3, step = 486400, mean_episode_return = 0.50633, mean_episode_step = 51.603, total_loss = 130.89, entropy_loss = -8.9687, pg_loss = 70.81, baseline_loss = 69.045, learner_queue_size = 32, _tick = 189, _time = 1.7371e+09)
[2025-01-17 17:47:31,761][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 17:47:31,931][root][INFO] - Step 488960 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1804.3, step = 488960, mean_episode_return = 0.55018, mean_episode_step = 52.687, total_loss = 308.36, entropy_loss = -8.9692, pg_loss = 231.15, baseline_loss = 86.179, learner_queue_size = 32, _tick = 190, _time = 1.7371e+09)
[2025-01-17 17:47:36,940][root][INFO] - Step 488960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1809.5, step = 488960, mean_episode_return = 0.55018, mean_episode_step = 52.687, total_loss = 308.36, entropy_loss = -8.9692, pg_loss = 231.15, baseline_loss = 86.179, learner_queue_size = 32, _tick = 190, _time = 1.7371e+09)
[2025-01-17 17:47:41,945][root][INFO] - Step 491520 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1814.5, step = 491520, mean_episode_return = 0.33813, mean_episode_step = 43.537, total_loss = -502.67, entropy_loss = -8.9683, pg_loss = -546.09, baseline_loss = 52.39, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)
[2025-01-17 17:47:46,951][root][INFO] - Step 491520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1819.5, step = 491520, mean_episode_return = 0.33813, mean_episode_step = 43.537, total_loss = -502.67, entropy_loss = -8.9683, pg_loss = -546.09, baseline_loss = 52.39, learner_queue_size = 32, _tick = 191, _time = 1.7371e+09)
[2025-01-17 17:47:51,956][root][INFO] - Step 494080 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1824.5, step = 494080, mean_episode_return = 0.67181, mean_episode_step = 47.952, total_loss = 171.67, entropy_loss = -8.9655, pg_loss = 95.109, baseline_loss = 85.525, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)
[2025-01-17 17:47:56,961][root][INFO] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1829.5, step = 494080, mean_episode_return = 0.67181, mean_episode_step = 47.952, total_loss = 171.67, entropy_loss = -8.9655, pg_loss = 95.109, baseline_loss = 85.525, learner_queue_size = 32, _tick = 192, _time = 1.7371e+09)
[2025-01-17 17:48:01,967][root][INFO] - Step 496640 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1834.5, step = 496640, mean_episode_return = 0.47349, mean_episode_step = 57.521, total_loss = -2.8805, entropy_loss = -8.964, pg_loss = -67.936, baseline_loss = 74.02, learner_queue_size = 32, _tick = 193, _time = 1.7371e+09)
[2025-01-17 17:48:06,972][root][INFO] - Step 496640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1839.5, step = 496640, mean_episode_return = 0.47349, mean_episode_step = 57.521, total_loss = -2.8805, entropy_loss = -8.964, pg_loss = -67.936, baseline_loss = 74.02, learner_queue_size = 32, _tick = 193, _time = 1.7371e+09)
[2025-01-17 17:48:11,979][root][INFO] - Step 499200 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1844.5, step = 499200, mean_episode_return = 0.5229, mean_episode_step = 66.634, total_loss = -86.302, entropy_loss = -8.9627, pg_loss = -160.08, baseline_loss = 82.742, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)
[2025-01-17 17:48:16,984][root][INFO] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1849.5, step = 499200, mean_episode_return = 0.5229, mean_episode_step = 66.634, total_loss = -86.302, entropy_loss = -8.9627, pg_loss = -160.08, baseline_loss = 82.742, learner_queue_size = 32, _tick = 194, _time = 1.7371e+09)
[2025-01-17 17:48:21,989][root][INFO] - Step 501760 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1854.6, step = 501760, mean_episode_return = 0.58825, mean_episode_step = 50.961, total_loss = 74.733, entropy_loss = -8.9631, pg_loss = 14.375, baseline_loss = 69.321, learner_queue_size = 32, _tick = 195, _time = 1.7371e+09)
[2025-01-17 17:48:21,990][root][INFO] - Learning finished after 501760 steps.
[2025-01-17 17:48:21,990][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-17 18:02:01,188][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,206][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,185][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,223][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,274][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,205][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,210][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,305][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,220][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,338][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,305][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,297][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,285][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,347][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,228][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,321][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,265][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,305][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,270][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,280][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,376][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,384][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,280][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,294][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,316][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,247][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,206][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,277][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,306][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,366][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,342][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,302][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,312][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,350][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,321][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,323][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,275][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,357][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,403][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,324][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,336][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,337][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,311][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,276][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,339][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,381][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,321][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,341][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,321][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,382][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,327][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,302][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,360][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,374][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,398][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,364][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,354][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,307][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,315][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,345][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,349][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,346][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,366][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,366][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,351][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,395][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,343][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,418][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,384][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,392][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,392][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,332][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,401][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,402][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,336][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,401][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,370][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,283][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,279][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,323][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,295][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,324][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,453][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,354][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,383][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,437][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,299][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,433][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,386][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,377][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,394][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,408][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,396][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,364][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,342][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,312][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,365][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,387][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,389][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,401][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,383][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,362][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,418][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,356][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,328][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,445][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,302][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,363][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,437][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,335][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,439][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,419][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,383][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,425][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,351][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,368][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,404][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,339][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,431][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,474][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,413][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,331][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,380][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,377][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,473][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,359][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,405][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,477][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,402][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,409][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,410][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,387][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,356][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,364][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,336][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,447][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,417][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,406][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,392][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,422][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,409][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,366][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,432][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,396][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,406][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,469][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,412][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,379][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,421][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,397][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,357][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,416][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,430][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,393][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,403][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,381][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,414][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,393][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,427][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,431][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,389][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,465][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,437][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,450][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,408][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,438][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,322][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,453][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,452][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,428][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,412][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,420][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,438][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,479][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,457][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,441][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,417][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,443][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,549][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-17 18:02:01,455][nle.env.base][INFO] - Not saving any NLE data.
