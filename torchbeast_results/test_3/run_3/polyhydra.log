[2025-01-20 09:14:17,242][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-20 09:14:17,297][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-20 09:14:17,299][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-20 09:14:17,304][root][INFO] - Logging results to /opt/minihack
[2025-01-20 09:14:17,371][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-20 09:14:17,371][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-20 09:14:17,372][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-20 09:14:17,372][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-20 09:14:17,372][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-20 09:14:17,375][root][INFO] - Not using CUDA.
[2025-01-20 09:14:17,384][root][INFO] - Using model baseline
[2025-01-20 09:14:17,384][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,505][root][INFO] - Number of model parameters: 4264078
[2025-01-20 09:14:17,506][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,566][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,566][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,567][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,567][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,568][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,565][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,569][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,570][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,571][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,571][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,574][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,575][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,577][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,578][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,579][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,580][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,581][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,581][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,565][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,583][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,572][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,587][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,589][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,586][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,588][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,575][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,592][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,592][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,594][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,594][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,588][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,596][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,596][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,598][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,598][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,598][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,601][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,600][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,601][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,603][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,603][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,603][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,604][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,605][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,605][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,607][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,607][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,609][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,610][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,612][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,612][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,614][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,611][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,606][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,620][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,622][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,624][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,626][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,629][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,626][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,629][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,631][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,630][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,606][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,644][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,624][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:22,563][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 6. Learner queue size: 30. Other stats: (train_seconds = 5.0)
[2025-01-20 09:14:27,569][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 21. Learner queue size: 9. Other stats: (train_seconds = 10.0)
[2025-01-20 09:14:32,575][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 110. Learner queue size: 11. Other stats: (train_seconds = 15.0)
[2025-01-20 09:14:37,577][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 144. Learner queue size: 11. Other stats: (train_seconds = 20.0)
[2025-01-20 09:14:42,582][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 97. Learner queue size: 11. Other stats: (train_seconds = 25.0)
[2025-01-20 09:14:43,122][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-20 09:14:47,587][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-20 09:14:47,643][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 92. Learner queue size: 14. Other stats: (train_seconds = 30.0, step = 2560, mean_episode_return = 0.042313, mean_episode_step = 64.293, total_loss = -365.39, entropy_loss = -11.371, pg_loss = -571.8, baseline_loss = 217.78, learner_queue_size = 11, _tick = 0, _time = 1.7374e+09)
[2025-01-20 09:14:52,648][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 137. Learner queue size: 23. Other stats: (train_seconds = 35.1, step = 2560, mean_episode_return = 0.042313, mean_episode_step = 64.293, total_loss = -365.39, entropy_loss = -11.371, pg_loss = -571.8, baseline_loss = 217.78, learner_queue_size = 11, _tick = 0, _time = 1.7374e+09)
[2025-01-20 09:14:57,653][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 141. Learner queue size: 30. Other stats: (train_seconds = 40.1, step = 2560, mean_episode_return = 0.042313, mean_episode_step = 64.293, total_loss = -365.39, entropy_loss = -11.371, pg_loss = -571.8, baseline_loss = 217.78, learner_queue_size = 11, _tick = 0, _time = 1.7374e+09)
[2025-01-20 09:15:02,658][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 71. Learner queue size: 32. Other stats: (train_seconds = 45.1, step = 2560, mean_episode_return = 0.042313, mean_episode_step = 64.293, total_loss = -365.39, entropy_loss = -11.371, pg_loss = -571.8, baseline_loss = 217.78, learner_queue_size = 11, _tick = 0, _time = 1.7374e+09)
[2025-01-20 09:15:07,663][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 50.1, step = 2560, mean_episode_return = 0.042313, mean_episode_step = 64.293, total_loss = -365.39, entropy_loss = -11.371, pg_loss = -571.8, baseline_loss = 217.78, learner_queue_size = 11, _tick = 0, _time = 1.7374e+09)
[2025-01-20 09:15:12,726][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 55.1, step = 2560, mean_episode_return = 0.042313, mean_episode_step = 64.293, total_loss = -365.39, entropy_loss = -11.371, pg_loss = -571.8, baseline_loss = 217.78, learner_queue_size = 11, _tick = 0, _time = 1.7374e+09)
[2025-01-20 09:15:17,738][root][INFO] - Step 5120 @ 506.3 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 60.2, step = 5120, mean_episode_return = -0.00013632, mean_episode_step = 55.834, total_loss = 2311.1, entropy_loss = -11.326, pg_loss = 2086.7, baseline_loss = 235.71, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)
[2025-01-20 09:15:22,740][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 65.2, step = 5120, mean_episode_return = -0.00013632, mean_episode_step = 55.834, total_loss = 2311.1, entropy_loss = -11.326, pg_loss = 2086.7, baseline_loss = 235.71, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)
[2025-01-20 09:15:27,746][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 70.2, step = 5120, mean_episode_return = -0.00013632, mean_episode_step = 55.834, total_loss = 2311.1, entropy_loss = -11.326, pg_loss = 2086.7, baseline_loss = 235.71, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)
[2025-01-20 09:15:33,235][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 75.7, step = 5120, mean_episode_return = -0.00013632, mean_episode_step = 55.834, total_loss = 2311.1, entropy_loss = -11.326, pg_loss = 2086.7, baseline_loss = 235.71, learner_queue_size = 32, _tick = 1, _time = 1.7374e+09)
[2025-01-20 09:15:39,491][root][INFO] - Step 7680 @ 409.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 81.9, step = 7680, mean_episode_return = 0.12358, mean_episode_step = 37.52, total_loss = 422.29, entropy_loss = -11.369, pg_loss = 331.8, baseline_loss = 101.86, learner_queue_size = 32, _tick = 2, _time = 1.7374e+09)
[2025-01-20 09:15:44,497][root][INFO] - Step 7680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 86.9, step = 7680, mean_episode_return = 0.12358, mean_episode_step = 37.52, total_loss = 422.29, entropy_loss = -11.369, pg_loss = 331.8, baseline_loss = 101.86, learner_queue_size = 32, _tick = 2, _time = 1.7374e+09)
[2025-01-20 09:15:49,502][root][INFO] - Step 10240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 91.9, step = 10240, mean_episode_return = -0.039125, mean_episode_step = 35.159, total_loss = -707.15, entropy_loss = -11.357, pg_loss = -724.36, baseline_loss = 28.558, learner_queue_size = 32, _tick = 3, _time = 1.7374e+09)
[2025-01-20 09:15:54,507][root][INFO] - Step 12800 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 96.9, step = 12800, mean_episode_return = -0.049, mean_episode_step = 40.964, total_loss = -258.25, entropy_loss = -11.37, pg_loss = -277.86, baseline_loss = 30.981, learner_queue_size = 32, _tick = 4, _time = 1.7374e+09)
[2025-01-20 09:15:59,513][root][INFO] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 102.0, step = 12800, mean_episode_return = -0.049, mean_episode_step = 40.964, total_loss = -258.25, entropy_loss = -11.37, pg_loss = -277.86, baseline_loss = 30.981, learner_queue_size = 32, _tick = 4, _time = 1.7374e+09)
[2025-01-20 09:16:04,519][root][INFO] - Step 15360 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 107.0, step = 15360, mean_episode_return = -0.062762, mean_episode_step = 49.016, total_loss = 504.33, entropy_loss = -11.332, pg_loss = 481.81, baseline_loss = 33.849, learner_queue_size = 32, _tick = 5, _time = 1.7374e+09)
[2025-01-20 09:16:09,525][root][INFO] - Step 17920 @ 511.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 112.0, step = 17920, mean_episode_return = -0.055444, mean_episode_step = 52.043, total_loss = -184.28, entropy_loss = -11.358, pg_loss = -203.72, baseline_loss = 30.804, learner_queue_size = 32, _tick = 6, _time = 1.7374e+09)
[2025-01-20 09:16:14,532][root][INFO] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 117.0, step = 17920, mean_episode_return = -0.055444, mean_episode_step = 52.043, total_loss = -184.28, entropy_loss = -11.358, pg_loss = -203.72, baseline_loss = 30.804, learner_queue_size = 32, _tick = 6, _time = 1.7374e+09)
[2025-01-20 09:16:19,537][root][INFO] - Step 20480 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 122.0, step = 20480, mean_episode_return = -0.014357, mean_episode_step = 49.854, total_loss = 590.27, entropy_loss = -11.335, pg_loss = 523.36, baseline_loss = 78.249, learner_queue_size = 32, _tick = 7, _time = 1.7374e+09)
[2025-01-20 09:16:24,550][root][INFO] - Step 23040 @ 510.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 127.0, step = 23040, mean_episode_return = 0.061, mean_episode_step = 68.977, total_loss = 269.64, entropy_loss = -11.366, pg_loss = 140.9, baseline_loss = 140.11, learner_queue_size = 32, _tick = 8, _time = 1.7374e+09)
[2025-01-20 09:16:29,557][root][INFO] - Step 23040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 132.0, step = 23040, mean_episode_return = 0.061, mean_episode_step = 68.977, total_loss = 269.64, entropy_loss = -11.366, pg_loss = 140.9, baseline_loss = 140.11, learner_queue_size = 32, _tick = 8, _time = 1.7374e+09)
[2025-01-20 09:16:34,562][root][INFO] - Step 25600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 137.0, step = 25600, mean_episode_return = -0.075824, mean_episode_step = 53.925, total_loss = 711.81, entropy_loss = -11.347, pg_loss = 525.16, baseline_loss = 198.0, learner_queue_size = 32, _tick = 9, _time = 1.7374e+09)
[2025-01-20 09:16:39,569][root][INFO] - Step 28160 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 142.0, step = 28160, mean_episode_return = -0.046936, mean_episode_step = 57.854, total_loss = -301.13, entropy_loss = -11.33, pg_loss = -455.44, baseline_loss = 165.63, learner_queue_size = 32, _tick = 10, _time = 1.7374e+09)
[2025-01-20 09:16:44,576][root][INFO] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 147.0, step = 28160, mean_episode_return = -0.046936, mean_episode_step = 57.854, total_loss = -301.13, entropy_loss = -11.33, pg_loss = -455.44, baseline_loss = 165.63, learner_queue_size = 32, _tick = 10, _time = 1.7374e+09)
[2025-01-20 09:16:49,584][root][INFO] - Step 30720 @ 511.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 152.0, step = 30720, mean_episode_return = 0.0041502, mean_episode_step = 65.075, total_loss = 367.89, entropy_loss = -11.333, pg_loss = 266.46, baseline_loss = 112.75, learner_queue_size = 32, _tick = 11, _time = 1.7374e+09)
[2025-01-20 09:16:54,590][root][INFO] - Step 30720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 157.0, step = 30720, mean_episode_return = 0.0041502, mean_episode_step = 65.075, total_loss = 367.89, entropy_loss = -11.333, pg_loss = 266.46, baseline_loss = 112.75, learner_queue_size = 32, _tick = 11, _time = 1.7374e+09)
[2025-01-20 09:16:59,597][root][INFO] - Step 33280 @ 511.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 162.0, step = 33280, mean_episode_return = -0.039548, mean_episode_step = 57.682, total_loss = -665.33, entropy_loss = -11.298, pg_loss = -725.19, baseline_loss = 71.164, learner_queue_size = 32, _tick = 12, _time = 1.7374e+09)
[2025-01-20 09:17:04,645][root][INFO] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 167.1, step = 33280, mean_episode_return = -0.039548, mean_episode_step = 57.682, total_loss = -665.33, entropy_loss = -11.298, pg_loss = -725.19, baseline_loss = 71.164, learner_queue_size = 32, _tick = 12, _time = 1.7374e+09)
[2025-01-20 09:17:09,651][root][INFO] - Step 35840 @ 508.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 172.1, step = 35840, mean_episode_return = 0.013933, mean_episode_step = 60.096, total_loss = 537.92, entropy_loss = -11.296, pg_loss = 423.04, baseline_loss = 126.17, learner_queue_size = 32, _tick = 13, _time = 1.7374e+09)
[2025-01-20 09:17:14,663][root][INFO] - Step 35840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 177.1, step = 35840, mean_episode_return = 0.013933, mean_episode_step = 60.096, total_loss = 537.92, entropy_loss = -11.296, pg_loss = 423.04, baseline_loss = 126.17, learner_queue_size = 32, _tick = 13, _time = 1.7374e+09)
[2025-01-20 09:17:19,668][root][INFO] - Step 38400 @ 510.9 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 182.1, step = 38400, mean_episode_return = -0.049536, mean_episode_step = 67.655, total_loss = -163.31, entropy_loss = -11.278, pg_loss = -222.55, baseline_loss = 70.519, learner_queue_size = 32, _tick = 14, _time = 1.7374e+09)
[2025-01-20 09:17:24,680][root][INFO] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 187.1, step = 38400, mean_episode_return = -0.049536, mean_episode_step = 67.655, total_loss = -163.31, entropy_loss = -11.278, pg_loss = -222.55, baseline_loss = 70.519, learner_queue_size = 32, _tick = 14, _time = 1.7374e+09)
[2025-01-20 09:17:29,687][root][INFO] - Step 40960 @ 510.6 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 192.1, step = 40960, mean_episode_return = -0.031077, mean_episode_step = 50.195, total_loss = -134.5, entropy_loss = -11.247, pg_loss = -165.17, baseline_loss = 41.916, learner_queue_size = 32, _tick = 15, _time = 1.7374e+09)
[2025-01-20 09:17:34,694][root][INFO] - Step 43520 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 197.1, step = 43520, mean_episode_return = -0.083273, mean_episode_step = 70.884, total_loss = -91.57, entropy_loss = -11.187, pg_loss = -121.15, baseline_loss = 40.763, learner_queue_size = 32, _tick = 16, _time = 1.7374e+09)
[2025-01-20 09:17:39,701][root][INFO] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 202.1, step = 43520, mean_episode_return = -0.083273, mean_episode_step = 70.884, total_loss = -91.57, entropy_loss = -11.187, pg_loss = -121.15, baseline_loss = 40.763, learner_queue_size = 32, _tick = 16, _time = 1.7374e+09)
[2025-01-20 09:17:44,708][root][INFO] - Step 46080 @ 511.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 207.1, step = 46080, mean_episode_return = 0.019839, mean_episode_step = 54.232, total_loss = 356.97, entropy_loss = -11.047, pg_loss = 314.68, baseline_loss = 53.331, learner_queue_size = 32, _tick = 17, _time = 1.7374e+09)
[2025-01-20 09:17:49,713][root][INFO] - Step 46080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 212.2, step = 46080, mean_episode_return = 0.019839, mean_episode_step = 54.232, total_loss = 356.97, entropy_loss = -11.047, pg_loss = 314.68, baseline_loss = 53.331, learner_queue_size = 32, _tick = 17, _time = 1.7374e+09)
[2025-01-20 09:17:54,719][root][INFO] - Step 48640 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 217.2, step = 48640, mean_episode_return = 0.1415, mean_episode_step = 63.807, total_loss = 490.8, entropy_loss = -11.083, pg_loss = 378.06, baseline_loss = 123.82, learner_queue_size = 32, _tick = 18, _time = 1.7374e+09)
[2025-01-20 09:17:59,724][root][INFO] - Step 48640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 222.2, step = 48640, mean_episode_return = 0.1415, mean_episode_step = 63.807, total_loss = 490.8, entropy_loss = -11.083, pg_loss = 378.06, baseline_loss = 123.82, learner_queue_size = 32, _tick = 18, _time = 1.7374e+09)
[2025-01-20 09:18:04,733][root][INFO] - Step 51200 @ 511.1 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 227.2, step = 51200, mean_episode_return = -0.0011249, mean_episode_step = 52.134, total_loss = 78.649, entropy_loss = -11.058, pg_loss = 6.6139, baseline_loss = 83.093, learner_queue_size = 32, _tick = 19, _time = 1.7374e+09)
[2025-01-20 09:18:09,750][root][INFO] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 232.2, step = 51200, mean_episode_return = -0.0011249, mean_episode_step = 52.134, total_loss = 78.649, entropy_loss = -11.058, pg_loss = 6.6139, baseline_loss = 83.093, learner_queue_size = 32, _tick = 19, _time = 1.7374e+09)
[2025-01-20 09:18:14,757][root][INFO] - Step 53760 @ 510.2 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 237.2, step = 53760, mean_episode_return = 0.061258, mean_episode_step = 52.529, total_loss = 296.4, entropy_loss = -10.996, pg_loss = 183.51, baseline_loss = 123.88, learner_queue_size = 32, _tick = 20, _time = 1.7374e+09)
[2025-01-20 09:18:19,767][root][INFO] - Step 53760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 242.2, step = 53760, mean_episode_return = 0.061258, mean_episode_step = 52.529, total_loss = 296.4, entropy_loss = -10.996, pg_loss = 183.51, baseline_loss = 123.88, learner_queue_size = 32, _tick = 20, _time = 1.7374e+09)
[2025-01-20 09:18:24,774][root][INFO] - Step 56320 @ 510.8 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 247.2, step = 56320, mean_episode_return = -0.037154, mean_episode_step = 59.943, total_loss = -1.3013, entropy_loss = -10.856, pg_loss = -81.02, baseline_loss = 90.574, learner_queue_size = 32, _tick = 21, _time = 1.7374e+09)
[2025-01-20 09:18:29,780][root][INFO] - Step 58880 @ 511.4 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 252.2, step = 58880, mean_episode_return = 0.021, mean_episode_step = 53.764, total_loss = 207.77, entropy_loss = -10.78, pg_loss = 105.41, baseline_loss = 113.14, learner_queue_size = 32, _tick = 22, _time = 1.7374e+09)
[2025-01-20 09:18:34,786][root][INFO] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 257.2, step = 58880, mean_episode_return = 0.021, mean_episode_step = 53.764, total_loss = 207.77, entropy_loss = -10.78, pg_loss = 105.41, baseline_loss = 113.14, learner_queue_size = 32, _tick = 22, _time = 1.7374e+09)
[2025-01-20 09:18:39,792][root][INFO] - Step 61440 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 262.2, step = 61440, mean_episode_return = 0.041267, mean_episode_step = 54.601, total_loss = -377.1, entropy_loss = -10.714, pg_loss = -400.9, baseline_loss = 34.519, learner_queue_size = 32, _tick = 23, _time = 1.7374e+09)
[2025-01-20 09:18:44,799][root][INFO] - Step 61440 @ 0.0 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 267.2, step = 61440, mean_episode_return = 0.041267, mean_episode_step = 54.601, total_loss = -377.1, entropy_loss = -10.714, pg_loss = -400.9, baseline_loss = 34.519, learner_queue_size = 32, _tick = 23, _time = 1.7374e+09)
[2025-01-20 09:18:49,808][root][INFO] - Step 64000 @ 511.3 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 272.2, step = 64000, mean_episode_return = 0.1649, mean_episode_step = 58.16, total_loss = 238.66, entropy_loss = -10.68, pg_loss = 141.02, baseline_loss = 108.32, learner_queue_size = 32, _tick = 24, _time = 1.7374e+09)
[2025-01-20 09:18:54,817][root][INFO] - Step 64000 @ 0.0 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 277.3, step = 64000, mean_episode_return = 0.1649, mean_episode_step = 58.16, total_loss = 238.66, entropy_loss = -10.68, pg_loss = 141.02, baseline_loss = 108.32, learner_queue_size = 32, _tick = 24, _time = 1.7374e+09)
[2025-01-20 09:18:59,825][root][INFO] - Step 66560 @ 511.2 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 282.3, step = 66560, mean_episode_return = 0.063933, mean_episode_step = 59.425, total_loss = 225.16, entropy_loss = -10.556, pg_loss = 132.38, baseline_loss = 103.33, learner_queue_size = 32, _tick = 25, _time = 1.7374e+09)
[2025-01-20 09:19:04,831][root][INFO] - Step 66560 @ 0.0 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 287.3, step = 66560, mean_episode_return = 0.063933, mean_episode_step = 59.425, total_loss = 225.16, entropy_loss = -10.556, pg_loss = 132.38, baseline_loss = 103.33, learner_queue_size = 32, _tick = 25, _time = 1.7374e+09)
[2025-01-20 09:19:09,840][root][INFO] - Step 69120 @ 511.1 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 292.3, step = 69120, mean_episode_return = 0.10783, mean_episode_step = 68.316, total_loss = 163.56, entropy_loss = -10.574, pg_loss = 48.615, baseline_loss = 125.52, learner_queue_size = 32, _tick = 26, _time = 1.7374e+09)
[2025-01-20 09:19:14,846][root][INFO] - Step 69120 @ 0.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 297.3, step = 69120, mean_episode_return = 0.10783, mean_episode_step = 68.316, total_loss = 163.56, entropy_loss = -10.574, pg_loss = 48.615, baseline_loss = 125.52, learner_queue_size = 32, _tick = 26, _time = 1.7374e+09)
[2025-01-20 09:19:19,856][root][INFO] - Step 69120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 302.3, step = 69120, mean_episode_return = 0.10783, mean_episode_step = 68.316, total_loss = 163.56, entropy_loss = -10.574, pg_loss = 48.615, baseline_loss = 125.52, learner_queue_size = 32, _tick = 26, _time = 1.7374e+09)
[2025-01-20 09:19:24,861][root][INFO] - Step 71680 @ 511.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 307.3, step = 71680, mean_episode_return = 0.044414, mean_episode_step = 54.127, total_loss = 96.307, entropy_loss = -10.516, pg_loss = -2.8395, baseline_loss = 109.66, learner_queue_size = 32, _tick = 27, _time = 1.7374e+09)
[2025-01-20 09:19:29,867][root][INFO] - Step 74240 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 312.3, step = 74240, mean_episode_return = -0.028606, mean_episode_step = 59.533, total_loss = 259.58, entropy_loss = -10.585, pg_loss = 114.92, baseline_loss = 155.24, learner_queue_size = 32, _tick = 28, _time = 1.7374e+09)
[2025-01-20 09:19:34,873][root][INFO] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 317.3, step = 74240, mean_episode_return = -0.028606, mean_episode_step = 59.533, total_loss = 259.58, entropy_loss = -10.585, pg_loss = 114.92, baseline_loss = 155.24, learner_queue_size = 32, _tick = 28, _time = 1.7374e+09)
[2025-01-20 09:19:39,881][root][INFO] - Step 76800 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 322.3, step = 76800, mean_episode_return = 0.10192, mean_episode_step = 61.88, total_loss = 328.2, entropy_loss = -10.503, pg_loss = 132.18, baseline_loss = 206.52, learner_queue_size = 32, _tick = 29, _time = 1.7374e+09)
[2025-01-20 09:19:44,950][root][INFO] - Step 76800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 327.3, step = 76800, mean_episode_return = 0.10192, mean_episode_step = 61.88, total_loss = 328.2, entropy_loss = -10.503, pg_loss = 132.18, baseline_loss = 206.52, learner_queue_size = 32, _tick = 29, _time = 1.7374e+09)
[2025-01-20 09:19:49,976][root][INFO] - Step 79360 @ 503.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 332.4, step = 79360, mean_episode_return = 0.09196, mean_episode_step = 65.849, total_loss = -163.87, entropy_loss = -10.33, pg_loss = -292.71, baseline_loss = 139.17, learner_queue_size = 32, _tick = 30, _time = 1.7374e+09)
[2025-01-20 09:19:55,052][root][INFO] - Step 79360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 337.4, step = 79360, mean_episode_return = 0.09196, mean_episode_step = 65.849, total_loss = -163.87, entropy_loss = -10.33, pg_loss = -292.71, baseline_loss = 139.17, learner_queue_size = 32, _tick = 30, _time = 1.7374e+09)
[2025-01-20 09:20:00,079][root][INFO] - Step 81920 @ 502.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 342.5, step = 81920, mean_episode_return = 0.023152, mean_episode_step = 64.286, total_loss = 434.41, entropy_loss = -10.288, pg_loss = 276.76, baseline_loss = 167.94, learner_queue_size = 32, _tick = 31, _time = 1.7374e+09)
[2025-01-20 09:20:05,175][root][INFO] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 347.5, step = 81920, mean_episode_return = 0.023152, mean_episode_step = 64.286, total_loss = 434.41, entropy_loss = -10.288, pg_loss = 276.76, baseline_loss = 167.94, learner_queue_size = 32, _tick = 31, _time = 1.7374e+09)
[2025-01-20 09:20:10,185][root][INFO] - Step 84480 @ 502.8 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 352.6, step = 84480, mean_episode_return = 0.25253, mean_episode_step = 58.87, total_loss = 495.72, entropy_loss = -10.267, pg_loss = 309.4, baseline_loss = 196.59, learner_queue_size = 32, _tick = 32, _time = 1.7374e+09)
[2025-01-20 09:20:15,212][root][INFO] - Step 84480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 357.6, step = 84480, mean_episode_return = 0.25253, mean_episode_step = 58.87, total_loss = 495.72, entropy_loss = -10.267, pg_loss = 309.4, baseline_loss = 196.59, learner_queue_size = 32, _tick = 32, _time = 1.7374e+09)
[2025-01-20 09:20:20,222][root][INFO] - Step 87040 @ 509.0 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 362.7, step = 87040, mean_episode_return = 0.057, mean_episode_step = 60.888, total_loss = -522.06, entropy_loss = -10.231, pg_loss = -664.8, baseline_loss = 152.97, learner_queue_size = 32, _tick = 33, _time = 1.7374e+09)
[2025-01-20 09:20:25,280][root][INFO] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 367.7, step = 87040, mean_episode_return = 0.057, mean_episode_step = 60.888, total_loss = -522.06, entropy_loss = -10.231, pg_loss = -664.8, baseline_loss = 152.97, learner_queue_size = 32, _tick = 33, _time = 1.7374e+09)
[2025-01-20 09:20:30,287][root][INFO] - Step 89600 @ 508.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 372.7, step = 89600, mean_episode_return = 0.25651, mean_episode_step = 55.454, total_loss = 656.88, entropy_loss = -10.222, pg_loss = 388.5, baseline_loss = 278.61, learner_queue_size = 32, _tick = 34, _time = 1.7374e+09)
[2025-01-20 09:20:35,311][root][INFO] - Step 89600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 377.7, step = 89600, mean_episode_return = 0.25651, mean_episode_step = 55.454, total_loss = 656.88, entropy_loss = -10.222, pg_loss = 388.5, baseline_loss = 278.61, learner_queue_size = 32, _tick = 34, _time = 1.7374e+09)
[2025-01-20 09:20:40,317][root][INFO] - Step 92160 @ 509.6 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 382.8, step = 92160, mean_episode_return = 0.016381, mean_episode_step = 49.938, total_loss = -1639.4, entropy_loss = -10.128, pg_loss = -1751.2, baseline_loss = 121.89, learner_queue_size = 32, _tick = 35, _time = 1.7374e+09)
[2025-01-20 09:20:45,330][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 387.8, step = 92160, mean_episode_return = 0.016381, mean_episode_step = 49.938, total_loss = -1639.4, entropy_loss = -10.128, pg_loss = -1751.2, baseline_loss = 121.89, learner_queue_size = 32, _tick = 35, _time = 1.7374e+09)
[2025-01-20 09:20:50,337][root][INFO] - Step 94720 @ 510.6 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 392.8, step = 94720, mean_episode_return = 0.12136, mean_episode_step = 56.185, total_loss = 120.97, entropy_loss = -10.113, pg_loss = -103.06, baseline_loss = 234.14, learner_queue_size = 32, _tick = 36, _time = 1.7374e+09)
[2025-01-20 09:20:55,349][root][INFO] - Step 94720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 397.8, step = 94720, mean_episode_return = 0.12136, mean_episode_step = 56.185, total_loss = 120.97, entropy_loss = -10.113, pg_loss = -103.06, baseline_loss = 234.14, learner_queue_size = 32, _tick = 36, _time = 1.7374e+09)
[2025-01-20 09:21:00,355][root][INFO] - Step 97280 @ 510.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 402.8, step = 97280, mean_episode_return = 0.37232, mean_episode_step = 59.464, total_loss = 501.09, entropy_loss = -10.132, pg_loss = 325.97, baseline_loss = 185.25, learner_queue_size = 32, _tick = 37, _time = 1.7374e+09)
[2025-01-20 09:21:05,366][root][INFO] - Step 97280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 407.8, step = 97280, mean_episode_return = 0.37232, mean_episode_step = 59.464, total_loss = 501.09, entropy_loss = -10.132, pg_loss = 325.97, baseline_loss = 185.25, learner_queue_size = 32, _tick = 37, _time = 1.7374e+09)
[2025-01-20 09:21:10,371][root][INFO] - Step 99840 @ 511.0 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 412.8, step = 99840, mean_episode_return = 0.24803, mean_episode_step = 53.778, total_loss = 16.857, entropy_loss = -10.114, pg_loss = -128.87, baseline_loss = 155.84, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)
[2025-01-20 09:21:15,383][root][INFO] - Step 99840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 417.8, step = 99840, mean_episode_return = 0.24803, mean_episode_step = 53.778, total_loss = 16.857, entropy_loss = -10.114, pg_loss = -128.87, baseline_loss = 155.84, learner_queue_size = 32, _tick = 38, _time = 1.7374e+09)
[2025-01-20 09:21:20,390][root][INFO] - Step 102400 @ 510.8 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 422.8, step = 102400, mean_episode_return = 0.1466, mean_episode_step = 46.057, total_loss = -687.55, entropy_loss = -9.9229, pg_loss = -783.05, baseline_loss = 105.42, learner_queue_size = 32, _tick = 39, _time = 1.7374e+09)
[2025-01-20 09:21:25,398][root][INFO] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 427.8, step = 102400, mean_episode_return = 0.1466, mean_episode_step = 46.057, total_loss = -687.55, entropy_loss = -9.9229, pg_loss = -783.05, baseline_loss = 105.42, learner_queue_size = 32, _tick = 39, _time = 1.7374e+09)
[2025-01-20 09:21:30,408][root][INFO] - Step 104960 @ 511.2 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 432.8, step = 104960, mean_episode_return = 0.091647, mean_episode_step = 49.201, total_loss = -340.71, entropy_loss = -9.8644, pg_loss = -422.85, baseline_loss = 92.0, learner_queue_size = 32, _tick = 40, _time = 1.7374e+09)
[2025-01-20 09:21:35,424][root][INFO] - Step 104960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 437.9, step = 104960, mean_episode_return = 0.091647, mean_episode_step = 49.201, total_loss = -340.71, entropy_loss = -9.8644, pg_loss = -422.85, baseline_loss = 92.0, learner_queue_size = 32, _tick = 40, _time = 1.7374e+09)
[2025-01-20 09:21:40,433][root][INFO] - Step 107520 @ 510.6 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 442.9, step = 107520, mean_episode_return = 0.092512, mean_episode_step = 52.816, total_loss = -98.549, entropy_loss = -9.7682, pg_loss = -162.49, baseline_loss = 73.713, learner_queue_size = 32, _tick = 41, _time = 1.7374e+09)
[2025-01-20 09:21:45,444][root][INFO] - Step 107520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 447.9, step = 107520, mean_episode_return = 0.092512, mean_episode_step = 52.816, total_loss = -98.549, entropy_loss = -9.7682, pg_loss = -162.49, baseline_loss = 73.713, learner_queue_size = 32, _tick = 41, _time = 1.7374e+09)
[2025-01-20 09:21:50,450][root][INFO] - Step 110080 @ 510.9 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 452.9, step = 110080, mean_episode_return = 0.25832, mean_episode_step = 62.909, total_loss = 451.65, entropy_loss = -9.7185, pg_loss = 372.45, baseline_loss = 88.915, learner_queue_size = 32, _tick = 42, _time = 1.7374e+09)
[2025-01-20 09:21:55,466][root][INFO] - Step 110080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 457.9, step = 110080, mean_episode_return = 0.25832, mean_episode_step = 62.909, total_loss = 451.65, entropy_loss = -9.7185, pg_loss = 372.45, baseline_loss = 88.915, learner_queue_size = 32, _tick = 42, _time = 1.7374e+09)
[2025-01-20 09:22:00,471][root][INFO] - Step 112640 @ 510.6 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 462.9, step = 112640, mean_episode_return = 0.18128, mean_episode_step = 66.372, total_loss = 143.05, entropy_loss = -9.5914, pg_loss = 58.9, baseline_loss = 93.742, learner_queue_size = 32, _tick = 43, _time = 1.7374e+09)
[2025-01-20 09:22:05,483][root][INFO] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 467.9, step = 112640, mean_episode_return = 0.18128, mean_episode_step = 66.372, total_loss = 143.05, entropy_loss = -9.5914, pg_loss = 58.9, baseline_loss = 93.742, learner_queue_size = 32, _tick = 43, _time = 1.7374e+09)
[2025-01-20 09:22:10,489][root][INFO] - Step 115200 @ 510.9 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 472.9, step = 115200, mean_episode_return = 0.16788, mean_episode_step = 55.121, total_loss = -159.09, entropy_loss = -9.5507, pg_loss = -236.57, baseline_loss = 87.03, learner_queue_size = 32, _tick = 44, _time = 1.7374e+09)
[2025-01-20 09:22:15,499][root][INFO] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 477.9, step = 115200, mean_episode_return = 0.16788, mean_episode_step = 55.121, total_loss = -159.09, entropy_loss = -9.5507, pg_loss = -236.57, baseline_loss = 87.03, learner_queue_size = 32, _tick = 44, _time = 1.7374e+09)
[2025-01-20 09:22:20,505][root][INFO] - Step 117760 @ 510.9 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 482.9, step = 117760, mean_episode_return = 0.50541, mean_episode_step = 72.107, total_loss = 398.52, entropy_loss = -9.3779, pg_loss = 332.6, baseline_loss = 75.299, learner_queue_size = 32, _tick = 45, _time = 1.7374e+09)
[2025-01-20 09:22:25,518][root][INFO] - Step 117760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 488.0, step = 117760, mean_episode_return = 0.50541, mean_episode_step = 72.107, total_loss = 398.52, entropy_loss = -9.3779, pg_loss = 332.6, baseline_loss = 75.299, learner_queue_size = 32, _tick = 45, _time = 1.7374e+09)
[2025-01-20 09:22:30,525][root][INFO] - Step 120320 @ 510.6 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 493.0, step = 120320, mean_episode_return = 0.132, mean_episode_step = 51.99, total_loss = -17.059, entropy_loss = -9.4011, pg_loss = -85.93, baseline_loss = 78.272, learner_queue_size = 32, _tick = 46, _time = 1.7374e+09)
[2025-01-20 09:22:35,537][root][INFO] - Step 120320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 498.0, step = 120320, mean_episode_return = 0.132, mean_episode_step = 51.99, total_loss = -17.059, entropy_loss = -9.4011, pg_loss = -85.93, baseline_loss = 78.272, learner_queue_size = 32, _tick = 46, _time = 1.7374e+09)
[2025-01-20 09:22:40,544][root][INFO] - Step 122880 @ 510.8 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 503.0, step = 122880, mean_episode_return = 0.13849, mean_episode_step = 55.566, total_loss = -6.2618, entropy_loss = -9.3253, pg_loss = -63.188, baseline_loss = 66.251, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)
[2025-01-20 09:22:45,551][root][INFO] - Step 122880 @ 0.0 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 508.0, step = 122880, mean_episode_return = 0.13849, mean_episode_step = 55.566, total_loss = -6.2618, entropy_loss = -9.3253, pg_loss = -63.188, baseline_loss = 66.251, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)
[2025-01-20 09:22:50,562][root][INFO] - Step 122880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 513.0, step = 122880, mean_episode_return = 0.13849, mean_episode_step = 55.566, total_loss = -6.2618, entropy_loss = -9.3253, pg_loss = -63.188, baseline_loss = 66.251, learner_queue_size = 32, _tick = 47, _time = 1.7374e+09)
[2025-01-20 09:22:55,569][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar
[2025-01-20 09:22:55,625][root][INFO] - Step 125440 @ 510.8 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 518.0, step = 125440, mean_episode_return = 0.29259, mean_episode_step = 50.545, total_loss = 72.374, entropy_loss = -9.2521, pg_loss = -26.558, baseline_loss = 108.18, learner_queue_size = 32, _tick = 48, _time = 1.7374e+09)
[2025-01-20 09:23:00,808][root][INFO] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 523.1, step = 125440, mean_episode_return = 0.29259, mean_episode_step = 50.545, total_loss = 72.374, entropy_loss = -9.2521, pg_loss = -26.558, baseline_loss = 108.18, learner_queue_size = 32, _tick = 48, _time = 1.7374e+09)
[2025-01-20 09:23:05,830][root][INFO] - Step 128000 @ 492.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 528.3, step = 128000, mean_episode_return = 0.2209, mean_episode_step = 59.688, total_loss = 48.145, entropy_loss = -9.0422, pg_loss = -3.9006, baseline_loss = 61.088, learner_queue_size = 32, _tick = 49, _time = 1.7374e+09)
[2025-01-20 09:23:10,874][root][INFO] - Step 128000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 533.3, step = 128000, mean_episode_return = 0.2209, mean_episode_step = 59.688, total_loss = 48.145, entropy_loss = -9.0422, pg_loss = -3.9006, baseline_loss = 61.088, learner_queue_size = 32, _tick = 49, _time = 1.7374e+09)
[2025-01-20 09:23:15,900][root][INFO] - Step 130560 @ 505.8 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 538.3, step = 130560, mean_episode_return = 0.38538, mean_episode_step = 59.694, total_loss = -133.22, entropy_loss = -9.1008, pg_loss = -183.75, baseline_loss = 59.637, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)
[2025-01-20 09:23:20,905][root][INFO] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 543.3, step = 130560, mean_episode_return = 0.38538, mean_episode_step = 59.694, total_loss = -133.22, entropy_loss = -9.1008, pg_loss = -183.75, baseline_loss = 59.637, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)
[2025-01-20 09:23:25,916][root][INFO] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 548.4, step = 130560, mean_episode_return = 0.38538, mean_episode_step = 59.694, total_loss = -133.22, entropy_loss = -9.1008, pg_loss = -183.75, baseline_loss = 59.637, learner_queue_size = 32, _tick = 50, _time = 1.7374e+09)
[2025-01-20 09:23:30,929][root][INFO] - Step 133120 @ 510.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 553.4, step = 133120, mean_episode_return = 0.04968, mean_episode_step = 47.809, total_loss = -481.13, entropy_loss = -9.1766, pg_loss = -523.17, baseline_loss = 51.212, learner_queue_size = 32, _tick = 51, _time = 1.7374e+09)
[2025-01-20 09:23:35,944][root][INFO] - Step 133120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 558.4, step = 133120, mean_episode_return = 0.04968, mean_episode_step = 47.809, total_loss = -481.13, entropy_loss = -9.1766, pg_loss = -523.17, baseline_loss = 51.212, learner_queue_size = 32, _tick = 51, _time = 1.7374e+09)
[2025-01-20 09:23:40,949][root][INFO] - Step 135680 @ 510.6 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 563.4, step = 135680, mean_episode_return = 0.33247, mean_episode_step = 53.337, total_loss = 340.09, entropy_loss = -9.1578, pg_loss = 276.56, baseline_loss = 72.694, learner_queue_size = 32, _tick = 52, _time = 1.7374e+09)
[2025-01-20 09:23:46,612][root][INFO] - Step 135680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 568.8, step = 135680, mean_episode_return = 0.33247, mean_episode_step = 53.337, total_loss = 340.09, entropy_loss = -9.1578, pg_loss = 276.56, baseline_loss = 72.694, learner_queue_size = 32, _tick = 52, _time = 1.7374e+09)
[2025-01-20 09:23:51,642][root][INFO] - Step 138240 @ 484.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 574.1, step = 138240, mean_episode_return = 0.27489, mean_episode_step = 45.872, total_loss = 648.48, entropy_loss = -9.1516, pg_loss = 534.96, baseline_loss = 122.67, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)
[2025-01-20 09:23:56,651][root][INFO] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 579.1, step = 138240, mean_episode_return = 0.27489, mean_episode_step = 45.872, total_loss = 648.48, entropy_loss = -9.1516, pg_loss = 534.96, baseline_loss = 122.67, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)
[2025-01-20 09:24:01,663][root][INFO] - Step 138240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 584.1, step = 138240, mean_episode_return = 0.27489, mean_episode_step = 45.872, total_loss = 648.48, entropy_loss = -9.1516, pg_loss = 534.96, baseline_loss = 122.67, learner_queue_size = 32, _tick = 53, _time = 1.7374e+09)
[2025-01-20 09:24:06,669][root][INFO] - Step 140800 @ 510.9 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 589.1, step = 140800, mean_episode_return = 0.3472, mean_episode_step = 51.766, total_loss = 585.69, entropy_loss = -9.152, pg_loss = 433.88, baseline_loss = 160.96, learner_queue_size = 32, _tick = 54, _time = 1.7374e+09)
[2025-01-20 09:24:12,092][root][INFO] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 594.3, step = 140800, mean_episode_return = 0.3472, mean_episode_step = 51.766, total_loss = 585.69, entropy_loss = -9.152, pg_loss = 433.88, baseline_loss = 160.96, learner_queue_size = 32, _tick = 54, _time = 1.7374e+09)
[2025-01-20 09:24:17,171][root][INFO] - Step 143360 @ 479.8 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 599.6, step = 143360, mean_episode_return = 0.38664, mean_episode_step = 58.823, total_loss = 330.13, entropy_loss = -9.1699, pg_loss = 246.22, baseline_loss = 93.082, learner_queue_size = 32, _tick = 55, _time = 1.7374e+09)
[2025-01-20 09:24:22,177][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 09:24:22,240][root][INFO] - Step 143360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 604.6, step = 143360, mean_episode_return = 0.38664, mean_episode_step = 58.823, total_loss = 330.13, entropy_loss = -9.1699, pg_loss = 246.22, baseline_loss = 93.082, learner_queue_size = 32, _tick = 55, _time = 1.7374e+09)
[2025-01-20 09:24:27,251][root][INFO] - Step 143360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 609.7, step = 143360, mean_episode_return = 0.38664, mean_episode_step = 58.823, total_loss = 330.13, entropy_loss = -9.1699, pg_loss = 246.22, baseline_loss = 93.082, learner_queue_size = 32, _tick = 55, _time = 1.7374e+09)
[2025-01-20 09:24:32,257][root][INFO] - Step 145920 @ 510.9 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 614.7, step = 145920, mean_episode_return = 0.23697, mean_episode_step = 56.322, total_loss = -280.72, entropy_loss = -9.0396, pg_loss = -365.41, baseline_loss = 93.729, learner_queue_size = 32, _tick = 56, _time = 1.7374e+09)
[2025-01-20 09:24:37,356][root][INFO] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 619.8, step = 145920, mean_episode_return = 0.23697, mean_episode_step = 56.322, total_loss = -280.72, entropy_loss = -9.0396, pg_loss = -365.41, baseline_loss = 93.729, learner_queue_size = 32, _tick = 56, _time = 1.7374e+09)
[2025-01-20 09:24:42,371][root][INFO] - Step 148480 @ 506.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 624.8, step = 148480, mean_episode_return = 0.35419, mean_episode_step = 54.591, total_loss = -259.42, entropy_loss = -9.136, pg_loss = -332.77, baseline_loss = 82.484, learner_queue_size = 32, _tick = 57, _time = 1.7374e+09)
[2025-01-20 09:24:47,392][root][INFO] - Step 148480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 629.8, step = 148480, mean_episode_return = 0.35419, mean_episode_step = 54.591, total_loss = -259.42, entropy_loss = -9.136, pg_loss = -332.77, baseline_loss = 82.484, learner_queue_size = 32, _tick = 57, _time = 1.7374e+09)
[2025-01-20 09:24:52,399][root][INFO] - Step 151040 @ 510.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 634.8, step = 151040, mean_episode_return = 0.41618, mean_episode_step = 58.239, total_loss = -105.05, entropy_loss = -9.0933, pg_loss = -230.92, baseline_loss = 134.96, learner_queue_size = 32, _tick = 58, _time = 1.7374e+09)
[2025-01-20 09:24:57,413][root][INFO] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 639.8, step = 151040, mean_episode_return = 0.41618, mean_episode_step = 58.239, total_loss = -105.05, entropy_loss = -9.0933, pg_loss = -230.92, baseline_loss = 134.96, learner_queue_size = 32, _tick = 58, _time = 1.7374e+09)
[2025-01-20 09:25:02,418][root][INFO] - Step 153600 @ 510.9 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 644.9, step = 153600, mean_episode_return = 0.13514, mean_episode_step = 55.836, total_loss = -374.58, entropy_loss = -9.0485, pg_loss = -450.44, baseline_loss = 84.915, learner_queue_size = 32, _tick = 59, _time = 1.7374e+09)
[2025-01-20 09:25:07,597][root][INFO] - Step 153600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 650.0, step = 153600, mean_episode_return = 0.13514, mean_episode_step = 55.836, total_loss = -374.58, entropy_loss = -9.0485, pg_loss = -450.44, baseline_loss = 84.915, learner_queue_size = 32, _tick = 59, _time = 1.7374e+09)
[2025-01-20 09:25:12,607][root][INFO] - Step 156160 @ 508.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 655.0, step = 156160, mean_episode_return = 0.35154, mean_episode_step = 53.705, total_loss = 745.69, entropy_loss = -9.0964, pg_loss = 611.76, baseline_loss = 143.02, learner_queue_size = 32, _tick = 60, _time = 1.7374e+09)
[2025-01-20 09:25:18,027][root][INFO] - Step 156160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 660.4, step = 156160, mean_episode_return = 0.35154, mean_episode_step = 53.705, total_loss = 745.69, entropy_loss = -9.0964, pg_loss = 611.76, baseline_loss = 143.02, learner_queue_size = 32, _tick = 60, _time = 1.7374e+09)
[2025-01-20 09:25:23,038][root][INFO] - Step 158720 @ 500.7 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 665.5, step = 158720, mean_episode_return = 0.55831, mean_episode_step = 53.652, total_loss = 229.36, entropy_loss = -9.1067, pg_loss = 129.93, baseline_loss = 108.54, learner_queue_size = 32, _tick = 61, _time = 1.7374e+09)
[2025-01-20 09:25:28,132][root][INFO] - Step 158720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 670.5, step = 158720, mean_episode_return = 0.55831, mean_episode_step = 53.652, total_loss = 229.36, entropy_loss = -9.1067, pg_loss = 129.93, baseline_loss = 108.54, learner_queue_size = 32, _tick = 61, _time = 1.7374e+09)
[2025-01-20 09:25:33,138][root][INFO] - Step 161280 @ 504.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 675.6, step = 161280, mean_episode_return = 0.45063, mean_episode_step = 65.63, total_loss = -179.22, entropy_loss = -8.97, pg_loss = -268.76, baseline_loss = 98.512, learner_queue_size = 32, _tick = 62, _time = 1.7374e+09)
[2025-01-20 09:25:38,147][root][INFO] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 680.6, step = 161280, mean_episode_return = 0.45063, mean_episode_step = 65.63, total_loss = -179.22, entropy_loss = -8.97, pg_loss = -268.76, baseline_loss = 98.512, learner_queue_size = 32, _tick = 62, _time = 1.7374e+09)
[2025-01-20 09:25:43,158][root][INFO] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 685.6, step = 161280, mean_episode_return = 0.45063, mean_episode_step = 65.63, total_loss = -179.22, entropy_loss = -8.97, pg_loss = -268.76, baseline_loss = 98.512, learner_queue_size = 32, _tick = 62, _time = 1.7374e+09)
[2025-01-20 09:25:48,164][root][INFO] - Step 163840 @ 510.9 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 690.6, step = 163840, mean_episode_return = 0.62121, mean_episode_step = 51.205, total_loss = 847.26, entropy_loss = -8.9492, pg_loss = 713.05, baseline_loss = 143.16, learner_queue_size = 32, _tick = 63, _time = 1.7374e+09)
[2025-01-20 09:25:53,179][root][INFO] - Step 163840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 695.6, step = 163840, mean_episode_return = 0.62121, mean_episode_step = 51.205, total_loss = 847.26, entropy_loss = -8.9492, pg_loss = 713.05, baseline_loss = 143.16, learner_queue_size = 32, _tick = 63, _time = 1.7374e+09)
[2025-01-20 09:25:58,186][root][INFO] - Step 166400 @ 510.3 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 700.6, step = 166400, mean_episode_return = 0.24716, mean_episode_step = 55.355, total_loss = -593.66, entropy_loss = -8.9334, pg_loss = -642.83, baseline_loss = 58.101, learner_queue_size = 32, _tick = 64, _time = 1.7374e+09)
[2025-01-20 09:26:03,685][root][INFO] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 706.0, step = 166400, mean_episode_return = 0.24716, mean_episode_step = 55.355, total_loss = -593.66, entropy_loss = -8.9334, pg_loss = -642.83, baseline_loss = 58.101, learner_queue_size = 32, _tick = 64, _time = 1.7374e+09)
[2025-01-20 09:26:08,694][root][INFO] - Step 168960 @ 500.7 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 711.1, step = 168960, mean_episode_return = 0.33398, mean_episode_step = 49.245, total_loss = -79.704, entropy_loss = -8.9362, pg_loss = -197.11, baseline_loss = 126.34, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)
[2025-01-20 09:26:13,699][root][INFO] - Step 168960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 716.1, step = 168960, mean_episode_return = 0.33398, mean_episode_step = 49.245, total_loss = -79.704, entropy_loss = -8.9362, pg_loss = -197.11, baseline_loss = 126.34, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)
[2025-01-20 09:26:18,755][root][INFO] - Step 168960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 721.2, step = 168960, mean_episode_return = 0.33398, mean_episode_step = 49.245, total_loss = -79.704, entropy_loss = -8.9362, pg_loss = -197.11, baseline_loss = 126.34, learner_queue_size = 32, _tick = 65, _time = 1.7374e+09)
[2025-01-20 09:26:23,761][root][INFO] - Step 171520 @ 509.8 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 726.2, step = 171520, mean_episode_return = 0.32308, mean_episode_step = 57.476, total_loss = 131.73, entropy_loss = -8.9169, pg_loss = 35.011, baseline_loss = 105.63, learner_queue_size = 32, _tick = 66, _time = 1.7374e+09)
[2025-01-20 09:26:28,772][root][INFO] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 731.2, step = 171520, mean_episode_return = 0.32308, mean_episode_step = 57.476, total_loss = 131.73, entropy_loss = -8.9169, pg_loss = 35.011, baseline_loss = 105.63, learner_queue_size = 32, _tick = 66, _time = 1.7374e+09)
[2025-01-20 09:26:33,786][root][INFO] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 736.2, step = 171520, mean_episode_return = 0.32308, mean_episode_step = 57.476, total_loss = 131.73, entropy_loss = -8.9169, pg_loss = 35.011, baseline_loss = 105.63, learner_queue_size = 32, _tick = 66, _time = 1.7374e+09)
[2025-01-20 09:26:38,792][root][INFO] - Step 174080 @ 510.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 741.2, step = 174080, mean_episode_return = 0.56303, mean_episode_step = 62.887, total_loss = 484.85, entropy_loss = -8.8682, pg_loss = 385.04, baseline_loss = 108.69, learner_queue_size = 32, _tick = 67, _time = 1.7374e+09)
[2025-01-20 09:26:44,207][root][INFO] - Step 174080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 746.4, step = 174080, mean_episode_return = 0.56303, mean_episode_step = 62.887, total_loss = 484.85, entropy_loss = -8.8682, pg_loss = 385.04, baseline_loss = 108.69, learner_queue_size = 32, _tick = 67, _time = 1.7374e+09)
[2025-01-20 09:26:49,219][root][INFO] - Step 176640 @ 488.2 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 751.7, step = 176640, mean_episode_return = 0.30844, mean_episode_step = 51.358, total_loss = -482.64, entropy_loss = -8.9127, pg_loss = -568.24, baseline_loss = 94.509, learner_queue_size = 32, _tick = 68, _time = 1.7374e+09)
[2025-01-20 09:26:54,231][root][INFO] - Step 176640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 756.7, step = 176640, mean_episode_return = 0.30844, mean_episode_step = 51.358, total_loss = -482.64, entropy_loss = -8.9127, pg_loss = -568.24, baseline_loss = 94.509, learner_queue_size = 32, _tick = 68, _time = 1.7374e+09)
[2025-01-20 09:26:59,358][root][INFO] - Step 176640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 761.7, step = 176640, mean_episode_return = 0.30844, mean_episode_step = 51.358, total_loss = -482.64, entropy_loss = -8.9127, pg_loss = -568.24, baseline_loss = 94.509, learner_queue_size = 32, _tick = 68, _time = 1.7374e+09)
[2025-01-20 09:27:04,375][root][INFO] - Step 179200 @ 503.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 766.8, step = 179200, mean_episode_return = 0.51935, mean_episode_step = 55.207, total_loss = 664.64, entropy_loss = -8.8726, pg_loss = 544.88, baseline_loss = 128.64, learner_queue_size = 32, _tick = 69, _time = 1.7374e+09)
[2025-01-20 09:27:10,045][root][INFO] - Step 179200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 772.4, step = 179200, mean_episode_return = 0.51935, mean_episode_step = 55.207, total_loss = 664.64, entropy_loss = -8.8726, pg_loss = 544.88, baseline_loss = 128.64, learner_queue_size = 32, _tick = 69, _time = 1.7374e+09)
[2025-01-20 09:27:15,069][root][INFO] - Step 181760 @ 497.2 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 777.5, step = 181760, mean_episode_return = 0.43148, mean_episode_step = 49.545, total_loss = 49.197, entropy_loss = -8.9134, pg_loss = -59.562, baseline_loss = 117.67, learner_queue_size = 32, _tick = 70, _time = 1.7374e+09)
[2025-01-20 09:27:20,081][root][INFO] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 782.5, step = 181760, mean_episode_return = 0.43148, mean_episode_step = 49.545, total_loss = 49.197, entropy_loss = -8.9134, pg_loss = -59.562, baseline_loss = 117.67, learner_queue_size = 32, _tick = 70, _time = 1.7374e+09)
[2025-01-20 09:27:25,172][root][INFO] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 787.5, step = 181760, mean_episode_return = 0.43148, mean_episode_step = 49.545, total_loss = 49.197, entropy_loss = -8.9134, pg_loss = -59.562, baseline_loss = 117.67, learner_queue_size = 32, _tick = 70, _time = 1.7374e+09)
[2025-01-20 09:27:30,190][root][INFO] - Step 184320 @ 503.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 792.6, step = 184320, mean_episode_return = 0.27783, mean_episode_step = 46.9, total_loss = -352.31, entropy_loss = -8.8237, pg_loss = -421.01, baseline_loss = 77.519, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)
[2025-01-20 09:27:35,200][root][INFO] - Step 184320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 797.6, step = 184320, mean_episode_return = 0.27783, mean_episode_step = 46.9, total_loss = -352.31, entropy_loss = -8.8237, pg_loss = -421.01, baseline_loss = 77.519, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)
[2025-01-20 09:27:40,817][root][INFO] - Step 184320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 802.7, step = 184320, mean_episode_return = 0.27783, mean_episode_step = 46.9, total_loss = -352.31, entropy_loss = -8.8237, pg_loss = -421.01, baseline_loss = 77.519, learner_queue_size = 32, _tick = 71, _time = 1.7374e+09)
[2025-01-20 09:27:45,864][root][INFO] - Step 186880 @ 459.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 808.3, step = 186880, mean_episode_return = 0.63196, mean_episode_step = 43.492, total_loss = 214.44, entropy_loss = -8.8939, pg_loss = 105.82, baseline_loss = 117.52, learner_queue_size = 32, _tick = 72, _time = 1.7374e+09)
[2025-01-20 09:27:50,967][root][INFO] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 813.4, step = 186880, mean_episode_return = 0.63196, mean_episode_step = 43.492, total_loss = 214.44, entropy_loss = -8.8939, pg_loss = 105.82, baseline_loss = 117.52, learner_queue_size = 32, _tick = 72, _time = 1.7374e+09)
[2025-01-20 09:27:56,001][root][INFO] - Step 189440 @ 503.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 818.4, step = 189440, mean_episode_return = 0.29615, mean_episode_step = 45.211, total_loss = -16.874, entropy_loss = -8.7737, pg_loss = -101.36, baseline_loss = 93.26, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)
[2025-01-20 09:28:01,057][root][INFO] - Step 189440 @ 0.0 SPS. Inference batcher size: 25. Learner queue size: 32. Other stats: (train_seconds = 823.5, step = 189440, mean_episode_return = 0.29615, mean_episode_step = 45.211, total_loss = -16.874, entropy_loss = -8.7737, pg_loss = -101.36, baseline_loss = 93.26, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)
[2025-01-20 09:28:06,296][root][INFO] - Step 189440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 828.7, step = 189440, mean_episode_return = 0.29615, mean_episode_step = 45.211, total_loss = -16.874, entropy_loss = -8.7737, pg_loss = -101.36, baseline_loss = 93.26, learner_queue_size = 32, _tick = 73, _time = 1.7374e+09)
[2025-01-20 09:28:11,326][root][INFO] - Step 192000 @ 505.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 833.8, step = 192000, mean_episode_return = 0.44363, mean_episode_step = 47.473, total_loss = 491.22, entropy_loss = -8.8422, pg_loss = 353.23, baseline_loss = 146.83, learner_queue_size = 32, _tick = 74, _time = 1.7374e+09)
[2025-01-20 09:28:16,332][root][INFO] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 838.8, step = 192000, mean_episode_return = 0.44363, mean_episode_step = 47.473, total_loss = 491.22, entropy_loss = -8.8422, pg_loss = 353.23, baseline_loss = 146.83, learner_queue_size = 32, _tick = 74, _time = 1.7374e+09)
[2025-01-20 09:28:21,355][root][INFO] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 843.8, step = 192000, mean_episode_return = 0.44363, mean_episode_step = 47.473, total_loss = 491.22, entropy_loss = -8.8422, pg_loss = 353.23, baseline_loss = 146.83, learner_queue_size = 32, _tick = 74, _time = 1.7374e+09)
[2025-01-20 09:28:26,370][root][INFO] - Step 194560 @ 508.9 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 848.8, step = 194560, mean_episode_return = 0.42862, mean_episode_step = 63.896, total_loss = -429.0, entropy_loss = -8.8384, pg_loss = -520.19, baseline_loss = 100.02, learner_queue_size = 32, _tick = 75, _time = 1.7374e+09)
[2025-01-20 09:28:31,674][root][INFO] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 853.9, step = 194560, mean_episode_return = 0.42862, mean_episode_step = 63.896, total_loss = -429.0, entropy_loss = -8.8384, pg_loss = -520.19, baseline_loss = 100.02, learner_queue_size = 32, _tick = 75, _time = 1.7374e+09)
[2025-01-20 09:28:36,727][root][INFO] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 859.2, step = 194560, mean_episode_return = 0.42862, mean_episode_step = 63.896, total_loss = -429.0, entropy_loss = -8.8384, pg_loss = -520.19, baseline_loss = 100.02, learner_queue_size = 32, _tick = 75, _time = 1.7374e+09)
[2025-01-20 09:28:42,240][root][INFO] - Step 197120 @ 473.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 864.6, step = 197120, mean_episode_return = 0.22943, mean_episode_step = 57.055, total_loss = -146.4, entropy_loss = -8.7772, pg_loss = -202.65, baseline_loss = 65.035, learner_queue_size = 32, _tick = 76, _time = 1.7374e+09)
[2025-01-20 09:28:47,331][root][INFO] - Step 197120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 869.8, step = 197120, mean_episode_return = 0.22943, mean_episode_step = 57.055, total_loss = -146.4, entropy_loss = -8.7772, pg_loss = -202.65, baseline_loss = 65.035, learner_queue_size = 32, _tick = 76, _time = 1.7374e+09)
[2025-01-20 09:28:52,348][root][INFO] - Step 199680 @ 508.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 874.8, step = 199680, mean_episode_return = 0.41609, mean_episode_step = 51.003, total_loss = -209.19, entropy_loss = -8.7441, pg_loss = -273.11, baseline_loss = 72.658, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)
[2025-01-20 09:28:57,355][root][INFO] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 879.8, step = 199680, mean_episode_return = 0.41609, mean_episode_step = 51.003, total_loss = -209.19, entropy_loss = -8.7441, pg_loss = -273.11, baseline_loss = 72.658, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)
[2025-01-20 09:29:02,369][root][INFO] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 884.8, step = 199680, mean_episode_return = 0.41609, mean_episode_step = 51.003, total_loss = -209.19, entropy_loss = -8.7441, pg_loss = -273.11, baseline_loss = 72.658, learner_queue_size = 32, _tick = 77, _time = 1.7374e+09)
[2025-01-20 09:29:07,396][root][INFO] - Step 202240 @ 508.9 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 889.8, step = 202240, mean_episode_return = 0.5544, mean_episode_step = 57.156, total_loss = 405.23, entropy_loss = -8.74, pg_loss = 337.15, baseline_loss = 76.814, learner_queue_size = 32, _tick = 78, _time = 1.7374e+09)
[2025-01-20 09:29:13,095][root][INFO] - Step 202240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 894.9, step = 202240, mean_episode_return = 0.5544, mean_episode_step = 57.156, total_loss = 405.23, entropy_loss = -8.74, pg_loss = 337.15, baseline_loss = 76.814, learner_queue_size = 32, _tick = 78, _time = 1.7374e+09)
[2025-01-20 09:29:18,102][root][INFO] - Step 204800 @ 449.9 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 900.5, step = 204800, mean_episode_return = 0.35565, mean_episode_step = 51.23, total_loss = -378.7, entropy_loss = -8.7317, pg_loss = -444.79, baseline_loss = 74.823, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)
[2025-01-20 09:29:23,111][root][INFO] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 905.5, step = 204800, mean_episode_return = 0.35565, mean_episode_step = 51.23, total_loss = -378.7, entropy_loss = -8.7317, pg_loss = -444.79, baseline_loss = 74.823, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)
[2025-01-20 09:29:28,124][root][INFO] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 910.6, step = 204800, mean_episode_return = 0.35565, mean_episode_step = 51.23, total_loss = -378.7, entropy_loss = -8.7317, pg_loss = -444.79, baseline_loss = 74.823, learner_queue_size = 32, _tick = 79, _time = 1.7374e+09)
[2025-01-20 09:29:33,130][root][INFO] - Step 207360 @ 510.7 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 915.6, step = 207360, mean_episode_return = 0.44956, mean_episode_step = 55.627, total_loss = 566.07, entropy_loss = -8.7091, pg_loss = 452.86, baseline_loss = 121.92, learner_queue_size = 32, _tick = 80, _time = 1.7374e+09)
[2025-01-20 09:29:38,149][root][INFO] - Step 207360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 920.6, step = 207360, mean_episode_return = 0.44956, mean_episode_step = 55.627, total_loss = 566.07, entropy_loss = -8.7091, pg_loss = 452.86, baseline_loss = 121.92, learner_queue_size = 32, _tick = 80, _time = 1.7374e+09)
[2025-01-20 09:29:43,158][root][INFO] - Step 209920 @ 510.1 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 925.6, step = 209920, mean_episode_return = 0.35335, mean_episode_step = 48.939, total_loss = 87.68, entropy_loss = -8.699, pg_loss = -8.1177, baseline_loss = 104.5, learner_queue_size = 32, _tick = 81, _time = 1.7374e+09)
[2025-01-20 09:29:48,168][root][INFO] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 930.6, step = 209920, mean_episode_return = 0.35335, mean_episode_step = 48.939, total_loss = 87.68, entropy_loss = -8.699, pg_loss = -8.1177, baseline_loss = 104.5, learner_queue_size = 32, _tick = 81, _time = 1.7374e+09)
[2025-01-20 09:29:53,262][root][INFO] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 935.6, step = 209920, mean_episode_return = 0.35335, mean_episode_step = 48.939, total_loss = 87.68, entropy_loss = -8.699, pg_loss = -8.1177, baseline_loss = 104.5, learner_queue_size = 32, _tick = 81, _time = 1.7374e+09)
[2025-01-20 09:29:58,274][root][INFO] - Step 212480 @ 504.2 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 940.7, step = 212480, mean_episode_return = 0.52815, mean_episode_step = 62.114, total_loss = -44.059, entropy_loss = -8.6043, pg_loss = -101.96, baseline_loss = 66.502, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)
[2025-01-20 09:30:03,282][root][INFO] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 945.7, step = 212480, mean_episode_return = 0.52815, mean_episode_step = 62.114, total_loss = -44.059, entropy_loss = -8.6043, pg_loss = -101.96, baseline_loss = 66.502, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)
[2025-01-20 09:30:08,392][root][INFO] - Step 212480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 950.7, step = 212480, mean_episode_return = 0.52815, mean_episode_step = 62.114, total_loss = -44.059, entropy_loss = -8.6043, pg_loss = -101.96, baseline_loss = 66.502, learner_queue_size = 32, _tick = 82, _time = 1.7374e+09)
[2025-01-20 09:30:13,402][root][INFO] - Step 215040 @ 501.7 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 955.8, step = 215040, mean_episode_return = 0.47197, mean_episode_step = 56.621, total_loss = 429.43, entropy_loss = -8.4885, pg_loss = 364.8, baseline_loss = 73.114, learner_queue_size = 32, _tick = 83, _time = 1.7374e+09)
[2025-01-20 09:30:18,504][root][INFO] - Step 215040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 960.9, step = 215040, mean_episode_return = 0.47197, mean_episode_step = 56.621, total_loss = 429.43, entropy_loss = -8.4885, pg_loss = 364.8, baseline_loss = 73.114, learner_queue_size = 32, _tick = 83, _time = 1.7374e+09)
[2025-01-20 09:30:23,760][root][INFO] - Step 217600 @ 482.9 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 966.2, step = 217600, mean_episode_return = 0.38018, mean_episode_step = 55.855, total_loss = -339.36, entropy_loss = -8.5419, pg_loss = -396.79, baseline_loss = 65.979, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)
[2025-01-20 09:30:28,957][root][INFO] - Step 217600 @ 0.0 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 971.2, step = 217600, mean_episode_return = 0.38018, mean_episode_step = 55.855, total_loss = -339.36, entropy_loss = -8.5419, pg_loss = -396.79, baseline_loss = 65.979, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)
[2025-01-20 09:30:34,061][root][INFO] - Step 217600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 976.4, step = 217600, mean_episode_return = 0.38018, mean_episode_step = 55.855, total_loss = -339.36, entropy_loss = -8.5419, pg_loss = -396.79, baseline_loss = 65.979, learner_queue_size = 32, _tick = 84, _time = 1.7374e+09)
[2025-01-20 09:30:39,071][root][INFO] - Step 220160 @ 502.8 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 981.5, step = 220160, mean_episode_return = 0.51222, mean_episode_step = 59.572, total_loss = -95.822, entropy_loss = -8.4303, pg_loss = -132.69, baseline_loss = 45.296, learner_queue_size = 32, _tick = 85, _time = 1.7374e+09)
[2025-01-20 09:30:44,082][root][INFO] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 986.5, step = 220160, mean_episode_return = 0.51222, mean_episode_step = 59.572, total_loss = -95.822, entropy_loss = -8.4303, pg_loss = -132.69, baseline_loss = 45.296, learner_queue_size = 32, _tick = 85, _time = 1.7374e+09)
[2025-01-20 09:30:49,094][root][INFO] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 991.5, step = 220160, mean_episode_return = 0.51222, mean_episode_step = 59.572, total_loss = -95.822, entropy_loss = -8.4303, pg_loss = -132.69, baseline_loss = 45.296, learner_queue_size = 32, _tick = 85, _time = 1.7374e+09)
[2025-01-20 09:30:54,099][root][INFO] - Step 222720 @ 511.0 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 996.5, step = 222720, mean_episode_return = 0.54054, mean_episode_step = 57.914, total_loss = 189.34, entropy_loss = -8.3788, pg_loss = 143.25, baseline_loss = 54.463, learner_queue_size = 32, _tick = 86, _time = 1.7374e+09)
[2025-01-20 09:30:59,542][root][INFO] - Step 222720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1001.9, step = 222720, mean_episode_return = 0.54054, mean_episode_step = 57.914, total_loss = 189.34, entropy_loss = -8.3788, pg_loss = 143.25, baseline_loss = 54.463, learner_queue_size = 32, _tick = 86, _time = 1.7374e+09)
[2025-01-20 09:31:04,554][root][INFO] - Step 225280 @ 506.2 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1007.0, step = 225280, mean_episode_return = 0.62772, mean_episode_step = 52.362, total_loss = 293.64, entropy_loss = -8.4206, pg_loss = 230.64, baseline_loss = 71.429, learner_queue_size = 32, _tick = 87, _time = 1.7374e+09)
[2025-01-20 09:31:09,563][root][INFO] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1012.0, step = 225280, mean_episode_return = 0.62772, mean_episode_step = 52.362, total_loss = 293.64, entropy_loss = -8.4206, pg_loss = 230.64, baseline_loss = 71.429, learner_queue_size = 32, _tick = 87, _time = 1.7374e+09)
[2025-01-20 09:31:14,993][root][INFO] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1017.4, step = 225280, mean_episode_return = 0.62772, mean_episode_step = 52.362, total_loss = 293.64, entropy_loss = -8.4206, pg_loss = 230.64, baseline_loss = 71.429, learner_queue_size = 32, _tick = 87, _time = 1.7374e+09)
[2025-01-20 09:31:19,998][root][INFO] - Step 227840 @ 503.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1022.4, step = 227840, mean_episode_return = 0.47229, mean_episode_step = 62.223, total_loss = -249.07, entropy_loss = -8.4247, pg_loss = -311.08, baseline_loss = 70.435, learner_queue_size = 32, _tick = 88, _time = 1.7374e+09)
[2025-01-20 09:31:26,592][root][INFO] - Step 227840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1027.6, step = 227840, mean_episode_return = 0.47229, mean_episode_step = 62.223, total_loss = -249.07, entropy_loss = -8.4247, pg_loss = -311.08, baseline_loss = 70.435, learner_queue_size = 32, _tick = 88, _time = 1.7374e+09)
[2025-01-20 09:31:31,740][root][INFO] - Step 227840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1034.2, step = 227840, mean_episode_return = 0.47229, mean_episode_step = 62.223, total_loss = -249.07, entropy_loss = -8.4247, pg_loss = -311.08, baseline_loss = 70.435, learner_queue_size = 32, _tick = 88, _time = 1.7374e+09)
[2025-01-20 09:31:36,751][root][INFO] - Step 230400 @ 511.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1039.2, step = 230400, mean_episode_return = 0.47136, mean_episode_step = 55.016, total_loss = -75.551, entropy_loss = -8.4637, pg_loss = -159.22, baseline_loss = 92.137, learner_queue_size = 32, _tick = 89, _time = 1.7374e+09)
[2025-01-20 09:31:41,765][root][INFO] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1044.2, step = 230400, mean_episode_return = 0.47136, mean_episode_step = 55.016, total_loss = -75.551, entropy_loss = -8.4637, pg_loss = -159.22, baseline_loss = 92.137, learner_queue_size = 32, _tick = 89, _time = 1.7374e+09)
[2025-01-20 09:31:46,773][root][INFO] - Step 232960 @ 510.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1049.2, step = 232960, mean_episode_return = 0.52897, mean_episode_step = 51.829, total_loss = 579.06, entropy_loss = -8.41, pg_loss = 504.25, baseline_loss = 83.219, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)
[2025-01-20 09:31:51,782][root][INFO] - Step 232960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1054.2, step = 232960, mean_episode_return = 0.52897, mean_episode_step = 51.829, total_loss = 579.06, entropy_loss = -8.41, pg_loss = 504.25, baseline_loss = 83.219, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)
[2025-01-20 09:31:57,010][root][INFO] - Step 232960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1059.3, step = 232960, mean_episode_return = 0.52897, mean_episode_step = 51.829, total_loss = 579.06, entropy_loss = -8.41, pg_loss = 504.25, baseline_loss = 83.219, learner_queue_size = 32, _tick = 90, _time = 1.7374e+09)
[2025-01-20 09:32:02,019][root][INFO] - Step 235520 @ 499.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1064.5, step = 235520, mean_episode_return = 0.60485, mean_episode_step = 57.584, total_loss = -432.72, entropy_loss = -8.4536, pg_loss = -476.74, baseline_loss = 52.473, learner_queue_size = 32, _tick = 91, _time = 1.7374e+09)
[2025-01-20 09:32:07,028][root][INFO] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1069.5, step = 235520, mean_episode_return = 0.60485, mean_episode_step = 57.584, total_loss = -432.72, entropy_loss = -8.4536, pg_loss = -476.74, baseline_loss = 52.473, learner_queue_size = 32, _tick = 91, _time = 1.7374e+09)
[2025-01-20 09:32:12,042][root][INFO] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1074.5, step = 235520, mean_episode_return = 0.60485, mean_episode_step = 57.584, total_loss = -432.72, entropy_loss = -8.4536, pg_loss = -476.74, baseline_loss = 52.473, learner_queue_size = 32, _tick = 91, _time = 1.7374e+09)
[2025-01-20 09:32:17,050][root][INFO] - Step 238080 @ 510.6 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1079.5, step = 238080, mean_episode_return = 0.37521, mean_episode_step = 52.446, total_loss = -291.02, entropy_loss = -8.4469, pg_loss = -339.33, baseline_loss = 56.76, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)
[2025-01-20 09:32:22,228][root][INFO] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1084.5, step = 238080, mean_episode_return = 0.37521, mean_episode_step = 52.446, total_loss = -291.02, entropy_loss = -8.4469, pg_loss = -339.33, baseline_loss = 56.76, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)
[2025-01-20 09:32:27,291][root][INFO] - Step 238080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1089.7, step = 238080, mean_episode_return = 0.37521, mean_episode_step = 52.446, total_loss = -291.02, entropy_loss = -8.4469, pg_loss = -339.33, baseline_loss = 56.76, learner_queue_size = 32, _tick = 92, _time = 1.7374e+09)
[2025-01-20 09:32:32,296][root][INFO] - Step 240640 @ 510.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1094.7, step = 240640, mean_episode_return = 0.5569, mean_episode_step = 55.634, total_loss = 196.42, entropy_loss = -8.4052, pg_loss = 129.31, baseline_loss = 75.514, learner_queue_size = 32, _tick = 93, _time = 1.7374e+09)
[2025-01-20 09:32:37,563][root][INFO] - Step 240640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1099.8, step = 240640, mean_episode_return = 0.5569, mean_episode_step = 55.634, total_loss = 196.42, entropy_loss = -8.4052, pg_loss = 129.31, baseline_loss = 75.514, learner_queue_size = 32, _tick = 93, _time = 1.7374e+09)
[2025-01-20 09:32:42,597][root][INFO] - Step 243200 @ 489.0 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1105.0, step = 243200, mean_episode_return = 0.51487, mean_episode_step = 51.886, total_loss = 279.86, entropy_loss = -8.4088, pg_loss = 209.77, baseline_loss = 78.499, learner_queue_size = 32, _tick = 94, _time = 1.7374e+09)
[2025-01-20 09:32:48,041][root][INFO] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1110.1, step = 243200, mean_episode_return = 0.51487, mean_episode_step = 51.886, total_loss = 279.86, entropy_loss = -8.4088, pg_loss = 209.77, baseline_loss = 78.499, learner_queue_size = 32, _tick = 94, _time = 1.7374e+09)
[2025-01-20 09:32:53,054][root][INFO] - Step 243200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1115.5, step = 243200, mean_episode_return = 0.51487, mean_episode_step = 51.886, total_loss = 279.86, entropy_loss = -8.4088, pg_loss = 209.77, baseline_loss = 78.499, learner_queue_size = 32, _tick = 94, _time = 1.7374e+09)
[2025-01-20 09:32:58,059][root][INFO] - Step 245760 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1120.5, step = 245760, mean_episode_return = 0.67507, mean_episode_step = 55.081, total_loss = 326.73, entropy_loss = -8.3654, pg_loss = 242.19, baseline_loss = 92.908, learner_queue_size = 32, _tick = 95, _time = 1.7374e+09)
[2025-01-20 09:33:03,293][root][INFO] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1125.6, step = 245760, mean_episode_return = 0.67507, mean_episode_step = 55.081, total_loss = 326.73, entropy_loss = -8.3654, pg_loss = 242.19, baseline_loss = 92.908, learner_queue_size = 32, _tick = 95, _time = 1.7374e+09)
[2025-01-20 09:33:08,994][root][INFO] - Step 248320 @ 438.3 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1131.4, step = 248320, mean_episode_return = 0.3847, mean_episode_step = 43.024, total_loss = -82.17, entropy_loss = -8.4085, pg_loss = -161.1, baseline_loss = 87.341, learner_queue_size = 32, _tick = 96, _time = 1.7374e+09)
[2025-01-20 09:33:14,000][root][INFO] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1136.4, step = 248320, mean_episode_return = 0.3847, mean_episode_step = 43.024, total_loss = -82.17, entropy_loss = -8.4085, pg_loss = -161.1, baseline_loss = 87.341, learner_queue_size = 32, _tick = 96, _time = 1.7374e+09)
[2025-01-20 09:33:19,121][root][INFO] - Step 248320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1141.5, step = 248320, mean_episode_return = 0.3847, mean_episode_step = 43.024, total_loss = -82.17, entropy_loss = -8.4085, pg_loss = -161.1, baseline_loss = 87.341, learner_queue_size = 32, _tick = 96, _time = 1.7374e+09)
[2025-01-20 09:33:24,135][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar
[2025-01-20 09:33:24,182][root][INFO] - Step 250880 @ 500.8 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (train_seconds = 1146.6, step = 250880, mean_episode_return = 0.4238, mean_episode_step = 51.973, total_loss = -126.44, entropy_loss = -8.3747, pg_loss = -197.31, baseline_loss = 79.243, learner_queue_size = 32, _tick = 97, _time = 1.7374e+09)
[2025-01-20 09:33:29,211][root][INFO] - Step 250880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1151.6, step = 250880, mean_episode_return = 0.4238, mean_episode_step = 51.973, total_loss = -126.44, entropy_loss = -8.3747, pg_loss = -197.31, baseline_loss = 79.243, learner_queue_size = 32, _tick = 97, _time = 1.7374e+09)
[2025-01-20 09:33:34,462][root][INFO] - Step 250880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1156.7, step = 250880, mean_episode_return = 0.4238, mean_episode_step = 51.973, total_loss = -126.44, entropy_loss = -8.3747, pg_loss = -197.31, baseline_loss = 79.243, learner_queue_size = 32, _tick = 97, _time = 1.7374e+09)
[2025-01-20 09:33:39,475][root][INFO] - Step 253440 @ 495.1 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1161.9, step = 253440, mean_episode_return = 0.40526, mean_episode_step = 43.982, total_loss = -159.8, entropy_loss = -8.3298, pg_loss = -213.98, baseline_loss = 62.507, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)
[2025-01-20 09:33:44,516][root][INFO] - Step 253440 @ 0.0 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1166.9, step = 253440, mean_episode_return = 0.40526, mean_episode_step = 43.982, total_loss = -159.8, entropy_loss = -8.3298, pg_loss = -213.98, baseline_loss = 62.507, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)
[2025-01-20 09:33:49,784][root][INFO] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1172.0, step = 253440, mean_episode_return = 0.40526, mean_episode_step = 43.982, total_loss = -159.8, entropy_loss = -8.3298, pg_loss = -213.98, baseline_loss = 62.507, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)
[2025-01-20 09:33:54,852][root][INFO] - Step 253440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1177.3, step = 253440, mean_episode_return = 0.40526, mean_episode_step = 43.982, total_loss = -159.8, entropy_loss = -8.3298, pg_loss = -213.98, baseline_loss = 62.507, learner_queue_size = 32, _tick = 98, _time = 1.7374e+09)
[2025-01-20 09:34:00,156][root][INFO] - Step 256000 @ 494.7 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1182.5, step = 256000, mean_episode_return = 0.41746, mean_episode_step = 55.975, total_loss = 225.25, entropy_loss = -8.2985, pg_loss = 162.25, baseline_loss = 71.298, learner_queue_size = 32, _tick = 99, _time = 1.7374e+09)
[2025-01-20 09:34:05,640][root][INFO] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1188.1, step = 256000, mean_episode_return = 0.41746, mean_episode_step = 55.975, total_loss = 225.25, entropy_loss = -8.2985, pg_loss = 162.25, baseline_loss = 71.298, learner_queue_size = 32, _tick = 99, _time = 1.7374e+09)
[2025-01-20 09:34:10,688][root][INFO] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1193.1, step = 256000, mean_episode_return = 0.41746, mean_episode_step = 55.975, total_loss = 225.25, entropy_loss = -8.2985, pg_loss = 162.25, baseline_loss = 71.298, learner_queue_size = 32, _tick = 99, _time = 1.7374e+09)
[2025-01-20 09:34:15,698][root][INFO] - Step 258560 @ 507.7 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1198.1, step = 258560, mean_episode_return = 0.43687, mean_episode_step = 63.218, total_loss = -499.78, entropy_loss = -8.2891, pg_loss = -535.69, baseline_loss = 44.199, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)
[2025-01-20 09:34:20,707][root][INFO] - Step 258560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1203.1, step = 258560, mean_episode_return = 0.43687, mean_episode_step = 63.218, total_loss = -499.78, entropy_loss = -8.2891, pg_loss = -535.69, baseline_loss = 44.199, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)
[2025-01-20 09:34:26,020][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 09:34:26,665][root][INFO] - Step 258560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1208.4, step = 258560, mean_episode_return = 0.43687, mean_episode_step = 63.218, total_loss = -499.78, entropy_loss = -8.2891, pg_loss = -535.69, baseline_loss = 44.199, learner_queue_size = 32, _tick = 100, _time = 1.7374e+09)
[2025-01-20 09:34:31,670][root][INFO] - Step 261120 @ 448.1 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1214.1, step = 261120, mean_episode_return = 0.58854, mean_episode_step = 55.676, total_loss = 279.09, entropy_loss = -8.2934, pg_loss = 205.3, baseline_loss = 82.088, learner_queue_size = 32, _tick = 101, _time = 1.7374e+09)
[2025-01-20 09:34:36,677][root][INFO] - Step 263680 @ 511.3 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1219.1, step = 263680, mean_episode_return = 0.56778, mean_episode_step = 64.235, total_loss = -50.066, entropy_loss = -8.3226, pg_loss = -117.48, baseline_loss = 75.735, learner_queue_size = 32, _tick = 102, _time = 1.7374e+09)
[2025-01-20 09:34:41,687][root][INFO] - Step 263680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1224.1, step = 263680, mean_episode_return = 0.56778, mean_episode_step = 64.235, total_loss = -50.066, entropy_loss = -8.3226, pg_loss = -117.48, baseline_loss = 75.735, learner_queue_size = 32, _tick = 102, _time = 1.7374e+09)
[2025-01-20 09:34:46,699][root][INFO] - Step 266240 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1229.1, step = 266240, mean_episode_return = 0.68859, mean_episode_step = 58.388, total_loss = 33.037, entropy_loss = -8.3205, pg_loss = -20.621, baseline_loss = 61.978, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)
[2025-01-20 09:34:51,708][root][INFO] - Step 266240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1234.1, step = 266240, mean_episode_return = 0.68859, mean_episode_step = 58.388, total_loss = 33.037, entropy_loss = -8.3205, pg_loss = -20.621, baseline_loss = 61.978, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)
[2025-01-20 09:34:56,720][root][INFO] - Step 266240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1239.2, step = 266240, mean_episode_return = 0.68859, mean_episode_step = 58.388, total_loss = 33.037, entropy_loss = -8.3205, pg_loss = -20.621, baseline_loss = 61.978, learner_queue_size = 32, _tick = 103, _time = 1.7374e+09)
[2025-01-20 09:35:01,725][root][INFO] - Step 268800 @ 510.8 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1244.2, step = 268800, mean_episode_return = 0.36115, mean_episode_step = 54.411, total_loss = -166.08, entropy_loss = -8.3817, pg_loss = -211.01, baseline_loss = 53.313, learner_queue_size = 32, _tick = 104, _time = 1.7374e+09)
[2025-01-20 09:35:06,731][root][INFO] - Step 271360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1249.2, step = 271360, mean_episode_return = 0.64383, mean_episode_step = 50.429, total_loss = 222.05, entropy_loss = -8.409, pg_loss = 177.83, baseline_loss = 52.628, learner_queue_size = 32, _tick = 105, _time = 1.7374e+09)
[2025-01-20 09:35:11,737][root][INFO] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1254.2, step = 271360, mean_episode_return = 0.64383, mean_episode_step = 50.429, total_loss = 222.05, entropy_loss = -8.409, pg_loss = 177.83, baseline_loss = 52.628, learner_queue_size = 32, _tick = 105, _time = 1.7374e+09)
[2025-01-20 09:35:16,746][root][INFO] - Step 273920 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1259.2, step = 273920, mean_episode_return = 0.4847, mean_episode_step = 53.521, total_loss = -42.86, entropy_loss = -8.3983, pg_loss = -93.093, baseline_loss = 58.631, learner_queue_size = 32, _tick = 106, _time = 1.7374e+09)
[2025-01-20 09:35:21,757][root][INFO] - Step 273920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1264.2, step = 273920, mean_episode_return = 0.4847, mean_episode_step = 53.521, total_loss = -42.86, entropy_loss = -8.3983, pg_loss = -93.093, baseline_loss = 58.631, learner_queue_size = 32, _tick = 106, _time = 1.7374e+09)
[2025-01-20 09:35:26,763][root][INFO] - Step 276480 @ 510.9 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 1269.2, step = 276480, mean_episode_return = 0.45596, mean_episode_step = 49.354, total_loss = -25.746, entropy_loss = -8.4128, pg_loss = -67.089, baseline_loss = 49.756, learner_queue_size = 32, _tick = 107, _time = 1.7374e+09)
[2025-01-20 09:35:31,774][root][INFO] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1274.2, step = 276480, mean_episode_return = 0.45596, mean_episode_step = 49.354, total_loss = -25.746, entropy_loss = -8.4128, pg_loss = -67.089, baseline_loss = 49.756, learner_queue_size = 32, _tick = 107, _time = 1.7374e+09)
[2025-01-20 09:35:36,780][root][INFO] - Step 279040 @ 510.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1279.2, step = 279040, mean_episode_return = 0.69597, mean_episode_step = 59.337, total_loss = 455.79, entropy_loss = -8.3625, pg_loss = 420.19, baseline_loss = 43.958, learner_queue_size = 32, _tick = 108, _time = 1.7374e+09)
[2025-01-20 09:35:41,788][root][INFO] - Step 279040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1284.2, step = 279040, mean_episode_return = 0.69597, mean_episode_step = 59.337, total_loss = 455.79, entropy_loss = -8.3625, pg_loss = 420.19, baseline_loss = 43.958, learner_queue_size = 32, _tick = 108, _time = 1.7374e+09)
[2025-01-20 09:35:46,793][root][INFO] - Step 281600 @ 511.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1289.2, step = 281600, mean_episode_return = 0.46898, mean_episode_step = 61.736, total_loss = -86.219, entropy_loss = -8.4039, pg_loss = -124.57, baseline_loss = 46.754, learner_queue_size = 32, _tick = 109, _time = 1.7374e+09)
[2025-01-20 09:35:51,799][root][INFO] - Step 284160 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1294.2, step = 284160, mean_episode_return = 0.78829, mean_episode_step = 52.416, total_loss = 354.9, entropy_loss = -8.3603, pg_loss = 319.25, baseline_loss = 44.011, learner_queue_size = 32, _tick = 110, _time = 1.7374e+09)
[2025-01-20 09:35:56,805][root][INFO] - Step 284160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1299.2, step = 284160, mean_episode_return = 0.78829, mean_episode_step = 52.416, total_loss = 354.9, entropy_loss = -8.3603, pg_loss = 319.25, baseline_loss = 44.011, learner_queue_size = 32, _tick = 110, _time = 1.7374e+09)
[2025-01-20 09:36:01,811][root][INFO] - Step 286720 @ 511.5 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 1304.3, step = 286720, mean_episode_return = 0.6557, mean_episode_step = 54.487, total_loss = 333.06, entropy_loss = -8.396, pg_loss = 278.94, baseline_loss = 62.514, learner_queue_size = 32, _tick = 111, _time = 1.7374e+09)
[2025-01-20 09:36:07,463][root][INFO] - Step 286720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1309.5, step = 286720, mean_episode_return = 0.6557, mean_episode_step = 54.487, total_loss = 333.06, entropy_loss = -8.396, pg_loss = 278.94, baseline_loss = 62.514, learner_queue_size = 32, _tick = 111, _time = 1.7374e+09)
[2025-01-20 09:36:12,480][root][INFO] - Step 289280 @ 473.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1314.9, step = 289280, mean_episode_return = 0.62764, mean_episode_step = 54.803, total_loss = -176.38, entropy_loss = -8.4298, pg_loss = -224.67, baseline_loss = 56.714, learner_queue_size = 32, _tick = 112, _time = 1.7374e+09)
[2025-01-20 09:36:17,497][root][INFO] - Step 289280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1319.9, step = 289280, mean_episode_return = 0.62764, mean_episode_step = 54.803, total_loss = -176.38, entropy_loss = -8.4298, pg_loss = -224.67, baseline_loss = 56.714, learner_queue_size = 32, _tick = 112, _time = 1.7374e+09)
[2025-01-20 09:36:22,502][root][INFO] - Step 291840 @ 510.6 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1324.9, step = 291840, mean_episode_return = 0.33789, mean_episode_step = 55.874, total_loss = -345.24, entropy_loss = -8.3631, pg_loss = -377.02, baseline_loss = 40.142, learner_queue_size = 32, _tick = 113, _time = 1.7374e+09)
[2025-01-20 09:36:28,667][root][INFO] - Step 291840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1330.0, step = 291840, mean_episode_return = 0.33789, mean_episode_step = 55.874, total_loss = -345.24, entropy_loss = -8.3631, pg_loss = -377.02, baseline_loss = 40.142, learner_queue_size = 32, _tick = 113, _time = 1.7374e+09)
[2025-01-20 09:36:33,687][root][INFO] - Step 294400 @ 418.4 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1336.1, step = 294400, mean_episode_return = 0.42384, mean_episode_step = 44.927, total_loss = -125.75, entropy_loss = -8.3878, pg_loss = -182.94, baseline_loss = 65.575, learner_queue_size = 32, _tick = 114, _time = 1.7374e+09)
[2025-01-20 09:36:38,943][root][INFO] - Step 294400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1341.1, step = 294400, mean_episode_return = 0.42384, mean_episode_step = 44.927, total_loss = -125.75, entropy_loss = -8.3878, pg_loss = -182.94, baseline_loss = 65.575, learner_queue_size = 32, _tick = 114, _time = 1.7374e+09)
[2025-01-20 09:36:43,964][root][INFO] - Step 296960 @ 486.7 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1346.4, step = 296960, mean_episode_return = 0.55717, mean_episode_step = 51.216, total_loss = 228.54, entropy_loss = -8.3933, pg_loss = 189.71, baseline_loss = 47.223, learner_queue_size = 32, _tick = 115, _time = 1.7374e+09)
[2025-01-20 09:36:49,259][root][INFO] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1351.6, step = 296960, mean_episode_return = 0.55717, mean_episode_step = 51.216, total_loss = 228.54, entropy_loss = -8.3933, pg_loss = 189.71, baseline_loss = 47.223, learner_queue_size = 32, _tick = 115, _time = 1.7374e+09)
[2025-01-20 09:36:54,264][root][INFO] - Step 299520 @ 502.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1356.7, step = 299520, mean_episode_return = 0.49654, mean_episode_step = 54.429, total_loss = 215.62, entropy_loss = -8.3751, pg_loss = 154.82, baseline_loss = 69.18, learner_queue_size = 32, _tick = 116, _time = 1.7374e+09)
[2025-01-20 09:36:59,545][root][INFO] - Step 299520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1361.9, step = 299520, mean_episode_return = 0.49654, mean_episode_step = 54.429, total_loss = 215.62, entropy_loss = -8.3751, pg_loss = 154.82, baseline_loss = 69.18, learner_queue_size = 32, _tick = 116, _time = 1.7374e+09)
[2025-01-20 09:37:04,580][root][INFO] - Step 299520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1367.0, step = 299520, mean_episode_return = 0.49654, mean_episode_step = 54.429, total_loss = 215.62, entropy_loss = -8.3751, pg_loss = 154.82, baseline_loss = 69.18, learner_queue_size = 32, _tick = 116, _time = 1.7374e+09)
[2025-01-20 09:37:09,589][root][INFO] - Step 302080 @ 510.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1372.0, step = 302080, mean_episode_return = 0.63464, mean_episode_step = 62.902, total_loss = 58.365, entropy_loss = -8.3575, pg_loss = 7.8033, baseline_loss = 58.92, learner_queue_size = 32, _tick = 117, _time = 1.7374e+09)
[2025-01-20 09:37:14,601][root][INFO] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1377.0, step = 302080, mean_episode_return = 0.63464, mean_episode_step = 62.902, total_loss = 58.365, entropy_loss = -8.3575, pg_loss = 7.8033, baseline_loss = 58.92, learner_queue_size = 32, _tick = 117, _time = 1.7374e+09)
[2025-01-20 09:37:19,606][root][INFO] - Step 304640 @ 510.9 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1382.0, step = 304640, mean_episode_return = 0.65748, mean_episode_step = 50.345, total_loss = 176.43, entropy_loss = -8.4339, pg_loss = 104.31, baseline_loss = 80.553, learner_queue_size = 32, _tick = 118, _time = 1.7374e+09)
[2025-01-20 09:37:24,615][root][INFO] - Step 307200 @ 511.3 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1387.1, step = 307200, mean_episode_return = 0.58178, mean_episode_step = 60.39, total_loss = 265.73, entropy_loss = -8.4034, pg_loss = 184.32, baseline_loss = 89.821, learner_queue_size = 32, _tick = 119, _time = 1.7374e+09)
[2025-01-20 09:37:29,622][root][INFO] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1392.1, step = 307200, mean_episode_return = 0.58178, mean_episode_step = 60.39, total_loss = 265.73, entropy_loss = -8.4034, pg_loss = 184.32, baseline_loss = 89.821, learner_queue_size = 32, _tick = 119, _time = 1.7374e+09)
[2025-01-20 09:37:34,627][root][INFO] - Step 309760 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1397.1, step = 309760, mean_episode_return = 0.50681, mean_episode_step = 57.773, total_loss = 156.22, entropy_loss = -8.4346, pg_loss = 110.98, baseline_loss = 53.675, learner_queue_size = 32, _tick = 120, _time = 1.7374e+09)
[2025-01-20 09:37:39,633][root][INFO] - Step 309760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1402.1, step = 309760, mean_episode_return = 0.50681, mean_episode_step = 57.773, total_loss = 156.22, entropy_loss = -8.4346, pg_loss = 110.98, baseline_loss = 53.675, learner_queue_size = 32, _tick = 120, _time = 1.7374e+09)
[2025-01-20 09:37:44,638][root][INFO] - Step 312320 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1407.1, step = 312320, mean_episode_return = 0.54333, mean_episode_step = 50.942, total_loss = -145.04, entropy_loss = -8.4659, pg_loss = -197.52, baseline_loss = 60.942, learner_queue_size = 32, _tick = 121, _time = 1.7374e+09)
[2025-01-20 09:37:49,651][root][INFO] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1412.1, step = 312320, mean_episode_return = 0.54333, mean_episode_step = 50.942, total_loss = -145.04, entropy_loss = -8.4659, pg_loss = -197.52, baseline_loss = 60.942, learner_queue_size = 32, _tick = 121, _time = 1.7374e+09)
[2025-01-20 09:37:54,657][root][INFO] - Step 314880 @ 510.9 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1417.1, step = 314880, mean_episode_return = 0.49093, mean_episode_step = 46.123, total_loss = 147.78, entropy_loss = -8.425, pg_loss = 77.642, baseline_loss = 78.564, learner_queue_size = 32, _tick = 122, _time = 1.7374e+09)
[2025-01-20 09:37:59,672][root][INFO] - Step 314880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1422.1, step = 314880, mean_episode_return = 0.49093, mean_episode_step = 46.123, total_loss = 147.78, entropy_loss = -8.425, pg_loss = 77.642, baseline_loss = 78.564, learner_queue_size = 32, _tick = 122, _time = 1.7374e+09)
[2025-01-20 09:38:04,679][root][INFO] - Step 317440 @ 510.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1427.1, step = 317440, mean_episode_return = 0.49062, mean_episode_step = 57.481, total_loss = -0.086082, entropy_loss = -8.392, pg_loss = -69.669, baseline_loss = 77.975, learner_queue_size = 32, _tick = 123, _time = 1.7374e+09)
[2025-01-20 09:38:10,874][root][INFO] - Step 317440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1433.1, step = 317440, mean_episode_return = 0.49062, mean_episode_step = 57.481, total_loss = -0.086082, entropy_loss = -8.392, pg_loss = -69.669, baseline_loss = 77.975, learner_queue_size = 32, _tick = 123, _time = 1.7374e+09)
[2025-01-20 09:38:15,921][root][INFO] - Step 317440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1438.4, step = 317440, mean_episode_return = 0.49062, mean_episode_step = 57.481, total_loss = -0.086082, entropy_loss = -8.392, pg_loss = -69.669, baseline_loss = 77.975, learner_queue_size = 32, _tick = 123, _time = 1.7374e+09)
[2025-01-20 09:38:20,927][root][INFO] - Step 320000 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1443.4, step = 320000, mean_episode_return = 0.67419, mean_episode_step = 60.082, total_loss = 131.67, entropy_loss = -8.381, pg_loss = 74.997, baseline_loss = 65.051, learner_queue_size = 32, _tick = 124, _time = 1.7374e+09)
[2025-01-20 09:38:25,933][root][INFO] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1448.4, step = 320000, mean_episode_return = 0.67419, mean_episode_step = 60.082, total_loss = 131.67, entropy_loss = -8.381, pg_loss = 74.997, baseline_loss = 65.051, learner_queue_size = 32, _tick = 124, _time = 1.7374e+09)
[2025-01-20 09:38:31,489][root][INFO] - Step 320000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1453.5, step = 320000, mean_episode_return = 0.67419, mean_episode_step = 60.082, total_loss = 131.67, entropy_loss = -8.381, pg_loss = 74.997, baseline_loss = 65.051, learner_queue_size = 32, _tick = 124, _time = 1.7374e+09)
[2025-01-20 09:38:36,516][root][INFO] - Step 322560 @ 471.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1459.0, step = 322560, mean_episode_return = 0.53078, mean_episode_step = 41.35, total_loss = -42.621, entropy_loss = -8.4101, pg_loss = -94.231, baseline_loss = 60.019, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)
[2025-01-20 09:38:41,529][root][INFO] - Step 322560 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1464.0, step = 322560, mean_episode_return = 0.53078, mean_episode_step = 41.35, total_loss = -42.621, entropy_loss = -8.4101, pg_loss = -94.231, baseline_loss = 60.019, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)
[2025-01-20 09:38:47,336][root][INFO] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1469.0, step = 322560, mean_episode_return = 0.53078, mean_episode_step = 41.35, total_loss = -42.621, entropy_loss = -8.4101, pg_loss = -94.231, baseline_loss = 60.019, learner_queue_size = 32, _tick = 125, _time = 1.7374e+09)
[2025-01-20 09:38:52,849][root][INFO] - Step 325120 @ 405.8 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1475.3, step = 325120, mean_episode_return = 0.56998, mean_episode_step = 53.671, total_loss = -306.23, entropy_loss = -8.3641, pg_loss = -350.26, baseline_loss = 52.388, learner_queue_size = 32, _tick = 126, _time = 1.7374e+09)
[2025-01-20 09:38:58,242][root][INFO] - Step 325120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1480.5, step = 325120, mean_episode_return = 0.56998, mean_episode_step = 53.671, total_loss = -306.23, entropy_loss = -8.3641, pg_loss = -350.26, baseline_loss = 52.388, learner_queue_size = 32, _tick = 126, _time = 1.7374e+09)
[2025-01-20 09:39:03,679][root][INFO] - Step 325120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1485.7, step = 325120, mean_episode_return = 0.56998, mean_episode_step = 53.671, total_loss = -306.23, entropy_loss = -8.3641, pg_loss = -350.26, baseline_loss = 52.388, learner_queue_size = 32, _tick = 126, _time = 1.7374e+09)
[2025-01-20 09:39:08,696][root][INFO] - Step 327680 @ 471.6 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1491.1, step = 327680, mean_episode_return = 0.77958, mean_episode_step = 55.615, total_loss = 79.594, entropy_loss = -8.3364, pg_loss = 36.498, baseline_loss = 51.432, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)
[2025-01-20 09:39:13,878][root][INFO] - Step 327680 @ 0.0 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1496.1, step = 327680, mean_episode_return = 0.77958, mean_episode_step = 55.615, total_loss = 79.594, entropy_loss = -8.3364, pg_loss = 36.498, baseline_loss = 51.432, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)
[2025-01-20 09:39:19,560][root][INFO] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1501.5, step = 327680, mean_episode_return = 0.77958, mean_episode_step = 55.615, total_loss = 79.594, entropy_loss = -8.3364, pg_loss = 36.498, baseline_loss = 51.432, learner_queue_size = 32, _tick = 127, _time = 1.7374e+09)
[2025-01-20 09:39:24,765][root][INFO] - Step 330240 @ 452.7 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1507.2, step = 330240, mean_episode_return = 0.38267, mean_episode_step = 49.407, total_loss = -533.29, entropy_loss = -8.3627, pg_loss = -573.01, baseline_loss = 48.081, learner_queue_size = 32, _tick = 128, _time = 1.7374e+09)
[2025-01-20 09:39:29,772][root][INFO] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1512.2, step = 330240, mean_episode_return = 0.38267, mean_episode_step = 49.407, total_loss = -533.29, entropy_loss = -8.3627, pg_loss = -573.01, baseline_loss = 48.081, learner_queue_size = 32, _tick = 128, _time = 1.7374e+09)
[2025-01-20 09:39:34,783][root][INFO] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1517.2, step = 330240, mean_episode_return = 0.38267, mean_episode_step = 49.407, total_loss = -533.29, entropy_loss = -8.3627, pg_loss = -573.01, baseline_loss = 48.081, learner_queue_size = 32, _tick = 128, _time = 1.7374e+09)
[2025-01-20 09:39:39,788][root][INFO] - Step 332800 @ 511.0 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1522.2, step = 332800, mean_episode_return = 0.46134, mean_episode_step = 54.691, total_loss = -277.88, entropy_loss = -8.3387, pg_loss = -320.4, baseline_loss = 50.862, learner_queue_size = 32, _tick = 129, _time = 1.7374e+09)
[2025-01-20 09:39:44,802][root][INFO] - Step 332800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1527.2, step = 332800, mean_episode_return = 0.46134, mean_episode_step = 54.691, total_loss = -277.88, entropy_loss = -8.3387, pg_loss = -320.4, baseline_loss = 50.862, learner_queue_size = 32, _tick = 129, _time = 1.7374e+09)
[2025-01-20 09:39:49,808][root][INFO] - Step 335360 @ 510.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1532.2, step = 335360, mean_episode_return = 0.53004, mean_episode_step = 57.684, total_loss = -87.523, entropy_loss = -8.3253, pg_loss = -123.65, baseline_loss = 44.452, learner_queue_size = 32, _tick = 130, _time = 1.7374e+09)
[2025-01-20 09:39:54,820][root][INFO] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1537.3, step = 335360, mean_episode_return = 0.53004, mean_episode_step = 57.684, total_loss = -87.523, entropy_loss = -8.3253, pg_loss = -123.65, baseline_loss = 44.452, learner_queue_size = 32, _tick = 130, _time = 1.7374e+09)
[2025-01-20 09:39:59,840][root][INFO] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1542.3, step = 335360, mean_episode_return = 0.53004, mean_episode_step = 57.684, total_loss = -87.523, entropy_loss = -8.3253, pg_loss = -123.65, baseline_loss = 44.452, learner_queue_size = 32, _tick = 130, _time = 1.7374e+09)
[2025-01-20 09:40:04,846][root][INFO] - Step 337920 @ 510.2 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1547.3, step = 337920, mean_episode_return = 0.53933, mean_episode_step = 49.641, total_loss = -23.333, entropy_loss = -8.3069, pg_loss = -59.51, baseline_loss = 44.484, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)
[2025-01-20 09:40:09,917][root][INFO] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1552.4, step = 337920, mean_episode_return = 0.53933, mean_episode_step = 49.641, total_loss = -23.333, entropy_loss = -8.3069, pg_loss = -59.51, baseline_loss = 44.484, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)
[2025-01-20 09:40:15,486][root][INFO] - Step 337920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1557.6, step = 337920, mean_episode_return = 0.53933, mean_episode_step = 49.641, total_loss = -23.333, entropy_loss = -8.3069, pg_loss = -59.51, baseline_loss = 44.484, learner_queue_size = 32, _tick = 131, _time = 1.7374e+09)
[2025-01-20 09:40:20,499][root][INFO] - Step 340480 @ 482.5 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 1562.9, step = 340480, mean_episode_return = 0.52033, mean_episode_step = 44.238, total_loss = 199.99, entropy_loss = -8.3115, pg_loss = 151.62, baseline_loss = 56.676, learner_queue_size = 32, _tick = 132, _time = 1.7374e+09)
[2025-01-20 09:40:25,509][root][INFO] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1567.9, step = 340480, mean_episode_return = 0.52033, mean_episode_step = 44.238, total_loss = 199.99, entropy_loss = -8.3115, pg_loss = 151.62, baseline_loss = 56.676, learner_queue_size = 32, _tick = 132, _time = 1.7374e+09)
[2025-01-20 09:40:31,259][root][INFO] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1573.5, step = 340480, mean_episode_return = 0.52033, mean_episode_step = 44.238, total_loss = 199.99, entropy_loss = -8.3115, pg_loss = 151.62, baseline_loss = 56.676, learner_queue_size = 32, _tick = 132, _time = 1.7374e+09)
[2025-01-20 09:40:36,269][root][INFO] - Step 343040 @ 493.6 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1578.7, step = 343040, mean_episode_return = 0.53047, mean_episode_step = 40.995, total_loss = -24.361, entropy_loss = -8.2941, pg_loss = -67.526, baseline_loss = 51.46, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)
[2025-01-20 09:40:41,278][root][INFO] - Step 343040 @ 0.0 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1583.7, step = 343040, mean_episode_return = 0.53047, mean_episode_step = 40.995, total_loss = -24.361, entropy_loss = -8.2941, pg_loss = -67.526, baseline_loss = 51.46, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)
[2025-01-20 09:40:46,618][root][INFO] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1588.8, step = 343040, mean_episode_return = 0.53047, mean_episode_step = 40.995, total_loss = -24.361, entropy_loss = -8.2941, pg_loss = -67.526, baseline_loss = 51.46, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)
[2025-01-20 09:40:51,644][root][INFO] - Step 343040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1594.1, step = 343040, mean_episode_return = 0.53047, mean_episode_step = 40.995, total_loss = -24.361, entropy_loss = -8.2941, pg_loss = -67.526, baseline_loss = 51.46, learner_queue_size = 32, _tick = 133, _time = 1.7374e+09)
[2025-01-20 09:40:56,655][root][INFO] - Step 345600 @ 511.3 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1599.1, step = 345600, mean_episode_return = 0.62308, mean_episode_step = 49.234, total_loss = -16.105, entropy_loss = -8.2737, pg_loss = -49.562, baseline_loss = 41.73, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)
[2025-01-20 09:41:01,667][root][INFO] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1604.1, step = 345600, mean_episode_return = 0.62308, mean_episode_step = 49.234, total_loss = -16.105, entropy_loss = -8.2737, pg_loss = -49.562, baseline_loss = 41.73, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)
[2025-01-20 09:41:06,833][root][INFO] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1609.1, step = 345600, mean_episode_return = 0.62308, mean_episode_step = 49.234, total_loss = -16.105, entropy_loss = -8.2737, pg_loss = -49.562, baseline_loss = 41.73, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)
[2025-01-20 09:41:11,855][root][INFO] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1614.3, step = 345600, mean_episode_return = 0.62308, mean_episode_step = 49.234, total_loss = -16.105, entropy_loss = -8.2737, pg_loss = -49.562, baseline_loss = 41.73, learner_queue_size = 32, _tick = 134, _time = 1.7374e+09)
[2025-01-20 09:41:16,869][root][INFO] - Step 348160 @ 510.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1619.3, step = 348160, mean_episode_return = 0.58786, mean_episode_step = 44.307, total_loss = 317.23, entropy_loss = -8.3102, pg_loss = 265.87, baseline_loss = 59.669, learner_queue_size = 32, _tick = 135, _time = 1.7374e+09)
[2025-01-20 09:41:21,880][root][INFO] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1624.3, step = 348160, mean_episode_return = 0.58786, mean_episode_step = 44.307, total_loss = 317.23, entropy_loss = -8.3102, pg_loss = 265.87, baseline_loss = 59.669, learner_queue_size = 32, _tick = 135, _time = 1.7374e+09)
[2025-01-20 09:41:27,310][root][INFO] - Step 348160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1629.5, step = 348160, mean_episode_return = 0.58786, mean_episode_step = 44.307, total_loss = 317.23, entropy_loss = -8.3102, pg_loss = 265.87, baseline_loss = 59.669, learner_queue_size = 32, _tick = 135, _time = 1.7374e+09)
[2025-01-20 09:41:32,343][root][INFO] - Step 350720 @ 486.1 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1634.8, step = 350720, mean_episode_return = 0.55962, mean_episode_step = 46.529, total_loss = 512.14, entropy_loss = -8.2862, pg_loss = 456.1, baseline_loss = 64.328, learner_queue_size = 32, _tick = 136, _time = 1.7374e+09)
[2025-01-20 09:41:37,351][root][INFO] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1639.8, step = 350720, mean_episode_return = 0.55962, mean_episode_step = 46.529, total_loss = 512.14, entropy_loss = -8.2862, pg_loss = 456.1, baseline_loss = 64.328, learner_queue_size = 32, _tick = 136, _time = 1.7374e+09)
[2025-01-20 09:41:42,692][root][INFO] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1644.8, step = 350720, mean_episode_return = 0.55962, mean_episode_step = 46.529, total_loss = 512.14, entropy_loss = -8.2862, pg_loss = 456.1, baseline_loss = 64.328, learner_queue_size = 32, _tick = 136, _time = 1.7374e+09)
[2025-01-20 09:41:47,702][root][INFO] - Step 353280 @ 479.1 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1650.1, step = 353280, mean_episode_return = 0.60385, mean_episode_step = 44.979, total_loss = -64.01, entropy_loss = -8.2833, pg_loss = -111.42, baseline_loss = 55.697, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)
[2025-01-20 09:41:52,709][root][INFO] - Step 353280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1655.1, step = 353280, mean_episode_return = 0.60385, mean_episode_step = 44.979, total_loss = -64.01, entropy_loss = -8.2833, pg_loss = -111.42, baseline_loss = 55.697, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)
[2025-01-20 09:41:57,743][root][INFO] - Step 353280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1660.2, step = 353280, mean_episode_return = 0.60385, mean_episode_step = 44.979, total_loss = -64.01, entropy_loss = -8.2833, pg_loss = -111.42, baseline_loss = 55.697, learner_queue_size = 32, _tick = 137, _time = 1.7374e+09)
[2025-01-20 09:42:02,751][root][INFO] - Step 355840 @ 509.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1665.2, step = 355840, mean_episode_return = 0.45815, mean_episode_step = 37.474, total_loss = -64.725, entropy_loss = -8.2799, pg_loss = -108.68, baseline_loss = 52.232, learner_queue_size = 32, _tick = 138, _time = 1.7374e+09)
[2025-01-20 09:42:07,762][root][INFO] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1670.2, step = 355840, mean_episode_return = 0.45815, mean_episode_step = 37.474, total_loss = -64.725, entropy_loss = -8.2799, pg_loss = -108.68, baseline_loss = 52.232, learner_queue_size = 32, _tick = 138, _time = 1.7374e+09)
[2025-01-20 09:42:12,937][root][INFO] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1675.2, step = 355840, mean_episode_return = 0.45815, mean_episode_step = 37.474, total_loss = -64.725, entropy_loss = -8.2799, pg_loss = -108.68, baseline_loss = 52.232, learner_queue_size = 32, _tick = 138, _time = 1.7374e+09)
[2025-01-20 09:42:18,058][root][INFO] - Step 358400 @ 483.6 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1680.5, step = 358400, mean_episode_return = 0.39376, mean_episode_step = 39.738, total_loss = -140.9, entropy_loss = -8.2456, pg_loss = -184.11, baseline_loss = 51.465, learner_queue_size = 32, _tick = 139, _time = 1.7374e+09)
[2025-01-20 09:42:23,166][root][INFO] - Step 358400 @ 0.0 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1685.5, step = 358400, mean_episode_return = 0.39376, mean_episode_step = 39.738, total_loss = -140.9, entropy_loss = -8.2456, pg_loss = -184.11, baseline_loss = 51.465, learner_queue_size = 32, _tick = 139, _time = 1.7374e+09)
[2025-01-20 09:42:28,406][root][INFO] - Step 358400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1690.6, step = 358400, mean_episode_return = 0.39376, mean_episode_step = 39.738, total_loss = -140.9, entropy_loss = -8.2456, pg_loss = -184.11, baseline_loss = 51.465, learner_queue_size = 32, _tick = 139, _time = 1.7374e+09)
[2025-01-20 09:42:33,427][root][INFO] - Step 360960 @ 490.6 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1695.9, step = 360960, mean_episode_return = 0.85584, mean_episode_step = 42.13, total_loss = 778.64, entropy_loss = -8.2176, pg_loss = 717.14, baseline_loss = 69.719, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)
[2025-01-20 09:42:38,432][root][INFO] - Step 360960 @ 0.0 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 1700.9, step = 360960, mean_episode_return = 0.85584, mean_episode_step = 42.13, total_loss = 778.64, entropy_loss = -8.2176, pg_loss = 717.14, baseline_loss = 69.719, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)
[2025-01-20 09:42:44,010][root][INFO] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1705.9, step = 360960, mean_episode_return = 0.85584, mean_episode_step = 42.13, total_loss = 778.64, entropy_loss = -8.2176, pg_loss = 717.14, baseline_loss = 69.719, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)
[2025-01-20 09:42:49,088][root][INFO] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1711.5, step = 360960, mean_episode_return = 0.85584, mean_episode_step = 42.13, total_loss = 778.64, entropy_loss = -8.2176, pg_loss = 717.14, baseline_loss = 69.719, learner_queue_size = 32, _tick = 140, _time = 1.7374e+09)
[2025-01-20 09:42:54,095][root][INFO] - Step 363520 @ 507.2 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1716.5, step = 363520, mean_episode_return = 0.5899, mean_episode_step = 55.825, total_loss = -151.23, entropy_loss = -8.2043, pg_loss = -180.81, baseline_loss = 37.786, learner_queue_size = 32, _tick = 141, _time = 1.7374e+09)
[2025-01-20 09:42:59,105][root][INFO] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1721.5, step = 363520, mean_episode_return = 0.5899, mean_episode_step = 55.825, total_loss = -151.23, entropy_loss = -8.2043, pg_loss = -180.81, baseline_loss = 37.786, learner_queue_size = 32, _tick = 141, _time = 1.7374e+09)
[2025-01-20 09:43:04,121][root][INFO] - Step 363520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1726.6, step = 363520, mean_episode_return = 0.5899, mean_episode_step = 55.825, total_loss = -151.23, entropy_loss = -8.2043, pg_loss = -180.81, baseline_loss = 37.786, learner_queue_size = 32, _tick = 141, _time = 1.7374e+09)
[2025-01-20 09:43:09,127][root][INFO] - Step 366080 @ 510.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1731.6, step = 366080, mean_episode_return = 0.77027, mean_episode_step = 44.812, total_loss = 645.86, entropy_loss = -8.2102, pg_loss = 577.19, baseline_loss = 76.881, learner_queue_size = 32, _tick = 142, _time = 1.7374e+09)
[2025-01-20 09:43:14,432][root][INFO] - Step 366080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1736.6, step = 366080, mean_episode_return = 0.77027, mean_episode_step = 44.812, total_loss = 645.86, entropy_loss = -8.2102, pg_loss = 577.19, baseline_loss = 76.881, learner_queue_size = 32, _tick = 142, _time = 1.7374e+09)
[2025-01-20 09:43:19,450][root][INFO] - Step 366080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1741.9, step = 366080, mean_episode_return = 0.77027, mean_episode_step = 44.812, total_loss = 645.86, entropy_loss = -8.2102, pg_loss = 577.19, baseline_loss = 76.881, learner_queue_size = 32, _tick = 142, _time = 1.7374e+09)
[2025-01-20 09:43:24,464][root][INFO] - Step 368640 @ 509.9 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1746.9, step = 368640, mean_episode_return = 0.50542, mean_episode_step = 43.655, total_loss = 56.608, entropy_loss = -8.2318, pg_loss = 0.93977, baseline_loss = 63.9, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)
[2025-01-20 09:43:29,489][root][INFO] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1751.9, step = 368640, mean_episode_return = 0.50542, mean_episode_step = 43.655, total_loss = 56.608, entropy_loss = -8.2318, pg_loss = 0.93977, baseline_loss = 63.9, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)
[2025-01-20 09:43:34,764][root][INFO] - Step 368640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1757.0, step = 368640, mean_episode_return = 0.50542, mean_episode_step = 43.655, total_loss = 56.608, entropy_loss = -8.2318, pg_loss = 0.93977, baseline_loss = 63.9, learner_queue_size = 32, _tick = 143, _time = 1.7374e+09)
[2025-01-20 09:43:40,084][root][INFO] - Step 371200 @ 460.6 SPS. Inference batcher size: 26. Learner queue size: 32. Other stats: (train_seconds = 1762.5, step = 371200, mean_episode_return = 0.4777, mean_episode_step = 55.549, total_loss = -455.25, entropy_loss = -8.2177, pg_loss = -502.44, baseline_loss = 55.401, learner_queue_size = 32, _tick = 144, _time = 1.7374e+09)
[2025-01-20 09:43:45,091][root][INFO] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1767.5, step = 371200, mean_episode_return = 0.4777, mean_episode_step = 55.549, total_loss = -455.25, entropy_loss = -8.2177, pg_loss = -502.44, baseline_loss = 55.401, learner_queue_size = 32, _tick = 144, _time = 1.7374e+09)
[2025-01-20 09:43:50,103][root][INFO] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1772.5, step = 371200, mean_episode_return = 0.4777, mean_episode_step = 55.549, total_loss = -455.25, entropy_loss = -8.2177, pg_loss = -502.44, baseline_loss = 55.401, learner_queue_size = 32, _tick = 144, _time = 1.7374e+09)
[2025-01-20 09:43:55,349][root][INFO] - Step 373760 @ 490.0 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1777.8, step = 373760, mean_episode_return = 0.81923, mean_episode_step = 55.84, total_loss = 680.95, entropy_loss = -8.1914, pg_loss = 614.13, baseline_loss = 75.013, learner_queue_size = 32, _tick = 145, _time = 1.7374e+09)
[2025-01-20 09:44:00,620][root][INFO] - Step 373760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1782.8, step = 373760, mean_episode_return = 0.81923, mean_episode_step = 55.84, total_loss = 680.95, entropy_loss = -8.1914, pg_loss = 614.13, baseline_loss = 75.013, learner_queue_size = 32, _tick = 145, _time = 1.7374e+09)
[2025-01-20 09:44:05,646][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar
[2025-01-20 09:44:05,723][root][INFO] - Step 376320 @ 487.0 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1788.1, step = 376320, mean_episode_return = 0.54796, mean_episode_step = 53.575, total_loss = -112.79, entropy_loss = -8.209, pg_loss = -163.63, baseline_loss = 59.042, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)
[2025-01-20 09:44:10,783][root][INFO] - Step 376320 @ 0.0 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1793.2, step = 376320, mean_episode_return = 0.54796, mean_episode_step = 53.575, total_loss = -112.79, entropy_loss = -8.209, pg_loss = -163.63, baseline_loss = 59.042, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)
[2025-01-20 09:44:16,064][root][INFO] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1798.3, step = 376320, mean_episode_return = 0.54796, mean_episode_step = 53.575, total_loss = -112.79, entropy_loss = -8.209, pg_loss = -163.63, baseline_loss = 59.042, learner_queue_size = 32, _tick = 146, _time = 1.7374e+09)
[2025-01-20 09:44:21,076][root][INFO] - Step 378880 @ 489.1 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1803.5, step = 378880, mean_episode_return = 0.7004, mean_episode_step = 54.514, total_loss = 742.16, entropy_loss = -8.1918, pg_loss = 665.35, baseline_loss = 85.008, learner_queue_size = 32, _tick = 147, _time = 1.7374e+09)
[2025-01-20 09:44:26,084][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 09:44:26,210][root][INFO] - Step 378880 @ 0.0 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1808.5, step = 378880, mean_episode_return = 0.7004, mean_episode_step = 54.514, total_loss = 742.16, entropy_loss = -8.1918, pg_loss = 665.35, baseline_loss = 85.008, learner_queue_size = 32, _tick = 147, _time = 1.7374e+09)
[2025-01-20 09:44:32,140][root][INFO] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1814.1, step = 378880, mean_episode_return = 0.7004, mean_episode_step = 54.514, total_loss = 742.16, entropy_loss = -8.1918, pg_loss = 665.35, baseline_loss = 85.008, learner_queue_size = 32, _tick = 147, _time = 1.7374e+09)
[2025-01-20 09:44:37,177][root][INFO] - Step 378880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1819.6, step = 378880, mean_episode_return = 0.7004, mean_episode_step = 54.514, total_loss = 742.16, entropy_loss = -8.1918, pg_loss = 665.35, baseline_loss = 85.008, learner_queue_size = 32, _tick = 147, _time = 1.7374e+09)
[2025-01-20 09:44:42,310][root][INFO] - Step 381440 @ 509.0 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1824.6, step = 381440, mean_episode_return = 0.51015, mean_episode_step = 56.536, total_loss = -33.493, entropy_loss = -8.175, pg_loss = -85.862, baseline_loss = 60.544, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)
[2025-01-20 09:44:47,659][root][INFO] - Step 381440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1830.0, step = 381440, mean_episode_return = 0.51015, mean_episode_step = 56.536, total_loss = -33.493, entropy_loss = -8.175, pg_loss = -85.862, baseline_loss = 60.544, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)
[2025-01-20 09:44:52,669][root][INFO] - Step 381440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1835.1, step = 381440, mean_episode_return = 0.51015, mean_episode_step = 56.536, total_loss = -33.493, entropy_loss = -8.175, pg_loss = -85.862, baseline_loss = 60.544, learner_queue_size = 32, _tick = 148, _time = 1.7374e+09)
[2025-01-20 09:44:57,675][root][INFO] - Step 384000 @ 511.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1840.1, step = 384000, mean_episode_return = 0.61424, mean_episode_step = 46.741, total_loss = 126.1, entropy_loss = -8.1719, pg_loss = 67.809, baseline_loss = 66.461, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)
[2025-01-20 09:45:02,685][root][INFO] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1845.1, step = 384000, mean_episode_return = 0.61424, mean_episode_step = 46.741, total_loss = 126.1, entropy_loss = -8.1719, pg_loss = 67.809, baseline_loss = 66.461, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)
[2025-01-20 09:45:07,770][root][INFO] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1850.2, step = 384000, mean_episode_return = 0.61424, mean_episode_step = 46.741, total_loss = 126.1, entropy_loss = -8.1719, pg_loss = 67.809, baseline_loss = 66.461, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)
[2025-01-20 09:45:12,788][root][INFO] - Step 384000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1855.2, step = 384000, mean_episode_return = 0.61424, mean_episode_step = 46.741, total_loss = 126.1, entropy_loss = -8.1719, pg_loss = 67.809, baseline_loss = 66.461, learner_queue_size = 32, _tick = 149, _time = 1.7374e+09)
[2025-01-20 09:45:17,801][root][INFO] - Step 386560 @ 510.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1860.2, step = 386560, mean_episode_return = 0.48938, mean_episode_step = 52.6, total_loss = -221.04, entropy_loss = -8.1598, pg_loss = -268.07, baseline_loss = 55.186, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)
[2025-01-20 09:45:22,888][root][INFO] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1865.3, step = 386560, mean_episode_return = 0.48938, mean_episode_step = 52.6, total_loss = -221.04, entropy_loss = -8.1598, pg_loss = -268.07, baseline_loss = 55.186, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)
[2025-01-20 09:45:27,973][root][INFO] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1870.4, step = 386560, mean_episode_return = 0.48938, mean_episode_step = 52.6, total_loss = -221.04, entropy_loss = -8.1598, pg_loss = -268.07, baseline_loss = 55.186, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)
[2025-01-20 09:45:33,179][root][INFO] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1875.4, step = 386560, mean_episode_return = 0.48938, mean_episode_step = 52.6, total_loss = -221.04, entropy_loss = -8.1598, pg_loss = -268.07, baseline_loss = 55.186, learner_queue_size = 32, _tick = 150, _time = 1.7374e+09)
[2025-01-20 09:45:38,224][root][INFO] - Step 389120 @ 487.6 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1880.7, step = 389120, mean_episode_return = 0.69229, mean_episode_step = 40.154, total_loss = 231.73, entropy_loss = -8.178, pg_loss = 166.06, baseline_loss = 73.847, learner_queue_size = 32, _tick = 151, _time = 1.7374e+09)
[2025-01-20 09:45:43,564][root][INFO] - Step 389120 @ 0.0 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1885.7, step = 389120, mean_episode_return = 0.69229, mean_episode_step = 40.154, total_loss = 231.73, entropy_loss = -8.178, pg_loss = 166.06, baseline_loss = 73.847, learner_queue_size = 32, _tick = 151, _time = 1.7374e+09)
[2025-01-20 09:45:48,630][root][INFO] - Step 389120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1891.1, step = 389120, mean_episode_return = 0.69229, mean_episode_step = 40.154, total_loss = 231.73, entropy_loss = -8.178, pg_loss = 166.06, baseline_loss = 73.847, learner_queue_size = 32, _tick = 151, _time = 1.7374e+09)
[2025-01-20 09:45:53,698][root][INFO] - Step 389120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1896.1, step = 389120, mean_episode_return = 0.69229, mean_episode_step = 40.154, total_loss = 231.73, entropy_loss = -8.178, pg_loss = 166.06, baseline_loss = 73.847, learner_queue_size = 32, _tick = 151, _time = 1.7374e+09)
[2025-01-20 09:45:58,716][root][INFO] - Step 391680 @ 504.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1901.2, step = 391680, mean_episode_return = 0.71349, mean_episode_step = 57.581, total_loss = -81.84, entropy_loss = -8.1205, pg_loss = -120.95, baseline_loss = 47.235, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)
[2025-01-20 09:46:03,871][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1906.2, step = 391680, mean_episode_return = 0.71349, mean_episode_step = 57.581, total_loss = -81.84, entropy_loss = -8.1205, pg_loss = -120.95, baseline_loss = 47.235, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)
[2025-01-20 09:46:09,538][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1911.8, step = 391680, mean_episode_return = 0.71349, mean_episode_step = 57.581, total_loss = -81.84, entropy_loss = -8.1205, pg_loss = -120.95, baseline_loss = 47.235, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)
[2025-01-20 09:46:14,555][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1917.0, step = 391680, mean_episode_return = 0.71349, mean_episode_step = 57.581, total_loss = -81.84, entropy_loss = -8.1205, pg_loss = -120.95, baseline_loss = 47.235, learner_queue_size = 32, _tick = 152, _time = 1.7374e+09)
[2025-01-20 09:46:19,560][root][INFO] - Step 394240 @ 511.0 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1922.0, step = 394240, mean_episode_return = 0.7186, mean_episode_step = 51.444, total_loss = 18.105, entropy_loss = -8.1007, pg_loss = -16.296, baseline_loss = 42.502, learner_queue_size = 32, _tick = 153, _time = 1.7374e+09)
[2025-01-20 09:46:24,582][root][INFO] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1927.0, step = 394240, mean_episode_return = 0.7186, mean_episode_step = 51.444, total_loss = 18.105, entropy_loss = -8.1007, pg_loss = -16.296, baseline_loss = 42.502, learner_queue_size = 32, _tick = 153, _time = 1.7374e+09)
[2025-01-20 09:46:29,620][root][INFO] - Step 394240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1932.1, step = 394240, mean_episode_return = 0.7186, mean_episode_step = 51.444, total_loss = 18.105, entropy_loss = -8.1007, pg_loss = -16.296, baseline_loss = 42.502, learner_queue_size = 32, _tick = 153, _time = 1.7374e+09)
[2025-01-20 09:46:34,627][root][INFO] - Step 396800 @ 511.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1937.1, step = 396800, mean_episode_return = 0.69916, mean_episode_step = 50.01, total_loss = 454.89, entropy_loss = -8.082, pg_loss = 398.6, baseline_loss = 64.375, learner_queue_size = 32, _tick = 154, _time = 1.7374e+09)
[2025-01-20 09:46:39,673][root][INFO] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1942.1, step = 396800, mean_episode_return = 0.69916, mean_episode_step = 50.01, total_loss = 454.89, entropy_loss = -8.082, pg_loss = 398.6, baseline_loss = 64.375, learner_queue_size = 32, _tick = 154, _time = 1.7374e+09)
[2025-01-20 09:46:44,802][root][INFO] - Step 399360 @ 495.8 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1947.2, step = 399360, mean_episode_return = 0.53921, mean_episode_step = 61.922, total_loss = 18.273, entropy_loss = -8.0776, pg_loss = -23.141, baseline_loss = 49.492, learner_queue_size = 32, _tick = 155, _time = 1.7374e+09)
[2025-01-20 09:46:49,813][root][INFO] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1952.2, step = 399360, mean_episode_return = 0.53921, mean_episode_step = 61.922, total_loss = 18.273, entropy_loss = -8.0776, pg_loss = -23.141, baseline_loss = 49.492, learner_queue_size = 32, _tick = 155, _time = 1.7374e+09)
[2025-01-20 09:46:54,919][root][INFO] - Step 399360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1957.3, step = 399360, mean_episode_return = 0.53921, mean_episode_step = 61.922, total_loss = 18.273, entropy_loss = -8.0776, pg_loss = -23.141, baseline_loss = 49.492, learner_queue_size = 32, _tick = 155, _time = 1.7374e+09)
[2025-01-20 09:47:00,046][root][INFO] - Step 401920 @ 491.0 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1962.5, step = 401920, mean_episode_return = 0.62487, mean_episode_step = 52.043, total_loss = 142.7, entropy_loss = -8.0557, pg_loss = 91.691, baseline_loss = 59.066, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)
[2025-01-20 09:47:05,053][root][INFO] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1967.5, step = 401920, mean_episode_return = 0.62487, mean_episode_step = 52.043, total_loss = 142.7, entropy_loss = -8.0557, pg_loss = 91.691, baseline_loss = 59.066, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)
[2025-01-20 09:47:10,538][root][INFO] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1972.7, step = 401920, mean_episode_return = 0.62487, mean_episode_step = 52.043, total_loss = 142.7, entropy_loss = -8.0557, pg_loss = 91.691, baseline_loss = 59.066, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)
[2025-01-20 09:47:15,577][root][INFO] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1978.0, step = 401920, mean_episode_return = 0.62487, mean_episode_step = 52.043, total_loss = 142.7, entropy_loss = -8.0557, pg_loss = 91.691, baseline_loss = 59.066, learner_queue_size = 32, _tick = 156, _time = 1.7374e+09)
[2025-01-20 09:47:20,669][root][INFO] - Step 404480 @ 500.6 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1983.1, step = 404480, mean_episode_return = 0.55186, mean_episode_step = 46.474, total_loss = -217.0, entropy_loss = -8.0665, pg_loss = -263.3, baseline_loss = 54.367, learner_queue_size = 32, _tick = 157, _time = 1.7374e+09)
[2025-01-20 09:47:25,738][root][INFO] - Step 404480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1988.1, step = 404480, mean_episode_return = 0.55186, mean_episode_step = 46.474, total_loss = -217.0, entropy_loss = -8.0665, pg_loss = -263.3, baseline_loss = 54.367, learner_queue_size = 32, _tick = 157, _time = 1.7374e+09)
[2025-01-20 09:47:30,825][root][INFO] - Step 407040 @ 498.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1993.3, step = 407040, mean_episode_return = 0.61591, mean_episode_step = 45.758, total_loss = -138.52, entropy_loss = -8.067, pg_loss = -185.03, baseline_loss = 54.576, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)
[2025-01-20 09:47:36,204][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1998.4, step = 407040, mean_episode_return = 0.61591, mean_episode_step = 45.758, total_loss = -138.52, entropy_loss = -8.067, pg_loss = -185.03, baseline_loss = 54.576, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)
[2025-01-20 09:47:44,715][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2005.5, step = 407040, mean_episode_return = 0.61591, mean_episode_step = 45.758, total_loss = -138.52, entropy_loss = -8.067, pg_loss = -185.03, baseline_loss = 54.576, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)
[2025-01-20 09:47:49,769][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2010.9, step = 407040, mean_episode_return = 0.61591, mean_episode_step = 45.758, total_loss = -138.52, entropy_loss = -8.067, pg_loss = -185.03, baseline_loss = 54.576, learner_queue_size = 32, _tick = 158, _time = 1.7374e+09)
[2025-01-20 09:47:54,775][root][INFO] - Step 409600 @ 510.7 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2015.9, step = 409600, mean_episode_return = 0.56312, mean_episode_step = 51.528, total_loss = 13.058, entropy_loss = -8.0369, pg_loss = -24.869, baseline_loss = 45.963, learner_queue_size = 32, _tick = 159, _time = 1.7374e+09)
[2025-01-20 09:47:59,874][root][INFO] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2021.0, step = 409600, mean_episode_return = 0.56312, mean_episode_step = 51.528, total_loss = 13.058, entropy_loss = -8.0369, pg_loss = -24.869, baseline_loss = 45.963, learner_queue_size = 32, _tick = 159, _time = 1.7374e+09)
[2025-01-20 09:48:04,893][root][INFO] - Step 409600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2026.0, step = 409600, mean_episode_return = 0.56312, mean_episode_step = 51.528, total_loss = 13.058, entropy_loss = -8.0369, pg_loss = -24.869, baseline_loss = 45.963, learner_queue_size = 32, _tick = 159, _time = 1.7374e+09)
[2025-01-20 09:48:09,904][root][INFO] - Step 412160 @ 509.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 2031.0, step = 412160, mean_episode_return = 0.65491, mean_episode_step = 44.321, total_loss = 117.64, entropy_loss = -8.0156, pg_loss = 66.63, baseline_loss = 59.021, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)
[2025-01-20 09:48:14,911][root][INFO] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2036.0, step = 412160, mean_episode_return = 0.65491, mean_episode_step = 44.321, total_loss = 117.64, entropy_loss = -8.0156, pg_loss = 66.63, baseline_loss = 59.021, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)
[2025-01-20 09:48:20,665][root][INFO] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2041.1, step = 412160, mean_episode_return = 0.65491, mean_episode_step = 44.321, total_loss = 117.64, entropy_loss = -8.0156, pg_loss = 66.63, baseline_loss = 59.021, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)
[2025-01-20 09:48:25,706][root][INFO] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2046.8, step = 412160, mean_episode_return = 0.65491, mean_episode_step = 44.321, total_loss = 117.64, entropy_loss = -8.0156, pg_loss = 66.63, baseline_loss = 59.021, learner_queue_size = 32, _tick = 160, _time = 1.7374e+09)
[2025-01-20 09:48:30,713][root][INFO] - Step 414720 @ 510.8 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 2051.8, step = 414720, mean_episode_return = 0.50356, mean_episode_step = 41.639, total_loss = -82.443, entropy_loss = -8.0104, pg_loss = -124.29, baseline_loss = 49.856, learner_queue_size = 32, _tick = 161, _time = 1.7374e+09)
[2025-01-20 09:48:36,208][root][INFO] - Step 414720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2056.9, step = 414720, mean_episode_return = 0.50356, mean_episode_step = 41.639, total_loss = -82.443, entropy_loss = -8.0104, pg_loss = -124.29, baseline_loss = 49.856, learner_queue_size = 32, _tick = 161, _time = 1.7374e+09)
[2025-01-20 09:48:41,230][root][INFO] - Step 414720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2062.4, step = 414720, mean_episode_return = 0.50356, mean_episode_step = 41.639, total_loss = -82.443, entropy_loss = -8.0104, pg_loss = -124.29, baseline_loss = 49.856, learner_queue_size = 32, _tick = 161, _time = 1.7374e+09)
[2025-01-20 09:48:46,236][root][INFO] - Step 417280 @ 510.7 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 2067.4, step = 417280, mean_episode_return = 0.43768, mean_episode_step = 52.684, total_loss = -176.47, entropy_loss = -8.0021, pg_loss = -220.46, baseline_loss = 51.995, learner_queue_size = 32, _tick = 162, _time = 1.7374e+09)
[2025-01-20 09:48:51,676][root][INFO] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2072.5, step = 417280, mean_episode_return = 0.43768, mean_episode_step = 52.684, total_loss = -176.47, entropy_loss = -8.0021, pg_loss = -220.46, baseline_loss = 51.995, learner_queue_size = 32, _tick = 162, _time = 1.7374e+09)
[2025-01-20 09:48:56,690][root][INFO] - Step 419840 @ 479.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 2077.8, step = 419840, mean_episode_return = 0.49338, mean_episode_step = 49.743, total_loss = -189.24, entropy_loss = -7.9954, pg_loss = -230.95, baseline_loss = 49.712, learner_queue_size = 32, _tick = 163, _time = 1.7374e+09)
[2025-01-20 09:49:01,808][root][INFO] - Step 419840 @ 0.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 2082.8, step = 419840, mean_episode_return = 0.49338, mean_episode_step = 49.743, total_loss = -189.24, entropy_loss = -7.9954, pg_loss = -230.95, baseline_loss = 49.712, learner_queue_size = 32, _tick = 163, _time = 1.7374e+09)
[2025-01-20 09:49:06,947][root][INFO] - Step 419840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2088.0, step = 419840, mean_episode_return = 0.49338, mean_episode_step = 49.743, total_loss = -189.24, entropy_loss = -7.9954, pg_loss = -230.95, baseline_loss = 49.712, learner_queue_size = 32, _tick = 163, _time = 1.7374e+09)
[2025-01-20 09:49:11,970][root][INFO] - Step 422400 @ 502.3 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 2093.1, step = 422400, mean_episode_return = 0.5111, mean_episode_step = 50.307, total_loss = -96.819, entropy_loss = -7.9606, pg_loss = -137.8, baseline_loss = 48.942, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)
[2025-01-20 09:49:17,012][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 2098.1, step = 422400, mean_episode_return = 0.5111, mean_episode_step = 50.307, total_loss = -96.819, entropy_loss = -7.9606, pg_loss = -137.8, baseline_loss = 48.942, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)
[2025-01-20 09:49:22,284][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2103.2, step = 422400, mean_episode_return = 0.5111, mean_episode_step = 50.307, total_loss = -96.819, entropy_loss = -7.9606, pg_loss = -137.8, baseline_loss = 48.942, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)
[2025-01-20 09:49:27,428][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2108.6, step = 422400, mean_episode_return = 0.5111, mean_episode_step = 50.307, total_loss = -96.819, entropy_loss = -7.9606, pg_loss = -137.8, baseline_loss = 48.942, learner_queue_size = 32, _tick = 164, _time = 1.7374e+09)
[2025-01-20 09:49:32,643][root][INFO] - Step 424960 @ 506.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 2113.6, step = 424960, mean_episode_return = 0.47614, mean_episode_step = 46.391, total_loss = 75.688, entropy_loss = -7.9535, pg_loss = 31.493, baseline_loss = 52.148, learner_queue_size = 32, _tick = 165, _time = 1.7374e+09)
[2025-01-20 09:49:37,684][root][INFO] - Step 424960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2118.8, step = 424960, mean_episode_return = 0.47614, mean_episode_step = 46.391, total_loss = 75.688, entropy_loss = -7.9535, pg_loss = 31.493, baseline_loss = 52.148, learner_queue_size = 32, _tick = 165, _time = 1.7374e+09)
[2025-01-20 09:49:42,745][root][INFO] - Step 427520 @ 504.0 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2123.9, step = 427520, mean_episode_return = 0.7429, mean_episode_step = 44.382, total_loss = 85.336, entropy_loss = -7.9672, pg_loss = 45.298, baseline_loss = 48.005, learner_queue_size = 32, _tick = 166, _time = 1.7374e+09)
[2025-01-20 09:49:47,837][root][INFO] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2128.9, step = 427520, mean_episode_return = 0.7429, mean_episode_step = 44.382, total_loss = 85.336, entropy_loss = -7.9672, pg_loss = 45.298, baseline_loss = 48.005, learner_queue_size = 32, _tick = 166, _time = 1.7374e+09)
[2025-01-20 09:49:52,848][root][INFO] - Step 430080 @ 503.8 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 2134.0, step = 430080, mean_episode_return = 0.60688, mean_episode_step = 45.223, total_loss = 150.7, entropy_loss = -7.9581, pg_loss = 97.309, baseline_loss = 61.352, learner_queue_size = 32, _tick = 167, _time = 1.7374e+09)
[2025-01-20 09:49:57,858][root][INFO] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2139.0, step = 430080, mean_episode_return = 0.60688, mean_episode_step = 45.223, total_loss = 150.7, entropy_loss = -7.9581, pg_loss = 97.309, baseline_loss = 61.352, learner_queue_size = 32, _tick = 167, _time = 1.7374e+09)
[2025-01-20 09:50:03,076][root][INFO] - Step 430080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2144.0, step = 430080, mean_episode_return = 0.60688, mean_episode_step = 45.223, total_loss = 150.7, entropy_loss = -7.9581, pg_loss = 97.309, baseline_loss = 61.352, learner_queue_size = 32, _tick = 167, _time = 1.7374e+09)
[2025-01-20 09:50:08,087][root][INFO] - Step 432640 @ 491.0 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 2149.2, step = 432640, mean_episode_return = 0.58496, mean_episode_step = 36.136, total_loss = 106.48, entropy_loss = -7.9561, pg_loss = 60.794, baseline_loss = 53.646, learner_queue_size = 32, _tick = 168, _time = 1.7374e+09)
[2025-01-20 09:50:13,096][root][INFO] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2154.2, step = 432640, mean_episode_return = 0.58496, mean_episode_step = 36.136, total_loss = 106.48, entropy_loss = -7.9561, pg_loss = 60.794, baseline_loss = 53.646, learner_queue_size = 32, _tick = 168, _time = 1.7374e+09)
[2025-01-20 09:50:18,324][root][INFO] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2159.2, step = 432640, mean_episode_return = 0.58496, mean_episode_step = 36.136, total_loss = 106.48, entropy_loss = -7.9561, pg_loss = 60.794, baseline_loss = 53.646, learner_queue_size = 32, _tick = 168, _time = 1.7374e+09)
[2025-01-20 09:50:23,380][root][INFO] - Step 435200 @ 485.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 2164.5, step = 435200, mean_episode_return = 0.63856, mean_episode_step = 46.802, total_loss = 110.0, entropy_loss = -7.9547, pg_loss = 57.993, baseline_loss = 59.962, learner_queue_size = 32, _tick = 169, _time = 1.7374e+09)
[2025-01-20 09:50:28,394][root][INFO] - Step 435200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2169.5, step = 435200, mean_episode_return = 0.63856, mean_episode_step = 46.802, total_loss = 110.0, entropy_loss = -7.9547, pg_loss = 57.993, baseline_loss = 59.962, learner_queue_size = 32, _tick = 169, _time = 1.7374e+09)
[2025-01-20 09:50:33,624][root][INFO] - Step 435200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2174.6, step = 435200, mean_episode_return = 0.63856, mean_episode_step = 46.802, total_loss = 110.0, entropy_loss = -7.9547, pg_loss = 57.993, baseline_loss = 59.962, learner_queue_size = 32, _tick = 169, _time = 1.7374e+09)
[2025-01-20 09:50:38,849][root][INFO] - Step 437760 @ 473.9 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 2180.0, step = 437760, mean_episode_return = 0.5455, mean_episode_step = 50.682, total_loss = 176.65, entropy_loss = -7.9188, pg_loss = 133.48, baseline_loss = 51.084, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)
[2025-01-20 09:50:43,860][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 2185.0, step = 437760, mean_episode_return = 0.5455, mean_episode_step = 50.682, total_loss = 176.65, entropy_loss = -7.9188, pg_loss = 133.48, baseline_loss = 51.084, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)
[2025-01-20 09:50:48,870][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2190.0, step = 437760, mean_episode_return = 0.5455, mean_episode_step = 50.682, total_loss = 176.65, entropy_loss = -7.9188, pg_loss = 133.48, baseline_loss = 51.084, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)
[2025-01-20 09:50:53,941][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2195.0, step = 437760, mean_episode_return = 0.5455, mean_episode_step = 50.682, total_loss = 176.65, entropy_loss = -7.9188, pg_loss = 133.48, baseline_loss = 51.084, learner_queue_size = 32, _tick = 170, _time = 1.7374e+09)
[2025-01-20 09:50:58,950][root][INFO] - Step 440320 @ 506.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2200.1, step = 440320, mean_episode_return = 0.55589, mean_episode_step = 44.72, total_loss = -183.03, entropy_loss = -7.9503, pg_loss = -239.53, baseline_loss = 64.454, learner_queue_size = 32, _tick = 171, _time = 1.7374e+09)
[2025-01-20 09:51:03,968][root][INFO] - Step 440320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2205.1, step = 440320, mean_episode_return = 0.55589, mean_episode_step = 44.72, total_loss = -183.03, entropy_loss = -7.9503, pg_loss = -239.53, baseline_loss = 64.454, learner_queue_size = 32, _tick = 171, _time = 1.7374e+09)
[2025-01-20 09:51:09,126][root][INFO] - Step 440320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2210.1, step = 440320, mean_episode_return = 0.55589, mean_episode_step = 44.72, total_loss = -183.03, entropy_loss = -7.9503, pg_loss = -239.53, baseline_loss = 64.454, learner_queue_size = 32, _tick = 171, _time = 1.7374e+09)
[2025-01-20 09:51:14,166][root][INFO] - Step 440320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2215.3, step = 440320, mean_episode_return = 0.55589, mean_episode_step = 44.72, total_loss = -183.03, entropy_loss = -7.9503, pg_loss = -239.53, baseline_loss = 64.454, learner_queue_size = 32, _tick = 171, _time = 1.7374e+09)
[2025-01-20 09:51:19,172][root][INFO] - Step 442880 @ 511.1 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 2220.3, step = 442880, mean_episode_return = 0.65702, mean_episode_step = 65.646, total_loss = -63.388, entropy_loss = -7.8934, pg_loss = -103.01, baseline_loss = 47.515, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)
[2025-01-20 09:51:24,244][root][INFO] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2225.3, step = 442880, mean_episode_return = 0.65702, mean_episode_step = 65.646, total_loss = -63.388, entropy_loss = -7.8934, pg_loss = -103.01, baseline_loss = 47.515, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)
[2025-01-20 09:51:29,407][root][INFO] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2230.4, step = 442880, mean_episode_return = 0.65702, mean_episode_step = 65.646, total_loss = -63.388, entropy_loss = -7.8934, pg_loss = -103.01, baseline_loss = 47.515, learner_queue_size = 32, _tick = 172, _time = 1.7374e+09)
[2025-01-20 09:51:34,416][root][INFO] - Step 445440 @ 497.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 2235.5, step = 445440, mean_episode_return = 0.37707, mean_episode_step = 39.3, total_loss = -438.48, entropy_loss = -7.9326, pg_loss = -482.22, baseline_loss = 51.676, learner_queue_size = 32, _tick = 173, _time = 1.7374e+09)
[2025-01-20 09:51:39,453][root][INFO] - Step 445440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2240.5, step = 445440, mean_episode_return = 0.37707, mean_episode_step = 39.3, total_loss = -438.48, entropy_loss = -7.9326, pg_loss = -482.22, baseline_loss = 51.676, learner_queue_size = 32, _tick = 173, _time = 1.7374e+09)
[2025-01-20 09:51:44,489][root][INFO] - Step 448000 @ 505.2 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2245.6, step = 448000, mean_episode_return = 0.65198, mean_episode_step = 55.935, total_loss = 107.51, entropy_loss = -7.9019, pg_loss = 57.784, baseline_loss = 57.632, learner_queue_size = 32, _tick = 174, _time = 1.7374e+09)
[2025-01-20 09:51:49,619][root][INFO] - Step 448000 @ 0.0 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 2250.7, step = 448000, mean_episode_return = 0.65198, mean_episode_step = 55.935, total_loss = 107.51, entropy_loss = -7.9019, pg_loss = 57.784, baseline_loss = 57.632, learner_queue_size = 32, _tick = 174, _time = 1.7374e+09)
[2025-01-20 09:51:55,078][root][INFO] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2255.8, step = 448000, mean_episode_return = 0.65198, mean_episode_step = 55.935, total_loss = 107.51, entropy_loss = -7.9019, pg_loss = 57.784, baseline_loss = 57.632, learner_queue_size = 32, _tick = 174, _time = 1.7374e+09)
[2025-01-20 09:52:00,086][root][INFO] - Step 450560 @ 472.0 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 2261.2, step = 450560, mean_episode_return = 0.73, mean_episode_step = 46.804, total_loss = 598.47, entropy_loss = -7.909, pg_loss = 528.63, baseline_loss = 77.747, learner_queue_size = 32, _tick = 175, _time = 1.7374e+09)
[2025-01-20 09:52:05,168][root][INFO] - Step 450560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2266.2, step = 450560, mean_episode_return = 0.73, mean_episode_step = 46.804, total_loss = 598.47, entropy_loss = -7.909, pg_loss = 528.63, baseline_loss = 77.747, learner_queue_size = 32, _tick = 175, _time = 1.7374e+09)
[2025-01-20 09:52:10,201][root][INFO] - Step 453120 @ 501.0 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 2271.3, step = 453120, mean_episode_return = 0.46417, mean_episode_step = 46.533, total_loss = -355.77, entropy_loss = -7.9271, pg_loss = -404.44, baseline_loss = 56.597, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)
[2025-01-20 09:52:15,231][root][INFO] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2276.3, step = 453120, mean_episode_return = 0.46417, mean_episode_step = 46.533, total_loss = -355.77, entropy_loss = -7.9271, pg_loss = -404.44, baseline_loss = 56.597, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)
[2025-01-20 09:52:20,240][root][INFO] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2281.4, step = 453120, mean_episode_return = 0.46417, mean_episode_step = 46.533, total_loss = -355.77, entropy_loss = -7.9271, pg_loss = -404.44, baseline_loss = 56.597, learner_queue_size = 32, _tick = 176, _time = 1.7374e+09)
[2025-01-20 09:52:25,266][root][INFO] - Step 455680 @ 511.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2286.4, step = 455680, mean_episode_return = 0.59955, mean_episode_step = 57.861, total_loss = 189.55, entropy_loss = -7.8868, pg_loss = 147.24, baseline_loss = 50.196, learner_queue_size = 32, _tick = 177, _time = 1.7374e+09)
[2025-01-20 09:52:30,378][root][INFO] - Step 455680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2291.5, step = 455680, mean_episode_return = 0.59955, mean_episode_step = 57.861, total_loss = 189.55, entropy_loss = -7.8868, pg_loss = 147.24, baseline_loss = 50.196, learner_queue_size = 32, _tick = 177, _time = 1.7374e+09)
[2025-01-20 09:52:35,699][root][INFO] - Step 458240 @ 476.3 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2296.8, step = 458240, mean_episode_return = 0.56711, mean_episode_step = 48.474, total_loss = -4.4039, entropy_loss = -7.9102, pg_loss = -53.22, baseline_loss = 56.727, learner_queue_size = 32, _tick = 178, _time = 1.7374e+09)
[2025-01-20 09:52:40,809][root][INFO] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2301.9, step = 458240, mean_episode_return = 0.56711, mean_episode_step = 48.474, total_loss = -4.4039, entropy_loss = -7.9102, pg_loss = -53.22, baseline_loss = 56.727, learner_queue_size = 32, _tick = 178, _time = 1.7374e+09)
[2025-01-20 09:52:45,860][root][INFO] - Step 460800 @ 501.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 2307.0, step = 460800, mean_episode_return = 0.52534, mean_episode_step = 60.021, total_loss = -277.65, entropy_loss = -7.8733, pg_loss = -314.31, baseline_loss = 44.537, learner_queue_size = 32, _tick = 179, _time = 1.7374e+09)
[2025-01-20 09:52:50,866][root][INFO] - Step 460800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2312.0, step = 460800, mean_episode_return = 0.52534, mean_episode_step = 60.021, total_loss = -277.65, entropy_loss = -7.8733, pg_loss = -314.31, baseline_loss = 44.537, learner_queue_size = 32, _tick = 179, _time = 1.7374e+09)
[2025-01-20 09:52:55,878][root][INFO] - Step 460800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2317.0, step = 460800, mean_episode_return = 0.52534, mean_episode_step = 60.021, total_loss = -277.65, entropy_loss = -7.8733, pg_loss = -314.31, baseline_loss = 44.537, learner_queue_size = 32, _tick = 179, _time = 1.7374e+09)
[2025-01-20 09:53:00,884][root][INFO] - Step 463360 @ 510.9 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 2322.0, step = 463360, mean_episode_return = 0.60771, mean_episode_step = 50.609, total_loss = 176.28, entropy_loss = -7.878, pg_loss = 120.6, baseline_loss = 63.553, learner_queue_size = 32, _tick = 180, _time = 1.7374e+09)
[2025-01-20 09:53:05,898][root][INFO] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2327.0, step = 463360, mean_episode_return = 0.60771, mean_episode_step = 50.609, total_loss = 176.28, entropy_loss = -7.878, pg_loss = 120.6, baseline_loss = 63.553, learner_queue_size = 32, _tick = 180, _time = 1.7374e+09)
[2025-01-20 09:53:10,905][root][INFO] - Step 465920 @ 510.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 2332.0, step = 465920, mean_episode_return = 0.51882, mean_episode_step = 55.334, total_loss = -474.49, entropy_loss = -7.9021, pg_loss = -528.32, baseline_loss = 61.728, learner_queue_size = 32, _tick = 181, _time = 1.7374e+09)
[2025-01-20 09:53:15,920][root][INFO] - Step 465920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2337.0, step = 465920, mean_episode_return = 0.51882, mean_episode_step = 55.334, total_loss = -474.49, entropy_loss = -7.9021, pg_loss = -528.32, baseline_loss = 61.728, learner_queue_size = 32, _tick = 181, _time = 1.7374e+09)
[2025-01-20 09:53:20,943][root][INFO] - Step 468480 @ 508.7 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 2342.1, step = 468480, mean_episode_return = 0.51632, mean_episode_step = 45.31, total_loss = -161.81, entropy_loss = -7.9008, pg_loss = -209.1, baseline_loss = 55.196, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)
[2025-01-20 09:53:25,951][root][INFO] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2347.1, step = 468480, mean_episode_return = 0.51632, mean_episode_step = 45.31, total_loss = -161.81, entropy_loss = -7.9008, pg_loss = -209.1, baseline_loss = 55.196, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)
[2025-01-20 09:53:30,962][root][INFO] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2352.1, step = 468480, mean_episode_return = 0.51632, mean_episode_step = 45.31, total_loss = -161.81, entropy_loss = -7.9008, pg_loss = -209.1, baseline_loss = 55.196, learner_queue_size = 32, _tick = 182, _time = 1.7374e+09)
[2025-01-20 09:53:35,970][root][INFO] - Step 471040 @ 510.9 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2357.1, step = 471040, mean_episode_return = 0.70331, mean_episode_step = 44.834, total_loss = -7.1772, entropy_loss = -7.9004, pg_loss = -62.495, baseline_loss = 63.219, learner_queue_size = 32, _tick = 183, _time = 1.7374e+09)
[2025-01-20 09:53:41,145][root][INFO] - Step 471040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2362.1, step = 471040, mean_episode_return = 0.70331, mean_episode_step = 44.834, total_loss = -7.1772, entropy_loss = -7.9004, pg_loss = -62.495, baseline_loss = 63.219, learner_queue_size = 32, _tick = 183, _time = 1.7374e+09)
[2025-01-20 09:53:46,160][root][INFO] - Step 473600 @ 496.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 2367.3, step = 473600, mean_episode_return = 0.68068, mean_episode_step = 58.964, total_loss = 1.3272, entropy_loss = -7.8629, pg_loss = -35.566, baseline_loss = 44.756, learner_queue_size = 32, _tick = 184, _time = 1.7374e+09)
[2025-01-20 09:53:51,168][root][INFO] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2372.3, step = 473600, mean_episode_return = 0.68068, mean_episode_step = 58.964, total_loss = 1.3272, entropy_loss = -7.8629, pg_loss = -35.566, baseline_loss = 44.756, learner_queue_size = 32, _tick = 184, _time = 1.7374e+09)
[2025-01-20 09:53:56,471][root][INFO] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2377.3, step = 473600, mean_episode_return = 0.68068, mean_episode_step = 58.964, total_loss = 1.3272, entropy_loss = -7.8629, pg_loss = -35.566, baseline_loss = 44.756, learner_queue_size = 32, _tick = 184, _time = 1.7374e+09)
[2025-01-20 09:54:01,479][root][INFO] - Step 476160 @ 483.2 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 2382.6, step = 476160, mean_episode_return = 0.60905, mean_episode_step = 40.213, total_loss = 85.476, entropy_loss = -7.8951, pg_loss = 37.596, baseline_loss = 55.775, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)
[2025-01-20 09:54:06,787][root][INFO] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2387.6, step = 476160, mean_episode_return = 0.60905, mean_episode_step = 40.213, total_loss = 85.476, entropy_loss = -7.8951, pg_loss = 37.596, baseline_loss = 55.775, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)
[2025-01-20 09:54:11,808][root][INFO] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2392.9, step = 476160, mean_episode_return = 0.60905, mean_episode_step = 40.213, total_loss = 85.476, entropy_loss = -7.8951, pg_loss = 37.596, baseline_loss = 55.775, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)
[2025-01-20 09:54:16,815][root][INFO] - Step 476160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2397.9, step = 476160, mean_episode_return = 0.60905, mean_episode_step = 40.213, total_loss = 85.476, entropy_loss = -7.8951, pg_loss = 37.596, baseline_loss = 55.775, learner_queue_size = 32, _tick = 185, _time = 1.7374e+09)
[2025-01-20 09:54:21,820][root][INFO] - Step 478720 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 2402.9, step = 478720, mean_episode_return = 0.81449, mean_episode_step = 53.714, total_loss = 646.14, entropy_loss = -7.8618, pg_loss = 590.03, baseline_loss = 63.976, learner_queue_size = 32, _tick = 186, _time = 1.7374e+09)
[2025-01-20 09:54:26,837][root][INFO] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2408.0, step = 478720, mean_episode_return = 0.81449, mean_episode_step = 53.714, total_loss = 646.14, entropy_loss = -7.8618, pg_loss = 590.03, baseline_loss = 63.976, learner_queue_size = 32, _tick = 186, _time = 1.7374e+09)
[2025-01-20 09:54:31,847][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 09:54:32,012][root][INFO] - Step 481280 @ 509.8 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 2413.0, step = 481280, mean_episode_return = 0.56717, mean_episode_step = 52.053, total_loss = -200.1, entropy_loss = -7.8864, pg_loss = -248.73, baseline_loss = 56.516, learner_queue_size = 32, _tick = 187, _time = 1.7374e+09)
[2025-01-20 09:54:37,018][root][INFO] - Step 481280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2418.1, step = 481280, mean_episode_return = 0.56717, mean_episode_step = 52.053, total_loss = -200.1, entropy_loss = -7.8864, pg_loss = -248.73, baseline_loss = 56.516, learner_queue_size = 32, _tick = 187, _time = 1.7374e+09)
[2025-01-20 09:54:42,027][root][INFO] - Step 481280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2423.2, step = 481280, mean_episode_return = 0.56717, mean_episode_step = 52.053, total_loss = -200.1, entropy_loss = -7.8864, pg_loss = -248.73, baseline_loss = 56.516, learner_queue_size = 32, _tick = 187, _time = 1.7374e+09)
[2025-01-20 09:54:47,033][root][INFO] - Step 483840 @ 511.2 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2428.2, step = 483840, mean_episode_return = 0.61863, mean_episode_step = 64.387, total_loss = -500.88, entropy_loss = -7.8473, pg_loss = -527.55, baseline_loss = 34.517, learner_queue_size = 32, _tick = 188, _time = 1.7374e+09)
[2025-01-20 09:54:52,043][root][INFO] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2433.2, step = 483840, mean_episode_return = 0.61863, mean_episode_step = 64.387, total_loss = -500.88, entropy_loss = -7.8473, pg_loss = -527.55, baseline_loss = 34.517, learner_queue_size = 32, _tick = 188, _time = 1.7374e+09)
[2025-01-20 09:54:57,049][root][INFO] - Step 486400 @ 511.0 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 2438.2, step = 486400, mean_episode_return = 0.55695, mean_episode_step = 42.039, total_loss = -313.5, entropy_loss = -7.9007, pg_loss = -355.39, baseline_loss = 49.788, learner_queue_size = 32, _tick = 189, _time = 1.7374e+09)
[2025-01-20 09:55:02,061][root][INFO] - Step 486400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2443.2, step = 486400, mean_episode_return = 0.55695, mean_episode_step = 42.039, total_loss = -313.5, entropy_loss = -7.9007, pg_loss = -355.39, baseline_loss = 49.788, learner_queue_size = 32, _tick = 189, _time = 1.7374e+09)
[2025-01-20 09:55:07,066][root][INFO] - Step 488960 @ 510.9 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 2448.2, step = 488960, mean_episode_return = 0.67464, mean_episode_step = 59.764, total_loss = 283.9, entropy_loss = -7.8523, pg_loss = 237.61, baseline_loss = 54.142, learner_queue_size = 32, _tick = 190, _time = 1.7374e+09)
[2025-01-20 09:55:12,076][root][INFO] - Step 488960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2453.2, step = 488960, mean_episode_return = 0.67464, mean_episode_step = 59.764, total_loss = 283.9, entropy_loss = -7.8523, pg_loss = 237.61, baseline_loss = 54.142, learner_queue_size = 32, _tick = 190, _time = 1.7374e+09)
[2025-01-20 09:55:17,084][root][INFO] - Step 491520 @ 510.7 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 2458.2, step = 491520, mean_episode_return = 0.63193, mean_episode_step = 60.81, total_loss = -191.95, entropy_loss = -7.8654, pg_loss = -229.02, baseline_loss = 44.943, learner_queue_size = 32, _tick = 191, _time = 1.7374e+09)
[2025-01-20 09:55:22,097][root][INFO] - Step 491520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2463.2, step = 491520, mean_episode_return = 0.63193, mean_episode_step = 60.81, total_loss = -191.95, entropy_loss = -7.8654, pg_loss = -229.02, baseline_loss = 44.943, learner_queue_size = 32, _tick = 191, _time = 1.7374e+09)
[2025-01-20 09:55:27,103][root][INFO] - Step 494080 @ 510.9 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 2468.2, step = 494080, mean_episode_return = 0.51214, mean_episode_step = 57.669, total_loss = -447.9, entropy_loss = -7.8609, pg_loss = -491.02, baseline_loss = 50.978, learner_queue_size = 32, _tick = 192, _time = 1.7374e+09)
[2025-01-20 09:55:32,470][root][INFO] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2473.3, step = 494080, mean_episode_return = 0.51214, mean_episode_step = 57.669, total_loss = -447.9, entropy_loss = -7.8609, pg_loss = -491.02, baseline_loss = 50.978, learner_queue_size = 32, _tick = 192, _time = 1.7374e+09)
[2025-01-20 09:55:37,477][root][INFO] - Step 496640 @ 478.2 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 2478.6, step = 496640, mean_episode_return = 0.68463, mean_episode_step = 59.233, total_loss = 167.39, entropy_loss = -7.8639, pg_loss = 109.27, baseline_loss = 65.989, learner_queue_size = 32, _tick = 193, _time = 1.7374e+09)
[2025-01-20 09:55:42,515][root][INFO] - Step 496640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2483.6, step = 496640, mean_episode_return = 0.68463, mean_episode_step = 59.233, total_loss = 167.39, entropy_loss = -7.8639, pg_loss = 109.27, baseline_loss = 65.989, learner_queue_size = 32, _tick = 193, _time = 1.7374e+09)
[2025-01-20 09:55:47,523][root][INFO] - Step 499200 @ 508.3 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 2488.7, step = 499200, mean_episode_return = 0.70854, mean_episode_step = 49.996, total_loss = 497.14, entropy_loss = -7.8545, pg_loss = 431.95, baseline_loss = 73.046, learner_queue_size = 32, _tick = 194, _time = 1.7374e+09)
[2025-01-20 09:55:52,563][root][INFO] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 2493.7, step = 499200, mean_episode_return = 0.70854, mean_episode_step = 49.996, total_loss = 497.14, entropy_loss = -7.8545, pg_loss = 431.95, baseline_loss = 73.046, learner_queue_size = 32, _tick = 194, _time = 1.7374e+09)
[2025-01-20 09:55:57,571][root][INFO] - Step 501760 @ 510.1 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 2498.7, step = 501760, mean_episode_return = 0.65931, mean_episode_step = 40.741, total_loss = 271.68, entropy_loss = -7.8843, pg_loss = 215.5, baseline_loss = 64.067, learner_queue_size = 32, _tick = 195, _time = 1.7374e+09)
[2025-01-20 09:55:57,571][root][INFO] - Learning finished after 501760 steps.
[2025-01-20 09:55:57,572][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 10:53:45,846][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,846][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,848][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,849][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,849][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,850][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,852][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,854][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,855][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,859][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,862][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,862][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,863][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,904][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,936][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,936][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,937][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,937][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,864][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,938][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,939][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,861][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,939][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,934][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,921][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,944][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,944][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,945][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,931][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,947][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,947][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,933][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,948][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,932][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,928][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,942][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,937][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,951][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,952][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,953][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,954][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,955][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,957][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,865][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,960][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,963][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,866][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,967][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,969][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,972][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,972][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,867][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,975][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,976][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,972][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,978][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,983][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,868][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,986][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,994][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,995][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,998][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,991][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,955][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,869][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,006][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,007][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,009][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,015][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,869][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,019][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,874][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,023][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,025][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,874][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,875][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:46,051][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,875][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,876][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,877][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,878][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,878][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,878][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,879][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,880][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,882][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,881][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,882][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,882][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,883][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,884][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,884][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,886][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,886][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,886][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,887][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,888][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,889][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,888][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,889][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,872][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,891][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,891][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,892][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,891][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,892][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,892][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,892][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,893][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,879][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,895][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,895][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,895][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,896][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,896][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,897][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,893][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,897][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,897][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,894][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,898][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,899][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,899][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,900][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,900][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,901][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,901][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,902][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,902][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,903][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,904][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,901][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,905][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,905][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,906][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,906][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,907][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,907][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,907][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,884][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,908][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,909][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,909][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,909][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,910][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,911][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,911][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,912][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,912][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,913][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,913][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,914][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,915][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,915][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,915][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,916][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,893][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,917][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,917][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,918][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,918][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,918][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,879][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,920][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,886][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,900][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,921][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,922][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,922][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,924][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,897][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,885][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,925][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,926][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,927][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,928][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,890][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,914][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,929][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,912][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,895][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,930][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,931][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,931][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,932][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,932][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,932][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,933][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,933][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,911][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,894][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,934][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,934][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 10:53:45,934][nle.env.base][INFO] - Not saving any NLE data.
