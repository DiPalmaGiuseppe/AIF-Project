[2025-01-19 22:56:16,358][root][INFO] - name: null
wandb: false
project: minihack
entity: entity_name
group: default
mock: false
single_ttyrec: true
num_seeds: 0
write_profiler_trace: false
relative_reward: false
fn_penalty_step: constant
penalty_time: 0.0
penalty_step: -0.001
reward_lose: 0
reward_win: 1
save_tty: false
character: null
mode: train
env: MiniHack-Combat-Skill-v0
obs_keys: glyphs,chars,colors,specials,blstats,message
num_actors: 256
total_steps: 500000
batch_size: 32
unroll_length: 80
num_learner_threads: 1
num_inference_threads: 1
disable_cuda: false
learner_device: cuda:0
actor_device: cuda:0
max_learner_queue_size: null
model: baseline
use_lstm: true
hidden_dim: 256
embedding_dim: 64
glyph_type: all_cat
equalize_input_dim: false
equalize_factor: 2
layers: 5
crop_model: cnn
crop_dim: 9
use_index_select: true
entropy_cost: 0.001
baseline_cost: 0.5
discounting: 0.999
reward_clipping: none
normalize_reward: true
learning_rate: 0.0002
grad_norm_clipping: 40
alpha: 0.99
momentum: 0
epsilon: 1.0e-06
state_counter: none
no_extrinsic: false
int:
  twoheaded: true
  input: full
  intrinsic_weight: 0.1
  discounting: 0.99
  baseline_cost: 0.5
  episodic: true
  reward_clipping: none
  normalize_reward: true
ride:
  count_norm: true
  forward_cost: 1
  inverse_cost: 0.1
  hidden_dim: 128
rnd:
  forward_cost: 0.01
msg:
  model: none
  hidden_dim: 64
  embedding_dim: 32

[2025-01-19 22:56:16,410][root][INFO] - Symlinked log directory: /opt/minihack/latest
[2025-01-19 22:56:16,411][root][INFO] - Found archive directory: /opt/minihack/archives
[2025-01-19 22:56:16,415][root][INFO] - Logging results to /opt/minihack
[2025-01-19 22:56:16,454][palaas/out][INFO] - Found log directory: /opt/minihack
[2025-01-19 22:56:16,454][palaas/out][INFO] - Saving arguments to /opt/minihack/meta.json
[2025-01-19 22:56:16,455][palaas/out][INFO] - Saving messages to /opt/minihack/out.log
[2025-01-19 22:56:16,455][palaas/out][INFO] - Saving logs data to /opt/minihack/logs.csv
[2025-01-19 22:56:16,455][palaas/out][INFO] - Saving logs' fields to /opt/minihack/fields.csv
[2025-01-19 22:56:16,455][root][INFO] - Not using CUDA.
[2025-01-19 22:56:16,464][root][INFO] - Using model baseline
[2025-01-19 22:56:16,464][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,524][root][INFO] - Number of model parameters: 4264078
[2025-01-19 22:56:16,524][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,585][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,587][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,588][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,588][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,591][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,591][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,594][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,595][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,595][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,597][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,599][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,601][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,602][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,602][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,605][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,605][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,611][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,611][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,611][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,615][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,625][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,625][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,598][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,627][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,632][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,651][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,653][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,657][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,660][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,667][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,684][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,695][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,702][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,705][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,681][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,708][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,714][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,714][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,715][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,716][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,718][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,739][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:16,772][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-19 22:56:21,582][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 4. Other stats: (train_seconds = 5.0)
[2025-01-19 22:56:28,456][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 5. Learner queue size: 3. Other stats: (train_seconds = 11.9)
[2025-01-19 22:56:33,461][root][INFO] - Step 0 @ 0.0 SPS. Inference batcher size: 127. Learner queue size: 4. Other stats: (train_seconds = 16.9)
[2025-01-19 22:56:37,296][palaas/out][INFO] - Updated log fields: ['_tick', '_time', 'train_seconds', 'step', 'mean_episode_return', 'mean_episode_step', 'total_loss', 'entropy_loss', 'pg_loss', 'baseline_loss', 'learner_queue_size']
[2025-01-19 22:56:38,466][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.tar
[2025-01-19 22:56:38,504][root][INFO] - Step 2560 @ 511.5 SPS. Inference batcher size: 74. Learner queue size: 6. Other stats: (train_seconds = 21.9, step = 2560, mean_episode_return = -0.063, mean_episode_step = 51.177, total_loss = 1349.3, entropy_loss = -11.371, pg_loss = 1031.7, baseline_loss = 329.04, learner_queue_size = 6, _tick = 0, _time = 1.7373e+09)
[2025-01-19 22:56:43,511][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 129. Learner queue size: 7. Other stats: (train_seconds = 26.9, step = 2560, mean_episode_return = -0.063, mean_episode_step = 51.177, total_loss = 1349.3, entropy_loss = -11.371, pg_loss = 1031.7, baseline_loss = 329.04, learner_queue_size = 6, _tick = 0, _time = 1.7373e+09)
[2025-01-19 22:56:48,517][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 129. Learner queue size: 10. Other stats: (train_seconds = 31.9, step = 2560, mean_episode_return = -0.063, mean_episode_step = 51.177, total_loss = 1349.3, entropy_loss = -11.371, pg_loss = 1031.7, baseline_loss = 329.04, learner_queue_size = 6, _tick = 0, _time = 1.7373e+09)
[2025-01-19 22:56:53,523][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 28. Learner queue size: 32. Other stats: (train_seconds = 36.9, step = 2560, mean_episode_return = -0.063, mean_episode_step = 51.177, total_loss = 1349.3, entropy_loss = -11.371, pg_loss = 1031.7, baseline_loss = 329.04, learner_queue_size = 6, _tick = 0, _time = 1.7373e+09)
[2025-01-19 22:56:58,528][root][INFO] - Step 2560 @ 0.0 SPS. Inference batcher size: 27. Learner queue size: 32. Other stats: (train_seconds = 41.9, step = 2560, mean_episode_return = -0.063, mean_episode_step = 51.177, total_loss = 1349.3, entropy_loss = -11.371, pg_loss = 1031.7, baseline_loss = 329.04, learner_queue_size = 6, _tick = 0, _time = 1.7373e+09)
[2025-01-19 22:57:03,534][root][INFO] - Step 5120 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 47.0, step = 5120, mean_episode_return = 0.10917, mean_episode_step = 50.755, total_loss = -2400.4, entropy_loss = -11.362, pg_loss = -2498.4, baseline_loss = 109.39, learner_queue_size = 32, _tick = 1, _time = 1.7373e+09)
[2025-01-19 22:57:08,539][root][INFO] - Step 5120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 52.0, step = 5120, mean_episode_return = 0.10917, mean_episode_step = 50.755, total_loss = -2400.4, entropy_loss = -11.362, pg_loss = -2498.4, baseline_loss = 109.39, learner_queue_size = 32, _tick = 1, _time = 1.7373e+09)
[2025-01-19 22:57:13,544][root][INFO] - Step 7680 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 57.0, step = 7680, mean_episode_return = -0.02875, mean_episode_step = 35.135, total_loss = -113.38, entropy_loss = -11.355, pg_loss = -168.18, baseline_loss = 66.151, learner_queue_size = 32, _tick = 2, _time = 1.7373e+09)
[2025-01-19 22:57:18,549][root][INFO] - Step 10240 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 62.0, step = 10240, mean_episode_return = 0.0057143, mean_episode_step = 32.719, total_loss = 814.97, entropy_loss = -11.166, pg_loss = 734.81, baseline_loss = 91.322, learner_queue_size = 32, _tick = 3, _time = 1.7373e+09)
[2025-01-19 22:57:23,556][root][INFO] - Step 10240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 67.0, step = 10240, mean_episode_return = 0.0057143, mean_episode_step = 32.719, total_loss = 814.97, entropy_loss = -11.166, pg_loss = 734.81, baseline_loss = 91.322, learner_queue_size = 32, _tick = 3, _time = 1.7373e+09)
[2025-01-19 22:57:28,562][root][INFO] - Step 12800 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 72.0, step = 12800, mean_episode_return = -0.046579, mean_episode_step = 38.891, total_loss = -145.06, entropy_loss = -11.126, pg_loss = -154.24, baseline_loss = 20.304, learner_queue_size = 32, _tick = 4, _time = 1.7373e+09)
[2025-01-19 22:57:33,567][root][INFO] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 77.0, step = 12800, mean_episode_return = -0.046579, mean_episode_step = 38.891, total_loss = -145.06, entropy_loss = -11.126, pg_loss = -154.24, baseline_loss = 20.304, learner_queue_size = 32, _tick = 4, _time = 1.7373e+09)
[2025-01-19 22:57:38,572][root][INFO] - Step 12800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 82.0, step = 12800, mean_episode_return = -0.046579, mean_episode_step = 38.891, total_loss = -145.06, entropy_loss = -11.126, pg_loss = -154.24, baseline_loss = 20.304, learner_queue_size = 32, _tick = 4, _time = 1.7373e+09)
[2025-01-19 22:57:43,578][root][INFO] - Step 15360 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 87.0, step = 15360, mean_episode_return = -0.057421, mean_episode_step = 44.274, total_loss = 435.95, entropy_loss = -11.12, pg_loss = 392.13, baseline_loss = 54.947, learner_queue_size = 32, _tick = 5, _time = 1.7373e+09)
[2025-01-19 22:57:48,583][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 92.0, step = 15360, mean_episode_return = -0.057421, mean_episode_step = 44.274, total_loss = 435.95, entropy_loss = -11.12, pg_loss = 392.13, baseline_loss = 54.947, learner_queue_size = 32, _tick = 5, _time = 1.7373e+09)
[2025-01-19 22:57:53,588][root][INFO] - Step 15360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 97.0, step = 15360, mean_episode_return = -0.057421, mean_episode_step = 44.274, total_loss = 435.95, entropy_loss = -11.12, pg_loss = 392.13, baseline_loss = 54.947, learner_queue_size = 32, _tick = 5, _time = 1.7373e+09)
[2025-01-19 22:57:58,593][root][INFO] - Step 17920 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 102.0, step = 17920, mean_episode_return = -0.054435, mean_episode_step = 56.0, total_loss = 426.98, entropy_loss = -11.111, pg_loss = 359.74, baseline_loss = 78.346, learner_queue_size = 32, _tick = 6, _time = 1.7373e+09)
[2025-01-19 22:58:03,599][root][INFO] - Step 17920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 107.0, step = 17920, mean_episode_return = -0.054435, mean_episode_step = 56.0, total_loss = 426.98, entropy_loss = -11.111, pg_loss = 359.74, baseline_loss = 78.346, learner_queue_size = 32, _tick = 6, _time = 1.7373e+09)
[2025-01-19 22:58:08,605][root][INFO] - Step 20480 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 112.0, step = 20480, mean_episode_return = -0.067643, mean_episode_step = 61.042, total_loss = -197.31, entropy_loss = -11.072, pg_loss = -207.58, baseline_loss = 21.342, learner_queue_size = 32, _tick = 7, _time = 1.7373e+09)
[2025-01-19 22:58:13,611][root][INFO] - Step 20480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 117.0, step = 20480, mean_episode_return = -0.067643, mean_episode_step = 61.042, total_loss = -197.31, entropy_loss = -11.072, pg_loss = -207.58, baseline_loss = 21.342, learner_queue_size = 32, _tick = 7, _time = 1.7373e+09)
[2025-01-19 22:58:18,617][root][INFO] - Step 23040 @ 511.3 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 122.0, step = 23040, mean_episode_return = -0.036704, mean_episode_step = 59.123, total_loss = -78.501, entropy_loss = -11.031, pg_loss = -69.261, baseline_loss = 1.7908, learner_queue_size = 32, _tick = 8, _time = 1.7373e+09)
[2025-01-19 22:58:23,623][root][INFO] - Step 25600 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 127.0, step = 25600, mean_episode_return = -0.034267, mean_episode_step = 49.293, total_loss = 262.67, entropy_loss = -11.005, pg_loss = 262.84, baseline_loss = 10.843, learner_queue_size = 32, _tick = 9, _time = 1.7373e+09)
[2025-01-19 22:58:28,628][root][INFO] - Step 25600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 132.0, step = 25600, mean_episode_return = -0.034267, mean_episode_step = 49.293, total_loss = 262.67, entropy_loss = -11.005, pg_loss = 262.84, baseline_loss = 10.843, learner_queue_size = 32, _tick = 9, _time = 1.7373e+09)
[2025-01-19 22:58:33,636][root][INFO] - Step 28160 @ 511.2 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 137.1, step = 28160, mean_episode_return = -0.05169, mean_episode_step = 54.166, total_loss = 735.76, entropy_loss = -10.987, pg_loss = 617.17, baseline_loss = 129.58, learner_queue_size = 32, _tick = 10, _time = 1.7373e+09)
[2025-01-19 22:58:38,642][root][INFO] - Step 28160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 142.1, step = 28160, mean_episode_return = -0.05169, mean_episode_step = 54.166, total_loss = 735.76, entropy_loss = -10.987, pg_loss = 617.17, baseline_loss = 129.58, learner_queue_size = 32, _tick = 10, _time = 1.7373e+09)
[2025-01-19 22:58:43,647][root][INFO] - Step 30720 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 147.1, step = 30720, mean_episode_return = -0.058577, mean_episode_step = 49.858, total_loss = 523.36, entropy_loss = -10.966, pg_loss = 401.57, baseline_loss = 132.75, learner_queue_size = 32, _tick = 11, _time = 1.7373e+09)
[2025-01-19 22:58:48,652][root][INFO] - Step 30720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 152.1, step = 30720, mean_episode_return = -0.058577, mean_episode_step = 49.858, total_loss = 523.36, entropy_loss = -10.966, pg_loss = 401.57, baseline_loss = 132.75, learner_queue_size = 32, _tick = 11, _time = 1.7373e+09)
[2025-01-19 22:58:53,657][root][INFO] - Step 33280 @ 511.5 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 157.1, step = 33280, mean_episode_return = -0.039062, mean_episode_step = 56.406, total_loss = -125.32, entropy_loss = -10.891, pg_loss = -165.31, baseline_loss = 50.881, learner_queue_size = 32, _tick = 12, _time = 1.7373e+09)
[2025-01-19 22:58:58,663][root][INFO] - Step 33280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 162.1, step = 33280, mean_episode_return = -0.039062, mean_episode_step = 56.406, total_loss = -125.32, entropy_loss = -10.891, pg_loss = -165.31, baseline_loss = 50.881, learner_queue_size = 32, _tick = 12, _time = 1.7373e+09)
[2025-01-19 22:59:03,669][root][INFO] - Step 35840 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 167.1, step = 35840, mean_episode_return = -0.061382, mean_episode_step = 50.195, total_loss = -160.51, entropy_loss = -10.863, pg_loss = -178.13, baseline_loss = 28.484, learner_queue_size = 32, _tick = 13, _time = 1.7373e+09)
[2025-01-19 22:59:08,674][root][INFO] - Step 35840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 172.1, step = 35840, mean_episode_return = -0.061382, mean_episode_step = 50.195, total_loss = -160.51, entropy_loss = -10.863, pg_loss = -178.13, baseline_loss = 28.484, learner_queue_size = 32, _tick = 13, _time = 1.7373e+09)
[2025-01-19 22:59:13,680][root][INFO] - Step 38400 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 177.1, step = 38400, mean_episode_return = 0.037268, mean_episode_step = 54.47, total_loss = 494.89, entropy_loss = -10.829, pg_loss = 389.37, baseline_loss = 116.35, learner_queue_size = 32, _tick = 14, _time = 1.7373e+09)
[2025-01-19 22:59:18,685][root][INFO] - Step 38400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 182.1, step = 38400, mean_episode_return = 0.037268, mean_episode_step = 54.47, total_loss = 494.89, entropy_loss = -10.829, pg_loss = 389.37, baseline_loss = 116.35, learner_queue_size = 32, _tick = 14, _time = 1.7373e+09)
[2025-01-19 22:59:23,690][root][INFO] - Step 40960 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 187.1, step = 40960, mean_episode_return = 0.017971, mean_episode_step = 51.602, total_loss = 604.59, entropy_loss = -10.76, pg_loss = 453.41, baseline_loss = 161.94, learner_queue_size = 32, _tick = 15, _time = 1.7373e+09)
[2025-01-19 22:59:28,695][root][INFO] - Step 43520 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 192.1, step = 43520, mean_episode_return = -0.064447, mean_episode_step = 49.932, total_loss = -252.49, entropy_loss = -10.677, pg_loss = -288.53, baseline_loss = 46.714, learner_queue_size = 32, _tick = 16, _time = 1.7373e+09)
[2025-01-19 22:59:33,700][root][INFO] - Step 43520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 197.1, step = 43520, mean_episode_return = -0.064447, mean_episode_step = 49.932, total_loss = -252.49, entropy_loss = -10.677, pg_loss = -288.53, baseline_loss = 46.714, learner_queue_size = 32, _tick = 16, _time = 1.7373e+09)
[2025-01-19 22:59:38,706][root][INFO] - Step 46080 @ 511.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 202.1, step = 46080, mean_episode_return = -0.00090238, mean_episode_step = 52.87, total_loss = -52.261, entropy_loss = -10.631, pg_loss = -104.3, baseline_loss = 62.668, learner_queue_size = 32, _tick = 17, _time = 1.7373e+09)
[2025-01-19 22:59:43,711][root][INFO] - Step 46080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 207.1, step = 46080, mean_episode_return = -0.00090238, mean_episode_step = 52.87, total_loss = -52.261, entropy_loss = -10.631, pg_loss = -104.3, baseline_loss = 62.668, learner_queue_size = 32, _tick = 17, _time = 1.7373e+09)
[2025-01-19 22:59:48,716][root][INFO] - Step 48640 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 212.1, step = 48640, mean_episode_return = 0.072021, mean_episode_step = 49.005, total_loss = 1036.9, entropy_loss = -10.482, pg_loss = 844.65, baseline_loss = 202.77, learner_queue_size = 32, _tick = 18, _time = 1.7373e+09)
[2025-01-19 22:59:53,724][root][INFO] - Step 51200 @ 511.2 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 217.1, step = 51200, mean_episode_return = 0.03051, mean_episode_step = 44.074, total_loss = 104.4, entropy_loss = -10.419, pg_loss = 29.087, baseline_loss = 85.729, learner_queue_size = 32, _tick = 19, _time = 1.7373e+09)
[2025-01-19 22:59:58,730][root][INFO] - Step 51200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 222.1, step = 51200, mean_episode_return = 0.03051, mean_episode_step = 44.074, total_loss = 104.4, entropy_loss = -10.419, pg_loss = 29.087, baseline_loss = 85.729, learner_queue_size = 32, _tick = 19, _time = 1.7373e+09)
[2025-01-19 23:00:03,735][root][INFO] - Step 53760 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 227.2, step = 53760, mean_episode_return = 0.026837, mean_episode_step = 47.205, total_loss = 633.37, entropy_loss = -10.455, pg_loss = 502.41, baseline_loss = 141.42, learner_queue_size = 32, _tick = 20, _time = 1.7373e+09)
[2025-01-19 23:00:08,741][root][INFO] - Step 53760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 232.2, step = 53760, mean_episode_return = 0.026837, mean_episode_step = 47.205, total_loss = 633.37, entropy_loss = -10.455, pg_loss = 502.41, baseline_loss = 141.42, learner_queue_size = 32, _tick = 20, _time = 1.7373e+09)
[2025-01-19 23:00:13,746][root][INFO] - Step 56320 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 237.2, step = 56320, mean_episode_return = 0.01698, mean_episode_step = 43.714, total_loss = 517.48, entropy_loss = -10.443, pg_loss = 396.14, baseline_loss = 131.78, learner_queue_size = 32, _tick = 21, _time = 1.7373e+09)
[2025-01-19 23:00:18,751][root][INFO] - Step 58880 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 242.2, step = 58880, mean_episode_return = -0.0032499, mean_episode_step = 48.459, total_loss = 390.49, entropy_loss = -10.418, pg_loss = 232.16, baseline_loss = 168.75, learner_queue_size = 32, _tick = 22, _time = 1.7373e+09)
[2025-01-19 23:00:23,756][root][INFO] - Step 58880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 247.2, step = 58880, mean_episode_return = -0.0032499, mean_episode_step = 48.459, total_loss = 390.49, entropy_loss = -10.418, pg_loss = 232.16, baseline_loss = 168.75, learner_queue_size = 32, _tick = 22, _time = 1.7373e+09)
[2025-01-19 23:00:28,761][root][INFO] - Step 61440 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 252.2, step = 61440, mean_episode_return = -0.0061702, mean_episode_step = 49.214, total_loss = -472.21, entropy_loss = -10.429, pg_loss = -551.54, baseline_loss = 89.754, learner_queue_size = 32, _tick = 23, _time = 1.7373e+09)
[2025-01-19 23:00:33,766][root][INFO] - Step 64000 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 257.2, step = 64000, mean_episode_return = 0.025933, mean_episode_step = 45.436, total_loss = 108.36, entropy_loss = -10.348, pg_loss = -31.191, baseline_loss = 149.9, learner_queue_size = 32, _tick = 24, _time = 1.7373e+09)
[2025-01-19 23:00:38,772][root][INFO] - Step 64000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 262.2, step = 64000, mean_episode_return = 0.025933, mean_episode_step = 45.436, total_loss = 108.36, entropy_loss = -10.348, pg_loss = -31.191, baseline_loss = 149.9, learner_queue_size = 32, _tick = 24, _time = 1.7373e+09)
[2025-01-19 23:00:43,777][root][INFO] - Step 66560 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 267.2, step = 66560, mean_episode_return = -0.02416, mean_episode_step = 45.557, total_loss = -66.039, entropy_loss = -10.233, pg_loss = -147.26, baseline_loss = 91.45, learner_queue_size = 32, _tick = 25, _time = 1.7373e+09)
[2025-01-19 23:00:48,782][root][INFO] - Step 69120 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 272.2, step = 69120, mean_episode_return = 0.073974, mean_episode_step = 63.982, total_loss = 231.33, entropy_loss = -10.165, pg_loss = 132.97, baseline_loss = 108.52, learner_queue_size = 32, _tick = 26, _time = 1.7373e+09)
[2025-01-19 23:00:53,786][root][INFO] - Step 69120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 277.2, step = 69120, mean_episode_return = 0.073974, mean_episode_step = 63.982, total_loss = 231.33, entropy_loss = -10.165, pg_loss = 132.97, baseline_loss = 108.52, learner_queue_size = 32, _tick = 26, _time = 1.7373e+09)
[2025-01-19 23:00:58,792][root][INFO] - Step 71680 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 282.2, step = 71680, mean_episode_return = 0.1251, mean_episode_step = 51.877, total_loss = 219.78, entropy_loss = -10.191, pg_loss = 107.91, baseline_loss = 122.06, learner_queue_size = 32, _tick = 27, _time = 1.7373e+09)
[2025-01-19 23:01:03,799][root][INFO] - Step 74240 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 287.2, step = 74240, mean_episode_return = 0.050911, mean_episode_step = 52.452, total_loss = -348.2, entropy_loss = -10.131, pg_loss = -420.14, baseline_loss = 82.068, learner_queue_size = 32, _tick = 28, _time = 1.7373e+09)
[2025-01-19 23:01:08,804][root][INFO] - Step 74240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 292.2, step = 74240, mean_episode_return = 0.050911, mean_episode_step = 52.452, total_loss = -348.2, entropy_loss = -10.131, pg_loss = -420.14, baseline_loss = 82.068, learner_queue_size = 32, _tick = 28, _time = 1.7373e+09)
[2025-01-19 23:01:13,811][root][INFO] - Step 76800 @ 511.3 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 297.2, step = 76800, mean_episode_return = 0.12043, mean_episode_step = 46.403, total_loss = 160.88, entropy_loss = -10.093, pg_loss = 71.237, baseline_loss = 99.734, learner_queue_size = 32, _tick = 29, _time = 1.7373e+09)
[2025-01-19 23:01:18,816][root][INFO] - Step 76800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 302.2, step = 76800, mean_episode_return = 0.12043, mean_episode_step = 46.403, total_loss = 160.88, entropy_loss = -10.093, pg_loss = 71.237, baseline_loss = 99.734, learner_queue_size = 32, _tick = 29, _time = 1.7373e+09)
[2025-01-19 23:01:23,821][root][INFO] - Step 79360 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 307.2, step = 79360, mean_episode_return = 0.073881, mean_episode_step = 60.215, total_loss = 255.03, entropy_loss = -10.07, pg_loss = 107.07, baseline_loss = 158.03, learner_queue_size = 32, _tick = 30, _time = 1.7373e+09)
[2025-01-19 23:01:28,827][root][INFO] - Step 81920 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 312.2, step = 81920, mean_episode_return = 0.080286, mean_episode_step = 45.814, total_loss = -5.3408, entropy_loss = -10.024, pg_loss = -129.47, baseline_loss = 134.15, learner_queue_size = 32, _tick = 31, _time = 1.7373e+09)
[2025-01-19 23:01:33,832][root][INFO] - Step 81920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 317.3, step = 81920, mean_episode_return = 0.080286, mean_episode_step = 45.814, total_loss = -5.3408, entropy_loss = -10.024, pg_loss = -129.47, baseline_loss = 134.15, learner_queue_size = 32, _tick = 31, _time = 1.7373e+09)
[2025-01-19 23:01:38,837][root][INFO] - Step 84480 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 322.3, step = 84480, mean_episode_return = 0.0714, mean_episode_step = 59.803, total_loss = -107.15, entropy_loss = -10.027, pg_loss = -191.16, baseline_loss = 94.041, learner_queue_size = 32, _tick = 32, _time = 1.7373e+09)
[2025-01-19 23:01:43,843][root][INFO] - Step 87040 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 327.3, step = 87040, mean_episode_return = 0.091429, mean_episode_step = 55.198, total_loss = 483.69, entropy_loss = -9.9615, pg_loss = 350.9, baseline_loss = 142.75, learner_queue_size = 32, _tick = 33, _time = 1.7373e+09)
[2025-01-19 23:01:48,848][root][INFO] - Step 87040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 332.3, step = 87040, mean_episode_return = 0.091429, mean_episode_step = 55.198, total_loss = 483.69, entropy_loss = -9.9615, pg_loss = 350.9, baseline_loss = 142.75, learner_queue_size = 32, _tick = 33, _time = 1.7373e+09)
[2025-01-19 23:01:53,853][root][INFO] - Step 89600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 337.3, step = 89600, mean_episode_return = 0.11658, mean_episode_step = 60.023, total_loss = 330.02, entropy_loss = -9.9394, pg_loss = 194.81, baseline_loss = 145.15, learner_queue_size = 32, _tick = 34, _time = 1.7373e+09)
[2025-01-19 23:01:58,858][root][INFO] - Step 92160 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 342.3, step = 92160, mean_episode_return = 0.073151, mean_episode_step = 49.656, total_loss = 266.59, entropy_loss = -9.9707, pg_loss = 112.66, baseline_loss = 163.9, learner_queue_size = 32, _tick = 35, _time = 1.7373e+09)
[2025-01-19 23:02:03,864][root][INFO] - Step 92160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 347.3, step = 92160, mean_episode_return = 0.073151, mean_episode_step = 49.656, total_loss = 266.59, entropy_loss = -9.9707, pg_loss = 112.66, baseline_loss = 163.9, learner_queue_size = 32, _tick = 35, _time = 1.7373e+09)
[2025-01-19 23:02:08,870][root][INFO] - Step 94720 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 352.3, step = 94720, mean_episode_return = 0.11839, mean_episode_step = 44.214, total_loss = -306.11, entropy_loss = -9.9364, pg_loss = -442.57, baseline_loss = 146.4, learner_queue_size = 32, _tick = 36, _time = 1.7373e+09)
[2025-01-19 23:02:13,876][root][INFO] - Step 97280 @ 511.4 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 357.3, step = 97280, mean_episode_return = 0.11841, mean_episode_step = 43.546, total_loss = -663.33, entropy_loss = -9.9439, pg_loss = -776.92, baseline_loss = 123.53, learner_queue_size = 32, _tick = 37, _time = 1.7373e+09)
[2025-01-19 23:02:18,881][root][INFO] - Step 97280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 362.3, step = 97280, mean_episode_return = 0.11841, mean_episode_step = 43.546, total_loss = -663.33, entropy_loss = -9.9439, pg_loss = -776.92, baseline_loss = 123.53, learner_queue_size = 32, _tick = 37, _time = 1.7373e+09)
[2025-01-19 23:02:23,886][root][INFO] - Step 99840 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 367.3, step = 99840, mean_episode_return = 0.001077, mean_episode_step = 50.12, total_loss = -1129.8, entropy_loss = -9.9238, pg_loss = -1172.4, baseline_loss = 52.434, learner_queue_size = 32, _tick = 38, _time = 1.7373e+09)
[2025-01-19 23:02:28,891][root][INFO] - Step 102400 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 372.3, step = 102400, mean_episode_return = 0.13969, mean_episode_step = 50.082, total_loss = -153.32, entropy_loss = -9.9194, pg_loss = -278.81, baseline_loss = 135.4, learner_queue_size = 32, _tick = 39, _time = 1.7373e+09)
[2025-01-19 23:02:33,896][root][INFO] - Step 102400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 377.3, step = 102400, mean_episode_return = 0.13969, mean_episode_step = 50.082, total_loss = -153.32, entropy_loss = -9.9194, pg_loss = -278.81, baseline_loss = 135.4, learner_queue_size = 32, _tick = 39, _time = 1.7373e+09)
[2025-01-19 23:02:38,902][root][INFO] - Step 104960 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 382.3, step = 104960, mean_episode_return = 0.080175, mean_episode_step = 57.287, total_loss = -125.0, entropy_loss = -9.8935, pg_loss = -185.2, baseline_loss = 70.087, learner_queue_size = 32, _tick = 40, _time = 1.7373e+09)
[2025-01-19 23:02:43,908][root][INFO] - Step 107520 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 387.3, step = 107520, mean_episode_return = 0.074811, mean_episode_step = 42.376, total_loss = 98.223, entropy_loss = -9.9198, pg_loss = -7.6952, baseline_loss = 115.84, learner_queue_size = 32, _tick = 41, _time = 1.7373e+09)
[2025-01-19 23:02:48,914][root][INFO] - Step 107520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 392.3, step = 107520, mean_episode_return = 0.074811, mean_episode_step = 42.376, total_loss = 98.223, entropy_loss = -9.9198, pg_loss = -7.6952, baseline_loss = 115.84, learner_queue_size = 32, _tick = 41, _time = 1.7373e+09)
[2025-01-19 23:02:53,919][root][INFO] - Step 110080 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 397.3, step = 110080, mean_episode_return = 0.18543, mean_episode_step = 58.36, total_loss = 465.81, entropy_loss = -9.8022, pg_loss = 358.03, baseline_loss = 117.58, learner_queue_size = 32, _tick = 42, _time = 1.7373e+09)
[2025-01-19 23:02:58,924][root][INFO] - Step 112640 @ 511.5 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 402.3, step = 112640, mean_episode_return = 0.17344, mean_episode_step = 59.919, total_loss = -165.72, entropy_loss = -9.8008, pg_loss = -242.41, baseline_loss = 86.498, learner_queue_size = 32, _tick = 43, _time = 1.7373e+09)
[2025-01-19 23:03:03,925][root][INFO] - Step 112640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 407.3, step = 112640, mean_episode_return = 0.17344, mean_episode_step = 59.919, total_loss = -165.72, entropy_loss = -9.8008, pg_loss = -242.41, baseline_loss = 86.498, learner_queue_size = 32, _tick = 43, _time = 1.7373e+09)
[2025-01-19 23:03:08,931][root][INFO] - Step 115200 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 412.4, step = 115200, mean_episode_return = 0.061674, mean_episode_step = 49.252, total_loss = 136.15, entropy_loss = -9.7828, pg_loss = 42.602, baseline_loss = 103.33, learner_queue_size = 32, _tick = 44, _time = 1.7373e+09)
[2025-01-19 23:03:13,936][root][INFO] - Step 115200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 417.4, step = 115200, mean_episode_return = 0.061674, mean_episode_step = 49.252, total_loss = 136.15, entropy_loss = -9.7828, pg_loss = 42.602, baseline_loss = 103.33, learner_queue_size = 32, _tick = 44, _time = 1.7373e+09)
[2025-01-19 23:03:18,941][root][INFO] - Step 117760 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 422.4, step = 117760, mean_episode_return = 0.15912, mean_episode_step = 56.477, total_loss = 37.13, entropy_loss = -9.6817, pg_loss = -41.75, baseline_loss = 88.562, learner_queue_size = 32, _tick = 45, _time = 1.7373e+09)
[2025-01-19 23:03:23,946][root][INFO] - Step 120320 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 427.4, step = 120320, mean_episode_return = 0.17568, mean_episode_step = 52.386, total_loss = 615.02, entropy_loss = -9.5852, pg_loss = 495.82, baseline_loss = 128.79, learner_queue_size = 32, _tick = 46, _time = 1.7373e+09)
[2025-01-19 23:03:28,951][root][INFO] - Step 120320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 432.4, step = 120320, mean_episode_return = 0.17568, mean_episode_step = 52.386, total_loss = 615.02, entropy_loss = -9.5852, pg_loss = 495.82, baseline_loss = 128.79, learner_queue_size = 32, _tick = 46, _time = 1.7373e+09)
[2025-01-19 23:03:33,956][root][INFO] - Step 122880 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 437.4, step = 122880, mean_episode_return = 0.17551, mean_episode_step = 53.975, total_loss = -678.72, entropy_loss = -9.7101, pg_loss = -751.85, baseline_loss = 82.845, learner_queue_size = 32, _tick = 47, _time = 1.7373e+09)
[2025-01-19 23:03:38,962][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.25.tar
[2025-01-19 23:03:39,020][root][INFO] - Step 125440 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 442.4, step = 125440, mean_episode_return = 0.17824, mean_episode_step = 54.896, total_loss = -661.01, entropy_loss = -9.6733, pg_loss = -718.43, baseline_loss = 67.093, learner_queue_size = 32, _tick = 48, _time = 1.7373e+09)
[2025-01-19 23:03:44,025][root][INFO] - Step 125440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 447.4, step = 125440, mean_episode_return = 0.17824, mean_episode_step = 54.896, total_loss = -661.01, entropy_loss = -9.6733, pg_loss = -718.43, baseline_loss = 67.093, learner_queue_size = 32, _tick = 48, _time = 1.7373e+09)
[2025-01-19 23:03:49,029][root][INFO] - Step 128000 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 452.4, step = 128000, mean_episode_return = 0.23103, mean_episode_step = 65.395, total_loss = 182.69, entropy_loss = -9.661, pg_loss = 91.568, baseline_loss = 100.78, learner_queue_size = 32, _tick = 49, _time = 1.7373e+09)
[2025-01-19 23:03:54,034][root][INFO] - Step 130560 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 457.5, step = 130560, mean_episode_return = 0.16874, mean_episode_step = 56.523, total_loss = -101.08, entropy_loss = -9.6037, pg_loss = -181.11, baseline_loss = 89.625, learner_queue_size = 32, _tick = 50, _time = 1.7373e+09)
[2025-01-19 23:03:59,039][root][INFO] - Step 130560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 462.5, step = 130560, mean_episode_return = 0.16874, mean_episode_step = 56.523, total_loss = -101.08, entropy_loss = -9.6037, pg_loss = -181.11, baseline_loss = 89.625, learner_queue_size = 32, _tick = 50, _time = 1.7373e+09)
[2025-01-19 23:04:04,044][root][INFO] - Step 133120 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 467.5, step = 133120, mean_episode_return = 0.15395, mean_episode_step = 48.991, total_loss = 617.04, entropy_loss = -9.3889, pg_loss = 517.82, baseline_loss = 108.61, learner_queue_size = 32, _tick = 51, _time = 1.7373e+09)
[2025-01-19 23:04:09,050][root][INFO] - Step 135680 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 472.5, step = 135680, mean_episode_return = 0.075914, mean_episode_step = 72.047, total_loss = -185.44, entropy_loss = -9.3969, pg_loss = -232.25, baseline_loss = 56.215, learner_queue_size = 32, _tick = 52, _time = 1.7373e+09)
[2025-01-19 23:04:14,055][root][INFO] - Step 135680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 477.5, step = 135680, mean_episode_return = 0.075914, mean_episode_step = 72.047, total_loss = -185.44, entropy_loss = -9.3969, pg_loss = -232.25, baseline_loss = 56.215, learner_queue_size = 32, _tick = 52, _time = 1.7373e+09)
[2025-01-19 23:04:19,061][root][INFO] - Step 138240 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 482.5, step = 138240, mean_episode_return = 0.079349, mean_episode_step = 61.642, total_loss = 250.91, entropy_loss = -9.3677, pg_loss = 178.29, baseline_loss = 81.986, learner_queue_size = 32, _tick = 53, _time = 1.7373e+09)
[2025-01-19 23:04:24,066][root][INFO] - Step 140800 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 487.5, step = 140800, mean_episode_return = 0.18525, mean_episode_step = 59.222, total_loss = -100.82, entropy_loss = -9.3342, pg_loss = -202.56, baseline_loss = 111.07, learner_queue_size = 32, _tick = 54, _time = 1.7373e+09)
[2025-01-19 23:04:29,071][root][INFO] - Step 140800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 492.5, step = 140800, mean_episode_return = 0.18525, mean_episode_step = 59.222, total_loss = -100.82, entropy_loss = -9.3342, pg_loss = -202.56, baseline_loss = 111.07, learner_queue_size = 32, _tick = 54, _time = 1.7373e+09)
[2025-01-19 23:04:34,076][root][INFO] - Step 143360 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 497.5, step = 143360, mean_episode_return = 0.23666, mean_episode_step = 62.208, total_loss = -18.34, entropy_loss = -9.3025, pg_loss = -77.593, baseline_loss = 68.555, learner_queue_size = 32, _tick = 55, _time = 1.7373e+09)
[2025-01-19 23:04:39,082][root][INFO] - Step 145920 @ 511.4 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 502.5, step = 145920, mean_episode_return = 0.07674, mean_episode_step = 55.576, total_loss = -367.33, entropy_loss = -9.3065, pg_loss = -432.32, baseline_loss = 74.294, learner_queue_size = 32, _tick = 56, _time = 1.7373e+09)
[2025-01-19 23:04:44,087][root][INFO] - Step 145920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 507.5, step = 145920, mean_episode_return = 0.07674, mean_episode_step = 55.576, total_loss = -367.33, entropy_loss = -9.3065, pg_loss = -432.32, baseline_loss = 74.294, learner_queue_size = 32, _tick = 56, _time = 1.7373e+09)
[2025-01-19 23:04:49,092][root][INFO] - Step 148480 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 512.5, step = 148480, mean_episode_return = 0.23092, mean_episode_step = 58.954, total_loss = 451.73, entropy_loss = -9.2132, pg_loss = 376.0, baseline_loss = 84.943, learner_queue_size = 32, _tick = 57, _time = 1.7373e+09)
[2025-01-19 23:04:54,097][root][INFO] - Step 151040 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 517.5, step = 151040, mean_episode_return = 0.14669, mean_episode_step = 76.316, total_loss = 246.33, entropy_loss = -9.2479, pg_loss = 151.16, baseline_loss = 104.42, learner_queue_size = 32, _tick = 58, _time = 1.7373e+09)
[2025-01-19 23:04:59,102][root][INFO] - Step 151040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 522.5, step = 151040, mean_episode_return = 0.14669, mean_episode_step = 76.316, total_loss = 246.33, entropy_loss = -9.2479, pg_loss = 151.16, baseline_loss = 104.42, learner_queue_size = 32, _tick = 58, _time = 1.7373e+09)
[2025-01-19 23:05:04,107][root][INFO] - Step 153600 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 527.5, step = 153600, mean_episode_return = 0.12468, mean_episode_step = 57.977, total_loss = -137.32, entropy_loss = -9.2143, pg_loss = -191.96, baseline_loss = 63.851, learner_queue_size = 32, _tick = 59, _time = 1.7373e+09)
[2025-01-19 23:05:09,112][root][INFO] - Step 156160 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 532.5, step = 156160, mean_episode_return = 0.11855, mean_episode_step = 49.726, total_loss = -71.303, entropy_loss = -9.1827, pg_loss = -142.18, baseline_loss = 80.064, learner_queue_size = 32, _tick = 60, _time = 1.7373e+09)
[2025-01-19 23:05:14,117][root][INFO] - Step 156160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 537.5, step = 156160, mean_episode_return = 0.11855, mean_episode_step = 49.726, total_loss = -71.303, entropy_loss = -9.1827, pg_loss = -142.18, baseline_loss = 80.064, learner_queue_size = 32, _tick = 60, _time = 1.7373e+09)
[2025-01-19 23:05:19,124][root][INFO] - Step 158720 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 542.5, step = 158720, mean_episode_return = 0.31461, mean_episode_step = 86.757, total_loss = -119.27, entropy_loss = -9.0008, pg_loss = -157.89, baseline_loss = 47.623, learner_queue_size = 32, _tick = 61, _time = 1.7373e+09)
[2025-01-19 23:05:24,130][root][INFO] - Step 161280 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 547.5, step = 161280, mean_episode_return = 0.17172, mean_episode_step = 74.677, total_loss = 101.89, entropy_loss = -8.8486, pg_loss = 69.003, baseline_loss = 41.735, learner_queue_size = 32, _tick = 62, _time = 1.7373e+09)
[2025-01-19 23:05:29,136][root][INFO] - Step 161280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 552.6, step = 161280, mean_episode_return = 0.17172, mean_episode_step = 74.677, total_loss = 101.89, entropy_loss = -8.8486, pg_loss = 69.003, baseline_loss = 41.735, learner_queue_size = 32, _tick = 62, _time = 1.7373e+09)
[2025-01-19 23:05:34,142][root][INFO] - Step 163840 @ 511.4 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 557.6, step = 163840, mean_episode_return = 0.14272, mean_episode_step = 69.265, total_loss = 11.239, entropy_loss = -8.8711, pg_loss = -29.646, baseline_loss = 49.756, learner_queue_size = 32, _tick = 63, _time = 1.7373e+09)
[2025-01-19 23:05:39,148][root][INFO] - Step 166400 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 562.6, step = 166400, mean_episode_return = 0.33412, mean_episode_step = 65.829, total_loss = 455.53, entropy_loss = -8.9032, pg_loss = 371.48, baseline_loss = 92.944, learner_queue_size = 32, _tick = 64, _time = 1.7373e+09)
[2025-01-19 23:05:44,153][root][INFO] - Step 166400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 567.6, step = 166400, mean_episode_return = 0.33412, mean_episode_step = 65.829, total_loss = 455.53, entropy_loss = -8.9032, pg_loss = 371.48, baseline_loss = 92.944, learner_queue_size = 32, _tick = 64, _time = 1.7373e+09)
[2025-01-19 23:05:49,159][root][INFO] - Step 168960 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 572.6, step = 168960, mean_episode_return = 0.20792, mean_episode_step = 62.9, total_loss = 121.18, entropy_loss = -9.0737, pg_loss = 34.77, baseline_loss = 95.487, learner_queue_size = 32, _tick = 65, _time = 1.7373e+09)
[2025-01-19 23:05:54,165][root][INFO] - Step 171520 @ 511.4 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 577.6, step = 171520, mean_episode_return = 0.18881, mean_episode_step = 63.71, total_loss = 231.64, entropy_loss = -8.9649, pg_loss = 132.27, baseline_loss = 108.34, learner_queue_size = 32, _tick = 66, _time = 1.7373e+09)
[2025-01-19 23:05:59,171][root][INFO] - Step 171520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 582.6, step = 171520, mean_episode_return = 0.18881, mean_episode_step = 63.71, total_loss = 231.64, entropy_loss = -8.9649, pg_loss = 132.27, baseline_loss = 108.34, learner_queue_size = 32, _tick = 66, _time = 1.7373e+09)
[2025-01-19 23:06:04,176][root][INFO] - Step 174080 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 587.6, step = 174080, mean_episode_return = 0.1559, mean_episode_step = 66.602, total_loss = -195.66, entropy_loss = -9.0065, pg_loss = -277.47, baseline_loss = 90.813, learner_queue_size = 32, _tick = 67, _time = 1.7373e+09)
[2025-01-19 23:06:09,182][root][INFO] - Step 176640 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 592.6, step = 176640, mean_episode_return = 0.26927, mean_episode_step = 62.635, total_loss = 617.02, entropy_loss = -8.9272, pg_loss = 517.01, baseline_loss = 108.94, learner_queue_size = 32, _tick = 68, _time = 1.7373e+09)
[2025-01-19 23:06:14,188][root][INFO] - Step 176640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 597.6, step = 176640, mean_episode_return = 0.26927, mean_episode_step = 62.635, total_loss = 617.02, entropy_loss = -8.9272, pg_loss = 517.01, baseline_loss = 108.94, learner_queue_size = 32, _tick = 68, _time = 1.7373e+09)
[2025-01-19 23:06:19,194][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-19 23:06:19,240][root][INFO] - Step 179200 @ 511.4 SPS. Inference batcher size: 24. Learner queue size: 32. Other stats: (train_seconds = 602.6, step = 179200, mean_episode_return = 0.22098, mean_episode_step = 59.541, total_loss = -345.83, entropy_loss = -8.9866, pg_loss = -412.71, baseline_loss = 75.866, learner_queue_size = 32, _tick = 69, _time = 1.7373e+09)
[2025-01-19 23:06:24,245][root][INFO] - Step 181760 @ 506.8 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 607.7, step = 181760, mean_episode_return = 0.32893, mean_episode_step = 72.998, total_loss = 88.743, entropy_loss = -8.8706, pg_loss = 21.867, baseline_loss = 75.746, learner_queue_size = 32, _tick = 70, _time = 1.7373e+09)
[2025-01-19 23:06:29,250][root][INFO] - Step 181760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 612.7, step = 181760, mean_episode_return = 0.32893, mean_episode_step = 72.998, total_loss = 88.743, entropy_loss = -8.8706, pg_loss = 21.867, baseline_loss = 75.746, learner_queue_size = 32, _tick = 70, _time = 1.7373e+09)
[2025-01-19 23:06:34,255][root][INFO] - Step 184320 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 617.7, step = 184320, mean_episode_return = 0.25002, mean_episode_step = 58.123, total_loss = 337.29, entropy_loss = -8.9857, pg_loss = 209.42, baseline_loss = 136.86, learner_queue_size = 32, _tick = 71, _time = 1.7373e+09)
[2025-01-19 23:06:39,261][root][INFO] - Step 186880 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 622.7, step = 186880, mean_episode_return = 0.2213, mean_episode_step = 76.421, total_loss = -299.96, entropy_loss = -8.9497, pg_loss = -361.42, baseline_loss = 70.411, learner_queue_size = 32, _tick = 72, _time = 1.7373e+09)
[2025-01-19 23:06:44,266][root][INFO] - Step 186880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 627.7, step = 186880, mean_episode_return = 0.2213, mean_episode_step = 76.421, total_loss = -299.96, entropy_loss = -8.9497, pg_loss = -361.42, baseline_loss = 70.411, learner_queue_size = 32, _tick = 72, _time = 1.7373e+09)
[2025-01-19 23:06:49,272][root][INFO] - Step 189440 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 632.7, step = 189440, mean_episode_return = 0.46058, mean_episode_step = 62.348, total_loss = 686.02, entropy_loss = -8.8943, pg_loss = 566.94, baseline_loss = 127.98, learner_queue_size = 32, _tick = 73, _time = 1.7373e+09)
[2025-01-19 23:06:54,277][root][INFO] - Step 192000 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 637.7, step = 192000, mean_episode_return = 0.35198, mean_episode_step = 65.141, total_loss = -91.119, entropy_loss = -8.989, pg_loss = -181.99, baseline_loss = 99.862, learner_queue_size = 32, _tick = 74, _time = 1.7373e+09)
[2025-01-19 23:06:59,282][root][INFO] - Step 192000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 642.7, step = 192000, mean_episode_return = 0.35198, mean_episode_step = 65.141, total_loss = -91.119, entropy_loss = -8.989, pg_loss = -181.99, baseline_loss = 99.862, learner_queue_size = 32, _tick = 74, _time = 1.7373e+09)
[2025-01-19 23:07:04,287][root][INFO] - Step 194560 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 647.7, step = 194560, mean_episode_return = 0.28949, mean_episode_step = 57.907, total_loss = -52.967, entropy_loss = -8.9924, pg_loss = -155.75, baseline_loss = 111.77, learner_queue_size = 32, _tick = 75, _time = 1.7373e+09)
[2025-01-19 23:07:09,293][root][INFO] - Step 194560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 652.7, step = 194560, mean_episode_return = 0.28949, mean_episode_step = 57.907, total_loss = -52.967, entropy_loss = -8.9924, pg_loss = -155.75, baseline_loss = 111.77, learner_queue_size = 32, _tick = 75, _time = 1.7373e+09)
[2025-01-19 23:07:14,298][root][INFO] - Step 197120 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 657.7, step = 197120, mean_episode_return = 0.14588, mean_episode_step = 72.108, total_loss = -447.79, entropy_loss = -8.9561, pg_loss = -500.31, baseline_loss = 61.478, learner_queue_size = 32, _tick = 76, _time = 1.7373e+09)
[2025-01-19 23:07:19,304][root][INFO] - Step 199680 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 662.7, step = 199680, mean_episode_return = 0.40933, mean_episode_step = 74.369, total_loss = 235.06, entropy_loss = -8.8672, pg_loss = 176.5, baseline_loss = 67.426, learner_queue_size = 32, _tick = 77, _time = 1.7373e+09)
[2025-01-19 23:07:24,309][root][INFO] - Step 199680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 667.7, step = 199680, mean_episode_return = 0.40933, mean_episode_step = 74.369, total_loss = 235.06, entropy_loss = -8.8672, pg_loss = 176.5, baseline_loss = 67.426, learner_queue_size = 32, _tick = 77, _time = 1.7373e+09)
[2025-01-19 23:07:29,314][root][INFO] - Step 202240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 672.7, step = 202240, mean_episode_return = 0.40956, mean_episode_step = 77.129, total_loss = -91.712, entropy_loss = -8.9588, pg_loss = -171.55, baseline_loss = 88.801, learner_queue_size = 32, _tick = 78, _time = 1.7373e+09)
[2025-01-19 23:07:34,320][root][INFO] - Step 204800 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 677.7, step = 204800, mean_episode_return = 0.26795, mean_episode_step = 70.928, total_loss = 1.4691, entropy_loss = -8.9357, pg_loss = -67.743, baseline_loss = 78.148, learner_queue_size = 32, _tick = 79, _time = 1.7373e+09)
[2025-01-19 23:07:39,325][root][INFO] - Step 204800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 682.7, step = 204800, mean_episode_return = 0.26795, mean_episode_step = 70.928, total_loss = 1.4691, entropy_loss = -8.9357, pg_loss = -67.743, baseline_loss = 78.148, learner_queue_size = 32, _tick = 79, _time = 1.7373e+09)
[2025-01-19 23:07:44,331][root][INFO] - Step 207360 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 687.7, step = 207360, mean_episode_return = 0.34756, mean_episode_step = 68.897, total_loss = 466.47, entropy_loss = -8.9363, pg_loss = 318.72, baseline_loss = 156.68, learner_queue_size = 32, _tick = 80, _time = 1.7373e+09)
[2025-01-19 23:07:49,336][root][INFO] - Step 209920 @ 511.4 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 692.8, step = 209920, mean_episode_return = 0.24821, mean_episode_step = 71.626, total_loss = -105.4, entropy_loss = -8.9793, pg_loss = -194.87, baseline_loss = 98.448, learner_queue_size = 32, _tick = 81, _time = 1.7373e+09)
[2025-01-19 23:07:54,342][root][INFO] - Step 209920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 697.8, step = 209920, mean_episode_return = 0.24821, mean_episode_step = 71.626, total_loss = -105.4, entropy_loss = -8.9793, pg_loss = -194.87, baseline_loss = 98.448, learner_queue_size = 32, _tick = 81, _time = 1.7373e+09)
[2025-01-19 23:07:59,347][root][INFO] - Step 212480 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 702.8, step = 212480, mean_episode_return = 0.23586, mean_episode_step = 65.298, total_loss = -384.58, entropy_loss = -8.9912, pg_loss = -456.16, baseline_loss = 80.577, learner_queue_size = 32, _tick = 82, _time = 1.7373e+09)
[2025-01-19 23:08:04,353][root][INFO] - Step 215040 @ 511.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 707.8, step = 215040, mean_episode_return = 0.21202, mean_episode_step = 62.037, total_loss = -16.377, entropy_loss = -8.9742, pg_loss = -78.898, baseline_loss = 71.495, learner_queue_size = 32, _tick = 83, _time = 1.7373e+09)
[2025-01-19 23:08:09,358][root][INFO] - Step 215040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 712.8, step = 215040, mean_episode_return = 0.21202, mean_episode_step = 62.037, total_loss = -16.377, entropy_loss = -8.9742, pg_loss = -78.898, baseline_loss = 71.495, learner_queue_size = 32, _tick = 83, _time = 1.7373e+09)
[2025-01-19 23:08:14,363][root][INFO] - Step 217600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 717.8, step = 217600, mean_episode_return = 0.14268, mean_episode_step = 52.452, total_loss = 184.99, entropy_loss = -8.9257, pg_loss = 96.493, baseline_loss = 97.426, learner_queue_size = 32, _tick = 84, _time = 1.7373e+09)
[2025-01-19 23:08:19,368][root][INFO] - Step 220160 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 722.8, step = 220160, mean_episode_return = 0.31862, mean_episode_step = 79.199, total_loss = -96.18, entropy_loss = -8.8752, pg_loss = -153.96, baseline_loss = 66.655, learner_queue_size = 32, _tick = 85, _time = 1.7373e+09)
[2025-01-19 23:08:24,373][root][INFO] - Step 220160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 727.8, step = 220160, mean_episode_return = 0.31862, mean_episode_step = 79.199, total_loss = -96.18, entropy_loss = -8.8752, pg_loss = -153.96, baseline_loss = 66.655, learner_queue_size = 32, _tick = 85, _time = 1.7373e+09)
[2025-01-19 23:08:29,378][root][INFO] - Step 222720 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 732.8, step = 222720, mean_episode_return = 0.27037, mean_episode_step = 72.124, total_loss = -37.13, entropy_loss = -8.8455, pg_loss = -81.835, baseline_loss = 53.55, learner_queue_size = 32, _tick = 86, _time = 1.7373e+09)
[2025-01-19 23:08:34,383][root][INFO] - Step 225280 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 737.8, step = 225280, mean_episode_return = 0.26211, mean_episode_step = 63.719, total_loss = -75.086, entropy_loss = -8.9598, pg_loss = -142.01, baseline_loss = 75.887, learner_queue_size = 32, _tick = 87, _time = 1.7373e+09)
[2025-01-19 23:08:39,388][root][INFO] - Step 225280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 742.8, step = 225280, mean_episode_return = 0.26211, mean_episode_step = 63.719, total_loss = -75.086, entropy_loss = -8.9598, pg_loss = -142.01, baseline_loss = 75.887, learner_queue_size = 32, _tick = 87, _time = 1.7373e+09)
[2025-01-19 23:08:44,394][root][INFO] - Step 227840 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 747.8, step = 227840, mean_episode_return = 0.26058, mean_episode_step = 59.96, total_loss = 653.2, entropy_loss = -8.9413, pg_loss = 548.97, baseline_loss = 113.17, learner_queue_size = 32, _tick = 88, _time = 1.7373e+09)
[2025-01-19 23:08:49,401][root][INFO] - Step 230400 @ 511.3 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 752.8, step = 230400, mean_episode_return = 0.15473, mean_episode_step = 65.052, total_loss = -441.22, entropy_loss = -8.9724, pg_loss = -485.34, baseline_loss = 53.095, learner_queue_size = 32, _tick = 89, _time = 1.7373e+09)
[2025-01-19 23:08:54,407][root][INFO] - Step 230400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 757.8, step = 230400, mean_episode_return = 0.15473, mean_episode_step = 65.052, total_loss = -441.22, entropy_loss = -8.9724, pg_loss = -485.34, baseline_loss = 53.095, learner_queue_size = 32, _tick = 89, _time = 1.7373e+09)
[2025-01-19 23:08:59,412][root][INFO] - Step 232960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 762.8, step = 232960, mean_episode_return = 0.29061, mean_episode_step = 62.98, total_loss = 470.99, entropy_loss = -8.9475, pg_loss = 359.83, baseline_loss = 120.1, learner_queue_size = 32, _tick = 90, _time = 1.7373e+09)
[2025-01-19 23:09:04,418][root][INFO] - Step 235520 @ 511.4 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 767.8, step = 235520, mean_episode_return = 0.31106, mean_episode_step = 66.619, total_loss = -204.95, entropy_loss = -8.9734, pg_loss = -280.88, baseline_loss = 84.894, learner_queue_size = 32, _tick = 91, _time = 1.7373e+09)
[2025-01-19 23:09:09,423][root][INFO] - Step 235520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 772.8, step = 235520, mean_episode_return = 0.31106, mean_episode_step = 66.619, total_loss = -204.95, entropy_loss = -8.9734, pg_loss = -280.88, baseline_loss = 84.894, learner_queue_size = 32, _tick = 91, _time = 1.7373e+09)
[2025-01-19 23:09:14,428][root][INFO] - Step 238080 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 777.8, step = 238080, mean_episode_return = 0.22605, mean_episode_step = 67.313, total_loss = 52.122, entropy_loss = -8.8794, pg_loss = -6.7562, baseline_loss = 67.758, learner_queue_size = 32, _tick = 92, _time = 1.7373e+09)
[2025-01-19 23:09:19,433][root][INFO] - Step 240640 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 782.9, step = 240640, mean_episode_return = 0.3251, mean_episode_step = 77.546, total_loss = 367.5, entropy_loss = -8.816, pg_loss = 282.67, baseline_loss = 93.64, learner_queue_size = 32, _tick = 93, _time = 1.7373e+09)
[2025-01-19 23:09:24,434][root][INFO] - Step 240640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 787.9, step = 240640, mean_episode_return = 0.3251, mean_episode_step = 77.546, total_loss = 367.5, entropy_loss = -8.816, pg_loss = 282.67, baseline_loss = 93.64, learner_queue_size = 32, _tick = 93, _time = 1.7373e+09)
[2025-01-19 23:09:29,439][root][INFO] - Step 243200 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 792.9, step = 243200, mean_episode_return = 0.20124, mean_episode_step = 61.696, total_loss = 62.737, entropy_loss = -8.9317, pg_loss = -14.364, baseline_loss = 86.033, learner_queue_size = 32, _tick = 94, _time = 1.7373e+09)
[2025-01-19 23:09:34,445][root][INFO] - Step 245760 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 797.9, step = 245760, mean_episode_return = 0.25519, mean_episode_step = 65.554, total_loss = -287.21, entropy_loss = -8.8885, pg_loss = -335.66, baseline_loss = 57.334, learner_queue_size = 32, _tick = 95, _time = 1.7373e+09)
[2025-01-19 23:09:39,450][root][INFO] - Step 245760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 802.9, step = 245760, mean_episode_return = 0.25519, mean_episode_step = 65.554, total_loss = -287.21, entropy_loss = -8.8885, pg_loss = -335.66, baseline_loss = 57.334, learner_queue_size = 32, _tick = 95, _time = 1.7373e+09)
[2025-01-19 23:09:44,456][root][INFO] - Step 248320 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 807.9, step = 248320, mean_episode_return = 0.39031, mean_episode_step = 57.564, total_loss = 116.47, entropy_loss = -8.8949, pg_loss = 33.629, baseline_loss = 91.734, learner_queue_size = 32, _tick = 96, _time = 1.7373e+09)
[2025-01-19 23:09:49,461][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.5.tar
[2025-01-19 23:09:49,509][root][INFO] - Step 250880 @ 511.4 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 812.9, step = 250880, mean_episode_return = 0.23149, mean_episode_step = 60.307, total_loss = 353.35, entropy_loss = -8.7773, pg_loss = 275.12, baseline_loss = 87.007, learner_queue_size = 32, _tick = 97, _time = 1.7373e+09)
[2025-01-19 23:09:54,515][root][INFO] - Step 250880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 817.9, step = 250880, mean_episode_return = 0.23149, mean_episode_step = 60.307, total_loss = 353.35, entropy_loss = -8.7773, pg_loss = 275.12, baseline_loss = 87.007, learner_queue_size = 32, _tick = 97, _time = 1.7373e+09)
[2025-01-19 23:09:59,520][root][INFO] - Step 253440 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 822.9, step = 253440, mean_episode_return = 0.25759, mean_episode_step = 73.299, total_loss = -76.646, entropy_loss = -8.7869, pg_loss = -144.89, baseline_loss = 77.034, learner_queue_size = 32, _tick = 98, _time = 1.7373e+09)
[2025-01-19 23:10:04,526][root][INFO] - Step 256000 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 827.9, step = 256000, mean_episode_return = 0.28352, mean_episode_step = 65.813, total_loss = -49.472, entropy_loss = -8.6032, pg_loss = -82.824, baseline_loss = 41.956, learner_queue_size = 32, _tick = 99, _time = 1.7373e+09)
[2025-01-19 23:10:09,531][root][INFO] - Step 256000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 833.0, step = 256000, mean_episode_return = 0.28352, mean_episode_step = 65.813, total_loss = -49.472, entropy_loss = -8.6032, pg_loss = -82.824, baseline_loss = 41.956, learner_queue_size = 32, _tick = 99, _time = 1.7373e+09)
[2025-01-19 23:10:14,536][root][INFO] - Step 258560 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 838.0, step = 258560, mean_episode_return = 0.21506, mean_episode_step = 57.882, total_loss = 105.02, entropy_loss = -8.6152, pg_loss = 51.817, baseline_loss = 61.82, learner_queue_size = 32, _tick = 100, _time = 1.7373e+09)
[2025-01-19 23:10:19,542][root][INFO] - Step 261120 @ 511.4 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 843.0, step = 261120, mean_episode_return = 0.2776, mean_episode_step = 65.348, total_loss = 219.19, entropy_loss = -8.7339, pg_loss = 134.68, baseline_loss = 93.237, learner_queue_size = 32, _tick = 101, _time = 1.7373e+09)
[2025-01-19 23:10:24,547][root][INFO] - Step 261120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 848.0, step = 261120, mean_episode_return = 0.2776, mean_episode_step = 65.348, total_loss = 219.19, entropy_loss = -8.7339, pg_loss = 134.68, baseline_loss = 93.237, learner_queue_size = 32, _tick = 101, _time = 1.7373e+09)
[2025-01-19 23:10:29,552][root][INFO] - Step 263680 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 853.0, step = 263680, mean_episode_return = 0.40554, mean_episode_step = 72.467, total_loss = 165.51, entropy_loss = -8.7423, pg_loss = 89.732, baseline_loss = 84.523, learner_queue_size = 32, _tick = 102, _time = 1.7373e+09)
[2025-01-19 23:10:34,559][root][INFO] - Step 266240 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 858.0, step = 266240, mean_episode_return = 0.36437, mean_episode_step = 63.588, total_loss = -107.82, entropy_loss = -8.7399, pg_loss = -181.06, baseline_loss = 81.985, learner_queue_size = 32, _tick = 103, _time = 1.7373e+09)
[2025-01-19 23:10:39,564][root][INFO] - Step 266240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 863.0, step = 266240, mean_episode_return = 0.36437, mean_episode_step = 63.588, total_loss = -107.82, entropy_loss = -8.7399, pg_loss = -181.06, baseline_loss = 81.985, learner_queue_size = 32, _tick = 103, _time = 1.7373e+09)
[2025-01-19 23:10:44,570][root][INFO] - Step 268800 @ 511.4 SPS. Inference batcher size: 23. Learner queue size: 32. Other stats: (train_seconds = 868.0, step = 268800, mean_episode_return = 0.20308, mean_episode_step = 64.141, total_loss = -177.39, entropy_loss = -8.5595, pg_loss = -222.85, baseline_loss = 54.025, learner_queue_size = 32, _tick = 104, _time = 1.7373e+09)
[2025-01-19 23:10:49,576][root][INFO] - Step 271360 @ 511.3 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 873.0, step = 271360, mean_episode_return = 0.1862, mean_episode_step = 55.731, total_loss = -77.605, entropy_loss = -8.5174, pg_loss = -127.18, baseline_loss = 58.089, learner_queue_size = 32, _tick = 105, _time = 1.7373e+09)
[2025-01-19 23:10:54,582][root][INFO] - Step 271360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 878.0, step = 271360, mean_episode_return = 0.1862, mean_episode_step = 55.731, total_loss = -77.605, entropy_loss = -8.5174, pg_loss = -127.18, baseline_loss = 58.089, learner_queue_size = 32, _tick = 105, _time = 1.7373e+09)
[2025-01-19 23:10:59,587][root][INFO] - Step 273920 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 883.0, step = 273920, mean_episode_return = 0.19948, mean_episode_step = 55.724, total_loss = 265.14, entropy_loss = -8.4938, pg_loss = 193.98, baseline_loss = 79.646, learner_queue_size = 32, _tick = 106, _time = 1.7373e+09)
[2025-01-19 23:11:04,592][root][INFO] - Step 276480 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 888.0, step = 276480, mean_episode_return = 0.21887, mean_episode_step = 57.472, total_loss = 46.464, entropy_loss = -8.5429, pg_loss = -17.638, baseline_loss = 72.645, learner_queue_size = 32, _tick = 107, _time = 1.7373e+09)
[2025-01-19 23:11:09,598][root][INFO] - Step 276480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 893.0, step = 276480, mean_episode_return = 0.21887, mean_episode_step = 57.472, total_loss = 46.464, entropy_loss = -8.5429, pg_loss = -17.638, baseline_loss = 72.645, learner_queue_size = 32, _tick = 107, _time = 1.7373e+09)
[2025-01-19 23:11:14,602][root][INFO] - Step 279040 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 898.0, step = 279040, mean_episode_return = 0.42728, mean_episode_step = 62.426, total_loss = 768.94, entropy_loss = -8.5317, pg_loss = 670.38, baseline_loss = 107.1, learner_queue_size = 32, _tick = 108, _time = 1.7373e+09)
[2025-01-19 23:11:19,607][root][INFO] - Step 281600 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 903.0, step = 281600, mean_episode_return = 0.39368, mean_episode_step = 76.114, total_loss = 460.93, entropy_loss = -8.5379, pg_loss = 384.87, baseline_loss = 84.602, learner_queue_size = 32, _tick = 109, _time = 1.7373e+09)
[2025-01-19 23:11:24,612][root][INFO] - Step 281600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 908.0, step = 281600, mean_episode_return = 0.39368, mean_episode_step = 76.114, total_loss = 460.93, entropy_loss = -8.5379, pg_loss = 384.87, baseline_loss = 84.602, learner_queue_size = 32, _tick = 109, _time = 1.7373e+09)
[2025-01-19 23:11:29,618][root][INFO] - Step 284160 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 913.0, step = 284160, mean_episode_return = 0.18656, mean_episode_step = 63.125, total_loss = -86.976, entropy_loss = -8.5654, pg_loss = -150.66, baseline_loss = 72.253, learner_queue_size = 32, _tick = 110, _time = 1.7373e+09)
[2025-01-19 23:11:34,623][root][INFO] - Step 286720 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 918.0, step = 286720, mean_episode_return = 0.19337, mean_episode_step = 64.864, total_loss = -312.16, entropy_loss = -8.5718, pg_loss = -354.02, baseline_loss = 50.434, learner_queue_size = 32, _tick = 111, _time = 1.7373e+09)
[2025-01-19 23:11:39,629][root][INFO] - Step 286720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 923.0, step = 286720, mean_episode_return = 0.19337, mean_episode_step = 64.864, total_loss = -312.16, entropy_loss = -8.5718, pg_loss = -354.02, baseline_loss = 50.434, learner_queue_size = 32, _tick = 111, _time = 1.7373e+09)
[2025-01-19 23:11:44,634][root][INFO] - Step 289280 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 928.1, step = 289280, mean_episode_return = 0.33374, mean_episode_step = 62.363, total_loss = 898.88, entropy_loss = -8.5351, pg_loss = 795.57, baseline_loss = 111.84, learner_queue_size = 32, _tick = 112, _time = 1.7373e+09)
[2025-01-19 23:11:49,640][root][INFO] - Step 291840 @ 511.4 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 933.1, step = 291840, mean_episode_return = 0.30936, mean_episode_step = 65.739, total_loss = 663.56, entropy_loss = -8.5647, pg_loss = 510.15, baseline_loss = 161.97, learner_queue_size = 32, _tick = 113, _time = 1.7373e+09)
[2025-01-19 23:11:54,645][root][INFO] - Step 291840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 938.1, step = 291840, mean_episode_return = 0.30936, mean_episode_step = 65.739, total_loss = 663.56, entropy_loss = -8.5647, pg_loss = 510.15, baseline_loss = 161.97, learner_queue_size = 32, _tick = 113, _time = 1.7373e+09)
[2025-01-19 23:11:59,650][root][INFO] - Step 294400 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 943.1, step = 294400, mean_episode_return = 0.23129, mean_episode_step = 64.336, total_loss = 323.35, entropy_loss = -8.5715, pg_loss = 213.19, baseline_loss = 118.74, learner_queue_size = 32, _tick = 114, _time = 1.7373e+09)
[2025-01-19 23:12:04,657][root][INFO] - Step 296960 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 948.1, step = 296960, mean_episode_return = 0.3307, mean_episode_step = 76.67, total_loss = 67.401, entropy_loss = -8.5209, pg_loss = -12.228, baseline_loss = 88.15, learner_queue_size = 32, _tick = 115, _time = 1.7373e+09)
[2025-01-19 23:12:09,664][root][INFO] - Step 296960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 953.1, step = 296960, mean_episode_return = 0.3307, mean_episode_step = 76.67, total_loss = 67.401, entropy_loss = -8.5209, pg_loss = -12.228, baseline_loss = 88.15, learner_queue_size = 32, _tick = 115, _time = 1.7373e+09)
[2025-01-19 23:12:14,669][root][INFO] - Step 299520 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 958.1, step = 299520, mean_episode_return = 0.14142, mean_episode_step = 73.351, total_loss = -482.79, entropy_loss = -8.5287, pg_loss = -541.31, baseline_loss = 67.047, learner_queue_size = 32, _tick = 116, _time = 1.7373e+09)
[2025-01-19 23:12:19,675][root][INFO] - Step 302080 @ 511.4 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 963.1, step = 302080, mean_episode_return = 0.41439, mean_episode_step = 72.736, total_loss = 736.12, entropy_loss = -8.5033, pg_loss = 611.41, baseline_loss = 133.21, learner_queue_size = 32, _tick = 117, _time = 1.7373e+09)
[2025-01-19 23:12:24,680][root][INFO] - Step 302080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 968.1, step = 302080, mean_episode_return = 0.41439, mean_episode_step = 72.736, total_loss = 736.12, entropy_loss = -8.5033, pg_loss = 611.41, baseline_loss = 133.21, learner_queue_size = 32, _tick = 117, _time = 1.7373e+09)
[2025-01-19 23:12:29,685][root][INFO] - Step 304640 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 973.1, step = 304640, mean_episode_return = 0.29969, mean_episode_step = 67.187, total_loss = 131.66, entropy_loss = -8.5348, pg_loss = 35.942, baseline_loss = 104.26, learner_queue_size = 32, _tick = 118, _time = 1.7373e+09)
[2025-01-19 23:12:34,690][root][INFO] - Step 307200 @ 511.5 SPS. Inference batcher size: 22. Learner queue size: 32. Other stats: (train_seconds = 978.1, step = 307200, mean_episode_return = 0.32954, mean_episode_step = 64.541, total_loss = -119.8, entropy_loss = -8.5047, pg_loss = -216.52, baseline_loss = 105.23, learner_queue_size = 32, _tick = 119, _time = 1.7373e+09)
[2025-01-19 23:12:39,695][root][INFO] - Step 307200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 983.1, step = 307200, mean_episode_return = 0.32954, mean_episode_step = 64.541, total_loss = -119.8, entropy_loss = -8.5047, pg_loss = -216.52, baseline_loss = 105.23, learner_queue_size = 32, _tick = 119, _time = 1.7373e+09)
[2025-01-19 23:12:44,700][root][INFO] - Step 309760 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 988.1, step = 309760, mean_episode_return = 0.22493, mean_episode_step = 61.346, total_loss = -402.36, entropy_loss = -8.5101, pg_loss = -475.77, baseline_loss = 81.925, learner_queue_size = 32, _tick = 120, _time = 1.7373e+09)
[2025-01-19 23:12:49,705][root][INFO] - Step 312320 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 993.1, step = 312320, mean_episode_return = 0.44479, mean_episode_step = 70.371, total_loss = 493.96, entropy_loss = -8.5034, pg_loss = 390.1, baseline_loss = 112.36, learner_queue_size = 32, _tick = 121, _time = 1.7373e+09)
[2025-01-19 23:12:54,710][root][INFO] - Step 312320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 998.1, step = 312320, mean_episode_return = 0.44479, mean_episode_step = 70.371, total_loss = 493.96, entropy_loss = -8.5034, pg_loss = 390.1, baseline_loss = 112.36, learner_queue_size = 32, _tick = 121, _time = 1.7373e+09)
[2025-01-19 23:12:59,716][root][INFO] - Step 314880 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1003.1, step = 314880, mean_episode_return = 0.43856, mean_episode_step = 78.118, total_loss = -475.63, entropy_loss = -8.4858, pg_loss = -542.17, baseline_loss = 75.025, learner_queue_size = 32, _tick = 122, _time = 1.7373e+09)
[2025-01-19 23:13:04,722][root][INFO] - Step 317440 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1008.1, step = 317440, mean_episode_return = 0.26108, mean_episode_step = 63.81, total_loss = 20.248, entropy_loss = -8.5165, pg_loss = -59.372, baseline_loss = 88.136, learner_queue_size = 32, _tick = 123, _time = 1.7373e+09)
[2025-01-19 23:13:09,727][root][INFO] - Step 317440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1013.1, step = 317440, mean_episode_return = 0.26108, mean_episode_step = 63.81, total_loss = 20.248, entropy_loss = -8.5165, pg_loss = -59.372, baseline_loss = 88.136, learner_queue_size = 32, _tick = 123, _time = 1.7373e+09)
[2025-01-19 23:13:14,732][root][INFO] - Step 320000 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1018.2, step = 320000, mean_episode_return = 0.10885, mean_episode_step = 74.498, total_loss = -125.3, entropy_loss = -8.4622, pg_loss = -187.55, baseline_loss = 70.708, learner_queue_size = 32, _tick = 124, _time = 1.7373e+09)
[2025-01-19 23:13:19,737][root][INFO] - Step 322560 @ 511.5 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1023.2, step = 322560, mean_episode_return = 0.30249, mean_episode_step = 60.682, total_loss = 309.08, entropy_loss = -8.4803, pg_loss = 204.86, baseline_loss = 112.7, learner_queue_size = 32, _tick = 125, _time = 1.7373e+09)
[2025-01-19 23:13:24,742][root][INFO] - Step 322560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1028.2, step = 322560, mean_episode_return = 0.30249, mean_episode_step = 60.682, total_loss = 309.08, entropy_loss = -8.4803, pg_loss = 204.86, baseline_loss = 112.7, learner_queue_size = 32, _tick = 125, _time = 1.7373e+09)
[2025-01-19 23:13:29,747][root][INFO] - Step 325120 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1033.2, step = 325120, mean_episode_return = 0.24996, mean_episode_step = 71.946, total_loss = -563.75, entropy_loss = -8.5276, pg_loss = -622.75, baseline_loss = 67.534, learner_queue_size = 32, _tick = 126, _time = 1.7373e+09)
[2025-01-19 23:13:34,752][root][INFO] - Step 327680 @ 511.5 SPS. Inference batcher size: 2. Learner queue size: 32. Other stats: (train_seconds = 1038.2, step = 327680, mean_episode_return = 0.40349, mean_episode_step = 75.057, total_loss = 9.9097, entropy_loss = -8.435, pg_loss = -43.735, baseline_loss = 62.079, learner_queue_size = 32, _tick = 127, _time = 1.7373e+09)
[2025-01-19 23:13:39,757][root][INFO] - Step 327680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1043.2, step = 327680, mean_episode_return = 0.40349, mean_episode_step = 75.057, total_loss = 9.9097, entropy_loss = -8.435, pg_loss = -43.735, baseline_loss = 62.079, learner_queue_size = 32, _tick = 127, _time = 1.7373e+09)
[2025-01-19 23:13:44,762][root][INFO] - Step 330240 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1048.2, step = 330240, mean_episode_return = 0.30081, mean_episode_step = 80.806, total_loss = 15.669, entropy_loss = -8.3134, pg_loss = -22.697, baseline_loss = 46.68, learner_queue_size = 32, _tick = 128, _time = 1.7373e+09)
[2025-01-19 23:13:49,767][root][INFO] - Step 330240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1053.2, step = 330240, mean_episode_return = 0.30081, mean_episode_step = 80.806, total_loss = 15.669, entropy_loss = -8.3134, pg_loss = -22.697, baseline_loss = 46.68, learner_queue_size = 32, _tick = 128, _time = 1.7373e+09)
[2025-01-19 23:13:54,772][root][INFO] - Step 332800 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1058.2, step = 332800, mean_episode_return = 0.24636, mean_episode_step = 76.308, total_loss = -205.5, entropy_loss = -8.3586, pg_loss = -245.78, baseline_loss = 48.641, learner_queue_size = 32, _tick = 129, _time = 1.7373e+09)
[2025-01-19 23:13:59,779][root][INFO] - Step 335360 @ 511.3 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1063.2, step = 335360, mean_episode_return = 0.14371, mean_episode_step = 62.137, total_loss = -195.32, entropy_loss = -8.3361, pg_loss = -230.09, baseline_loss = 43.104, learner_queue_size = 32, _tick = 130, _time = 1.7373e+09)
[2025-01-19 23:14:04,784][root][INFO] - Step 335360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1068.2, step = 335360, mean_episode_return = 0.14371, mean_episode_step = 62.137, total_loss = -195.32, entropy_loss = -8.3361, pg_loss = -230.09, baseline_loss = 43.104, learner_queue_size = 32, _tick = 130, _time = 1.7373e+09)
[2025-01-19 23:14:09,789][root][INFO] - Step 337920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1073.2, step = 337920, mean_episode_return = 0.35042, mean_episode_step = 76.254, total_loss = 531.62, entropy_loss = -8.288, pg_loss = 459.68, baseline_loss = 80.219, learner_queue_size = 32, _tick = 131, _time = 1.7373e+09)
[2025-01-19 23:14:14,796][root][INFO] - Step 340480 @ 511.3 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1078.2, step = 340480, mean_episode_return = 0.42583, mean_episode_step = 66.94, total_loss = 51.081, entropy_loss = -8.3559, pg_loss = 0.039246, baseline_loss = 59.397, learner_queue_size = 32, _tick = 132, _time = 1.7373e+09)
[2025-01-19 23:14:19,801][root][INFO] - Step 340480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1083.2, step = 340480, mean_episode_return = 0.42583, mean_episode_step = 66.94, total_loss = 51.081, entropy_loss = -8.3559, pg_loss = 0.039246, baseline_loss = 59.397, learner_queue_size = 32, _tick = 132, _time = 1.7373e+09)
[2025-01-19 23:14:24,806][root][INFO] - Step 343040 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1088.2, step = 343040, mean_episode_return = 0.37626, mean_episode_step = 62.679, total_loss = 225.32, entropy_loss = -8.3726, pg_loss = 142.73, baseline_loss = 90.959, learner_queue_size = 32, _tick = 133, _time = 1.7373e+09)
[2025-01-19 23:14:29,811][root][INFO] - Step 345600 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1093.2, step = 345600, mean_episode_return = 0.29539, mean_episode_step = 60.616, total_loss = 543.09, entropy_loss = -8.4279, pg_loss = 438.4, baseline_loss = 113.12, learner_queue_size = 32, _tick = 134, _time = 1.7373e+09)
[2025-01-19 23:14:34,816][root][INFO] - Step 345600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1098.2, step = 345600, mean_episode_return = 0.29539, mean_episode_step = 60.616, total_loss = 543.09, entropy_loss = -8.4279, pg_loss = 438.4, baseline_loss = 113.12, learner_queue_size = 32, _tick = 134, _time = 1.7373e+09)
[2025-01-19 23:14:39,822][root][INFO] - Step 348160 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1103.2, step = 348160, mean_episode_return = 0.36055, mean_episode_step = 79.596, total_loss = 313.05, entropy_loss = -8.4195, pg_loss = 218.38, baseline_loss = 103.09, learner_queue_size = 32, _tick = 135, _time = 1.7373e+09)
[2025-01-19 23:14:44,827][root][INFO] - Step 350720 @ 511.4 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1108.2, step = 350720, mean_episode_return = 0.24148, mean_episode_step = 71.564, total_loss = -13.258, entropy_loss = -8.3897, pg_loss = -74.835, baseline_loss = 69.967, learner_queue_size = 32, _tick = 136, _time = 1.7373e+09)
[2025-01-19 23:14:49,832][root][INFO] - Step 350720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1113.3, step = 350720, mean_episode_return = 0.24148, mean_episode_step = 71.564, total_loss = -13.258, entropy_loss = -8.3897, pg_loss = -74.835, baseline_loss = 69.967, learner_queue_size = 32, _tick = 136, _time = 1.7373e+09)
[2025-01-19 23:14:54,837][root][INFO] - Step 353280 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1118.3, step = 353280, mean_episode_return = 0.29498, mean_episode_step = 69.591, total_loss = -150.52, entropy_loss = -8.3622, pg_loss = -228.34, baseline_loss = 86.184, learner_queue_size = 32, _tick = 137, _time = 1.7373e+09)
[2025-01-19 23:14:59,843][root][INFO] - Step 355840 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1123.3, step = 355840, mean_episode_return = 0.39405, mean_episode_step = 75.575, total_loss = -274.46, entropy_loss = -8.315, pg_loss = -329.11, baseline_loss = 62.965, learner_queue_size = 32, _tick = 138, _time = 1.7373e+09)
[2025-01-19 23:15:04,848][root][INFO] - Step 355840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1128.3, step = 355840, mean_episode_return = 0.39405, mean_episode_step = 75.575, total_loss = -274.46, entropy_loss = -8.315, pg_loss = -329.11, baseline_loss = 62.965, learner_queue_size = 32, _tick = 138, _time = 1.7373e+09)
[2025-01-19 23:15:09,853][root][INFO] - Step 358400 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1133.3, step = 358400, mean_episode_return = 0.24453, mean_episode_step = 62.779, total_loss = 20.827, entropy_loss = -8.3033, pg_loss = -39.59, baseline_loss = 68.72, learner_queue_size = 32, _tick = 139, _time = 1.7373e+09)
[2025-01-19 23:15:14,858][root][INFO] - Step 360960 @ 511.5 SPS. Inference batcher size: 16. Learner queue size: 32. Other stats: (train_seconds = 1138.3, step = 360960, mean_episode_return = 0.42221, mean_episode_step = 72.396, total_loss = 27.232, entropy_loss = -8.2787, pg_loss = -25.979, baseline_loss = 61.489, learner_queue_size = 32, _tick = 140, _time = 1.7373e+09)
[2025-01-19 23:15:19,864][root][INFO] - Step 360960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1143.3, step = 360960, mean_episode_return = 0.42221, mean_episode_step = 72.396, total_loss = 27.232, entropy_loss = -8.2787, pg_loss = -25.979, baseline_loss = 61.489, learner_queue_size = 32, _tick = 140, _time = 1.7373e+09)
[2025-01-19 23:15:24,869][root][INFO] - Step 363520 @ 511.4 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1148.3, step = 363520, mean_episode_return = 0.28745, mean_episode_step = 67.514, total_loss = 388.11, entropy_loss = -8.2767, pg_loss = 285.24, baseline_loss = 111.15, learner_queue_size = 32, _tick = 141, _time = 1.7373e+09)
[2025-01-19 23:15:29,874][root][INFO] - Step 366080 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1153.3, step = 366080, mean_episode_return = 0.13517, mean_episode_step = 60.668, total_loss = 96.022, entropy_loss = -8.3248, pg_loss = 6.3733, baseline_loss = 97.974, learner_queue_size = 32, _tick = 142, _time = 1.7373e+09)
[2025-01-19 23:15:34,880][root][INFO] - Step 366080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1158.3, step = 366080, mean_episode_return = 0.13517, mean_episode_step = 60.668, total_loss = 96.022, entropy_loss = -8.3248, pg_loss = 6.3733, baseline_loss = 97.974, learner_queue_size = 32, _tick = 142, _time = 1.7373e+09)
[2025-01-19 23:15:39,885][root][INFO] - Step 368640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1163.3, step = 368640, mean_episode_return = 0.20513, mean_episode_step = 68.806, total_loss = 135.57, entropy_loss = -8.2053, pg_loss = 63.271, baseline_loss = 80.507, learner_queue_size = 32, _tick = 143, _time = 1.7373e+09)
[2025-01-19 23:15:44,890][root][INFO] - Step 371200 @ 511.4 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1168.3, step = 371200, mean_episode_return = 0.327, mean_episode_step = 69.782, total_loss = 3.9367, entropy_loss = -8.2377, pg_loss = -60.061, baseline_loss = 72.236, learner_queue_size = 32, _tick = 144, _time = 1.7373e+09)
[2025-01-19 23:15:49,892][root][INFO] - Step 371200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1173.3, step = 371200, mean_episode_return = 0.327, mean_episode_step = 69.782, total_loss = 3.9367, entropy_loss = -8.2377, pg_loss = -60.061, baseline_loss = 72.236, learner_queue_size = 32, _tick = 144, _time = 1.7373e+09)
[2025-01-19 23:15:54,897][root][INFO] - Step 373760 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1178.3, step = 373760, mean_episode_return = 0.37513, mean_episode_step = 74.189, total_loss = -55.052, entropy_loss = -8.227, pg_loss = -127.71, baseline_loss = 80.881, learner_queue_size = 32, _tick = 145, _time = 1.7373e+09)
[2025-01-19 23:15:59,902][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint_0.75.tar
[2025-01-19 23:15:59,941][root][INFO] - Step 376320 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1183.3, step = 376320, mean_episode_return = 0.31547, mean_episode_step = 75.963, total_loss = 68.853, entropy_loss = -8.0943, pg_loss = 27.488, baseline_loss = 49.459, learner_queue_size = 32, _tick = 146, _time = 1.7373e+09)
[2025-01-19 23:16:04,946][root][INFO] - Step 376320 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1188.4, step = 376320, mean_episode_return = 0.31547, mean_episode_step = 75.963, total_loss = 68.853, entropy_loss = -8.0943, pg_loss = 27.488, baseline_loss = 49.459, learner_queue_size = 32, _tick = 146, _time = 1.7373e+09)
[2025-01-19 23:16:09,951][root][INFO] - Step 378880 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1193.4, step = 378880, mean_episode_return = 0.30547, mean_episode_step = 73.939, total_loss = -106.07, entropy_loss = -8.1067, pg_loss = -157.41, baseline_loss = 59.441, learner_queue_size = 32, _tick = 147, _time = 1.7373e+09)
[2025-01-19 23:16:14,956][root][INFO] - Step 381440 @ 511.5 SPS. Inference batcher size: 10. Learner queue size: 32. Other stats: (train_seconds = 1198.4, step = 381440, mean_episode_return = 0.18526, mean_episode_step = 70.265, total_loss = -306.05, entropy_loss = -8.1803, pg_loss = -355.99, baseline_loss = 58.121, learner_queue_size = 32, _tick = 148, _time = 1.7373e+09)
[2025-01-19 23:16:19,962][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-19 23:16:20,587][root][INFO] - Step 381440 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1203.4, step = 381440, mean_episode_return = 0.18526, mean_episode_step = 70.265, total_loss = -306.05, entropy_loss = -8.1803, pg_loss = -355.99, baseline_loss = 58.121, learner_queue_size = 32, _tick = 148, _time = 1.7373e+09)
[2025-01-19 23:16:25,592][root][INFO] - Step 384000 @ 454.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1209.0, step = 384000, mean_episode_return = 0.39943, mean_episode_step = 78.562, total_loss = 235.36, entropy_loss = -8.0791, pg_loss = 188.66, baseline_loss = 54.777, learner_queue_size = 32, _tick = 149, _time = 1.7373e+09)
[2025-01-19 23:16:30,597][root][INFO] - Step 386560 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1214.0, step = 386560, mean_episode_return = 0.34679, mean_episode_step = 71.17, total_loss = 283.0, entropy_loss = -8.1659, pg_loss = 207.37, baseline_loss = 83.795, learner_queue_size = 32, _tick = 150, _time = 1.7373e+09)
[2025-01-19 23:16:35,602][root][INFO] - Step 386560 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1219.0, step = 386560, mean_episode_return = 0.34679, mean_episode_step = 71.17, total_loss = 283.0, entropy_loss = -8.1659, pg_loss = 207.37, baseline_loss = 83.795, learner_queue_size = 32, _tick = 150, _time = 1.7373e+09)
[2025-01-19 23:16:40,607][root][INFO] - Step 389120 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1224.0, step = 389120, mean_episode_return = 0.48539, mean_episode_step = 76.262, total_loss = 409.3, entropy_loss = -8.1964, pg_loss = 329.64, baseline_loss = 87.86, learner_queue_size = 32, _tick = 151, _time = 1.7373e+09)
[2025-01-19 23:16:45,612][root][INFO] - Step 391680 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1229.0, step = 391680, mean_episode_return = 0.42773, mean_episode_step = 59.432, total_loss = 83.493, entropy_loss = -8.2539, pg_loss = -9.2049, baseline_loss = 100.95, learner_queue_size = 32, _tick = 152, _time = 1.7373e+09)
[2025-01-19 23:16:50,617][root][INFO] - Step 391680 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1234.0, step = 391680, mean_episode_return = 0.42773, mean_episode_step = 59.432, total_loss = 83.493, entropy_loss = -8.2539, pg_loss = -9.2049, baseline_loss = 100.95, learner_queue_size = 32, _tick = 152, _time = 1.7373e+09)
[2025-01-19 23:16:55,622][root][INFO] - Step 394240 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1239.0, step = 394240, mean_episode_return = 0.31242, mean_episode_step = 62.601, total_loss = 55.412, entropy_loss = -8.1898, pg_loss = -20.192, baseline_loss = 83.793, learner_queue_size = 32, _tick = 153, _time = 1.7373e+09)
[2025-01-19 23:17:00,628][root][INFO] - Step 396800 @ 511.4 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1244.0, step = 396800, mean_episode_return = 0.28223, mean_episode_step = 71.123, total_loss = -167.94, entropy_loss = -8.1303, pg_loss = -220.49, baseline_loss = 60.681, learner_queue_size = 32, _tick = 154, _time = 1.7373e+09)
[2025-01-19 23:17:05,633][root][INFO] - Step 396800 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1249.1, step = 396800, mean_episode_return = 0.28223, mean_episode_step = 71.123, total_loss = -167.94, entropy_loss = -8.1303, pg_loss = -220.49, baseline_loss = 60.681, learner_queue_size = 32, _tick = 154, _time = 1.7373e+09)
[2025-01-19 23:17:10,638][root][INFO] - Step 399360 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1254.1, step = 399360, mean_episode_return = 0.40908, mean_episode_step = 68.092, total_loss = 438.49, entropy_loss = -8.1052, pg_loss = 357.57, baseline_loss = 89.024, learner_queue_size = 32, _tick = 155, _time = 1.7373e+09)
[2025-01-19 23:17:15,643][root][INFO] - Step 401920 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1259.1, step = 401920, mean_episode_return = 0.1929, mean_episode_step = 69.295, total_loss = -560.64, entropy_loss = -8.1659, pg_loss = -598.52, baseline_loss = 46.042, learner_queue_size = 32, _tick = 156, _time = 1.7373e+09)
[2025-01-19 23:17:20,648][root][INFO] - Step 401920 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1264.1, step = 401920, mean_episode_return = 0.1929, mean_episode_step = 69.295, total_loss = -560.64, entropy_loss = -8.1659, pg_loss = -598.52, baseline_loss = 46.042, learner_queue_size = 32, _tick = 156, _time = 1.7373e+09)
[2025-01-19 23:17:25,652][root][INFO] - Step 404480 @ 511.7 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1269.1, step = 404480, mean_episode_return = 0.30367, mean_episode_step = 77.394, total_loss = 60.748, entropy_loss = -8.1303, pg_loss = -6.4288, baseline_loss = 75.308, learner_queue_size = 32, _tick = 157, _time = 1.7373e+09)
[2025-01-19 23:17:30,657][root][INFO] - Step 407040 @ 511.4 SPS. Inference batcher size: 5. Learner queue size: 32. Other stats: (train_seconds = 1274.1, step = 407040, mean_episode_return = 0.23746, mean_episode_step = 70.284, total_loss = -168.66, entropy_loss = -8.0907, pg_loss = -209.19, baseline_loss = 48.616, learner_queue_size = 32, _tick = 158, _time = 1.7373e+09)
[2025-01-19 23:17:35,662][root][INFO] - Step 407040 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1279.1, step = 407040, mean_episode_return = 0.23746, mean_episode_step = 70.284, total_loss = -168.66, entropy_loss = -8.0907, pg_loss = -209.19, baseline_loss = 48.616, learner_queue_size = 32, _tick = 158, _time = 1.7373e+09)
[2025-01-19 23:17:40,667][root][INFO] - Step 409600 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1284.1, step = 409600, mean_episode_return = 0.37106, mean_episode_step = 67.986, total_loss = 530.26, entropy_loss = -8.0638, pg_loss = 447.42, baseline_loss = 90.898, learner_queue_size = 32, _tick = 159, _time = 1.7373e+09)
[2025-01-19 23:17:45,672][root][INFO] - Step 412160 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1289.1, step = 412160, mean_episode_return = 0.20279, mean_episode_step = 75.352, total_loss = -198.25, entropy_loss = -8.0566, pg_loss = -232.29, baseline_loss = 42.097, learner_queue_size = 32, _tick = 160, _time = 1.7373e+09)
[2025-01-19 23:17:50,677][root][INFO] - Step 412160 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1294.1, step = 412160, mean_episode_return = 0.20279, mean_episode_step = 75.352, total_loss = -198.25, entropy_loss = -8.0566, pg_loss = -232.29, baseline_loss = 42.097, learner_queue_size = 32, _tick = 160, _time = 1.7373e+09)
[2025-01-19 23:17:55,684][root][INFO] - Step 414720 @ 511.3 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1299.1, step = 414720, mean_episode_return = 0.32026, mean_episode_step = 64.059, total_loss = 506.79, entropy_loss = -8.0769, pg_loss = 416.92, baseline_loss = 97.947, learner_queue_size = 32, _tick = 161, _time = 1.7373e+09)
[2025-01-19 23:18:00,689][root][INFO] - Step 417280 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1304.1, step = 417280, mean_episode_return = 0.21672, mean_episode_step = 52.472, total_loss = 398.05, entropy_loss = -8.1372, pg_loss = 312.56, baseline_loss = 93.628, learner_queue_size = 32, _tick = 162, _time = 1.7373e+09)
[2025-01-19 23:18:05,694][root][INFO] - Step 417280 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1309.1, step = 417280, mean_episode_return = 0.21672, mean_episode_step = 52.472, total_loss = 398.05, entropy_loss = -8.1372, pg_loss = 312.56, baseline_loss = 93.628, learner_queue_size = 32, _tick = 162, _time = 1.7373e+09)
[2025-01-19 23:18:10,699][root][INFO] - Step 419840 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1314.1, step = 419840, mean_episode_return = 0.34354, mean_episode_step = 85.717, total_loss = 169.42, entropy_loss = -8.0911, pg_loss = 105.6, baseline_loss = 71.915, learner_queue_size = 32, _tick = 163, _time = 1.7373e+09)
[2025-01-19 23:18:15,704][root][INFO] - Step 422400 @ 511.5 SPS. Inference batcher size: 21. Learner queue size: 32. Other stats: (train_seconds = 1319.1, step = 422400, mean_episode_return = 0.28602, mean_episode_step = 59.123, total_loss = 176.07, entropy_loss = -8.1686, pg_loss = 102.17, baseline_loss = 82.073, learner_queue_size = 32, _tick = 164, _time = 1.7373e+09)
[2025-01-19 23:18:20,709][root][INFO] - Step 422400 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1324.1, step = 422400, mean_episode_return = 0.28602, mean_episode_step = 59.123, total_loss = 176.07, entropy_loss = -8.1686, pg_loss = 102.17, baseline_loss = 82.073, learner_queue_size = 32, _tick = 164, _time = 1.7373e+09)
[2025-01-19 23:18:25,714][root][INFO] - Step 424960 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1329.1, step = 424960, mean_episode_return = 0.34334, mean_episode_step = 50.434, total_loss = 463.79, entropy_loss = -8.2204, pg_loss = 361.58, baseline_loss = 110.43, learner_queue_size = 32, _tick = 165, _time = 1.7373e+09)
[2025-01-19 23:18:30,719][root][INFO] - Step 427520 @ 511.5 SPS. Inference batcher size: 12. Learner queue size: 32. Other stats: (train_seconds = 1334.1, step = 427520, mean_episode_return = 0.38176, mean_episode_step = 70.423, total_loss = 79.725, entropy_loss = -8.1688, pg_loss = 12.97, baseline_loss = 74.924, learner_queue_size = 32, _tick = 166, _time = 1.7373e+09)
[2025-01-19 23:18:35,724][root][INFO] - Step 427520 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1339.1, step = 427520, mean_episode_return = 0.38176, mean_episode_step = 70.423, total_loss = 79.725, entropy_loss = -8.1688, pg_loss = 12.97, baseline_loss = 74.924, learner_queue_size = 32, _tick = 166, _time = 1.7373e+09)
[2025-01-19 23:18:40,729][root][INFO] - Step 430080 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1344.1, step = 430080, mean_episode_return = 0.18374, mean_episode_step = 67.306, total_loss = -608.92, entropy_loss = -8.198, pg_loss = -665.32, baseline_loss = 64.599, learner_queue_size = 32, _tick = 167, _time = 1.7373e+09)
[2025-01-19 23:18:45,734][root][INFO] - Step 432640 @ 511.5 SPS. Inference batcher size: 8. Learner queue size: 32. Other stats: (train_seconds = 1349.2, step = 432640, mean_episode_return = 0.41603, mean_episode_step = 74.187, total_loss = 449.46, entropy_loss = -8.1467, pg_loss = 354.93, baseline_loss = 102.67, learner_queue_size = 32, _tick = 168, _time = 1.7373e+09)
[2025-01-19 23:18:50,739][root][INFO] - Step 432640 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1354.2, step = 432640, mean_episode_return = 0.41603, mean_episode_step = 74.187, total_loss = 449.46, entropy_loss = -8.1467, pg_loss = 354.93, baseline_loss = 102.67, learner_queue_size = 32, _tick = 168, _time = 1.7373e+09)
[2025-01-19 23:18:55,744][root][INFO] - Step 435200 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1359.2, step = 435200, mean_episode_return = 0.23496, mean_episode_step = 63.234, total_loss = -429.65, entropy_loss = -8.2335, pg_loss = -484.19, baseline_loss = 62.773, learner_queue_size = 32, _tick = 169, _time = 1.7373e+09)
[2025-01-19 23:19:00,751][root][INFO] - Step 437760 @ 511.3 SPS. Inference batcher size: 3. Learner queue size: 32. Other stats: (train_seconds = 1364.2, step = 437760, mean_episode_return = 0.21018, mean_episode_step = 69.481, total_loss = -100.25, entropy_loss = -8.1717, pg_loss = -159.53, baseline_loss = 67.457, learner_queue_size = 32, _tick = 170, _time = 1.7373e+09)
[2025-01-19 23:19:05,756][root][INFO] - Step 437760 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1369.2, step = 437760, mean_episode_return = 0.21018, mean_episode_step = 69.481, total_loss = -100.25, entropy_loss = -8.1717, pg_loss = -159.53, baseline_loss = 67.457, learner_queue_size = 32, _tick = 170, _time = 1.7373e+09)
[2025-01-19 23:19:10,761][root][INFO] - Step 440320 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1374.2, step = 440320, mean_episode_return = 0.2772, mean_episode_step = 65.438, total_loss = 289.2, entropy_loss = -8.1678, pg_loss = 197.47, baseline_loss = 99.901, learner_queue_size = 32, _tick = 171, _time = 1.7373e+09)
[2025-01-19 23:19:15,766][root][INFO] - Step 442880 @ 511.5 SPS. Inference batcher size: 18. Learner queue size: 32. Other stats: (train_seconds = 1379.2, step = 442880, mean_episode_return = 0.17584, mean_episode_step = 61.022, total_loss = -191.98, entropy_loss = -8.1914, pg_loss = -276.75, baseline_loss = 92.962, learner_queue_size = 32, _tick = 172, _time = 1.7373e+09)
[2025-01-19 23:19:20,771][root][INFO] - Step 442880 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1384.2, step = 442880, mean_episode_return = 0.17584, mean_episode_step = 61.022, total_loss = -191.98, entropy_loss = -8.1914, pg_loss = -276.75, baseline_loss = 92.962, learner_queue_size = 32, _tick = 172, _time = 1.7373e+09)
[2025-01-19 23:19:25,776][root][INFO] - Step 445440 @ 511.5 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1389.2, step = 445440, mean_episode_return = 0.34211, mean_episode_step = 75.77, total_loss = 213.59, entropy_loss = -8.1267, pg_loss = 150.15, baseline_loss = 71.561, learner_queue_size = 32, _tick = 173, _time = 1.7373e+09)
[2025-01-19 23:19:30,781][root][INFO] - Step 448000 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1394.2, step = 448000, mean_episode_return = 0.47431, mean_episode_step = 69.81, total_loss = 205.56, entropy_loss = -8.1648, pg_loss = 107.09, baseline_loss = 106.64, learner_queue_size = 32, _tick = 174, _time = 1.7373e+09)
[2025-01-19 23:19:35,785][root][INFO] - Step 448000 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1399.2, step = 448000, mean_episode_return = 0.47431, mean_episode_step = 69.81, total_loss = 205.56, entropy_loss = -8.1648, pg_loss = 107.09, baseline_loss = 106.64, learner_queue_size = 32, _tick = 174, _time = 1.7373e+09)
[2025-01-19 23:19:40,790][root][INFO] - Step 450560 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1404.2, step = 450560, mean_episode_return = 0.39231, mean_episode_step = 77.839, total_loss = 248.92, entropy_loss = -8.1513, pg_loss = 150.34, baseline_loss = 106.73, learner_queue_size = 32, _tick = 175, _time = 1.7373e+09)
[2025-01-19 23:19:45,795][root][INFO] - Step 453120 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1409.2, step = 453120, mean_episode_return = 0.16756, mean_episode_step = 66.911, total_loss = 53.541, entropy_loss = -8.1674, pg_loss = -35.795, baseline_loss = 97.503, learner_queue_size = 32, _tick = 176, _time = 1.7373e+09)
[2025-01-19 23:19:50,800][root][INFO] - Step 453120 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1414.2, step = 453120, mean_episode_return = 0.16756, mean_episode_step = 66.911, total_loss = 53.541, entropy_loss = -8.1674, pg_loss = -35.795, baseline_loss = 97.503, learner_queue_size = 32, _tick = 176, _time = 1.7373e+09)
[2025-01-19 23:19:55,806][root][INFO] - Step 455680 @ 511.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1419.2, step = 455680, mean_episode_return = 0.45347, mean_episode_step = 63.231, total_loss = 814.37, entropy_loss = -8.161, pg_loss = 673.87, baseline_loss = 148.67, learner_queue_size = 32, _tick = 177, _time = 1.7373e+09)
[2025-01-19 23:20:00,812][root][INFO] - Step 458240 @ 511.4 SPS. Inference batcher size: 4. Learner queue size: 32. Other stats: (train_seconds = 1424.2, step = 458240, mean_episode_return = 0.44881, mean_episode_step = 66.997, total_loss = 166.7, entropy_loss = -8.196, pg_loss = 67.501, baseline_loss = 107.4, learner_queue_size = 32, _tick = 178, _time = 1.7373e+09)
[2025-01-19 23:20:05,817][root][INFO] - Step 458240 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1429.2, step = 458240, mean_episode_return = 0.44881, mean_episode_step = 66.997, total_loss = 166.7, entropy_loss = -8.196, pg_loss = 67.501, baseline_loss = 107.4, learner_queue_size = 32, _tick = 178, _time = 1.7373e+09)
[2025-01-19 23:20:10,822][root][INFO] - Step 460800 @ 511.5 SPS. Inference batcher size: 17. Learner queue size: 32. Other stats: (train_seconds = 1434.2, step = 460800, mean_episode_return = 0.43053, mean_episode_step = 66.954, total_loss = 611.07, entropy_loss = -8.1946, pg_loss = 501.15, baseline_loss = 118.12, learner_queue_size = 32, _tick = 179, _time = 1.7373e+09)
[2025-01-19 23:20:15,827][root][INFO] - Step 463360 @ 511.5 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1439.2, step = 463360, mean_episode_return = 0.39517, mean_episode_step = 60.409, total_loss = 293.61, entropy_loss = -8.2445, pg_loss = 181.57, baseline_loss = 120.29, learner_queue_size = 32, _tick = 180, _time = 1.7373e+09)
[2025-01-19 23:20:20,832][root][INFO] - Step 463360 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1444.3, step = 463360, mean_episode_return = 0.39517, mean_episode_step = 60.409, total_loss = 293.61, entropy_loss = -8.2445, pg_loss = 181.57, baseline_loss = 120.29, learner_queue_size = 32, _tick = 180, _time = 1.7373e+09)
[2025-01-19 23:20:25,837][root][INFO] - Step 465920 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1449.3, step = 465920, mean_episode_return = 0.26676, mean_episode_step = 74.342, total_loss = -381.51, entropy_loss = -8.1651, pg_loss = -438.06, baseline_loss = 64.716, learner_queue_size = 32, _tick = 181, _time = 1.7373e+09)
[2025-01-19 23:20:30,843][root][INFO] - Step 468480 @ 511.4 SPS. Inference batcher size: 11. Learner queue size: 32. Other stats: (train_seconds = 1454.3, step = 468480, mean_episode_return = 0.25109, mean_episode_step = 42.68, total_loss = -619.87, entropy_loss = -8.2944, pg_loss = -697.27, baseline_loss = 85.687, learner_queue_size = 32, _tick = 182, _time = 1.7373e+09)
[2025-01-19 23:20:35,848][root][INFO] - Step 468480 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1459.3, step = 468480, mean_episode_return = 0.25109, mean_episode_step = 42.68, total_loss = -619.87, entropy_loss = -8.2944, pg_loss = -697.27, baseline_loss = 85.687, learner_queue_size = 32, _tick = 182, _time = 1.7373e+09)
[2025-01-19 23:20:40,853][root][INFO] - Step 471040 @ 511.5 SPS. Inference batcher size: 1. Learner queue size: 32. Other stats: (train_seconds = 1464.3, step = 471040, mean_episode_return = 0.43739, mean_episode_step = 65.784, total_loss = 18.007, entropy_loss = -8.1675, pg_loss = -67.785, baseline_loss = 93.96, learner_queue_size = 32, _tick = 183, _time = 1.7373e+09)
[2025-01-19 23:20:45,858][root][INFO] - Step 473600 @ 511.5 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1469.3, step = 473600, mean_episode_return = 0.75046, mean_episode_step = 76.167, total_loss = 1056.6, entropy_loss = -8.1051, pg_loss = 934.07, baseline_loss = 130.67, learner_queue_size = 32, _tick = 184, _time = 1.7373e+09)
[2025-01-19 23:20:50,861][root][INFO] - Step 473600 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1474.3, step = 473600, mean_episode_return = 0.75046, mean_episode_step = 76.167, total_loss = 1056.6, entropy_loss = -8.1051, pg_loss = 934.07, baseline_loss = 130.67, learner_queue_size = 32, _tick = 184, _time = 1.7373e+09)
[2025-01-19 23:20:55,866][root][INFO] - Step 476160 @ 511.5 SPS. Inference batcher size: 14. Learner queue size: 32. Other stats: (train_seconds = 1479.3, step = 476160, mean_episode_return = 0.32503, mean_episode_step = 75.571, total_loss = 14.167, entropy_loss = -8.1418, pg_loss = -54.448, baseline_loss = 76.757, learner_queue_size = 32, _tick = 185, _time = 1.7373e+09)
[2025-01-19 23:21:00,871][root][INFO] - Step 478720 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1484.3, step = 478720, mean_episode_return = 0.24403, mean_episode_step = 69.194, total_loss = -215.33, entropy_loss = -8.1589, pg_loss = -276.53, baseline_loss = 69.362, learner_queue_size = 32, _tick = 186, _time = 1.7373e+09)
[2025-01-19 23:21:05,876][root][INFO] - Step 478720 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1489.3, step = 478720, mean_episode_return = 0.24403, mean_episode_step = 69.194, total_loss = -215.33, entropy_loss = -8.1589, pg_loss = -276.53, baseline_loss = 69.362, learner_queue_size = 32, _tick = 186, _time = 1.7373e+09)
[2025-01-19 23:21:10,881][root][INFO] - Step 481280 @ 511.5 SPS. Inference batcher size: 9. Learner queue size: 32. Other stats: (train_seconds = 1494.3, step = 481280, mean_episode_return = 0.52291, mean_episode_step = 76.668, total_loss = 189.01, entropy_loss = -8.1371, pg_loss = 85.187, baseline_loss = 111.96, learner_queue_size = 32, _tick = 187, _time = 1.7373e+09)
[2025-01-19 23:21:15,886][root][INFO] - Step 483840 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1499.3, step = 483840, mean_episode_return = 0.30511, mean_episode_step = 64.914, total_loss = 123.64, entropy_loss = -8.1695, pg_loss = 40.624, baseline_loss = 91.183, learner_queue_size = 32, _tick = 188, _time = 1.7373e+09)
[2025-01-19 23:21:20,891][root][INFO] - Step 483840 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1504.3, step = 483840, mean_episode_return = 0.30511, mean_episode_step = 64.914, total_loss = 123.64, entropy_loss = -8.1695, pg_loss = 40.624, baseline_loss = 91.183, learner_queue_size = 32, _tick = 188, _time = 1.7373e+09)
[2025-01-19 23:21:25,898][root][INFO] - Step 486400 @ 511.3 SPS. Inference batcher size: 15. Learner queue size: 32. Other stats: (train_seconds = 1509.3, step = 486400, mean_episode_return = 0.41196, mean_episode_step = 74.575, total_loss = 316.33, entropy_loss = -8.143, pg_loss = 218.5, baseline_loss = 105.97, learner_queue_size = 32, _tick = 189, _time = 1.7373e+09)
[2025-01-19 23:21:30,903][root][INFO] - Step 488960 @ 511.5 SPS. Inference batcher size: 7. Learner queue size: 32. Other stats: (train_seconds = 1514.3, step = 488960, mean_episode_return = 0.31188, mean_episode_step = 71.309, total_loss = 45.868, entropy_loss = -8.1591, pg_loss = -29.352, baseline_loss = 83.379, learner_queue_size = 32, _tick = 190, _time = 1.7373e+09)
[2025-01-19 23:21:35,908][root][INFO] - Step 488960 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1519.3, step = 488960, mean_episode_return = 0.31188, mean_episode_step = 71.309, total_loss = 45.868, entropy_loss = -8.1591, pg_loss = -29.352, baseline_loss = 83.379, learner_queue_size = 32, _tick = 190, _time = 1.7373e+09)
[2025-01-19 23:21:40,915][root][INFO] - Step 491520 @ 511.3 SPS. Inference batcher size: 6. Learner queue size: 32. Other stats: (train_seconds = 1524.3, step = 491520, mean_episode_return = 0.37778, mean_episode_step = 74.44, total_loss = -291.44, entropy_loss = -8.149, pg_loss = -357.76, baseline_loss = 74.472, learner_queue_size = 32, _tick = 191, _time = 1.7373e+09)
[2025-01-19 23:21:45,920][root][INFO] - Step 494080 @ 511.5 SPS. Inference batcher size: 19. Learner queue size: 32. Other stats: (train_seconds = 1529.3, step = 494080, mean_episode_return = 0.517, mean_episode_step = 87.245, total_loss = -200.55, entropy_loss = -8.1107, pg_loss = -243.64, baseline_loss = 51.207, learner_queue_size = 32, _tick = 192, _time = 1.7373e+09)
[2025-01-19 23:21:50,923][root][INFO] - Step 494080 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1534.3, step = 494080, mean_episode_return = 0.517, mean_episode_step = 87.245, total_loss = -200.55, entropy_loss = -8.1107, pg_loss = -243.64, baseline_loss = 51.207, learner_queue_size = 32, _tick = 192, _time = 1.7373e+09)
[2025-01-19 23:21:55,928][root][INFO] - Step 496640 @ 511.5 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1539.3, step = 496640, mean_episode_return = 0.23515, mean_episode_step = 71.995, total_loss = -814.55, entropy_loss = -8.1796, pg_loss = -856.19, baseline_loss = 49.825, learner_queue_size = 32, _tick = 193, _time = 1.7373e+09)
[2025-01-19 23:22:00,933][root][INFO] - Step 499200 @ 511.5 SPS. Inference batcher size: 13. Learner queue size: 32. Other stats: (train_seconds = 1544.4, step = 499200, mean_episode_return = 0.36171, mean_episode_step = 74.027, total_loss = -333.72, entropy_loss = -8.1584, pg_loss = -400.47, baseline_loss = 74.903, learner_queue_size = 32, _tick = 194, _time = 1.7373e+09)
[2025-01-19 23:22:05,939][root][INFO] - Step 499200 @ 0.0 SPS. Inference batcher size: 0. Learner queue size: 32. Other stats: (train_seconds = 1549.4, step = 499200, mean_episode_return = 0.36171, mean_episode_step = 74.027, total_loss = -333.72, entropy_loss = -8.1584, pg_loss = -400.47, baseline_loss = 74.903, learner_queue_size = 32, _tick = 194, _time = 1.7373e+09)
[2025-01-19 23:22:10,944][root][INFO] - Step 501760 @ 511.5 SPS. Inference batcher size: 20. Learner queue size: 32. Other stats: (train_seconds = 1554.4, step = 501760, mean_episode_return = 0.464, mean_episode_step = 82.736, total_loss = -202.23, entropy_loss = -8.109, pg_loss = -255.95, baseline_loss = 61.83, learner_queue_size = 32, _tick = 195, _time = 1.7373e+09)
[2025-01-19 23:22:10,945][root][INFO] - Learning finished after 501760 steps.
[2025-01-19 23:22:10,945][root][INFO] - Saving checkpoint to /opt/minihack/checkpoint.tar
[2025-01-20 09:14:17,565][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,566][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,567][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,569][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,570][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,573][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,575][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,577][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,581][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,581][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,565][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,585][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,589][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,589][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,590][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,596][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,596][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,601][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,609][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,611][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,613][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,614][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,615][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,616][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,616][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,617][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,618][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,618][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,619][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,621][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,621][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,623][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,626][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,627][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,627][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,628][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,629][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,630][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,631][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,625][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,632][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,606][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,628][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,594][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,634][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,634][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,638][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,647][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,648][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,651][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,651][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,651][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,653][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,631][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,654][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,654][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,654][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,655][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,656][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,657][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,657][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,657][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,658][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,658][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,659][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,660][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,661][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,639][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,661][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,661][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,662][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,663][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,632][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,665][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,667][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,667][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,667][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,668][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,670][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,670][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,670][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,644][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,674][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,674][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,675][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,676][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,678][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,678][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,678][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,680][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,648][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,681][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,676][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,681][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,682][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,684][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,686][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,686][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,686][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,689][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,689][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,692][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,692][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,693][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,695][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,691][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,697][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,697][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,699][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,699][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,693][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,700][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,702][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,702][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,704][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,707][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,707][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,708][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,657][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,709][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,711][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,713][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,713][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,713][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,713][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,715][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,715][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,716][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,716][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,717][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,718][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,705][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,720][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,720][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,720][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,721][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,722][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,722][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,723][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,723][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,724][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,725][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,727][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,727][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,727][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,727][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,727][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,725][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,664][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,726][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,726][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,729][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,729][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,734][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,736][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,680][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,741][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,741][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,743][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,743][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,711][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,744][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,724][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,747][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,748][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,748][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,749][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,696][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,753][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,756][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,762][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,765][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,767][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,738][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,745][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,759][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,777][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,759][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,754][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,752][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,788][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,792][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,795][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,798][nle.env.base][INFO] - Not saving any NLE data.
[2025-01-20 09:14:17,801][nle.env.base][INFO] - Not saving any NLE data.
